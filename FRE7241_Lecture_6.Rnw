% FRE7241_Lecture_6
% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size="tiny", fig.width=4, fig.height=4)
options(width=80, dev="pdf")
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[9pt]{beamer}
\DeclareMathSizes{8pt}{6pt}{6pt}{5pt}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{mathtools}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
\usepackage{listings}
\usepackage{xcolor}
\definecolor{anti_flashwhite}{rgb}{0.95, 0.95, 0.96}
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE7241 Lecture\#6]{FRE7241 Algorithmic Portfolio Management}
\subtitle{Lecture\#6, Spring 2022}

\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color.png}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{May 10, 2022}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Portfolio Optimization}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk (\protect\emph{CVaR})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Conditional Value at Risk} (\emph{CVaR}) is equal to the average of the \emph{VaR} for confidence levels less than a given confidence level $\alpha$:
      \begin{displaymath}
        \mathrm{CVaR} = \frac{1}{\alpha} \int_{0}^\alpha \mathrm{VaR}(p) \, \mathrm{d}p
      \end{displaymath}
      The \emph{Conditional Value at Risk} is also called the Expected Shortfall (\emph{ES}), or the Expected Tail Loss (\emph{ETL}).
      \vskip1ex
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data, and returns a list with a vector of loss values and a vector of corresponding densities.
      <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=4)
par(mar=c(3, 2, 1, 0), oma=c(0, 0, 0, 0))
# VTI percentage returns
returns <- rutils::diffit(log(quantmod::Cl(rutils::etfenv$VTI)))
confl <- 0.1
varisk <- quantile(returns, confl)
cvar <- mean(returns[returns < varisk])
# Or
sortv <- sort(as.numeric(returns))
varind <- round(confl*NROW(returns))
varisk <- sortv[varind]
cvar <- mean(sortv[1:varind])
# Plot histogram of VTI returns
varmin <- (-0.05)
histp <- hist(returns, col="lightgrey",
  xlab="returns", breaks=100, xlim=c(varmin, 0.01),
  ylab="frequency", freq=FALSE, main="VTI Returns Histogram")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_var.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot density of losses
densv <- density(returns, adjust=1.5)
lines(densv, lwd=3, col="blue")
# Add line for VaR
abline(v=varisk, col="red", lwd=3)
ymax <- max(densv$y)
text(x=varisk, y=2*ymax/3, labels="VaR", lwd=2, pos=2)
# Add shading for CVaR
rangev <- (densv$x < varisk) & (densv$x > varmin)
polygon(
  c(varmin, densv$x[rangev], varisk),
  c(0, densv$y[rangev], 0),
  col=rgb(1, 0, 0,0.5), border=NA)
text(x=1.5*varisk, y=ymax/7, labels="CVaR", lwd=2, pos=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CVaR} Portfolio Weights Using Linear Programming}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The weights of the minimum \emph{CVaR} portfolio can be calculated using linear programming (\emph{LP}), which is the optimization of linear objective functions subject to linear constraints,
      \begin{displaymath}
        w_{min} = \operatorname*{arg\,max}_{w} [ \, \sum_{i=1}^n w_i b_i \, ]
      \end{displaymath}
      Where $b_i$ is the negative objective vector, and $\mathbf{w}$ is the vector of returns weights, constrained by:
      \begin{align*}
        \mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1\\
        0 \leq w_i \leq 1
      \end{align*}
      The function \texttt{Rglpk\_solve\_LP()} from package \emph{Rglpk} solves linear programming problems by calling the \emph{GNU Linear Programming Kit} library.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(rutils)  # Load rutils
library(Rglpk)
# Vector of symbol names and returns
symbolv <- c("VTI", "IEF", "DBC")
nweights <- NROW(symbolv)
returns <- rutils::etfenv$returns[((NROW(returns)-6):NROW(returns)), symbolv]
retsm <- colMeans(returns)
confl <- 0.05
rmin <- 0 ; wmin <- 0 ; wmax <- 1
weightsum <- 1
ncols <- NCOL(returns) # number of assets
nrows <- NROW(returns) # number of rows
# Create objective vector
objvec <- c(numeric(ncols), rep(-1/(confl/nrows), nrows), -1)
# Specify weight constraints
constr <- rbind(
  cbind(rbind(1, retsm),
        matrix(data=0, nrow=2, ncol=(nrows+1))),
  cbind(coredata(returns), diag(nrows), 1))
rhs <- c(weightsum, rmin, rep(0, nrows))
directs <- c("==", ">=", rep(">=", nrows))
# Specify weight bounds
bounds <- list(lower=list(ind=1:ncols, val=rep(wmin, ncols)),
               upper=list(ind=1:ncols, val=rep(wmax, ncols)))
# Perform optimization
optiml <- Rglpk_solve_LP(obj=objvec, mat=constr, dir=directs, rhs=rhs, types=rep("C", NROW(objvec)), max=T, bounds=bounds)
optiml$solution
constr %*% optiml$solution
objvec %*% optiml$solution
as.numeric(optiml$solution[1:ncols])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Sharpe} Ratio Objective Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{optimize()} performs \emph{one-dimensional} optimization over a single independent variable.
      \vskip1ex
      \texttt{optimize()} searches for the minimum of the objective function with respect to its first argument, in the specified interval.
      \vspace{-1em}
        <<echo=(-(1:3)),eval=FALSE>>=
# Calculate daily percentage returns
symbolv <- c("VTI", "IEF", "DBC")
returns <- rutils::etfenv$returns[, symbolv]
# Create initial vector of portfolio weights
weightv <- rep(1, NROW(symbolv))
names(weightv) <- symbolv
# Objective equal to minus Sharpe ratio
objfun <- function(weightv, returns) {
  retsp <- returns %*% weightv
  if (sd(retsp) == 0)
    return(0)
  else
    return(-mean(retsp)/sd(retsp))
}  # end objfun
# Objective for equal weight portfolio
objfun(weightv, returns=returns)
optiml <- unlist(optimize(
  f=function(weight)
    objfun(c(1, 1, weight), returns=returns),
  interval=c(-4, 1)))
# Vectorize objective function with respect to third weight
objvec <- function(weightv) sapply(weightv,
  function(weight) objfun(c(1, 1, weight),
    returns=returns))
# Or
objvec <- Vectorize(FUN=function(weight)
    objfun(c(1, 1, weight), returns=returns),
  vectorize.args="weight")  # end Vectorize
objvec(1)
objvec(1:3)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_obj_one_dim.png}
      \vspace{-1em}
        <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=5)
par(oma=c(1, 1, 1, 1), mgp=c(2, 1, 0), mar=c(3, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# Plot objective function with respect to third weight
curve(expr=objvec,
      type="l", xlim=c(-4.0, 1.0),
      xlab=paste("weight of", names(weightv[3])),
      ylab="", lwd=2)
title(main="Objective Function", line=(-1))  # Add title
points(x=optiml[1], y=optiml[2], col="green", lwd=6)
text(x=optiml[1], y=optiml[2],
     labels="minimum objective", pos=4, cex=0.8)

### below is simplified code for plotting objective function
# Create vector of DBC weights
weightv <- seq(from=-4, to=1, by=0.1)
obj_val <- sapply(weightv,
  function(weight) objfun(c(1, 1, weight)))
plot(x=weightv, y=obj_val, t="l",
      xlab="weight of DBC", ylab="", lwd=2)
title(main="Objective Function", line=(-1))  # Add title
points(x=optiml[1], y=optiml[2], col="green", lwd=6)
text(x=optiml[1], y=optiml[2],
     labels="minimum objective", pos=4, cex=0.8)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Perspective Plot of Portfolio Objective Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{persp()} plots a 3d perspective surface plot of a function specified over a grid of argument values.
      \vskip1ex
      The function \texttt{outer()} calculates the values of a function over a grid spanned by two variables, and returns a matrix of function values.
      \vskip1ex
      The package \emph{rgl} allows creating \emph{interactive} 3d scatterplots and surface plots including perspective plots, based on the \emph{OpenGL} framework.
      <<portf_persp,echo=TRUE,eval=FALSE,fig.width=10,fig.height=10,fig.show='hide'>>=
# Vectorize function with respect to all weights
objvec <- Vectorize(
  FUN=function(w1, w2, w3) objfun(c(w1, w2, w3)),
  vectorize.args=c("w2", "w3"))  # end Vectorize
# Calculate objective on 2-d (w2 x w3) parameter grid
w2 <- seq(-3, 7, length=50)
w3 <- seq(-5, 5, length=50)
grid_object <- outer(w2, w3, FUN=objvec, w1=1)
rownames(grid_object) <- round(w2, 2)
colnames(grid_object) <- round(w3, 2)
# Perspective plot of objective function
persp(w2, w3, -grid_object,
      theta=45, phi=30, shade=0.5,
      col=rainbow(50), border="green",
      main="objective function")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_persp.png}
    \vspace{-3em}
      <<echo=TRUE,eval=FALSE,fig.width=10,fig.height=10>>=
# Interactive perspective plot of objective function
library(rgl)
rgl::persp3d(z=-grid_object, zlab="objective",
        col="green", main="objective function")
rgl::persp3d(
  x=function(w2, w3) {-objvec(w1=1, w2, w3)},
  xlim=c(-3, 7), ylim=c(-5, 5),
  col="green", axes=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Multi-dimensional Portfolio Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functional \texttt{optim()} performs \emph{multi-dimensional} optimization.
      \vskip1ex
      The argument \texttt{par} are the initial parameter values.
      \vskip1ex
      The argument \texttt{fn} is the objective function to be minimized.
      \vskip1ex
      The argument of the objective function which is to be optimized, must be a vector argument.
      \vskip1ex
      \texttt{optim()} accepts additional parameters bound to the dots \texttt{"..."} argument, and passes them to the \texttt{fn} objective function.
      \vskip1ex
      The arguments \texttt{lower} and \texttt{upper} specify the search range for the variables of the objective function \texttt{fn}.
      \vskip1ex
      \texttt{method="L-BFGS-B"} specifies the quasi-Newton optimization method.
      \vskip1ex
      \texttt{optim()} returns a list containing the location of the minimum and the objective function value.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Optimization to find weights with maximum Sharpe ratio
optiml <- optim(par=weightv,
                   fn=objfun,
                   returns=returns,
                   method="L-BFGS-B",
                   upper=c(1.1, 10, 10),
                   lower=c(0.9, -10, -10))
# Optimal parameters
optiml$par
optiml$par <- optiml$par/sum(optiml$par)
# Optimal Sharpe ratio
-objfun(optiml$par)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimized Portfolio Performance}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The optimized portfolio has both long and short positions, and outperforms its individual component assets.
      \vskip1ex
      <<optim_portf_basic,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
x11(width=6, height=5)
par(oma=c(1, 1, 1, 0), mgp=c(2, 1, 0), mar=c(2, 1, 2, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# Plot in two vertical panels
layout(matrix(c(1,2), 2),
       widths=c(1,1), heights=c(1,3))
# barplot of optimal portfolio weights
barplot(optiml$par, col=c("red", "green", "blue"),
        main="Optimized portfolio weights")
# Calculate cumulative returns of VTI, IEF, DBC
retc <- lapply(returns,
  function(returns) exp(cumsum(returns)))
retc <- rutils::do_call(cbind, retc)
# Calculate optimal portfolio returns with VTI, IEF, DBC
optim_rets <- cbind(
  exp(cumsum(returns %*% optiml$par)),
  retc)
colnames(optim_rets)[1] <- "optim_rets"
# Plot optimal returns with VTI, IEF, DBC
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("black", "red", "green", "blue")
chart_Series(optim_rets, theme=plot_theme,
             name="Optimized portfolio performance")
legend("top", legend=colnames(optim_rets), cex=0.8,
       inset=0.1, bg="white", lty=1, lwd=6,
       col=plot_theme$col$line.col, bty="n")
# Or plot non-compounded (simple) cumulative returns
PerformanceAnalytics::chart.CumReturns(
  cbind(returns %*% optiml$par, returns),
  lwd=2, ylab="", legend.loc="topleft", main="")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/optim_portf.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{quadprog} for Quadratic Programming}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Quadratic programming (\emph{QP}) is the optimization of quadratic objective functions subject to linear constraints.
      \vskip1ex
      Let $O(x)$ be an objective function that is quadratic with respect to a vector variable $x$:
      \begin{displaymath}
        O(x) = \frac{1}{2} x^T \mathbb{Q} x - d^T x
      \end{displaymath}
      Where $\mathbb{Q}$ is a \emph{positive definite} matrix ($x^T \mathbb{Q} x > 0$), and $d$ is a vector.
      \vskip1ex
      An example of a \emph{positive definite} matrix is the covariance matrix of linearly independent variables.
      \vskip1ex
      Let the linear constraints on the variable $x$ be specified as:
      \begin{displaymath}
        \mathbb{A} x \geq b
      \end{displaymath}
      Where $\mathbb{A}$ is a matrix, and $b$ is a vector.
      \vskip1ex
      The function \texttt{solve.QP()} from package \emph{quadprog} performs optimization of quadratic objective functions subject to linear constraints.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=(-(1:6)),eval=FALSE>>=
riskf <- 0.03
returns <- c(asset1=0.05, asset2=0.06)
stdevs <- c(asset1=0.4, asset2=0.5)
corrp <- 0.6
covmat <- matrix(c(1, corrp, corrp, 1), nc=2)
covmat <- t(t(stdevs*covmat)*stdevs)
library(quadprog)
# Minimum variance weights without constraints
optiml <- solve.QP(Dmat=2*covmat,
                    dvec=rep(0, 2),
                    Amat=matrix(0, nr=2, nc=1),
                    bvec=0)
# Minimum variance weights sum equal to 1
optiml <- solve.QP(Dmat=2*covmat,
                    dvec=rep(0, 2),
                    Amat=matrix(1, nr=2, nc=1),
                    bvec=1)
# Optimal value of objective function
t(optiml$solution) %*% covmat %*% optiml$solution
## Perform simple optimization for reference
# Objective function for simple optimization
objfun <- function(x) {
  x <- c(x, 1-x)
  t(x) %*% covmat %*% x
}  # end objfun
unlist(optimize(f=objfun, interval=c(-1, 2)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Using Package \protect\emph{quadprog}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The objective function is designed to minimize portfolio variance and maximize its returns:
      \begin{displaymath}
        O(x) = \mathbf{w}^T \mathbb{C} \, \mathbf{w} - \mathbf{w}^T \mathbf{r}
      \end{displaymath}
      Where $\mathbb{C}$ is the covariance matrix of returns, $\mathbf{r}$ is the vector of returns, and $\mathbf{w}$ is the vector of  portfolio weights.
      \vskip1ex
      The portfolio weights $\mathbf{w}$ are constrained as:
      \begin{align*}
        \mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1\\
        0 \leq w_i \leq 1
      \end{align*}
      The function \texttt{solve.QP()} has the arguments:
      \vskip1ex
      \texttt{Dmat} and \texttt{dvec} are the matrix and vector defining the quadratic objective function.
      \vskip1ex
      \texttt{Amat} and \texttt{bvec} are the matrix and vector defining the constraints.
      \vskip1ex
      \texttt{meq} specifies the number of equality constraints
      (the first \texttt{meq} constraints are equalities, and the rest are inequalities).
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Calculate daily percentage returns
symbolv <- c("VTI", "IEF", "DBC")
returns <- rutils::etfenv$returns[, symbolv]
# Calculate the covariance matrix
covmat <- cov(returns)
# Minimum variance weights, with sum equal to 1
optiml <- quadprog::solve.QP(Dmat=2*covmat,
                    dvec=numeric(3),
                    Amat=matrix(1, nr=3, nc=1),
                    bvec=1)
# Minimum variance, maximum returns
optiml <- quadprog::solve.QP(Dmat=2*covmat,
                    dvec=apply(0.1*returns, 2, mean),
                    Amat=matrix(1, nr=3, nc=1),
                    bvec=1)
# Minimum variance positive weights, sum equal to 1
a_mat <- cbind(matrix(1, nr=3, nc=1),
               diag(3), -diag(3))
b_vec <- c(1, rep(0, 3), rep(-1, 3))
optiml <- quadprog::solve.QP(Dmat=2*covmat,
                    dvec=numeric(3),
                    Amat=a_mat,
                    bvec=b_vec,
                    meq=1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{DEoptim} for Global Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{DEoptim()} from package \emph{DEoptim} performs \emph{global} optimization using the \emph{Differential Evolution} algorithm.
      \vskip1ex
      \emph{Differential Evolution} is a genetic algorithm which evolves a population of solutions over several generations,\\
      \hskip1em\url{http://www1.icsi.berkeley.edu/~storn/code.html}
      \vskip1ex
      The first generation of solutions is selected randomly.
      \vskip1ex
      Each new generation is obtained by combining solutions from the previous generation.
      \vskip1ex
      The best solutions are selected for creating the next generation.
      \vskip1ex
      The \emph{Differential Evolution} algorithm is well suited for very large multi-dimensional optimization problems, such as portfolio optimization.
      \vskip1ex
      \emph{Gradient} optimization methods are more efficient than \emph{Differential Evolution} for smooth objective functions with no local minima.
    \column{0.5\textwidth}
        <<echo=TRUE,eval=FALSE>>=
# Rastrigin function with vector argument for optimization
rastrigin <- function(vectorv, param=25){
  sum(vectorv^2 - param*cos(vectorv))
}  # end rastrigin
vectorv <- c(pi/6, pi/6)
rastrigin(vectorv=vectorv)
library(DEoptim)
# Optimize rastrigin using DEoptim
optiml <-  DEoptim(rastrigin,
  upper=c(6, 6), lower=c(-6, -6),
  DEoptim.control(trace=FALSE, itermax=50))
# Optimal parameters and value
optiml$optim$bestmem
rastrigin(optiml$optim$bestmem)
summary(optiml)
plot(optiml)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Using Package \protect\emph{Deoptim}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Differential Evolution} algorithm is well suited for very large multi-dimensional optimization problems, such as portfolio optimization.
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Calculate daily percentage returns
returns <- rutils::etfenv$returns[, symbolv]
# Objective equal to minus Sharpe ratio
objfun <- function(weightv, returns) {
  retsp <- returns %*% weightv
  if (sd(retsp) == 0)
    return(0)
  else
    return(-mean(retsp)/sd(retsp))
}  # end objfun
# Perform optimization using DEoptim
optiml <- DEoptim::DEoptim(fn=objfun,
  upper=rep(10, NCOL(returns)),
  lower=rep(-10, NCOL(returns)),
  returns=returns,
  control=list(trace=FALSE, itermax=100, parallelType=1))
weightv <- optiml$optim$bestmem/sum(abs(optiml$optim$bestmem))
names(weightv) <- colnames(returns)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Using \protect\emph{Shrinkage}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The technique of \emph{shrinkage} (\emph{regularization}) is designed to reduce the number of parameters in a model, for example in portfolio optimization.
      \vskip1ex
      The \emph{shrinkage} technique adds a penalty term to the objective function.
      \vskip1ex
      The \emph{elastic net} regularization is a combination of \emph{ridge} regularization and \emph{Lasso} regularization:
      \begin{align*}
        w_{max} = \operatorname*{arg\,max}_{w} [ \, \mathbf{w}^T \mathbf{r} - \\
        \lambda ( (1-\alpha) \sum_{i=1}^n w^2_i + \alpha \sum_{i=1}^n|w_i| ) \, ]
      \end{align*}
      The portfolio weights $\mathbf{w}$ are shrunk to zero as the parameters $\lambda$ and $\alpha$ increase.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Objective with shrinkage penalty
objfun <- function(weightv, returns, lambda, alpha) {
  retsp <- returns %*% weightv
  if (sd(retsp) == 0)
    return(0)
  else {
    penaltyt <- lambda*((1-alpha)*sum(weightv^2) +
        alpha*sum(abs(weightv)))
    return(-mean(retsp)/sd(retsp) + penaltyt)
  }
}  # end objfun
# Objective for equal weight portfolio
weightv <- rep(1, NROW(symbolv))
names(weightv) <- symbolv
lambda <- 0.5 ; alpha <- 0.5
objfun(weightv, returns=returns, lambda=lambda, alpha=alpha)
# Perform optimization using DEoptim
optiml <- DEoptim::DEoptim(fn=objfun,
  upper=rep(10, NCOL(returns)),
  lower=rep(-10, NCOL(returns)),
  returns=returns,
  lambda=lambda,
  alpha=alpha,
  control=list(trace=FALSE, itermax=100, parallelType=1))
weightv <- optiml$optim$bestmem/sum(abs(optiml$optim$bestmem))
names(weightv) <- colnames(returns)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Portfolio Optimization Strategies}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{portfolio optimization} strategy invests in the best performing portfolio in the past \emph{in-sample} interval, expecting that it will continue performing well \emph{out-of-sample}.
      \vskip1ex
      The \emph{portfolio optimization} strategy consists of:
      \setlength{\leftmargini}{1.0em}
      \begin{enumerate}
        \item Calculating the maximum Sharpe ratio portfolio weights in the \emph{in-sample} interval,
        \item Applying the weights and calculating the portfolio returns in the \emph{out-of-sample} interval.
      \end{enumerate}
      The optimal portfolio weights $\mathbf{w}$ are equal to the past in-sample excess returns $\mu = \mathbf{r} - r_f$ (in excess of the risk-free rate $r_f$) multiplied by the inverse of the covariance matrix $\mathbb{C}$:
      \begin{displaymath}
        \mathbf{w} = \mathbb{C}^{-1} \mu
      \end{displaymath}
      <<echo=TRUE,eval=FALSE>>=
# Select all the ETF symbols except "VXX", "SVXY" "MTUM", "QUAL", "VLUE", and "USMV"
symbolv <- colnames(rutils::etfenv$returns)
symbolv <- symbolv[!(symbolv %in% c("VXX", "SVXY", "MTUM", "QUAL", "VLUE", "USMV"))]
# Extract columns of rutils::etfenv$returns and overwrite NA values
retsp <- rutils::etfenv$returns[, symbolv]
nassets <- NCOL(retsp)
# retsp <- na.omit(retsp)
retsp[1, is.na(retsp[1, ])] <- 0
retsp <- zoo::na.locf(retsp, na.rm=FALSE)
dates <- zoo::index(retsp)
# retsp in excess of risk-free rate
riskf <- 0.03/252
retsx <- (retsp - riskf)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_etf_weights_in_sample.png}
      <<echo=TRUE,eval=FALSE>>=
# Maximum Sharpe weights in-sample interval
retsis <- retsp["/2014"]
invmat <- MASS::ginv(cov(retsis))
weightv <- invmat %*% colMeans(retsx["/2014"])
weightv <- drop(weightv/sqrt(sum(weightv^2)))
names(weightv) <- colnames(retsp)
# Plot portfolio weights
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(0, 0, 0, 0), mgp=c(2, 1, 0))
barplot(sort(weightv), main="Maximum Sharpe Weights", cex.names=0.7)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Strategy In-Sample}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The in-sample performance of the optimal portfolio is much better than the equal weight portfolio.
      <<echo=TRUE,eval=FALSE>>=
# Calculate in-sample portfolio returns
portfis <- xts::xts(retsis %*% weightv, zoo::index(retsis))
indeks <- xts::xts(rowMeans(retsis), zoo::index(retsis))
portfis <- portfis*sd(indeks)/sd(portfis)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_etf_in_sample.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot cumulative portfolio returns
pnls <- cumsum(cbind(portfis, indeks))
colnames(pnls) <- c("Optimal Portfolio", "Equal Weight Portfolio")
endd <- rutils::calc_endpoints(pnls, interval="months")
dygraphs::dygraph(pnls[endd], main="In-sample Optimal Portfolio Returns") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Strategy Out-of-Sample}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The out-of-sample performance of the optimal portfolio is not nearly as good as in-sample.
      \vskip1ex
      Combining the optimal portfolio with the equal weight portfolio produces and even better performing portfolio.
      <<echo=TRUE,eval=FALSE>>=
# Calculate out-of-sample portfolio returns
retsos <- retsp["2015/"]
portfos <- xts::xts(retsos %*% weightv, zoo::index(retsos))
indeks <- xts::xts(rowMeans(retsos), zoo::index(retsos))
portfos <- portfos*sd(indeks)/sd(portfos)
pnls <- cbind(portfos, indeks, (portfos + indeks)/2)
colnames(pnls) <- c("Optimal", "Equal Weight", "Combined")
sqrt(252)*sapply(pnls, function(x) mean(x)/sd(x))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_etf_out_sample.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot cumulative portfolio returns
endd <- rutils::calc_endpoints(pnls, interval="months")
dygraphs::dygraph(cumsum(pnls)[endd], main="Out-of-sample Optimal Portfolio Returns") %>%
  dyOptions(colors=c("red", "blue", "green"), strokeWidth=2) %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Strategy for ETFs}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{portfolio optimization} strategy for ETFs is \emph{overfitted} in the \emph{in-sample} interval.
      \vskip1ex
      Therefore the strategy underperforms in the \emph{out-of-sample} interval.
      <<echo=TRUE,eval=FALSE>>=
# Maximum Sharpe weights in-sample interval
invmat <- MASS::ginv(cov(retsis))
weightv <- invmat %*% colMeans(retsx["/2014"])
weightv <- drop(weightv/sqrt(sum(weightv^2)))
names(weightv) <- colnames(retsp)
# Calculate in-sample portfolio returns
portfis <- xts::xts(retsis %*% weightv, zoo::index(retsis))
# Calculate out-of-sample portfolio returns
retsos <- retsp["2015/"]
portfos <- xts::xts(retsos %*% weightv, zoo::index(retsos))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_etfs_out_sample.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot cumulative portfolio returns
pnls <- rbind(portfis, portfos)
indeks <- xts::xts(rowMeans(retsp), dates)
pnls <- pnls*sd(indeks)/sd(pnls)
pnls <- cumsum(cbind(pnls, indeks))
colnames(pnls) <- c("Optimal Portfolio", "Equal Weight Portfolio")
endd <- rutils::calc_endpoints(pnls, interval="months")
dygraphs::dygraph(pnls[endd], main="Out-of-sample Optimal Portfolio Returns for ETFs") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyEvent(zoo::index(last(retsis[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Regularized Inverse of Singular Covariance Matrices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{regularization} technique allows calculating the inverse of \emph{singular} covariance matrices while reducing the effects of statistical noise.
      \vskip1ex
      If the number of time periods of returns is less than the number of assets (columns), then the covariance matrix of returns is \emph{singular}, and some of its \emph{eigenvalues} are zero, so it doesn't have an inverse.
      \vskip1ex
      The \emph{regularized} inverse $\mathbb{C}_n^{-1}$ is calculated by removing the higher order eigenvalues that are almost zero, and keeping only the first $n$ \emph{eigenvalues}:
      \begin{displaymath}
        \mathbb{C}_n^{-1} = \mathbb{O}_n \, \mathbb{D}_n^{-1} \, \mathbb{O}_n^T
      \end{displaymath}
      Where $\mathbb{D}_n$ and $\mathbb{O}_n$ are matrices with the higher order eigenvalues and eigenvectors removed.
      \vskip1ex
      The function \texttt{MASS::ginv()} calculates the \emph{regularized} inverse of a matrix.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Create rectangular matrix with collinear columns
matrixv <- matrix(rnorm(10*8), nc=10)
# Calculate covariance matrix
covmat <- cov(matrixv)
# Calculate inverse of covmat - error
invmat <- solve(covmat)
# Perform eigen decomposition
eigend <- eigen(covmat)
eigenvec <- eigend$vectors
eigenval <- eigend$values
# Set tolerance for determining zero singular values
precision <- sqrt(.Machine$double.eps)
# Calculate regularized inverse matrix
not_zero <- (eigenval > (precision * eigenval[1]))
invreg <- eigenvec[, not_zero] %*%
  (t(eigenvec[, not_zero]) / eigenval[not_zero])
# Verify inverse property of invreg
all.equal(covmat, covmat %*% invreg %*% covmat)
# Calculate regularized inverse of covmat
invmat <- MASS::ginv(covmat)
# Verify inverse property of matrixv
all.equal(invmat, invreg)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Shrinkage Inverse of the Covariance Matrix}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      For a portfolio of \emph{S\&P500} stocks, the number return columns is very large, which may make the covariance matrix of returns simgular.
      \vskip1ex
      Removing the very small higher order eigenvalues also reduces the propagation of statistical noise and improves the signal-to-noise ratio.
      \vskip1ex
      But removing a larger number of eigenvalues increases the bias of the covariance matrix, which is an example of the \emph{bias-variance tradeoff}.
      \vskip1ex
      Even though the \emph{shrinkage inverse} $\mathbb{C}_n^{-1}$ does not satisfy the matrix inverse property, its out-of-sample forecasts may be more accurate than those using the actual inverse matrix.
      \vskip1ex
      The parameter \texttt{max\_eigen} specifies the number of eigenvalues used for calculating the \emph{regularized} inverse of the covariance matrix of returns.
      \vskip1ex
      The optimal value of the parameter \texttt{max\_eigen} can be determined using \emph{backtesting} (\emph{cross-validation}).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate in-sample covariance matrix
covmat <- cov(retsis)
eigend <- eigen(covmat)
eigenvec <- eigend$vectors
eigenval <- eigend$values
# Calculate shrinkage inverse of covariance matrix
eigen_max <- 3
invmat <- eigenvec[, 1:eigen_max] %*%
  (t(eigenvec[, 1:eigen_max]) / eigend$values[1:eigen_max])
# Verify inverse property of inverse
all.equal(covmat, covmat %*% invmat %*% covmat)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization for ETFs with Shrinkage}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{out-of-sample} performance of the \emph{portfolio optimization} strategy is greatly improved by shrinking the inverse of the covariance matrix.
      \vskip1ex
      The \emph{in-sample} performance is worse because shrinkage reduces \emph{overfitting}.
      <<echo=TRUE,eval=FALSE>>=
# Calculate portfolio weights
weightv <- invmat %*% colMeans(retsx["/2014"])
weightv <- drop(weightv/sqrt(sum(weightv^2)))
names(weightv) <- colnames(retsp)
# Calculate portfolio returns
portfis <- xts::xts(retsis %*% weightv, zoo::index(retsis))
portfos <- xts::xts(retsos %*% weightv, zoo::index(retsos))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_etfs_out_sample_shrink.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot cumulative portfolio returns
pnls <- rbind(portfis, portfos)
pnls <- pnls*sd(indeks)/sd(pnls)
pnls <- cumsum(cbind(pnls, indeks))
colnames(pnls) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(pnls[endd], main="Regularized Out-of-sample Optimal Portfolio Returns for ETFs") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyEvent(zoo::index(last(retsis[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal ETF Portfolio Weights With Return Shrinkage}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      To further reduce the statistical noise, the individual returns $r_i$ can be \emph{shrunk} to the average portfolio returns $\bar{r}$:
      \begin{displaymath}
        r_i = (1 - \alpha) \, r_i + \alpha \, \bar{r}
      \end{displaymath}
      The parameter $\alpha$ is the \emph{shrinkage} intensity, and it determines the strength of the \emph{shrinkage} of individual returns to their mean.
      \vskip1ex
      If $\alpha = 0$ then there is no \emph{shrinkage}, while if $\alpha = 1$ then all the returns are \emph{shrunk} to their common mean: $r_i = \bar{r}$.
      \vskip1ex
      The optimal value of the \emph{shrinkage} intensity $\alpha$ can be determined using \emph{backtesting} (\emph{cross-validation}).
      <<echo=TRUE,eval=FALSE>>=
# Shrink the in-sample returns to their mean
alpha <- 0.7
retsxm <- rowMeans(retsx["/2014"])
retsxis <- (1 - alpha)*retsx["/2014"] + alpha*retsxm
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_etfs_out_sample_rets_shrink.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate portfolio weights
weightv <- invmat %*% colMeans(retsxis)
weightv <- drop(weightv/sqrt(sum(weightv^2)))
# Calculate portfolio returns
portfis <- xts::xts(retsis %*% weightv, zoo::index(retsis))
portfos <- xts::xts(retsos %*% weightv, zoo::index(retsos))
# Plot cumulative portfolio returns
pnls <- rbind(portfis, portfos)
pnls <- pnls*sd(indeks)/sd(pnls)
pnls <- cumsum(cbind(pnls, indeks))
colnames(pnls) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(pnls[endd], main="Out-of-sample Returns for ETFs With Regularization and Shrinkage") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyEvent(zoo::index(last(retsis[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Strategy for Stocks}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{portfolio optimization} strategy for stocks is \emph{overfitted} in the \emph{in-sample} interval.
      \vskip1ex
      Therefore the strategy completely fails in the \emph{out-of-sample} interval.
      <<echo=TRUE,eval=FALSE>>=
load("/Users/jerzy/Develop/lecture_slides/data/sp500_returns.RData")
# Overwrite NA values in returns
retsp <- returns["2000/"]
nassets <- NCOL(returns)
returns[1, is.na(returns[1, ])] <- 0
returns <- zoo::na.locf(returns, na.rm=FALSE)
dates <- zoo::index(returns)
riskf <- 0.03/252
retsx <- (returns - riskf)
retsis <- returns["/2010"]
retsos <- returns["2011/"]
# Maximum Sharpe weights in-sample interval
covmat <- cov(retsis)
invmat <- MASS::ginv(covmat)
weightv <- invmat %*% colMeans(retsx["/2010"])
weightv <- drop(weightv/sqrt(sum(weightv^2)))
names(weightv) <- colnames(returns)
# Calculate portfolio returns
portfis <- xts::xts(retsis %*% weightv, zoo::index(retsis))
portfos <- xts::xts(retsos %*% weightv, zoo::index(retsos))
indeks <- xts::xts(rowMeans(returns), dates)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_optim_out_sample.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot cumulative portfolio returns
pnls <- rbind(portfis, portfos)
pnls <- pnls*sd(indeks)/sd(pnls)
pnls <- cumsum(cbind(pnls, indeks))
colnames(pnls) <- c("Optimal Portfolio", "Equal Weight Portfolio")
endd <- rutils::calc_endpoints(pnls, interval="months")
dygraphs::dygraph(pnls[endd], main="Out-of-sample Optimal Portfolio Returns for Stocks") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyEvent(zoo::index(last(retsis[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization for Stocks with Shrinkage}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{out-of-sample} performance of the \emph{portfolio optimization} strategy is greatly improved by shrinking the inverse of the covariance matrix.
      \vskip1ex
      The \emph{in-sample} performance is worse because shrinkage reduces \emph{overfitting}.
      <<echo=TRUE,eval=FALSE>>=
# Calculate shrinkage inverse of covariance matrix
look_back <- 8; eigen_max <- 3
eigend <- eigen(cov(retsis))
eigenvec <- eigend$vectors
eigenval <- eigend$values
invmat <- eigenvec[, 1:eigen_max] %*%
  (t(eigenvec[, 1:eigen_max]) / eigend$values[1:eigen_max])
# Calculate portfolio weights
weightv <- invmat %*% colMeans(retsx["/2010"])
weightv <- drop(weightv/sqrt(sum(weightv^2)))
names(weightv) <- colnames(returns)
# Calculate portfolio returns
portfis <- xts::xts(retsis %*% weightv, zoo::index(retsis))
portfos <- xts::xts(retsos %*% weightv, zoo::index(retsos))
indeks <- xts::xts(rowMeans(returns), dates)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_optim_out_sample_shrink.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot cumulative portfolio returns
pnls <- rbind(portfis, portfos)
pnls <- pnls*sd(indeks)/sd(pnls)
pnls <- cumsum(cbind(pnls, indeks))
colnames(pnls) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(pnls[endd], main="Regularized Out-of-sample Optimal Portfolio Returns for Stocks") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyEvent(zoo::index(last(retsis[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Stock Portfolio Weights With Return Shrinkage}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      To further reduce the statistical noise, the individual returns $r_i$ can be \emph{shrunk} to the average portfolio returns $\bar{r}$:
      \begin{displaymath}
        r_i = (1 - \alpha) \, r_i + \alpha \, \bar{r}
      \end{displaymath}
      The parameter $\alpha$ is the \emph{shrinkage} intensity, and it determines the strength of the \emph{shrinkage} of individual returns to their mean.
      \vskip1ex
      If $\alpha = 0$ then there is no \emph{shrinkage}, while if $\alpha = 1$ then all the returns are \emph{shrunk} to their common mean: $r_i = \bar{r}$.
      \vskip1ex
      The optimal value of the \emph{shrinkage} intensity $\alpha$ can be determined using \emph{backtesting} (\emph{cross-validation}).
      <<echo=TRUE,eval=FALSE>>=
# Shrink the in-sample returns to their mean
alpha <- 0.7
retsxm <- rowMeans(retsx["/2010"])
retsxis <- (1 - alpha)*retsx["/2010"] + alpha*retsxm
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/portf_optim_out_sample_rets_shrink.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate portfolio weights
weightv <- invmat %*% colMeans(retsxis)
weightv <- drop(weightv/sqrt(sum(weightv^2)))
# Calculate portfolio returns
portfis <- xts::xts(retsis %*% weightv, zoo::index(retsis))
portfos <- xts::xts(retsos %*% weightv, zoo::index(retsos))
# Plot cumulative portfolio returns
pnls <- rbind(portfis, portfos)
pnls <- pnls*sd(indeks)/sd(pnls)
pnls <- cumsum(cbind(pnls, indeks))
colnames(pnls) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(pnls[endd], main="Out-of-sample Returns for Stocks With Regularization and Shrinkage") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyEvent(zoo::index(last(retsis[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\secname}
\vspace{-1em}
\begin{block}{Required}
  Study all the lecture slides in \texttt{FRE7241\_Lecture\_6.pdf}, and run all the code in \texttt{FRE7241\_Lecture\_6.R}
\end{block}
\begin{block}{Recommended}
  \begin{itemize}[]
    \item Read about \emph{estimator shrinkage}:\\
    \emph{Aswani Regression Shrinkage Bias Variance Tradeoff.pdf}\\
    \emph{Blei Regression Lasso Shrinkage Bias Variance Tradeoff.pdf}\\
    \item Read about \emph{optimization methods}:\\
    \emph{Bolker Optimization Methods.pdf}\\
    \emph{Yollin Optimization.pdf}\\
    \emph{DEoptim Introduction.pdf}\\
    \emph{Ardia DEoptim Portfolio Optimization.pdf}\\
    \emph{Boudt DEoptim Portfolio Optimization.pdf}\\
    \emph{Boudt DEoptim Large Portfolio Optimization.pdf}\\
    \emph{Mullen Package DEoptim.pdf}\\
    \item Read about \emph{momentum}:\\
    \emph{Bouchaud Momentum Mean Reversion Equity Returns.pdf}\\
  \end{itemize}
\end{block}

\end{frame}


\end{document}
