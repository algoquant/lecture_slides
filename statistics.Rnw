% Define knitr options
% !Rnw weave = knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, tidy=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% amsmath package for math symbols
% \usepackage{amsmath}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE6811_bib.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text footnotesize
\renewcommand\UrlFont{\footnotesize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape,bg=red,fg=red}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[Statistics]{Statistics}
\subtitle{FRE6871 R in Finance, Fall 2014}
% \subject{Getting Started With R}
\institute[NYU Polytechnic]{NYU Polytechnic School of Engineering}
\titlegraphic{\includegraphics[scale=0.8]{engineering_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \texorpdfstring{(\textit{\color{blue}{\footnotesize{jp3900@nyu.edu}}})}{}}
% \email{jp3900@poly.edu}
% \date{January 27, 2014}
\date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
% \section{Plotting}
\section{Probability Distributions}


%%%%%%%%%%%%%%%
\subsection{Normal Probability Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The Normal probability density function is given by:
      \begin{displaymath}
        P(x) = \frac{e^{-(x-\mu)^2/2\sigma^2}}{\sigma\sqrt{2 \pi}}
      \end{displaymath}
      The Standard Normal distribution is a special case of the Normal with $\mu=0$ and $\sigma=1$,
\vskip1ex
      The function \texttt{dnorm()} calculates the normal probability density,

        <<norm_dist,echo=3:30,fig.show='hide'>>=
rm(list=ls())
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
v.xval <- seq(-5, 7, length=100)
v.yval <- dnorm(v.xval, mean=1.0, sd=2.0)
plot(v.xval, v.yval, type="l", lty="solid", 
     xlab="", ylab="")
title(main="Normal Density Function", line=0.5)
n.low <- 3; n.up <- 5  # set lower and upper bounds
# set polygon base
v.reg <- ((v.xval >= n.low) & (v.xval <= n.up))
polygon(c(n.low, v.xval[v.reg], n.up),  # draw polygon
        c(-1, v.yval[v.reg], -1), col="red")
      @
    \column{0.5\textwidth}
    \includegraphics[width=0.5\paperwidth,valign=t]{figure/norm_dist}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Normal Probability Distributions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Plots of several Normal distributions with different values of $\sigma,$
        <<norm_dist_mult,echo=3:30,fig.show='hide'>>=
rm(list=ls())
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
v.xval <- seq(-4, 4, length=100)
v.sigma <- c(0.5, 1, 1.5, 2)  # sigma values
# create plot colors
v.colors <- c("red", "black", "blue", "green")
# create legend labels
v.labels <- paste("sigma", v.sigma, sep='=')
# plot an empty chart
plot(v.xval, dnorm(v.xval, sd=v.sigma[1]), 
     type="n", xlab="", ylab="", 
     main="Normal Distributions")
# add lines to plot
for (in_dex in 1:4) {
  lines(v.xval, dnorm(v.xval, sd=v.sigma[in_dex]), 
        lwd=2, col=v.colors[in_dex])
}
# add legend
legend("topright", inset=0.05, title="Sigmas", 
       v.labels, cex=0.8, lwd=2, lty=c(1, 1, 1, 1), 
       col=v.colors)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/norm_dist_mult}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Chi-squared Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Let $Z_{1},\ldots ,Z_{k}$ be independent standard normal random variables,
      \vskip1ex
      Let $X=\sum_{i=1}^{k}Z_{i}^{2}$, \hskip1em then $X\sim \chi _{k}^{2}$,
        <<chisq_dist_mult,echo=3:30,fig.show='hide'>>=
rm(list=ls())
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
v.xval <- seq(0, 20, length=100)
v.df <- c(2, 5, 8, 11)  # df values
# create plot colors
v.colors <- c("red", "black", "blue", "green")
# create legend labels
v.labels <- paste("df", v.df, sep='=')
# plot an empty chart
plot(v.xval, dchisq(v.xval, df=v.df[1]), 
     type="n", xlab="", ylab="", 
     main="Chi-squared Distributions")
# add lines to plot
for (in_dex in 1:4) {
  lines(v.xval, dchisq(v.xval, df=v.df[in_dex]), 
        lwd=2, col=v.colors[in_dex])
}
# add legend
legend("topright", inset=0.05, 
       title="Degrees of freedom", v.labels, 
       cex=0.8, lwd=2, lty=c(1, 1, 1, 1), 
       col=v.colors)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/chisq_dist_mult}
      \vspace{-4em}
      $X$ is distributed according to the \emph{chi-squared} distribution with $k$ degrees of freedom, given by:
% \normalsize
      \begin{displaymath}
        P(x) = \frac{x^{k/2-1}\,e^{-x/2}}{2^{k/2}\, \Gamma(k/2)}
      \end{displaymath}
% \footnotesize
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Student's $t$-distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Let $Z_{1},\ldots ,Z_{k}$ be independent standard normal random variables,
      \vskip1ex
      Let $s^2=\sum_{i=1}^{\nu}Z_{i}^{2}$, \hskip1em $t=\frac{\sum_{i=1}^{\nu}Z_{i}}{s}$,
        <<t_dist_mult,echo=3:30,fig.show='hide'>>=
rm(list=ls())
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
v.xval <- seq(-5, 5, length=100)
v.df <- c(3, 6, 9)  # df values
# create plot colors
v.colors <- c("black", "red", "blue", "green")
# create legend labels
v.labels <- c('normal', paste("df", v.df, sep='='))
# plot chart of normal distribution
plot(v.xval, dnorm(v.xval), type="l", 
     lwd=2, xlab="", ylab="", 
     main="t-distributions")
# add lines to plot
for (in_dex in 1:3) {
  lines(v.xval, dt(v.xval, df=v.df[in_dex]), 
        lwd=2, col=v.colors[in_dex+1])
}
# add legend
legend("topright", inset=0.05, 
       title="Degrees\n of freedom", v.labels, 
       cex=0.8, lwd=2, lty=c(1, 1, 1, 1), 
       col=v.colors)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/t_dist_mult}
      \vspace{-4em}
      $t$ is distributed according to the $t$-distribution with $\nu$ degrees of freedom, given by:
      \begin{displaymath}
        P(x) = \frac{\Gamma((\nu+1)/2)}{\sqrt{\pi \nu}\,\Gamma(\nu/2)}\, (1 + x^2/\nu)^{-(\nu+1)/2}
      \end{displaymath}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Pseudo-Random Numbers}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.3\textwidth}
      The function \texttt{set.seed()} initializes the random number generator by specifying the $seed$ value,
      \vskip1ex
      The function \texttt{runif()} produces random numbers from the uniform distribution,
      \vskip1ex
      The function \texttt{rnorm()} produces random numbers from the normal distribution,
      \vskip1ex
      The function \texttt{pnorm()} calculates the cumulative normal distribution,
      \vskip1ex
      The function \texttt{qnorm()} calculates the inverse cumulative normal distribution,
    \column{0.7\textwidth}
      \vspace{-1em}
        <<echo=2:30>>=
rm(list=ls())
set.seed(1121)  # initialize the random number generator
runif(3)  # three random numbers from the uniform distribution
runif(3)  # produce another three numbers
set.seed(1121)  # re-initialize the random number generator
runif(3)  # produce another three numbers
# produce a random number from the standard normal distribution
rnorm(1)
# produce five random numbers from the standard normal distribution
rnorm(5)
# produce five random numbers from the normal distribution
rnorm(n=5, mean=1, sd=2)  # match arguments by name
# calculate cumulative standard normal distribution
c(pnorm(-2), pnorm(2))
# calculate inverse cumulative standard normal distribution
c(qnorm(0.75), qnorm(0.25))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Statistical Estimators}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      A data \emph{sample} is a set of data selected from a statistical population (distribution),
      \vskip1ex
      Let $\{x_{1},\ldots ,x_{n}\}$ be a data \emph{sample} from a given distribution,
      \vskip1ex
      A \emph{statistic} is a function of a data \emph{sample}:  $f( x_{1},\ldots ,x_{n} )$,
      \vskip1ex
      A \emph{statistic} is itself a \emph{random variable},
      \vskip1ex
      A statistical \emph{estimator} is a \emph{statistic} that provides an estimate of a \emph{distribution} parameter,
      \vskip1ex
      For example:
      \begin{displaymath}
        \bar{x}=\frac{1}{n}{\sum_{i=1}^{n}x_{i}}
      \end{displaymath}
      Is an \emph{estimator} of the \emph{mean} of the \emph{distribution},
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=3:30>>=
rm(list=ls())
set.seed(1121)  # initialize the random number generator
# sample from Standard Normal Distribution
rand_sample <- rnorm(1000)

mean(rand_sample)  # sample mean

sd(rand_sample)  # sample standard deviation
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Estimators of Moments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The estimators of moments of a probability distribution are given by:
      \vskip1ex
      Mean: $\bar{x}=\frac{1}{k} \sum_{i=1}^{k} x_{i}$
      \vskip1ex
      Variance: $\hat{\sigma}^2=\frac{1}{k-1} \sum_{i=1}^{k} (x_{i}-\bar{x})^2$
      \vskip1ex
      Skewness:
      \begin{displaymath}
        \hat{s}=\frac{k}{(k-1)(k-2)} \sum_{i=1}^{k} (\frac{x_{i}-\bar{x}}{\hat{\sigma}})^3
      \end{displaymath}
      Kurtosis:
      \begin{displaymath}
        \hat{k}=\frac{k(k+1)}{(k-1)^3} \sum_{i=1}^{k} (\frac{x_{i}-\bar{x}}{\hat{\sigma}})^4
      \end{displaymath}
      The normal distribution has zero skewness and kurtosis equal to 3,
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=2:30>>=
rm(list=ls())
ts_rets <- diff(log(EuStockMarkets[, 1]))  # DAX returns
len_rets <- length(ts_rets)  # number of observations
mean_rets <- mean(ts_rets)  # calculate mean
sd_rets <- sd(ts_rets)  # calculate standard deviation
# calculate skew
len_rets*(sum(((ts_rets - mean_rets)/sd_rets)^3))/
  ((len_rets-1)*(len_rets-2))
# calculate kurtosis
len_rets*(len_rets+1)*(sum(((ts_rets - mean_rets)/sd_rets)^4))/
  ((len_rets-1)^3)
ts_rets <- rnorm(len_rets, sd=2)  # random normal returns
mean_rets <- mean(ts_rets); sd_rets <- sd(ts_rets)
# calculate skew
len_rets*(sum(((ts_rets - mean_rets)/sd_rets)^3))/
  ((len_rets-1)*(len_rets-2))
# calculate kurtosis
len_rets*(len_rets+1)*(sum(((ts_rets - mean_rets)/sd_rets)^4))/
  ((len_rets-1)^3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Function for Calculating Moments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.3\textwidth}
      \texttt{R} provides an easy way to write functions,
      \vskip1ex
      Function arguments can be matched by position or by name,
      \vskip1ex
      If the function arguments are missing then the default value is used,
      \vskip1ex
      Functions return the value of the last expression that is evaluated,
      \vskip1ex
      If a function name is called alone then \texttt{R} displays the function code,
    \column{0.7\textwidth}
      \vspace{-1em}
        <<echo=4:30>>=
rm(list=ls())
par(oma=c(1, 1, 1, 1), mgp=c(2, 1, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
set.seed(1121)  # initialize the random number generator
ts_rets <- diff(log(EuStockMarkets))[, 1]  # DAX returns
# define function CalcSkew to calculate the skew
CalcSkew <- function(ts.data=rnorm(1000)) {  # default is normal
# Calculates the skew of a time series of returns.
  len_data <- length(ts.data)  # number of observations
  mean_rets <- mean(ts.data)
  sd_rets <- sd(ts.data)
# the last statement is what is returned
  len_data*sum(((ts.data - mean_rets)/sd_rets)^3)/((len_data-1)*(len_data-2))
}  # end CalcSkew
# calculate skewness of DAX returns
CalcSkew(ts.data=ts_rets)  # match arguments by name
CalcSkew(ts_rets)  # match arguments by position
CalcSkew()  # use default value of arguments
CalcSkew  # show the function code
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\section{Hypothesis Testing}


%%%%%%%%%%%%%%%
\subsection{Hypothesis Testing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.45\textwidth}
      \emph{Hypothesis Testing} is designed to test the validity of a \emph{null hypothesis},
      \vskip1ex
      A \emph{Hypothesis Test} consists of:
      \begin{itemize}[]
        \item a \emph{null hypothesis},
        \item a  test \emph{statistic} (based on a sample),
        \item a \emph{significance level} $\alpha$, determining whether to accept or reject the \emph{null hypothesis},
        \item a \emph{p}-value (probability of observing the value of the test statistic, assuming the null hypothesis is true),
      \end{itemize}
      If the \emph{p}-value is less than the \emph{significance level} $\alpha$, then the \emph{null hypothesis} is rejected,
      \vskip1ex
      The objective of \emph{Hypothesis Testing} is to invalidate the \emph{null hypothesis},
      \vskip1ex
      In statistics we cannot \emph{prove} that a hypothesis is TRUE; we can only conclude that it's very unlikely to be FALSE,
    \column{0.55\textwidth}
      \vspace{-1em}
      <<echo=4:30>>=
rm(list=ls())
par(oma=c(1, 1, 1, 1), mgp=c(2, 0.5, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
set.seed(1121)  # initialize the random number generator
### Perform two-tailed test that sample is 
### from Standard Normal Distribution (mean=0, SD=1)
# generate vector of samples
rand.samples=rnorm(1000)
df.test <- data.frame(samples=rand.samples)
critical.value <- 2  # critical value = 2 SD
# two-tailed test significance level
signif.level <- 2*(1-pnorm(critical.value))
signif.level
# get p.values for all the samples
df.test$p.values <- sapply(df.test$samples, pnorm)
df.test$p.values <- 2*(0.5-abs(df.test$p.values-0.5))
# compare p.values to significance level
df.test$result <- df.test$p.values > signif.level
sum(!df.test$result)  # number of null rejections
# show null rejections
head(df.test[!df.test$result, ])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Visualizing Hypothesis Testing Using Package \texttt{ggplot2}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      <<hyp_test_ggp2,echo=3:30,fig.show='hide'>>=
rm(list=ls())
par(oma=c(1, 1, 1, 1), mgp=c(2, 0.5, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
library(ggplot2)  # load ggplot2

qplot(  # simple ggplot2
    main="Standard Normal Distribution", 
    c(-4, 4), 
    stat="function", 
    fun=dnorm, 
    geom="line", 
    xlab=NULL, ylab=NULL
    ) +  # end qplot

theme(  # modify plot theme
    plot.title=element_text(vjust=-1.0), 
    plot.background=element_blank()
    ) +  # end theme

geom_vline(  # add vertical line
  aes(xintercept=c(-2.0, 2.0)), 
  colour="red", 
  linetype="dashed"
  )  # end geom_vline
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/hyp_test_ggp2}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Visualizing Hypothesis Testing Using \texttt{ggplot2} (cont)}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      <<hyp_test_ggp2_2,echo=3:30,fig.show='hide'>>=
rm(list=ls())
par(oma=c(1, 1, 1, 1), mgp=c(2, 0.5, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
### create ggplot2 with shaded area
x.reg <- -400:400/100
df.dnorm <- data.frame(x.reg=x.reg, 
                       d.norm=dnorm(x.reg))
df.dnorm$shade <- ifelse(
                  abs(df.dnorm$x.reg) >= 2, 
                  df.dnorm$d.norm, NA)
ggplot(  # main function
  data=df.dnorm, 
  mapping=aes(x=x.reg, y=d.norm)
  ) +  # end ggplot
# plot line
  geom_line() + 
# plot shaded area
  geom_ribbon(aes(ymin=0, ymax=shade), fill="red") + 
# no axis labels
  xlab("") + ylab("") + 
# add title
  ggtitle("Standard Normal Distribution") +
# modify plot theme
  theme(
        plot.title=element_text(vjust=-1.0), 
        plot.background=element_blank()
  )  # end theme
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/hyp_test_ggp2_2}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\section{Univariate Statistical Models}


%%%%%%%%%%%%%%%
\subsection{Shapiro-Wilk Test of Normality}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Shapiro-Wilk} test is designed to test the \emph{null hypothesis} that a sample: $\{x_{1},\ldots ,x_{n}\}$ is from a normally distributed population,
      \vskip1ex
      The test statistic is:
      \begin{displaymath}
        W= \frac {(\sum_{i=1}^{n} a_{i} x_{(i)})^2} {\sum_{i=1}^{n} (x_{i}-\bar{x})^2}
      \end{displaymath}
      Where the: $\{a_{1},\ldots ,a_{n}\}$ are proportional to the \emph{order statistics} of random variables from the normal distribution,
      \vskip1ex
      The \emph{Shapiro-Wilk} statistic follows its own distribution, and is less than or equal to one,
      \vskip1ex
      The \emph{Shapiro-Wilk} statistic is close to one for samples from normal distributions,
      \vskip1ex
      The  p-value for DAX returns is extremely small, and we conclude that the \emph{null hypothesis} is FALSE, and the DAX returns are not from a normally distributed population,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=3:30>>=
rm(list=ls())
set.seed(1121)  # initialize the random number generator
# calculate DAX percentage returns
ts.dax <- diff(log(EuStockMarkets[, 1]))

# Shapiro-Wilk test for normal distribution
shapiro.test(rnorm(length(ts.dax)))

# Shapiro-Wilk test for DAX returns
shapiro.test(ts.dax)

# Shapiro-Wilk test for uniform distribution
shapiro.test(runif(length(ts.dax)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Jarque-Bera Test of Normality}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Jarque-Bera} test is designed to test the \emph{null hypothesis} that a sample: $\{x_{1},\ldots ,x_{n}\}$ is from a normally distributed population,
      \vskip1ex
      The test statistic is:
      \begin{displaymath}
        JB= \frac{n}{6} (\hat{s}^2 + \frac{1}{4} (\hat{k} - 3)^2)
      \end{displaymath}
      Where the skewness and kurtosis are defined as:
      \begin{align}{\notag}
        \hat{s} = \frac{1}{n} \sum_{i=1}^{n} (\frac{x_{i}-\bar{x}}{\hat{\sigma}})^3
      &&
        \hat{k} = \frac{1}{n} \sum_{i=1}^{n} (\frac{x_{i}-\bar{x}}{\hat{\sigma}})^4
      \end{align}
      The \emph{Jarque-Bera} statistic asymptotically follows the \emph{chi-squared} distribution with two degrees of freedom,
      \vskip1ex
      The \emph{Jarque-Bera} statistic is small for samples from normal distributions,
      \vskip1ex
      The  p-value for DAX returns is extremely small, and we conclude that the \emph{null hypothesis} is FALSE, and the DAX returns are not from a normally distributed population,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=2:30>>=
ts.dax <- diff(log(EuStockMarkets[, 1]))
library(tseries)  # load package tseries

# Jarque-Bera test for normal distribution
jarque.bera.test(rnorm(length(ts.dax)))

# Jarque-Bera test for DAX returns
jarque.bera.test(ts.dax)

# Jarque-Bera test for uniform distribution
jarque.bera.test(runif(length(ts.dax)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Autocorrelation Function} is the correlation coefficient of a time series with its lagged values:
      \begin{displaymath}
        \rho_{k} = \frac{1}{\sigma^2} {\sum_{i=k+1}^{n} (x_{i}-\bar{x})(x_{i-k}-\bar{x})}
      \end{displaymath}
      The package \texttt{forecast} contains functions for univariate time series forecasting,
        <<eustx_acf,echo=4:30,fig.height=8,eval=TRUE,fig.show='hide'>>=
par(oma=c(1, 1, 1, 1), mgp=c(2, 0.5, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# calculate DAX percentage returns
ts.dax <- diff(log(EuStockMarkets[, 1]))
library(forecast)  # load forecast
par(mfrow=c(2,1))  # set plot panels
# autocorrelation from "stats"
acf(ts.dax, lag=5, xlab=NA)
# autocorrelation from "forecast"
Acf(ts.dax, lag=5, xlab=NA)
      @
      The horizontal dashed lines are the confidence intervals corresponding to the 95\% significance level,
      \vskip1ex
      The DAX time series does not have statistically significant autocorrelations,
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/eustx_acf}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Filtering Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-2em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      <<dax_filter,echo=3:30,fig.show='hide'>>=
rm(list=ls())
library(zoo)  # load zoo
library(ggplot2)  # load ggplot2
library(gridExtra)  # load gridExtra
# coerce DAX time series to zoo
zoo.dax <- as.zoo(EuStockMarkets)[, 1]
index(zoo.dax) <-  # index to class 'Dates'
  as.Date(365*(index(zoo.dax)-1970))
# filter past values only (sides=1)
dax.filt <- filter(zoo.dax, 
                   filter=rep(1/5,5), sides=1)
dax.filt <- zoo(coredata(dax.filt), 
                order.by=index(zoo.dax))
dax.filt <- merge(zoo.dax, dax.filt)
dax.filt <- na.omit(dax.filt)
colnames(dax.filt) <- c("DAX", "DAX filtered")
dax.data <- window(dax.filt, 
                   start=as.Date("1997-01-01"), 
                   end=as.Date("1998-01-01"))
autoplot(  # plot ggplot2
    dax.data, main="Filtered DAX", facets=NULL
      ) +  # end autoplot
xlab("") + ylab("") +
theme(  # modify plot theme
    legend.position=c(0.1, 0.5), 
    plot.title=element_text(vjust=-2.0), 
    plot.margin=unit(c(-0.5, 0.0, -0.5, 0.0), "cm"), 
    plot.background=element_blank(),
    axis.text.y=element_blank()
    )  # end theme
# end ggplot2
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/dax_filter}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation Function for Filtered Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Filtering a time series creates spurious autocorrelations,
      <<dax_filter_acf,echo=1:30,fig.height=8,fig.show='hide'>>=
dax.diff <- na.omit(diff(log(dax.filt)))
par(mfrow=c(2,1))  # set plot panels
Acf(dax.diff[, 1], lag=20, xlab=NA, ylab=NA, 
    main="DAX")
Acf(dax.diff[, 2], lag=20, xlab=NA, ylab=NA, 
    main="DAX filtered")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/dax_filter_acf}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Partial Autocorrelation Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{partial autocorrelation} of lag $k$ is the autocorrelation after all the autocorrelations of lag $1,..., k-1$ have been removed,
        <<eustx_pacf,echo=2:30,fig.height=8,eval=TRUE,fig.show='hide'>>=
par(oma=c(1, 1, 1, 1), mgp=c(2, 0.5, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # set plot panels
# autocorrelation from "stats"
Acf(dax.diff[, 2], lag=20, xlab=NA, ylab=NA)
# autocorrelation from "forecast"
Pacf(dax.diff[, 2], lag=20, xlab=NA, ylab=NA)
      @

    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/eustx_pacf}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Improved Autocorrelation Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{acf()} from the base package \texttt{stats} returns the lag-zero autocorrelation,
      \vskip1ex
      We can easily create a wrapper function for \texttt{acf()} that omits the lag-zero autocorrelation,
      <<echo=7:30>>=
# calculate DAX percentage returns
ts.dax <- diff(log(EuStockMarkets[, 1]))
library(zoo)  # load zoo
library(ggplot2)  # load ggplot2
library(gridExtra)  # load gridExtra
library(forecast)  # load forecast
# autocorrelation from "stats"
acf.dax <- acf(ts.dax, plot=FALSE)
str(acf.dax)  # get the structure of the "acf" object
dim(acf.dax$acf)
dim(acf.dax$lag)
head(acf.dax$acf)
      @
    \column{0.5\textwidth}
      If a return value is wrapped in the function \texttt{invisible()} then it isn't printed automatically when the function is called,
      <<echo=1:30>>=
my.acf <- function (ts.data, xlab, 
                    ylab, main, ...)
# wrapper for base acf()
{
  acf.data <- acf(x=ts.data, plot=FALSE, ...)
  acf.data$acf <-  # remove first element
    array(data=acf.data$acf[-1], 
          dim=c(dim(acf.data$acf)[1]-1,1,1))
  acf.data$lag <-  # remove first element
    array(data=acf.data$lag[-1], 
          dim=c(dim(acf.data$lag)[1]-1,1,1))
  plot(acf.data, xlab=xlab, ylab=ylab, 
       main=main)
  return(invisible(acf.data))
}  # end my.acf
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{U.S. Macroeconomic Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \texttt{Ecdat} contains the \texttt{Macrodat} U.S. macroeconomic data,
      \vskip1ex
      "\texttt{lhur}" is the unemployment rate (average of months in quarter),
      \vskip1ex
      "\texttt{fygm3}" 3 month treasury bill interest rate (last month in quarter)
      <<macro_data,echo=1:30,fig.show='hide'>>=
library(Ecdat)  # load Ecdat
colnames(Macrodat)  # United States Macroeconomic Time Series
zoo.macro <- as.zoo(  # coerce to "zoo"
          Macrodat[, c("lhur", "fygm3")])
colnames(zoo.macro) <- c("unemprate", "3mTbill")
# ggplot2 in multiple panes
autoplot(  # generic ggplot2 for "zoo"
  object=zoo.macro, main="US Macro",
  facets=Series ~ .
  ) + xlab("") + # end autoplot
theme(  # modify plot theme
  legend.position=c(0.1, 0.5),
  plot.title=element_text(vjust=-2.0),
  plot.margin=unit(c(-0.5, 0.0, -0.5, 0.0), "cm"),
  plot.background=element_blank(),
  axis.text.y=element_blank()
)  # end theme
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/macro_data}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation in Macroeconomic Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Many examples of economic data display a high degree of autocorrelation,
      <<macro_corr,echo=2:30,fig.height=8,fig.show='hide'>>=
par(mfrow=c(2,1))  # set plot panels
diff.macro <- na.omit(diff(zoo.macro))

acf.unemprate <- 
  my.acf(diff.macro[, "unemprate"], lag.max=10,
  xlab="", ylab="",
  main="average quarterly unemployment rate")

acf.3mTbill <- 
  my.acf(diff.macro[, "3mTbill"], lag.max=10,
  xlab="", ylab="",
  main="3 month T-bill EOQ")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/macro_corr}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Ljung-Box Test of Autocorrelation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Ljung-Box} tests the \emph{null hypothesis} that autocorrelations are equal to zero,
      \vskip1ex
      The test statistic is:
      \begin{displaymath}
        Q = n(n+2) \sum_{k=1}^{maxlag} \frac{{\hat\rho}_{k}^2}{n-k}
      \end{displaymath}
      Where $n$ is the sample size, and the ${\hat\rho}_{k}$ are sample autocorrelations,
      \vskip1ex
      The \emph{Ljung-Box} statistic follows the \emph{chi-squared} distribution with \emph{maxlag} degrees of freedom,
      \vskip1ex
      The \emph{Ljung-Box} statistic is small for uncorrelated time series,
      \vskip1ex
      The \emph{p}-value for DAX returns is large, and we conclude that the \emph{null hypothesis} is TRUE, and the DAX returns are uncorrelated,
      \vskip1ex
      The \emph{p}-value for changes in macro data is extremely small, and we conclude that the \emph{null hypothesis} is FALSE, and the macro data are are autocorrelated,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=2:30>>=
# Ljung-Box test for DAX data
# 'lag' is the number of autocorrelation coefficients
Box.test(ts.dax, lag=10, type="Ljung")
# changes in unemployment rate are autocorrelated
Box.test(diff.macro[, "unemprate"], 
         lag=10, type="Ljung")
# changes in 3 month T-bill rate are autocorrelated
Box.test(diff.macro[, "3mTbill"], 
         lag=10, type="Ljung")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
      \column{0.5\textwidth}
        An \emph{autoregressive} time series process is defined by the formula:
        \begin{displaymath}
          x_{i} = c + {\varphi}_{1} x_{i-1} + {\varphi}_{2} x_{i-2} + \ldots + {\varphi}_{p} x_{i-p} + {\varepsilon}_{i}
        \end{displaymath}
        Where the ${\varepsilon}_{i}$ are independent random variables with zero mean and constant variance,
        \vskip1ex
        The function \texttt{arima.sim()} simulates an ARIMA process,
        \vspace{-1em}
      <<ar_process,echo=4:30,fig.height=7,fig.show='hide'>>=
# ARIMA processes
library(ggplot2)  # load ggplot2
library(gridExtra)  # load gridExtra
daily.index <- Sys.Date() + 0:999  # daily series over one year
zoo.ar <- zoo(  # AR time series of returns
  x=arima.sim(n=1000, model=list(ar=0.2)),
  order.by=daily.index)  # zoo.ar
zoo.ar <- cbind(zoo.ar, cumsum(zoo.ar))
colnames(zoo.ar) <- c("AR returns", "AR prices")
r1 <- range(zoo.ar[,1])
r2 <- range(zoo.ar[,2])
m.factor <- abs(r2[1]-r2[2])/abs(r1[1]-r1[2])
zoo.ar[,1] <- m.factor*zoo.ar[,1]
autoplot(object=zoo.ar, # plot AR returns
  main="Autoregressive process (phi=0.2)", 
  facets=Series ~ .) + xlab("") + ylab("") + 
theme(legend.position=c(0.1, 0.5), 
  plot.title=element_text(vjust=-2.0), 
  plot.margin=unit(c(-0.5, 0.0, -0.5, 0.0), "cm"), 
  plot.background=element_blank(),
  axis.text.y=element_blank())
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/ar_process}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Examples of Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
      \column{0.5\textwidth}
      <<ar_param,echo=1:30,fig.height=7,fig.show='hide'>>=
v.phis <- c(0.01, 0.4, 0.8)  # AR coefficients
zoo.ar <- sapply(  # create three AR time series
  v.phis, function(phi)
          arima.sim(n=1000, model=list(ar=phi)))
zoo.ar <- zoo(x=zoo.ar, order.by=daily.index)
zoo.ar <- cumsum(zoo.ar)  # returns to prices
colnames(zoo.ar) <- paste("autocorr", v.phis)
r1 <- range(zoo.ar[,1])
r2 <- range(zoo.ar[,2])
r3 <- range(zoo.ar[,3])
m.factor <- abs(r3[1]-r3[2])/abs(r1[1]-r1[2])
zoo.ar[,1] <- m.factor*zoo.ar[,1]
m.factor <- abs(r3[1]-r3[2])/abs(r2[1]-r2[2])
zoo.ar[,2] <- m.factor*zoo.ar[,2]
autoplot(zoo.ar, main="AR prices", 
         facets=Series ~ .) + xlab("") + 
theme(legend.position=c(0.1, 0.5), 
  plot.title=element_text(vjust=-2.0), 
  plot.margin=unit(c(-0.5, 0.0, -0.5, 0.0), "cm"), 
  plot.background=element_blank(),
  axis.text.y=element_blank())
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/ar_param}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation in Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An \emph{autoregressive} process of order \emph{one} \emph{AR}(1) is defined by the formula:
      \begin{displaymath}
        x_{i} = c + {\varphi}_{1} x_{i-1} + {\varepsilon}_{i}
      \end{displaymath}
      An \emph{AR}(1) process has an exponentially declining ACF and a non-zero PACF at lag one,
      <<ar_acf,echo=2:30,fig.height=8,fig.show='hide'>>=
par(mfrow=c(2,1))  # set plot panels
# ACF of AR(1) process
my.acf(na.omit(diff(zoo.ar[,3])), lag.max=10, 
       xlab="", ylab="", main="ACF of AR(1) process")

# PACF of AR(1) process
pacf(na.omit(diff(zoo.ar[,3])), lag.max=10,
     xlab="", ylab="", main="PACF of AR(1) process")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/ar_acf}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Identification of Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An \emph{AR}(3) process of order \emph{three} is defined by the formula:
      \begin{displaymath}
        x_{i} = c + {\varphi}_{1} x_{i-1} + {\varphi}_{2} x_{i-2} + {\varphi}_{3} x_{i-3} + {\varepsilon}_{i}
      \end{displaymath}
      Autoregressive processes \emph{AR}(n) of order \emph{n} have an exponentially declining ACF and a non-zero PACF up to lag \emph{n},
      <<ar_pacf,echo=2:30,fig.height=8,fig.show='hide'>>=
par(mfrow=c(2,1))  # set plot panels
zoo.ar3 <- zoo(  # AR(3) time series of returns
  x=arima.sim(n=1000, model=list(ar=c(0.1, 0.3, 0.1))),
  order.by=daily.index)  # zoo.ar
# ACF of AR(3) process
my.acf(zoo.ar3, lag.max=10, 
       xlab="", ylab="", main="ACF of AR(3) process")

# PACF of AR(3) process
pacf(zoo.ar3, lag.max=10,
     xlab="", ylab="", main="PACF of AR(3) process")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/ar_pacf}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Fitting Autoregressive Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The function \texttt{arima()} from the base package \texttt{stats} fits a specified ARIMA model to a univariate time series,
      \vskip1ex
      The function \texttt{auto.arima()} from the package \texttt{forecast} automatically fits an ARIMA model to a univariate time series,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=1:30>>=
zoo.ar3 <- arima.sim(n=10000, 
            model=list(ar=c(0.1, 0.3, 0.1)))
arima(zoo.ar3, order = c(5,0,0))  # fit AR(5) model
auto.arima(zoo.ar3)  # fit ARIMA model
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Regression Analysis}


%%%%%%%%%%%%%%%
\subsection{Formula Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Formulas in \texttt{R} are defined using the "\textasciitilde{}" operator followed by a series of terms separated by the "\texttt{+}" operator,
      \vskip1ex
      Formulas can be defined as separate objects, manipulated, and passed to functions,
      \vskip1ex
      For example the formula "\texttt{z} \textasciitilde{} \texttt{model}" means the response variable \texttt{z} is explained by the \texttt{model},
      \vskip1ex
      The formula "\texttt{z \textasciitilde{} x + y}" represents a linear model: $z = ax  + by + c$,
      \vskip1ex
      The formula "\texttt{y \textasciitilde{} x - 1}" or "\texttt{y \textasciitilde{} x + 0}" represents a linear model with zero intercept: $y = ax$,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=1:30>>=
# linear model with zero intercept
my.form <- z ~ x + y -1
my.form

# formula from text string
my.form <- as.formula(  # coerce text strings to formula
              paste("y ~ ", 
                paste(paste0("x", 1:5), collapse="+")
                )  # end paste
            )  # end as.formula
class(my.form)
my.form
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simple Regression Example}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.3\textwidth}
      The \emph{null} hypothesis for linear regression is that the regression coefficients are \emph{zero},
      \vskip1ex
      The function \texttt{lm()} from the base package \texttt{stats} fits a linear model (regression) into the data,
      \vskip1ex
      A small \emph{p}-value for a given coefficient means that this coefficient is very likely to be non-zero,
    \column{0.7\textwidth}
      \vspace{-1em}
        <<echo=3:30,fig.show='hide'>>=
# rm(list=ls())
set.seed(1121)  # initialize random number generator
v.xvar <- 0.1*1:30  # independent variable
v.yvar <- 3 + 2*v.xvar + rnorm(30)  # dependent variable plus noise
form.simple <- v.yvar ~ v.xvar  # specify model
lm.simple <- lm(form.simple)  # perform regression
summary(lm.simple)  # regression summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\begin{frame}[fragile,t]{Plotting a Regression}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Objects of class "\texttt{lm}" have their own plot method, designed to plot diagnostic tests,
      \vskip1ex
      Calling \texttt{plot()} and \texttt{abline()} on the regression formula produces a scatterplot with the regression line,
        <<simp_reg,echo=2:30,fig.show='hide'>>=
par(oma=c(1, 1, 1, 1), mgp=c(2, 0.5, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# plot(lm.simple)  # plot diagnostic tests
plot(form.simple)  # plot regression scatterplot
abline(lm.simple, col="red")  # add reg line
title(main="Simple Regression", line=-1)

# summary data
summary(lm.simple)$coefficients
summary(lm.simple)$r.squared
      @

    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/simp_reg}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Durbin-Watson Test of Autocorrelation of Regression Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Durbin-Watson} test is designed to test the \emph{null hypothesis} that the autocorrelations of regression residuals are equal to zero,
      \vskip1ex
      The test statistic is:
      \begin{displaymath}
        DW = \frac {\sum_{i=2}^{n} (\varepsilon_{i} - \varepsilon_{i-1})^2} {\sum_{i=1}^{n} \varepsilon_{i}^2}
      \end{displaymath}
      Where $\varepsilon_{i}$ are the regression residuals,
      \vskip1ex
      The value of the \emph{Durbin-Watson} statistic \emph{DW} is close to zero for large positive autocorrelations, and close to four for large negative autocorrelations,
      \vskip1ex
      The \emph{DW} is close to two for autocorrelations close to zero,
      \vskip1ex
      The \emph{p}-value for the \texttt{lm.simple} regression is large, and we conclude that the \emph{null hypothesis} is TRUE, and the regression residuals are uncorrelated,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=2:30>>=
# Durbin-Watson test for DAX data
library(lmtest)  # load lmtest
dwtest(lm.simple)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\subsecname}

\begin{block}{Required}
  \begin{itemize}[]
    \item Create a regression function called "\texttt{my.lm()}",
    \item The input is a data frame with the data in columns, and a formula object,
    \item The function should perform a regression by calling the function "\texttt{lm()}",
    \item The function should return a list object with summary information: regression coefficients, \emph{t}-values, \emph{p}-values, \emph{R}-squared, and the results of the Durbin-Watson test,
    \item The function should test for a variety of possible inputs: formula, character, matrix, etc.,
    \item The function should throw an error if the input is not a formula object,
  \end{itemize}
\end{block}
\pause

\begin{block}{Recommended}
  \begin{itemize}[]
    \item \fullcite{website:ggplot2}
    \item \fullcite{website:ggplot2cook}
  \end{itemize}
\end{block}

\end{frame}


\end{document}
