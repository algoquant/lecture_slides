% FRE6871_Lecture_6
% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{array}
\usepackage{multirow}
\usepackage{mathtools}
% bbold package for unitary vector or matrix symbol
\usepackage{bbold}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
\usepackage{listings}
\usepackage{xcolor}
\definecolor{anti_flashwhite}{rgb}{0.95, 0.95, 0.96}
\definecolor{cmd_background}{rgb}{0.2, 0.2, 0.0}
\definecolor{vba_background}{rgb}{0.0, 0.0, 0.9}
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE6871 Lecture\#6]{FRE6871 \texttt{R} in Finance}
\subtitle{Lecture\#6, Spring 2020}

\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@poly.edu}
\date{May 11, 2020}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Manipulating Lists and Data Frames}


%%%%%%%%%%%%%%%
\subsection{Flattening a List of Vectors to a Matrix Using \texttt{do.call()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A list of vectors can be flattened into a matrix using the functions \texttt{do.call()} and either \texttt{rbind()} or \texttt{cbind()}.
      \vskip1ex
      If the list contains vectors of different lengths, then \texttt{R} applies the recycling rule.
      \vskip1ex
      If the list contains a \texttt{NULL} element, that element is skipped.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Create list of vectors
li_st <- lapply(1:3, function(x) sample(6))
# Bind list elements into matrix - doesn't work
rbind(li_st)
# Bind list elements into matrix - tedious
rbind(li_st[[1]], li_st[[2]], li_st[[3]])
# Bind list elements into matrix - works!
do.call(rbind, li_st)
# Create numeric list
li_st <- list(1, 2, 3, 4)
do.call(rbind, li_st)  # returns single column matrix
do.call(cbind, li_st)  # returns single row matrix
# recycling rule applied
do.call(cbind, list(1:2, 3:5))
# NULL element is skipped
do.call(cbind, list(1, NULL, 3, 4))
# NA element isn't skipped
do.call(cbind, list(1, NA, 3, 4))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Efficient Binding of Lists Into Matrices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A list of vectors can be flattened into a matrix using the functions \texttt{do.call()} and either \texttt{rbind()} or \texttt{cbind()}.
      \vskip1ex
      But for large vectors this procedure can be very slow, and often causes an out of memory error.
      \vskip1ex
      The function \texttt{do\_call\_rbind()} efficiently combines a list of vectors into a matrix.
      \vskip1ex
      \texttt{do\_call\_rbind()} produces the same result as \texttt{do.call(rbind, list\_var)}, but using recursion.
      \vskip1ex
      \texttt{do\_call\_rbind()} calls lapply in a loop, each time binding neighboring list elements and dividing the length of the list by half.
      \vskip1ex
      \texttt{do\_call\_rbind()} is the same function as \texttt{do.call.rbind()} from package \emph{qmao}:\\
\hskip1em\url{https://r-forge.r-project.org/R/?group_id=1113}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)), eval=FALSE>>=
library(microbenchmark)
list_vectors <- lapply(1:5, rnorm, n=10)
mat_rix <- do.call(rbind, list_vectors)
dim(mat_rix)
do_call_rbind <- function(li_st) {
  while (NROW(li_st) > 1) {
# index of odd list elements
    odd_index <- seq(from=1, to=NROW(li_st), by=2)
# Bind odd and even elements, and divide li_st by half
    li_st <- lapply(odd_index, function(in_dex) {
      if (in_dex==NROW(li_st)) return(li_st[[in_dex]])
      rbind(li_st[[in_dex]], li_st[[in_dex+1]])
    })  # end lapply
  }  # end while
# li_st has only one element - return it
  li_st[[1]]
}  # end do_call_rbind
identical(mat_rix, do_call_rbind(list_vectors))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Filtering Data Frames Using \texttt{subset()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Filtering} means extracting rows from a \emph{data frame} that satisfy a logical condition.
      \vskip1ex
      \emph{Data frames} can be filtered using Boolean vectors and brackets \texttt{"[]"} operators.
      \vskip1ex
      The function \texttt{subset()} filters \emph{data frames}, by applying logical conditions to its columns, using the column names.
      \vskip1ex
      \texttt{subset()} provides a succinct notation and discards \texttt{NA} values, but it's slightly slower than using \texttt{Boolean} vectors and brackets \texttt{"[]"} operators.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)), eval=FALSE>>=
library(microbenchmark)
airquality[(airquality$Solar.R>320 &
              !is.na(airquality$Solar.R)), ]
subset(x=airquality, subset=(Solar.R>320))
summary(microbenchmark(
    subset=subset(x=airquality, subset=(Solar.R>320)),
    brackets=airquality[(airquality$Solar.R>320 &
                  !is.na(airquality$Solar.R)), ],
times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Splitting Data Frames Using \texttt{factor} Categorical Variables}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{split()} divides an object into a list of objects, according to a \texttt{factor} (categorical variable).
      \vskip1ex
      The list's \texttt{names} attribute is equal to the \texttt{factor} levels.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
unique(iris$Species)  # Species has three distinct values
# Split into separate data frames by hand
set_osa <- iris[iris$Species=="setosa", ]
versi_color <- iris[iris$Species=="versicolor", ]
virgin_ica <- iris[iris$Species=="virginica", ]
dim(set_osa)
head(set_osa, 2)
# Split iris into list based on Species
split_iris <- split(iris, iris$Species)
str(split_iris, max.level=1)
names(split_iris)
dim(split_iris$setosa)
head(split_iris$setosa, 2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{split-apply-combine} Procedure}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{split-apply-combine} procedure consists of:
      \begin{itemize}
        \item dividing an object into a list, according to a factor (attribute).
        \item applying a function to each list element.
        \item combining the results.
      \end{itemize}
      The \emph{split-apply-combine} procedure is also called the \emph{map-reduce} procedure, or simply \emph{data pivoting}, and it's similar to \emph{pivot tables} in \emph{Excel}.
      \vskip1ex
      \emph{Data pivoting} can be performed \emph{data frames}, by aggregating its columns based on categorical data stored in one of its columns.
      \vskip1ex
      You can read more about the \emph{split-apply-combine} procedure in Hadley Wickham's paper:\\
      \url{http://www.jstatsoft.org/v40/i01/paper}
      \vskip1ex
    \column{0.5\textwidth}
      \hskip1em\includegraphics[width=0.45\paperwidth]{figure/split_apply_combine_procedure.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Data Pivoting} Example}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Data pivoting} can be performed through successive applications of functions \texttt{split()}, \texttt{apply()}, and \texttt{unlist()}.
      \vskip1ex
      A \emph{data frame} can be \emph{pivoted} either by first splitting it into a list of \emph{data frames} and then aggregating, or by splitting just a single column and aggregating it.
      \vskip1ex
      The function \texttt{split()} divides an object into a list of objects, according to a \texttt{factor} (categorical variable).
      \vskip1ex
      The list's \texttt{names} attribute is equal to the \texttt{factor} levels.
      \vskip1ex
      The functional \texttt{aggregate()} \emph{pivots} the columns of a \emph{data frame}.
      \vskip1ex
      \texttt{aggregate()} can accept a \texttt{"formula"} argument with the column names, or it can accept \texttt{"x"} and \texttt{"by"} arguments with the columns.
      \vskip1ex
      \texttt{aggregate()} returns a \emph{data frame} containing the names of the groups (\texttt{factor} levels).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
unique(mtcars$cyl)  # cyl has three unique values
# Split mpg column based on number of cylinders
split(mtcars$mpg, mtcars$cyl)
# Split mtcars data frame based on number of cylinders
split_cars <- split(mtcars, mtcars$cyl)
str(split_cars, max.level=1)
names(split_cars)
# Aggregate the mean mpg over split mtcars data frame
sapply(split_cars, function(x) mean(x$mpg))
# Or: split mpg column and aggregate the mean
sapply(split(mtcars$mpg, mtcars$cyl), mean)
# Same but using with()
with(mtcars, sapply(split(mpg, cyl), mean))
# Or: aggregate() using formula syntax
aggregate(formula=(mpg ~ cyl), data=mtcars, 
          FUN=mean)
# Or: aggregate() using data frame syntax
aggregate(x=mtcars$mpg, 
  by=list(cyl=mtcars$cyl), FUN=mean)
# Or: using name for mpg
aggregate(x=list(mpg=mtcars$mpg), 
  by=list(cyl=mtcars$cyl), FUN=mean)
# Aggregate() all columns
aggregate(x=mtcars, 
  by=list(cyl=mtcars$cyl), FUN=mean)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{tapply()} Functional}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functional \texttt{tapply()} is a specialized version of the \texttt{apply()} functional, that applies a function to elements of a \emph{jagged array}.
      \vskip1ex
      A \emph{jagged array} is a list consisting of vectors or matrices of different lengths.
      \vskip1ex
      \texttt{tapply()} accepts a vector of values \texttt{"X"}, a factor \texttt{"INDEX"}, and a function \texttt{"FUN"}.
      \vskip1ex
      \texttt{tapply()} first groups the elements of \texttt{"X"} according to the factor \texttt{"INDEX"}, transforming it into a \emph{jagged array}, and then applies \texttt{"FUN"} to each element of the \emph{jagged array}.
      \vskip1ex
      \texttt{tapply()} applies a function to sub-vectors aggregated using a factor, and performs \emph{data pivoting} in a single function call.
      \vskip1ex
      The \texttt{by()} function is a wrapper for \texttt{tapply()}.
      \vskip1ex
      The \texttt{with()} function evaluates an expression in an environment constructed from the data.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Mean mpg for each cylinder group
tapply(X=mtcars$mpg, INDEX=mtcars$cyl, FUN=mean)
# using with() environment
with(mtcars,
     tapply(X=mpg, INDEX=cyl, FUN=mean))
# Function sapply() instead of tapply()
with(mtcars,
     sapply(sort(unique(cyl)), function(x) {
       structure(mean(mpg[x==cyl]), names=x)
       }, USE.NAMES=TRUE))  # end with

# Function by() instead of tapply()
with(mtcars,
     by(data=mpg, INDICES=cyl, FUN=mean))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Data Pivoting} Returning a Matrix}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Sometimes \emph{data pivoting} returns a list of vectors.
      \vskip1ex
      A list of vectors can be flattened into a matrix using the functions \texttt{do.call()} and either \texttt{rbind()} or \texttt{cbind()}.
      \vskip1ex
     The function \texttt{do.call()} executes a function call using a function name and a list of arguments.
      \vskip1ex
      \texttt{do.call()} passes the list elements individually, instead of passing the whole list as one argument:\\
      \texttt{do.call(fun, list)=
      fun(list[[1]], list[[2]], \ldots)}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Get several mpg stats for each cylinder group
data_cars <- sapply(split_cars,
              function(x) {
                c(mean=mean(x$mpg), max=max(x$mpg), min=min(x$mpg))
              }  # end anonymous function
              )  # end sapply
data_cars  # sapply() produces a matrix
data_cars <- lapply(split_cars,  # now same using lapply
              function(x) {
                c(mean=mean(x$mpg), max=max(x$mpg), min=min(x$mpg))
              }  # end anonymous function
              )  # end sapply
is.list(data_cars)  # lapply produces a list
# do.call flattens list into a matrix
do.call(cbind, data_cars)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Data Pivoting} of Panel Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{data frame} \texttt{panel\_data} contains fundamental financial data for \emph{S\&P500} stocks.
      \vskip1ex
      The \texttt{Industry} column has \texttt{22} unique elements, while the \texttt{Sector} column has \texttt{10} unique elements.
      \vskip1ex
      Each \texttt{Industry} belongs to a single \texttt{Sector}, but each \texttt{Sector} may have several \texttt{Industries} that belong to it.
      \vskip1ex
      The functional \texttt{aggregate()} allows aggregating over the \texttt{Industry} column, by perforing \emph{data pivoting}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Download CRSPpanel.txt from NYU Classes
# Read the file using read.table() with header and sep arguments
panel_data <- read.table(file="C:/Develop/lecture_slides/data/CRSPpanel.txt", 
                         header=TRUE, sep="\t")
# Split panel_data based on Industry column
split_panel <- split(panel_data, panel_data$Industry)
# number of companies in each Industry
sapply(split_panel, NROW)
# number of Sectors that each Industry belongs to
sapply(split_panel, function(x) {
  NROW(unique(x$Sector))
})  # end sapply
# Or
aggregate(formula=(Sector ~ Industry), 
  data=panel_data, FUN=function(x) NROW(unique(x)))
# Industries and the Sector to which they belong
aggregate(formula=(Sector ~ Industry), 
  data=panel_data, FUN=unique)
# Or
with(panel_data, aggregate(x=Sector, 
  by=list(Industry), FUN=unique))
# Or
with(panel_data, sapply(levels(Industry), 
  function(x) {
    Sector[match(x, Industry)]
  }))  # end sapply
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Data Pivoting} Returning a \protect\emph{Jagged Array}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{jagged array} is a list consisting of vectors or matrices of different lengths.
      \vskip1ex
      The functional \texttt{aggregate()} returns a \emph{data frame}, so it's output must be coerced if the \emph{data pivoting} attempts to return a \emph{jagged array}.
      \vskip1ex
      The functional \texttt{tapply()} returns an array, so it's output must be coerced if the \emph{data pivoting} attempts to return a \emph{jagged array}.
      \vskip1ex
      \texttt{tapply()} accepts a vector of values \texttt{"X"}, a factor \texttt{"INDEX"}, and a function \texttt{"FUN"}.
      \vskip1ex
      \texttt{tapply()} first groups the elements of \texttt{"X"} according to the factor \texttt{"INDEX"}, transforming it into a \emph{jagged array}, and then applies \texttt{"FUN"} to each element of the \emph{jagged array}.
      \vskip1ex
      \texttt{tapply()} applies a function to sub-vectors aggregated using a factor, and performs \emph{data pivoting} in a single function call.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Split panel_data based on Sector column
split_panel <- split(panel_data, panel_data$Sector)
# number of companies in each Sector
sapply(split_panel, NROW)
# Industries belonging to each Sector (jagged array)
sec_ind <- sapply(split_panel, 
  function(x) unique(as.vector(x$Industry)))
# Or use aggregate() (returns a data frame)
sec_ind2 <- aggregate(formula=(Industry ~ Sector), 
  data=panel_data, FUN=function(x) unique(as.vector(x)))
# Or use aggregate() with "by" argument
sec_ind2 <- with(panel_data, 
  aggregate(x=Industry, by=list(Sector), 
    FUN=function(x) as.vector(unique(x))))
# Coerce sec_ind2 into a jagged array
name_s <- as.vector(sec_ind2[, 1])
sec_ind2 <- sec_ind2[, 2]
names(sec_ind2) <- name_s
all.equal(sec_ind2, sec_ind)
# Or use tapply() (returns an array)
sec_ind2 <- with(panel_data, 
  tapply(X=as.vector(Industry), INDEX=Sector, FUN=unique))
# Coerce sec_ind2 into a jagged array
sec_ind2 <- drop(as.matrix(sec_ind2))
all.equal(sec_ind2, sec_ind)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Data Pivoting} Over Multiple Columns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Data pivoting} over multiple columns can be performed by splitting the \emph{data frame} and then performing an sapply() loop using an anonymous function.
      \vskip1ex
      Splitting the \emph{data frame} allows aggregations over multiple columns.
      \vskip1ex
      An anonymous function allows applying different aggregations on the same column.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Average ROE in each Industry
with(panel_data, 
  sapply(split(ROE, Industry), mean))
# Average, min, and max ROE in each Industry
t(with(panel_data, 
  sapply(split(ROE, Industry), 
    FUN=function(x) 
      c(mean=mean(x), max=max(x), min=min(x)))))
# Split panel_data based on Industry column
split_panel <- split(panel_data, 
  panel_data$Industry)
# Average ROE and EPS in each Industry
t(sapply(split_panel, FUN=function(x) 
  c(mean_roe=mean(x$ROE), 
    mean_eps=mean(x$EPS.EXCLUDE.EI))))
# Or: split panel_data based on Industry column
split_panel <- 
  split(panel_data[, c("ROE", "EPS.EXCLUDE.EI")], 
  panel_data$Industry)
# Average ROE and EPS in each Industry
t(sapply(split_panel, 
  FUN=function(x) sapply(x, mean)))
# Average ROE and EPS using aggregate()
aggregate(x=panel_data[, c("ROE", "EPS.EXCLUDE.EI")], 
  by=list(panel_data$Industry), 
  FUN=mean)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Debugging and Exception Handling}


%%%%%%%%%%%%%%%
\subsection{Exception Conditions: Errors and Warnings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Exception conditions} are \texttt{R} objects containing information about \emph{errors} or \emph{warnings} produced while evaluating expressions.
      \vskip1ex
      The function \texttt{warning()} produces a \emph{warning} condition, but doesn't halt function execution, and returns its message to the warning handler.
      \vskip1ex
      The function \texttt{stop()} produces an \emph{error} condition, halts function execution, and returns its message to the error handler.
      \vskip1ex
      The handling of \emph{warning} conditions depends on the value of \texttt{options("warn")}:
      \begin{itemize}
        \item \emph{negative} then warnings are ignored,
        \item \emph{zero} then warnings are stored and printed after the top-level function has completed,
        \item \emph{one} - warnings are printed as they occur,
        \item \emph{two} or larger - warnings are turned into errors,
      \end{itemize}
      The function \texttt{suppressWarnings()} evaluates its expressions and ignores all warnings.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# ?options  # Get info on global options
getOption("warn")  # Global option for "warn"
options("warn")  # Global option for "warn"
getOption("error")  # Global option for "error"
sqrt_safe <- function(in_put) {
# returns its argument
  if (in_put<0) {
    warning("sqrt_safe: in_put is negative")
    NULL  # return NULL for negative argument
  } else {
    sqrt(in_put)
  }  # end if
}  # end sqrt_safe
sqrt_safe(5)
sqrt_safe(-1)
options(warn=-1)
sqrt_safe(-1)
options(warn=0)
sqrt_safe()
options(warn=1)
sqrt_safe()
options(warn=3)
sqrt_safe()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Function Arguments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Argument validation consists of first determining if any arguments are \emph{missing}, and then determining if the arguments are of the correct \emph{type}.
      \vskip1ex
      An argument is \emph{missing} when the formal argument is not bound to an actual value in the function call.
      \vskip1ex
      The function \texttt{missing()} returns \texttt{TRUE} if an argument is missing, and \texttt{FALSE} otherwise.
      \vskip1ex
      Missing arguments can be detected by:\\
      - assigning a \texttt{NULL} default value to formal arguments and then calling  \texttt{is.null()} on them,\\
      - calling the function \texttt{missing()} on the arguments.
      \vskip1ex
      The argument \emph{type} can be validated using functions such as \texttt{is.numeric()}, \texttt{is.character()}, etc.
      \vskip1ex
      The function \texttt{return()} returns its argument and terminates futher function execution.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Function vali_date validates its arguments
vali_date <- function(in_put=NULL) {
# Check if argument is valid and return double
  if (is.null(in_put)) {
    return("vali_date: in_put is missing")
  } else if (is.numeric(in_put)) {
    2*in_put
  } else cat("vali_date: in_put not numeric")
}  # end vali_date
vali_date(3)
vali_date("a")
vali_date()
# vali_date validates arguments using missing()
vali_date <- function(in_put) {
# Check if argument is valid and return double
  if (missing(in_put)) {
    return("vali_date: in_put is missing")
  } else if (is.numeric(in_put)) {
    2*in_put
  } else cat("vali_date: in_put is not numeric")
}  # end vali_date
vali_date(3)
vali_date("a")
vali_date()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Assertions Inside Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If assertions about variables inside a function are \texttt{FALSE}, then \texttt{stop()} can be called to halt its execution.
      \vskip1ex
      Calling \texttt{stop()} is preferable to calling \texttt{return()}, or inserting \texttt{cat()} statements into the code.
      \vskip1ex
      Using \texttt{stop()} inside a function allows calling the function \texttt{traceback()}, if an error was produced.
      \vskip1ex
      The function \texttt{traceback()} prints the call stack, showing the function that produced the \emph{error} condition.
      \vskip1ex
      \texttt{cat()} statements inside the function body provide information about the state of its variables.
    \column{0.5\textwidth}
      \vspace{-1em}
            <<echo=TRUE,eval=FALSE>>=
# vali_date() validates its arguments and assertions
vali_date <- function(in_put) {
# Check if argument is valid and return double
  if (missing(in_put)) {
    stop("vali_date: in_put is missing")
  } else if (!is.numeric(in_put)) {
    cat("in_put=", in_put)
    stop("vali_date: in_put is not numeric")
  } else 2*in_put
}  # end vali_date
vali_date(3)
vali_date("a")
vali_date()
      @
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Print the call stack
traceback()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Assertions Using \texttt{stopifnot()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} provides robust validation and debugging tools through \emph{type} validation functions, and functions \texttt{missing()}, \texttt{stop()}, and \texttt{stopifnot()}.
      \vskip1ex
      If the argument to function \texttt{stopifnot()} is \texttt{FALSE}, then it produces an \emph{error} condition, and halts function execution.
      \vskip1ex
      \texttt{stopifnot()} is a convenience wrapper for \texttt{stop()}, and eliminates the need to use \texttt{if ()} statements.
      \vskip1ex
      \texttt{stopifnot()} is often used to check the validity of function arguments.
      \vskip1ex
      \texttt{stopifnot()} can be inserted anywhere in the function body in order to check assertions about its variables.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
vali_date <- function(in_put) {
# Check argument using long form '&&' operator
  stopifnot(!missing(in_put) &&
              is.numeric(in_put))
  2*in_put
}  # end vali_date
vali_date(3)
vali_date()
vali_date("a")
vali_date <- function(in_put) {
# Check argument using logical '&' operator
  stopifnot(!missing(in_put) & is.numeric(in_put))
  2*in_put
}  # end vali_date
vali_date()
vali_date("a")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Function Arguments and Assertions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functions \texttt{stop()} and \texttt{stopifnot()} halt function execution and produce \emph{error} conditions if certain assertions are \texttt{FALSE}.
      \vskip1ex
      The \emph{type} validation functions, such as \texttt{is.numeric()}, \texttt{is.na()}, etc., and \texttt{missing()}, allow for validation of arguments and variables inside functions.
      \vskip1ex
      \texttt{cat()} statements can provide information about the state of variables inside a function.
      \vskip1ex
      \texttt{cat()} statements don't return values, so they provide information even when a function produces an \texttt{error}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# sum_two() returns the sum of its two arguments
sum_two <- function(in_put1, in_put2) {  # Even more robust
# Check if at least one argument is not missing
  stopifnot(!missing(in_put1) &&
              !missing(in_put2))
# Check if arguments are valid and return sum
  if (is.numeric(in_put1) &&
      is.numeric(in_put2)) {
    in_put1 + in_put2  # Both valid
  } else if (is.numeric(in_put1)) {
    cat("in_put2 is not numeric\n")
    in_put1  # in_put1 is valid
  } else if (is.numeric(in_put2)) {
    cat("in_put1 is not numeric\n")
    in_put2  # in_put2 is valid
  } else {
    stop("none of the arguments are numeric")
  }
}  # end sum_two
sum_two(1, 2)
sum_two(5, 'a')
sum_two('a', 5)
sum_two('a', 'b')
sum_two()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{R} Debugger Facility}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{debug()} flags a function for future debugging, but doesn't invoke the debugger.
      \vskip1ex
      After a function is flagged for debugging with the call \texttt{"debug(my\_func)"}, then the function call \texttt{"my\_func()"} automatically invokes the debugger (browser).
      \vskip1ex
      When the debugger is first invoked, it prints the function code to the console, and produces a \emph{browser} prompt: \texttt{"Browse[2]>"}.
      \vskip1ex
      Once inside the debugger, the user can execute the function code one command at a time by pressing the \emph{Enter} key.
      \vskip1ex
      The user can examine the function arguments and variables with standard \texttt{R} commands, and can also change the values of objects or create new ones.
      \vskip1ex
      The command \texttt{"c"} executes the remainder of the function code without pausing.
      \vskip1ex
      The command \texttt{"Q"} exits the debugger (browser).
      \vskip1ex
      The call \texttt{"undebug(my\_func)"} at the \texttt{R} prompt unflags the function for debugging.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Flag "vali_date" for debugging
debug(vali_date)
# Calling "vali_date" starts debugger
vali_date(3)
# unflag "vali_date" for debugging
undebug(vali_date)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Debugging Using \texttt{browser()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      As an alternative to flagging a function for debugging, the user can insert the function \texttt{browser()} into the function body.
      \vskip1ex
      \texttt{browser()} pauses the execution of a function and invokes the debugger (browser) at the point where \texttt{browser()} was called.
      \vskip1ex
      Once inside the debugger, the user can execute all the same browser commands as when using \texttt{debug()}.
      \vskip1ex
      \texttt{browser()} is usually inserted just before the command that is suspected of producing an \emph{error} condition.
      \vskip1ex
      Another alternative to flagging a function for debugging, or inserting \texttt{browser()} calls, is setting the \texttt{"error"} option equal to \texttt{"recover"}.
      \vskip1ex
      Setting the \texttt{"error"} option equal to \texttt{"recover"} automatically invokes the debugger when an \emph{error} condition is produced.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
vali_date <- function(in_put) {
  browser()  # Pause and invoke browser
# Check argument using long form '&&' operator
  stopifnot(!missing(in_put) &&
              is.numeric(in_put))
  2*in_put
}  # end vali_date
vali_date()  # invokes debugger
options("error")  # Show default NULL "error" option
options(error=recover)  # Set "error" option to "recover"
options(error=NULL)  # Set back to default "error" option
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Using the Debugger in \protect\emph{RStudio}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{RStudio} has several built-in debugging facilities that complement those already installed in \texttt{R}:
      \begin{itemize}
        \item toggling breakpoints, instead of inserting \texttt{browser()} commands,
        \item stepping into functions,
        \item environment pane with environment stack, instead of calling \texttt{ls()},
        \item traceback pane, instead of calling \texttt{traceback()},
      \end{itemize}
      \emph{RStudio} provides an online debugging tutorial:
      \hskip1em\url{https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio}
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{image/rstudio_debug.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Handling Exception Conditions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{tryCatch()} executes functions and expressions, and handles any \emph{exception conditions} produced when they are evaluated.
      \vskip1ex
      \texttt{tryCatch()} first evaluates its \texttt{"expression"} argument.
      \vskip1ex
      If no error or warning \texttt{condition} is produced then \texttt{tryCatch()} just returns the value of the expression.
      \vskip1ex
      If an \texttt{exception condition} is produced then \texttt{tryCatch()} invokes error and warning \emph{handlers} and executes other expressions to provide information about the \texttt{exception condition}.
      \vskip1ex
      If a \emph{handler} is provided to \texttt{tryCatch()} then the error is captured by the \emph{handler}, instead of being broadcast to the console.
      \vskip1ex
      At the end, \texttt{tryCatch()} evaluates the expression provided to the \texttt{finally} argument.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
str(tryCatch)  # Get arguments of tryCatch()
tryCatch(  # Without error handler
  {  # Evaluate expressions
    num_var <- 101  # Assign
    stop('my error')  # Produce error
  },
  finally=print(paste("num_var=", num_var))
)  # end tryCatch

tryCatch(  # With error handler
  {  # Evaluate expressions
    num_var <- 101  # Assign
    stop('my error')  # Produce error
  },
  # Error handler captures error condition
  error=function(error_cond) {
    print(paste("error handler: ", error_cond))
  },  # end error handler
  # Warning handler captures warning condition
  warning=function(warning_cond) {
    print(paste("warning handler: ", warning_cond))
  },  # end warning handler
  finally=print(paste("num_var=", num_var))
)  # end tryCatch
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Error Conditions in Loops}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If an \emph{error} occurs in an \texttt{apply()} loop, then the loop exits without returning any result.
      \vskip1ex
      \texttt{apply()} collects the values returned by the function supplied to its \texttt{FUN} argument, and returns them only after the loop is finished.
      \vskip1ex
      If one of the function calls produces an error, then the loop is interrupted and \texttt{apply()} exits without returning any result.
      \vskip1ex
      The function \texttt{tryCatch()} captures errors, allowing loops to continue after the error \texttt{condition}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1))>>=
rm(list=ls())
# Apply loop without tryCatch
apply(as.matrix(1:5), 1, function(num_var) {  # Anonymous function
    stopifnot(num_var != 3)  # Check for error
    # Broadcast message to console
    cat("(cat) num_var =", num_var, "\n")
    # return a value
    paste("(return) num_var =", num_var)
  }  # end anonymous function
)  # end apply
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exception Handling in Loops}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the body of the function supplied to the \texttt{FUN} argument is wrapped in \texttt{tryCatch()}, then the loop can finish without interruption and return its results.
      \vskip1ex
      The messages produced by \emph{errors} and \emph{warnings} can be caught by \emph{handlers} (functions) that are supplied to \texttt{tryCatch()}.
      \vskip1ex
      The \emph{error} and \emph{warning} messages are bound (passed) to the formal arguments of the \emph{handler} functions that are supplied to \texttt{tryCatch()}.
      \vskip1ex
      \texttt{tryCatch()} always evaluates the expression provided to the \texttt{finally} argument, even after an \emph{error} occurs.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE>>=
# Apply loop with tryCatch
apply(as.matrix(1:5), 1, function(num_var) {  # Anonymous function
    tryCatch(  # With error handler
      {  # Body
        stopifnot(num_var != 3)  # Check for error
        # Broadcast message to console
        cat("(cat) num_var =", num_var, "\t")
        # return a value
        paste("(return) num_var =", num_var)
      },
      # Error handler captures error condition
      error=function(error_cond)
        paste("handler: ", error_cond),
      finally=print(paste("(finally) num_var =", num_var))
    )  # end tryCatch
  }  # end anonymous function
)  # end apply
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Environments in \texttt{R}}


%%%%%%%%%%%%%%%
\subsection{\secname}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Environments consist of a \emph{frame} (a set of symbol-value pairs) and an \emph{enclosure} (a pointer to an enclosing environment).
      \vskip1ex
      There are three system environments:
      \begin{itemize}
        \item \texttt{globalenv()} the user's workspace,
        \item \texttt{baseenv()} the environment of the base package,
        \item \texttt{emptyenv()} the only environment without an enclosure,
      \end{itemize}
      Environments form a tree structure of successive enclosures, with the empty environment at its root.
      \vskip1ex
      Packages have their own environments.
      \vskip1ex
      The enclosure of the base package is the empty environment.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
rm(list=ls())
# Get base environment
baseenv()
# Get global environment
globalenv()
# Get current environment
environment()
# Get environment class
class(environment())
# Define variable in current environment
glob_var <- 1
# Get objects in current environment
ls(environment())
# Create new environment
new_env <- new.env()
# Get calling environment of new environment
parent.env(new_env)
# Assign Value to Name
assign("new_var1", 3, envir=new_env)
# Create object in new environment
new_env$new_var2 <- 11
# Get objects in new environment
ls(new_env)
# Get objects in current environment
ls(environment())
# Environments are subset like lists
new_env$new_var1
# Environments are subset like lists
new_env[["new_var1"]]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{R} Search Path}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} evaluates variables using the search path, a series of environments:
      \begin{itemize}
        \item global environment,
        \item package environments,
        \item base environment,
      \end{itemize}
      The function \texttt{search()} returns the search path for \texttt{R} objects.
      \vskip1ex
      The function \texttt{attach()} attaches objects to the search path.
      \vskip1ex
      Using \texttt{attach()} allows referencing object components by their names alone, rather than as components of objects.
      \vskip1ex
      The function \texttt{detach()} detaches objects from the search path.
      \vskip1ex
      The function \texttt{find()} finds where objects are located on the search path.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=TRUE>>=
search()  # Get search path for R objects
my_list <-
  list(flowers=c("rose", "daisy", "tulip"),
       trees=c("pine", "oak", "maple"))
my_list$trees
attach(my_list)
trees
search()  # Get search path for R objects
detach(my_list)
head(trees)  # "trees" is in datasets base package
      @
      \begin{block}{\color{red}{Rule of Thumb}}
        Be very careful with using \texttt{attach()}.
        \vskip1ex
        Make sure to \texttt{detach()} objects once they're not needed.
      \end{block}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Extracting Time Series from Environments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Time series can be extracted from an \emph{environment} by coercing it into a \texttt{list}, and then subsetting and merging it into an \emph{xts} using the function \texttt{do.call()}.
      \vskip1ex
      A list of \emph{xts} can be flattened into a single \emph{xts} using the function \texttt{do.call()}.
      \vskip1ex
      The function \texttt{do.call()} executes a function call using a function name and a list of arguments.
      \vskip1ex
      \texttt{do.call()} passes the list elements individually, instead of passing the whole list as one argument.
      \vskip1ex
      The extractor (accessor) functions \texttt{Ad()}, \texttt{Vo()}, etc., from package \emph{quantmod}, extract columns from \emph{OHLC} data.
      \vskip1ex
      The function \texttt{eapply()} is similar to \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(HighFreq)  # Load package HighFreq
# ETF symbols
sym_bols <- c("VTI", "VEU", "IEF", "VNQ")
# Extract and merge all data, subset by sym_bols
price_s <- rutils::do_call(cbind,
  lapply(sym_bols, function(sym_bol) {
    quantmod::Ad(get(sym_bol, envir=rutils::etf_env))
}))
# Extract and merge adjusted prices, subset by sym_bols
price_s <- rutils::do_call(cbind,
  lapply(as.list(rutils::etf_env)[sym_bols], 
         quantmod::Ad))
# Same, but works only for OHLC series
price_s <- rutils::do_call(cbind,
  eapply(rutils::etf_env, quantmod::Ad)[sym_bols])
# Drop ".Adjusted" from colnames
colnames(price_s) <- sapply(colnames(price_s),
    function(col_name)
      strsplit(col_name, split="[.]")[[1]])[1, ]
tail(price_s[, 1:2], 3)
# Which objects in global environment are class xts?
unlist(eapply(globalenv(), is.xts))
# Save xts to csv file
write.zoo(price_s, file="etf_series.csv", sep=",")
# Copy price_s into etf_env and save to .RData file
assign("price_s", price_s, envir=etf_env)
save(etf_env, file="etf_data.RData")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Referencing Object Components Using \texttt{with()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{with()} evaluates an expression in an environment constructed from the data.
      \vskip1ex
      \texttt{with()} allows referencing object components by their names alone.
      \vskip1ex
      It's often better to use \texttt{with()} instead of \texttt{attach()}.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=TRUE>>=
# "trees" is in datasets base package
head(trees, 3)
colnames(trees)
mean(Girth)
mean(trees$Girth)
with(trees,
     c(mean(Girth), mean(Height), mean(Volume)))
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Time Series of Asset Prices}



%%%%%%%%%%%%%%%
\subsection{Monte Carlo Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Monte Carlo} simulation consists of generating random samples from a given probability distribution.
      \vskip1ex
      The \emph{Monte Carlo} data samples can then used to calculate different parameters of the probability distribution (moments, quantiles, etc.), and its functionals.
      \vskip1ex
      The \emph{quantile} of a probability distribution is the value of the \emph{random variable} \texttt{x}, such that the probability of values less than \texttt{x} is equal to the given \emph{probability} $p$.
      \vskip1ex
      The \emph{quantile} of a data sample can be calculated by first sorting the sample, and then finding the value corresponding closest to the given \emph{probability} $p$.
      \vskip1ex
      The function \texttt{quantile()} calculates the sample quantiles, but it's quite slow.
      \vskip1ex
      The function \texttt{sort()} returns a vector sorted into ascending order.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
n_rows <- 1000
da_ta <- rnorm(n_rows)
# Sample mean - MC estimate
mean(da_ta)
# Sample standard deviation - MC estimate
sd(da_ta)
# Monte Carlo estimate of cumulative probability
da_ta <- sort(da_ta)
pnorm(1)
sum(da_ta<1)/n_rows
# Monte Carlo estimate of quantile
conf_level <- 0.99
qnorm(conf_level)
cut_off <- conf_level*n_rows
da_ta[cut_off]
quantile(da_ta, probs=conf_level)
# Analyze the source code of quantile()
stats:::quantile.default
# Microbenchmark quantile
library(microbenchmark)
summary(microbenchmark(
  monte_carlo=da_ta[cut_off],
  quan_tile=quantile(da_ta, probs=conf_level),
  times=100))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Brownian Motion Using \texttt{while()} Loops}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{while()} loops are often used in simulations, when the number of required loops is unknown in advance.
      \vskip1ex
      Below is an example of a simulation of the path of \emph{Brownian Motion} crossing a barrier level.
      \vspace{-1em}
        <<simu_while,eval=FALSE,echo=(-(1:3)),fig.show='hide'>>=
x11(width=6, height=5)
par(oma=c(1, 1, 1, 1), mar=c(2, 2, 2, 1), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
set.seed(1121)  # Reset random number generator
bar_rier <- 20  # Barrier level
n_rows <- 1000  # Number of simulation steps
pa_th <- numeric(n_rows)  # Allocate path vector
pa_th[1] <- 0  # Initialize path
in_dex <- 2  # Initialize simulation index
while ((in_dex <= n_rows) &&
         (pa_th[in_dex - 1] < bar_rier)) {
# Simulate next step
  pa_th[in_dex] <-
    pa_th[in_dex - 1] + rnorm(1)
  in_dex <- in_dex + 1  # Advance in_dex
}  # end while
# Fill remaining pa_th after it crosses bar_rier
if (in_dex <= n_rows)
  pa_th[in_dex:n_rows] <- pa_th[in_dex - 1]
# Create daily time series starting 2011
ts_path <- ts(data=pa_th, frequency=365, start=c(2011, 1))
plot(ts_path, type="l", col="black",
     lty="solid", lwd=2, xlab="", ylab="")
abline(h=bar_rier, lwd=2, col="red")
title(main="Brownian motion crossing a barrier level",
      line=0.5)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/simu_brown_barrier.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Brownian Motion Using Vectorized Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Simulations in \texttt{R} can be accelerated by pre-computing a vector of random numbers, instead of generatng them one at a time in a loop.
      \vskip1ex
      Vectors of random numbers allow using \emph{vectorized} functions, instead of inefficient (slow) \texttt{while()} loops.
      \vspace{-1em}
        <<simu_vector,eval=FALSE,echo=(-(1:3)),fig.show='hide'>>=
x11(width=6, height=5)
par(oma=c(1, 1, 1, 1), mar=c(2, 2, 2, 1), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
set.seed(1121)  # Reset random number generator
bar_rier <- 20  # Barrier level
n_rows <- 1000  # Number of simulation steps
# Simulate path of Brownian motion
pa_th <- cumsum(rnorm(n_rows))
# Find index when pa_th crosses bar_rier
cro_ss <- which(pa_th > bar_rier)
# Fill remaining pa_th after it crosses bar_rier
if (NROW(cro_ss)>0) {
  pa_th[(cro_ss[1]+1):n_rows] <-
    pa_th[cro_ss[1]]
}  # end if
# Create daily time series starting 2011
ts_path <- ts(data=pa_th, frequency=365,
             start=c(2011, 1))
# Create plot with horizontal line
plot(ts_path, type="l", col="black",
     lty="solid", lwd=2, xlab="", ylab="")
abline(h=bar_rier, lwd=2, col="red")
title(main="Brownian motion crossing a barrier level",
      line=0.5)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/simu_brown_barrier.png}
      The trade-off between speed and memory usage: more memory may be used than necessary, since the simulation may stop before all the pre-computed random numbers are used up.
      \vskip1ex
      But the simulation is much faster because the path is simulated using \emph{vectorized} functions,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Geometric Brownian Motion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the percentage asset returns $r_t \mathrm{d} t = \mathrm{d} \log{P_t}$ follow \emph{Brownian motion}:
      \begin{displaymath}
        r_t \mathrm{d} t = \mathrm{d} \log{P_t} = ( \mu - \frac{\sigma^2}{2} ) \mathrm{d}t + \sigma \, \mathrm{d} W_t
      \end{displaymath}
      Then asset prices $P_t$ follow \emph{Geometric Brownian motion} (GBM):
      \begin{displaymath}
        \mathrm{d} P_t = \mu P_t \mathrm{d}t + \sigma \, P_t \mathrm{d} W_t
      \end{displaymath}
      Where $\sigma$ is the volatility of asset returns, and $W_t$ is a \emph{Brownian motion}, with $\mathrm{d} W_t$ following the standard normal distribution $\phi(0, \sqrt{\mathrm{d}t})$.
      \vskip1ex
      The solution of \emph{Geometric Brownian motion} is equal to:
      \begin{displaymath}
        P_t = P_0 \exp[( \mu - \frac{\sigma^2}{2} ) t + \sigma \, W_t]
      \end{displaymath}
      The convexity correction: $-\frac{\sigma^2}{2}$ ensures that the growth rate of prices is equal to $\mu$, (in accordance with Ito's lemma).
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/brown_geom.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Define daily volatility and growth rate
sigma_r <- 0.01; dri_ft <- 0.0; len_gth <- 1000
# Simulate geometric Brownian motion
re_turns <- sigma_r*rnorm(len_gth) +
  dri_ft - sigma_r^2/2
price_s <- exp(cumsum(re_turns))
plot(price_s, type="l",
     xlab="periods", ylab="prices",
     main="geometric Brownian motion")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Random \protect\emph{OHLC} Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Random \emph{OHLC} prices are useful for testing financial models.
      <<echo=TRUE,eval=FALSE>>=
# Simulate geometric Brownian motion
sigma_r <- 0.01/sqrt(48)
dri_ft <- 0.0
len_gth <- 1e4
in_dex <- seq(from=as.POSIXct(paste(Sys.Date()-250, "09:30:00")),
  length.out=len_gth, by="30 min")
price_s <- xts(exp(cumsum(sigma_r*rnorm(len_gth) + dri_ft - sigma_r^2/2)),
  order.by=in_dex)
price_s <- cbind(price_s,
  volume=sample(x=10*(2:18), size=len_gth, replace=TRUE))
# Aggregate to daily OHLC data
oh_lc <- xts::to.daily(price_s)
quantmod::chart_Series(oh_lc, name="random prices")
# dygraphs candlestick plot using pipes syntax
library(dygraphs)
dygraphs::dygraph(oh_lc[, 1:4]) %>%
  dyCandlestick()
# dygraphs candlestick plot without using pipes syntax
dygraphs::dyCandlestick(dygraphs::dygraph(oh_lc[, 1:4]))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/random_ohlc.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Log-normal} Probability Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If \texttt{x} follows the \emph{Normal} distribution $\phi(x, \mu, \sigma)$, then the exponential of \texttt{x}: $y = e^x$ follows the \emph{Log-normal} distribution $\log\phi()$:
      \begin{displaymath}
        \log\phi(y, \mu, \sigma) = \frac{\exp(-(\log{y} - \mu)^2/2 \sigma^2)}{y \sigma \, \sqrt{2 \pi}}
      \end{displaymath}
      With mean equal to: $\bar{y} = \mathbb{E}[y] = \exp(\mu + \sigma^2/2)$, and median equal to: $\tilde{y} = \exp(\mu)$
      <<echo=TRUE,eval=FALSE>>=
# Standard deviations of log-normal distribution
sig_mas <- c(0.5, 1, 1.5)
# Create plot colors
col_ors <- c("black", "red", "blue")
# Plot all curves
for (in_dex in 1:NROW(sig_mas)) {
  curve(expr=dlnorm(x, sdlog=sig_mas[in_dex]),
        type="l", xlim=c(0, 3), lwd=2,
        xlab="", ylab="", col=col_ors[in_dex],
        add=as.logical(in_dex-1))
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/log_norm_dist.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Add title and legend
title(main="Log-normal Distributions", line=0.5)
legend("topright", inset=0.05, title="Sigmas",
       paste("sigma", sig_mas, sep="="),
       cex=0.8, lwd=2, lty=rep(1, NROW(sig_mas)),
       col=col_ors)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Standard Deviation of \protect\emph{Log-normal} Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vskip1ex
      If percentage asset returns are \emph{normally} distributed and follow \emph{Brownian motion}, then asset prices follow \emph{Geometric Brownian motion}, and they are \emph{Log-normally} distributed at every point in time.
      \vskip1ex
      The standard deviation of \emph{log-normal} prices is equal to the return volatility $\sigma_r$ times the square root of time: $\sigma = \sigma_r \sqrt{t}$.
      \vskip1ex
      The \emph{Log-normal} distribution has a strong positive skewness (third moment) equal to: $\gamma = \mathbb{E}[(y - \mathbb{E}[y])^3] = (e^{\sigma^2} + 2) \sqrt{e^{\sigma^2} - 1}$
      \vskip1ex
      For large standard deviation, the skewness increases exponentially with the standard deviation and with time: $\gamma \propto e^{1.5 \sigma^2} = e^{1.5 t \sigma^2_r}$
      <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=5)
par(mar=c(4, 4, 3, 1))
# Return volatility of VTI ETF
sigma_r <- sd(rutils::diff_it(log(rutils::etf_env$VTI[, 4])))
sigmar_2 <- sigma_r^2
n_rows <- NROW(rutils::etf_env$VTI)
# Standard deviation of log-normal prices
sqrt(n_rows)*sigma_r
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/log_norm_skew.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Skewness of log-normal prices
skew_ness <- function(t) {
  ex_p <- exp(t*sigmar_2)
  (ex_p + 2)*sqrt(ex_p - 1)
}  # end skew_ness
curve(expr=skew_ness, xlim=c(1, n_rows), lwd=3,
      xlab="Number of days", ylab="Skewness", col="blue",
      main="Skewness of Log-normal Prices
      as a Function of Time")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Mean and Median of \protect\emph{Log-normal} Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The mean of the \emph{Log-normal} distribution: $\bar{y} = \mathbb{E}[y] = \exp(\mu + \sigma^2/2)$ is greater than its median, which is equal to: $\tilde{y} = \exp(\mu)$.
      \vskip1ex
      So if stock prices follow \emph{Geometric Brownian motion} and are distributed \emph{log-normally}, then a stock selected at random will have a high probability of havng a lower price than the mean expected price.
      \vskip1ex
      The cumulative \emph{Log-normal} probability distribution is equal to $\operatorname{F}(x) = \Phi(\frac{\log{y}-\mu}{\sigma})$, where $\Phi()$ is the cumulative standard normal distribution.
      \vskip1ex
      So the probability that the price of a randomly selected stock will be lower than the mean price is equal to $\operatorname{F}(\bar{y}) = \Phi(\sigma/2)$.
      \vskip1ex
      Therefore an investor without skill, who selects stocks at random, has a high probability of underperforming the index.
      \vskip1ex
      Performing as well as the index requires \emph{significant} investment skill, while outperforming the index requires \emph{exceptional} investment skill.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/log_norm_prob.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Probability that random log-normal price will be lower than the mean price
curve(expr=pnorm(sigma_r*sqrt(x)/2),
      xlim=c(1, n_rows), lwd=3,
      xlab="Number of days", ylab="Probability", col="blue",
      main="Probability That Random Log-normal Price
      Will be Lower Than the Mean Price")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Paths of Geometric Brownian Motion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The standard deviation of \emph{log-normal} prices is equal to the return volatility $\sigma_r$ times the square root of time: $\sigma = \sigma_r \sqrt{t}$.
      \vskip1ex
      For large standard deviation, the skewness $\gamma$ increases exponentially with the standard deviation and with time: $\gamma \propto e^{1.5 \sigma^2} = e^{1.5 t \sigma^2_r}$
      <<echo=TRUE,eval=FALSE>>=
# Define daily volatility and growth rate
sigma_r <- 0.01; dri_ft <- 0.0; len_gth <- 5000
path_s <- 10
# Simulate multiple paths of geometric Brownian motion
price_s <- matrix(sigma_r*rnorm(path_s*len_gth) +
    dri_ft - sigma_r^2/2, nc=path_s)
price_s <- exp(matrixStats::colCumsums(price_s))
# Create xts time series
price_s <- xts(price_s, order.by=seq.Date(Sys.Date()-NROW(price_s)+1, Sys.Date(), by=1))
# Plot xts time series
col_ors <- colorRampPalette(c("red", "blue"))(NCOL(price_s))
col_ors <- col_ors[order(order(price_s[NROW(price_s), ]))]
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
plot.zoo(price_s, main="Multiple paths of geometric Brownian motion",
         xlab=NA, ylab=NA, plot.type="single", col=col_ors)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/brown_geom_paths.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Paths of Geometric Brownian Motion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Prices following \emph{Geometric Brownian motion} have a large positive skewness, so that the expected value of prices is skewed by a few paths with very high prices, while the prices of the majority of paths are below their expected value.
      \vskip1ex
      For large standard deviation, the skewness $\gamma$ increases exponentially with the standard deviation and with time: $\gamma \propto e^{1.5 \sigma^2} = e^{1.5 t \sigma^2_r}$
      <<echo=TRUE,eval=FALSE>>=
# Define daily volatility and growth rate
sigma_r <- 0.01; dri_ft <- 0.0; len_gth <- 10000
path_s <- 100
# Simulate multiple paths of geometric Brownian motion
price_s <- matrix(sigma_r*rnorm(path_s*len_gth) +
    dri_ft - sigma_r^2/2, nc=path_s)
price_s <- exp(matrixStats::colCumsums(price_s))
# Calculate percentage of paths below the expected value
per_centage <- rowSums(price_s < 1.0) / path_s
# Create xts time series of percentage of paths below the expected value
per_centage <- xts(per_centage, order.by=seq.Date(Sys.Date()-NROW(per_centage)+1, Sys.Date(), by=1))
# Plot xts time series of percentage of paths below the expected value
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
plot.zoo(per_centage, main="Percentage of GBM paths below mean",
         xlab=NA, ylab=NA, col="blue")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/brown_geom_percent.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Time Evolution of Stock Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Stock prices evolve in time similarly to \emph{Geometric Brownian motion}, and they also exhibit a very skewed distribution of prices.
      <<echo=TRUE,eval=FALSE>>=
# Load S&P500 stock prices
load("C:/Develop/lecture_slides/data/sp500.RData")
ls(env_sp500)
# Extract closing prices
price_s <- eapply(env_sp500, quantmod::Cl)
# Flatten price_s into a single xts series
price_s <- rutils::do_call(cbind, price_s)
# Carry forward and backward non-NA prices
price_s <- xts:::na.locf.xts(price_s)
price_s <- xts:::na.locf.xts(price_s, fromLast=TRUE)
sum(is.na(price_s))
# Rename and normalize columns
colnames(price_s) <- sapply(colnames(price_s),
  function(col_name) strsplit(col_name, split="[.]")[[1]][1])
price_s <- xts(t(t(price_s) / as.numeric(price_s[1, ])),
               order.by=index(price_s))
# Calculate permution index for sorting the lowest to highest final price_s
or_der <- order(price_s[NROW(price_s), ])
# Select a few symbols
sym_bols <- colnames(price_s)[or_der]
sym_bols <- sym_bols[seq.int(from=1, to=(NROW(sym_bols)-1), length.out=20)]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/stock_index_paths.png}
    \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot xts time series of price_s
col_ors <- colorRampPalette(c("red", "blue"))(NROW(sym_bols))
col_ors <- col_ors[order(order(price_s[NROW(price_s), sym_bols]))]
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
plot.zoo(price_s[, sym_bols], main="20 S&P500 stock prices (normalized)",
         xlab=NA, ylab=NA, plot.type="single", col=col_ors)
legend(x="topleft", inset=0.05, cex=0.8,
       legend=rev(sym_bols), col=rev(col_ors), lwd=6, lty=1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Stock Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Usually, a small number of stocks in an index reach very high prices, while the prices of the majority of stocks remain below the index price (the average price of the index portfolio).
      \vskip1ex
      For example, the current prices of almost \texttt{80\%} of the S\&P500 constituent stocks from \texttt{1990} are now below the average price of that portfolio.
      \vskip1ex
      Therefore an investor without skill, who selects stocks at random, has a high probability of underperforming the index, because they will most likely miss selecting the best performing stocks.
      \vskip1ex
      Performing as well as the index requires \emph{significant} investment skill, while outperforming the index requires \emph{exceptional} investment skill.
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate average of valid stock prices
val_id <- (price_s != 1)  # valid stocks
n_stocks <- rowSums(val_id)
n_stocks[1] <- NCOL(price_s)
in_dex <- rowSums(price_s * val_id) / n_stocks
# Calculate percentage of stock prices below the average price
per_centage <- rowSums((price_s < in_dex) & val_id) / n_stocks
# Create xts time series of average stock prices
in_dex <- xts(in_dex, order.by=index(price_s))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
    %   \includegraphics[width=0.5\paperwidth]{figure/stock_index_prices.png}
    % \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/stock_index_prices_percent.png}
      <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=4)
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
# Plot xts time series of average stock prices
plot.zoo(in_dex, main="Average S&P500 stock prices (normalized from 1990)",
         xlab=NA, ylab=NA, col="blue")
# Create xts time series of percentage of stock prices below the average price
per_centage <- xts(per_centage, order.by=index(price_s))
# Plot percentage of stock prices below the average price
plot.zoo(per_centage[-(1:2),],
         main="Percentage of S&P500 stock prices below the average price",
         xlab=NA, ylab=NA, col="blue")
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{Required}
  \begin{itemize}[]
    \item Study all the lecture slides in \emph{FRE6871\_Lecture\_6.pdf}, and run all the code in \emph{FRE6871\_Lecture\_6.R}
  \end{itemize}
\end{block}
\begin{block}{Recommended}
  \begin{itemize}[]
    \item Read about \emph{PCA} in:\\
    \emph{pca-handout.pdf}\\
    \emph{pcaTutorial.pdf}\\
    \item Read about \emph{optimization methods}:\\
    \emph{Bolker Optimization Methods.pdf}\\
    \emph{Yollin Optimization.pdf}\\
    \emph{Boudt DEoptim Large Portfolio Optimization.pdf}\\
  \end{itemize}
\end{block}

\end{frame}


\end{document}
