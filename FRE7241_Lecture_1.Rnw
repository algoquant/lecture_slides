% FRE7241_Lecture1
% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size="tiny", fig.width=4, fig.height=4)
options(width=80, dev="pdf")
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[9pt]{beamer}
\DeclareMathSizes{8pt}{6pt}{6pt}{5pt}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{mathtools}
% bbm and bbold packages for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{bbold}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
\usepackage{listings}
\usepackage{xcolor}
\definecolor{anti_flashwhite}{rgb}{0.95, 0.95, 0.96}
% \bibliographystyle{amsalpha} % doesn't work
% \addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE7241 Lecture\#1]{FRE7241 Algorithmic Portfolio Management}
\subtitle{Lecture\#1, Spring 2025}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color.png}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{March 18, 2025}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Introduction}


%%%%%%%%%%%%%%%
\subsection{Welcome Students!}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      My name is Jerzy Pawlowski \href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}
      \vskip1ex
      I'm an adjunct professor at NYU Tandon because I love teaching and I want to share my professional knowledge with young, enthusiastic students.
      \vskip1ex
      I'm interested in applications of \emph{machine learning} to \emph{systematic investing}.
      \vskip1ex
      I'm an advocate of \emph{open-source software}, and I share it on GitHub:\\
      \href{https://github.com/algoquant/}{\color{blue}{My GitHub account}} 
      \vskip1ex
      In my finance career, I have worked as a hedge fund \emph{portfolio manager}, \emph{CLO banker} (structurer), and \emph{quant risk analyst}.\\
      \href{https://www.linkedin.com/in/jerzypawlowski/}{\color{blue}{My LinkedIn profile}} 
    \column{0.5\textwidth}
    \includegraphics[width=0.5\paperwidth]{image/Jerzy_Pawlowski_linked.png}
    \includegraphics[width=0.5\paperwidth]{image/github_algoquant.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Course Description and Objectives}
\begin{frame}[t]{\subsecname}
\vspace{-2em}

\begin{block}{Course Description}
  The course will apply the \texttt{R} programming language to \emph{trend following}, \emph{momentum trading}, \emph{statistical arbitrage} (pairs trading), and other active portfolio management strategies.  The course will implement volatility and price \emph{forecasting models}, asset pricing and \emph{factor models}, and \emph{portfolio optimization}.  The course will apply \emph{machine learning} techniques, such as \emph{parameter regularization} (shrinkage), \emph{bagging} and \emph{backtesting} (cross-validation).\\
  \textbf{This course is challenging, so it requires devoting a significant amount of time!}
\end{block}
\pause

\begin{block}{Course Objectives}
  Students will learn through \texttt{R} coding exercises how to:\\
  \hskip1em - download data from external sources, and to scrub and format it.\\
  \hskip1em - estimate time series parameters, and fit models such as \emph{ARIMA}, \emph{GARCH}, and factor models.\\
  \hskip1em - optimize portfolios under different constraints and risk-return objectives.\\
  \hskip1em - backtest active portfolio management strategies and evaluate their performance.\\
\end{block}
\pause

\begin{block}{Course Recommendations}
  It's recommended that you take \emph{FRE6123 Financial Risk Management and Asset Pricing}.  The \texttt{R} language is considered to be challenging, so this course requires programming experience with other languages such as \texttt{C++} or \texttt{Python}.  Students with less programming experience are encouraged to first take \emph{FRE6871 R in Finance}, and also \emph{FRE6883 Financial Computing} by prof. Song Tang.  Students should also have knowledge of basic statistics (random variables, estimators, hypothesis testing, regression, etc.)
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Homeworks and Tests}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Homeworks and Tests}
Grading will be based on homeworks and tests.  There will be no final exam.
      \vskip1ex
The tests will be announced several days in advance.
      \vskip1ex
The homeworks and tests will require writing code in \texttt{R}, which should run directly when loaded into an \texttt{R} session, and should produce the required output, \textbf{without any modifications}.
      \vskip1ex
The tests will be closely based on code contained in the lecture slides, so students are encouraged to become very familiar with those slides.
      \vskip1ex
Students must submit their homework and test files only through \emph{Brightspace} (not emails).
      \vskip1ex
Students will be allowed to copy code from the lecture slides, and to copy from books or any online sources, but they will be required to provide references to those external sources (such as links or titles and page numbers).
      \vskip1ex
Students are encouraged to use AI applications, such as ChatGPT, \href{https://copilot.github.com/}{\emph{GitHub Copilot}}, \href{https://docs.posit.co/ide/user/ide/guide/tools/copilot.html}{\emph{Copilot for RStudio}}, etc.
But you must include the name of the AI application in your solution.
      \vskip1ex
Students will be required to bring their laptop computers to class and run the \texttt{R} Interpreter, and the \texttt{RStudio} Integrated Development Environment (\emph{IDE}), during the lecture.
      \vskip1ex
Homeworks will also include reading assignments designed to help prepare for tests.
\end{block}
\pause

\begin{block}{Graduate Assistant}
The graduate assistant (GA) will be Lakshay Dua \href{mailto:ld3074@nyu.edu}{ld3074@nyu.edu}.\\
The GA will answer questions during office hours, or via \emph{Brightspace} forums, not via emails.  Please send emails regarding lecture matters from \emph{Brightspace} (not personal emails).
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Tips for Solving Homeworks and Tests}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
  \begin{block}{Tips for Solving Homeworks and Tests}
    The assignments will mostly require copying code samples from the lecture slides, making some modifications to them, and combining them with other code samples.
    \vskip1ex
    Partial credit will be given even for code that doesn't produce the correct output, but that has elements of code that can be useful for producing the right answer.
    \vskip1ex
    So don't leave test assignments unanswered, and instead copy any code samples from the lecture slides that are related to the solution and make sense.
    \vskip1ex
    Contact the GA during office hours via text or phone, and submit questions to the GA or to me via \emph{Brightspace}.
  \end{block}
\pause
  \begin{block}{Please Submit \emph{Minimal Working Examples} With Your Questions}
    When submitting questions, please provide a \emph{minimal working example} that produces the error in \texttt{R}, with the following items:
      \begin{itemize}
        \item The \emph{complete} \texttt{R} code that produces the error, including the seed value for random numbers,
        \item The version of \texttt{R} (output the of command: \texttt{sessionInfo()}), and the versions of \texttt{R} packages, 
        \item The type and version of your operating system (Windows or OSX),
        \item The dataset file used by the \texttt{R} code,
        \item The text or screenshots of error messages,
      \end{itemize}
    \vskip1ex
    You can read more about producing \emph{minimal working examples} here:
      \url{http://stackoverflow.com/help/mcve}\\
      \url{http://www.jaredknowles.com/journal/2013/5/27/writing-a-minimal-working-example-mwe-in-r}
  \end{block}
\end{frame}


%%%%%%%%%%%%%%%
\subsection{Course Grading Policies}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Numerical Scores}
  Homeworks and tests will be graded and assigned numerical scores.  
  Each part of homeworks and tests will be graded separately and assigned a numerical score.\\
  Maximum scores will be given only for complete code, that produces the correct output when it's pasted into an \texttt{R} session, without any modifications. 
  As long as the \texttt{R} code uses the required functions and produces the correct output, it will be given full credit.\\
  Partial credit will be given even for code that doesn't produce the correct output, but that has elements of code that can be useful for producing the right answer.
\end{block}
\pause

\begin{block}{Letter Grades}
  Letter grades for the course will be derived from the percentage scores obtained for all the homeworks and tests.
  The percentage scores will be calculated by adding together the scores of all the homeworks and tests, and dividing them by the sum of the maximum scores. 
  The percentage scores are usually very high - above \texttt{90\%}.  So a very high percentage score will not guarantee an A letter grade, since grading will also depend on the difficulty of the assignments.
\end{block}
\pause

\begin{block}{Plagiarism}
  Plagiarism (copying from other students) and cheating will be punished.\\
  But copying code from lecture slides, books, or any online sources is allowed and encouraged.\\
  Students must provide references to any external sources from which they copy code (such as links or titles and page numbers).
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Course Materials}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Lecture Slides}
The course will be mostly self-contained, using detailed lecture slides containing extensive, working \texttt{R} code examples.\\
The course will also utilize data and tutorials which are freely available on the internet.
\end{block}
\pause

\begin{block}{FRE7241 Recommended Textbooks}
\begin{itemize}[]
  \item \href{https://www.amazon.com/dp/1119482089/}{\emph{Advances in Financial Machine Learning}} by Marcos Lopez de Prado - Machine learning techniques applied to trading and portfolio management.
  
  \item \href{https://www.systematicmoney.org/systematic-trading}{\emph{Systematic Trading}} by Robert Carver - Practical trading knowledge by an experienced portfolio manager.
  
  \item \href{https://www.systematicmoney.org/smart}{\emph{Systematic Investing}} by Robert Carver - Practical investment knowledge by a successful investor.
  
  \item \href{https://quantstratbook.net}{\emph{Quantitative Trading}} by Xin Guo, Tze Leung Lai, Howard Shek, Samuel Po-Shing Wong - Advanced topics in quantitative trading by academic experts.
  
  \item \href{https://www.amazon.com/dp/331935731X/}{\emph{Financial Data and Models Using \texttt{R}}} by Clifford Ang - Good introduction to time series, portfolio optimization, and performance measures.
  
  \item \href{https://chrisconlan.com/automated-trading-r-apressspringer/}{\emph{Automated Trading}} by 
  \href{https://chrisconlan.com}{Chris Conlan} - How to implement practical computer trading systems.
  
  \item \href{https://people.orie.cornell.edu/davidr/SDAFE2/index.html}{\emph{Statistics and Data Analysis for Financial Engineering}} by David Ruppert - Introduces regression, cointegration, multivariate time series analysis, \emph{ARIMA}, \emph{GARCH}, \emph{CAPM}, and factor models, with examples in \texttt{R}.

  \item \href{https://www.pfaffikus.de/books/wiley/}{\emph{Financial Risk Modelling and Portfolio Optimization with \texttt{R}}} by Bernhard Pfaff - Introduces volatility models, portfolio optimization, and tactical asset allocation, with a great review of \texttt{R} packages and examples in \texttt{R}.

\end{itemize}

Many textbooks can be downloaded in electronic format from the 
\href{http://library.nyu.edu/}{\emph{NYU Library}}.

\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Supplementary Textbooks}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Supplementary Textbooks}
\begin{itemize}[]
  \item \href{https://www.statlearning.com}{\emph{Introduction to Statistical Learning}} by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, introduces machine learning techniques using \texttt{R}, but without deep learning.

  \item \href{https://press.princeton.edu/books/hardcover/9780691166278/quantitative-risk-management}{\emph{Quantitative Risk Management}} by Alexander J. McNeil, Rudiger Frey, and Paul Embrechts: review of Value at Risk, factor models, ARMA and GARCH, extreme value theory, and credit risk models.
  \item \href{http://eeecon.uibk.ac.at/~zeileis/teaching/AER/index.html}{\emph{Applied Econometrics with \texttt{R}}} by Christian Kleiber and Achim Zeileis, introduces advanced statistical models and econometrics.

  \item \href{http://it-ebooks.info/book/1734/}{\emph{The Art of \texttt{R} Programming}} by Norman Matloff, contains a good introduction to \texttt{R} and to statistical models.

  \item \href{http://adv-r.had.co.nz/}{\emph{Advanced \texttt{R}}} by Hadley Wickham, is the best book for learning the advanced features of \texttt{R}.

  \item \href{http://www.nr.com/}{\emph{Numerical Recipes in \texttt{C++}}} by William Press, Saul Teukolsky, William Vetterling, and Brian Flannery, is a great reference for linear algebra and numerical methods, implemented in working \texttt{C++} code.

  \item The books \href{http://www.statmethods.net/}{\emph{\texttt{R} in Action}} by Robert Kabacoff and \href{http://www.jaredlander.com/r-for-everyone/}{\emph{\texttt{R} for Everyone}} by Jared Lander, are good introductions to \texttt{R} and to statistical models.
  
  \item \href{https://www.amazon.com/hz/wishlist/ls/1C3R818RWTWNW}{\emph{Quant Finance books}} by Jerzy Pawlowski.
  
  \item \href{https://www.amazon.com/hz/wishlist/ls/1R44X8846DX3N}{\emph{Quant Trading books}} by Jerzy Pawlowski.

\end{itemize}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Supplementary Materials}
\begin{frame}[t]{\subsecname}

\begin{block}{Robert Carver's trading blog}
Great blog about practical systematic trading and investments, with Python code:
\hskip1em\url{http://qoppac.blogspot.com/}
\end{block}

\begin{block}{Introduction to Computational Finance with \texttt{R}}
Good course by prof. Eric Zivot, with lots of \texttt{R} examples:
\hskip1em\url{https://www.datacamp.com/community/open-courses/computational-finance-and-financial-econometrics-with-r}
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      \texttt{Notepad++} is a free source code editor for \texttt{MS Windows}, that supports several programming languages, including \texttt{R}.
      \vskip1ex
      \texttt{Notepad++} has a very convenient and fast \emph{search and replace} function, that allows \emph{search and replace} in multiple files.\\
      \hskip1em\url{http://notepad-plus-plus.org/}
    \column{0.3\textwidth}
      \includegraphics[height=0.5\textwidth]{image/npp.jpg}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{What is \texttt{R}?}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{}
\begin{columns}[T]
  \column{0.7\textwidth}
    \begin{itemize}
      \item An open-source software environment for statistical computing and graphics.
      \item An interpreted language, that allows interactive code development.
      \item A functional language where every operator is an \texttt{R} function.
      \item A very expressive language that can perform complex operations with very few lines of code.
      \item A language with metaprogramming facilities that allow programming on the language.
      \item A language written in \texttt{C/C++}, which can easily call other \texttt{C/C++} programs.
      \item Can be easily extended with \emph{packages} (function libraries), providing the latest developments like \emph{Machine Learning}.
      \item Supports object-oriented programming with \emph{classes} and \emph{methods}.
      \item Vectorized functions written in \texttt{C/C++}, allow very fast execution of loops over vector elements.
    \end{itemize}
  \column{0.3\textwidth}
    \href{http://www.r-project.org/}{\includegraphics[height=0.2\textwidth]{image/Rlogo.png} Project}
    \vskip1ex
    \href{http://en.wikipedia.org/wiki/R_(programming_language)}{\includegraphics[height=0.2\textwidth]{image/Rlogo.png} Wikipedia}
%    \hskip1em\url{http://blog.revolutionanalytics.com/2011/08/what-language-is-r-written-in.html}\\
\end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Differences Between \texttt{R} and \texttt{Python}}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{}
\begin{columns}[T]
  \column{0.6\textwidth}
    \texttt{R} was designed for statistics and data science, while \texttt{Python} was designed as a general-purpose programming language.\\
    \begin{itemize}
      \item \texttt{R} was designed for statistics and data science - \texttt{Python} wasn't.
      \item \texttt{R} has native date and time objects built in - \texttt{Python} doesn't.
      \item \texttt{R} has native dataframe objects built in - \texttt{Python} doesn't.
      \item \texttt{R} has native vector and matrix objects built in - \texttt{Python} doesn't.
      \item \texttt{R} is designed to be easily extended with \texttt{C++} code - \texttt{Python} isn't.
    \end{itemize}
  \column{0.4\textwidth}
    \href{http://blog.ephorie.de/why-r-for-data-science-and-not-python}{Why R is Better Than Python}
\end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Market Databases}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{ETF} Database}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Exchange-traded Funds (\emph{ETFs}) are funds which invest in portfolios of assets, such as stocks, commodities, or bonds.
      \vskip1ex
      \emph{ETFs} are shares in portfolios of assets, and they are traded just like stocks.
      \vskip1ex
      \emph{ETFs} provide investors with convenient, low cost, and liquid instruments to invest in various portfolios of assets.
      \vskip1ex
      The file \texttt{etf\_list.csv} contains a database of exchange-traded funds (\emph{ETFs}) and exchange traded notes (\emph{ETNs}).
      \vskip1ex
      We will select a portfolio of \emph{ETFs} for illustrating various investment strategies.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=TRUE,size="tiny">>=
# Select ETF symbols for asset allocation
symbolv <- c("SPY", "VTI", "QQQ", "VEU", "EEM", "XLY", "XLP", 
"XLE", "XLF", "XLV", "XLI", "XLB", "XLK", "XLU", "VYM", "IVW", 
"IWB", "IWD", "IWF", "IEF", "TLT", "VNQ", "DBC", "GLD", "USO", 
"VXX", "SVXY", "MTUM", "IVE", "VLUE", "QUAL", "VTV", "USMV", "AIEQ")
# Read etf database into data frame
etflist <- read.csv(file="/Users/jerzy/Develop/lecture_slides/data/etf_list.csv")
rownames(etflist) <- etflist$Symbol
# Select from etflist only those ETF's in symbolv
etflist <- etflist[symbolv, ]
# Shorten names
etfnames <- sapply(etflist$Name, function(name) {
  namesplit <- strsplit(name, split=" ")[[1]]
  namesplit <- namesplit[c(-1, -NROW(namesplit))]
  name_match <- match("Select", namesplit)
  if (!is.na(name_match))
    namesplit <- namesplit[-name_match]
  paste(namesplit, collapse=" ")
})  # end sapply
etflist$Name <- etfnames
etflist["IEF", "Name"] <- "10 year Treasury Bond Fund"
etflist["TLT", "Name"] <- "20 plus year Treasury Bond Fund"
etflist["XLY", "Name"] <- "Consumer Discr. Sector Fund"
etflist["EEM", "Name"] <- "Emerging Market Stock Fund"
etflist["MTUM", "Name"] <- "Momentum Factor Fund"
etflist["SVXY", "Name"] <- "Short VIX Futures"
etflist["VXX", "Name"] <- "Long VIX Futures"
etflist["DBC", "Name"] <- "Commodity Futures Fund"
etflist["USO", "Name"] <- "WTI Oil Futures Fund"
etflist["GLD", "Name"] <- "Physical Gold Fund"
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{ETF} Database for Investment Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The database contains \emph{ETFs} representing different \emph{industry sectors} and \emph{investment styles}.
      \vskip1ex
      The \emph{ETFs} with names \emph{X*} represent industry \emph{sector funds} (energy, financial, etc.)
      \vskip1ex
      The \emph{ETFs} with names \emph{I*} represent \emph{style funds} (value, growth, size).
      \vskip1ex
      \emph{IWB} is the Russell 1000 small-cap fund.
      \vskip1ex
      The 
      \href{https://www.ssga.com/us/en/intermediary/etfs/funds/spdr-sp-500-etf-trust-spy}{\emph{SPY ETF}}
      owns the \emph{S\&P500} index constituents.
      \emph{SPY} is the biggest, the most liquid, and the oldest ETF. 
      SPY has over \texttt{\$400} billion of shares outstanding, and trades over \texttt{\$20} billion per day, at a bid-ask spread of only one tick (cent=\texttt{\$0.01}, or about \texttt{0.0022\%}).
      \vskip1ex
      The 
      \href{https://www.invesco.com/qqq-etf/en/home.html}{\emph{QQQ ETF}}
      owns the \emph{Nasdaq-100} index constituents.
      \vskip1ex
      \emph{MTUM} is an \emph{ETF} which owns a stock portfolio representing the \emph{momentum factor}.
      \vskip1ex
      \emph{DBC} is an \emph{ETF} providing the total return on a portfolio of commodity futures.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=FALSE,eval=TRUE,results='asis'>>=
print(xtable::xtable(etflist), comment=FALSE, size="tiny", include.rownames=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exchange Traded Notes (\protect\emph{ETNs})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{ETNs} are similar to \emph{ETFs}, with the difference that \emph{ETFs} are shares in a fund which owns the underlying assets, while \emph{ETNs} are notes from issuers which promise payouts according to a formula tied to the underlying asset.
      \vskip1ex
      \emph{ETFs} are similar to mutual funds, while \emph{ETNs} are similar to corporate bonds.
      \vskip1ex
      \emph{ETNs} are technically unsecured corporate debt, but instead of fixed coupons, they promise to provide returns on a market index or futures contract.
      \vskip1ex
      The \emph{ETN} issuer promises the payout and is responsible for tracking the index.
      \vskip1ex
      The \emph{ETN} investor has counterparty credit risk to the \emph{ETN} issuer.
    \column{0.5\textwidth}
      \emph{VXX} is an \emph{ETN} providing the total return of \emph{long VIX} futures contracts (specifically the \emph{S\&P} VIX Short-Term Futures Index).
      \vskip1ex
      \emph{VXX} is \emph{bearish} because it's \emph{long} VIX futures, and the VIX \emph{rises} when stock prices \emph{drop}.
      \vskip1ex
      \emph{SVXY} is an \emph{ETF} providing the total return of \emph{short VIX} futures contracts.
      \vskip1ex
      \emph{SVXY} is \emph{bullish} because it's \emph{short} VIX futures, and the VIX \emph{drops} when stock prices \emph{rise}.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Downloading ETF Prices Using Package \protect\emph{quantmod}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{getSymbols()} downloads time series data into the specified \emph{environment}.
      \vskip1ex
      \texttt{getSymbols()} downloads the daily \emph{OHLC} prices and trading volume (Open, High, Low, Close, Adjusted, Volume).
      \vskip1ex
      \texttt{getSymbols()} creates objects in the specified \emph{environment} from the input strings (names), and assigns the data to those objects, without returning them as a function value, as a \emph{side effect}.
      \vskip1ex
      If the argument \texttt{"auto.assign"} is set to \texttt{FALSE}, then \texttt{getSymbols()} returns the data, instead of assigning it silently.
      \vskip1ex
      \emph{Yahoo} data quality deteriorated significantly in \texttt{2017}, and \emph{Google} data quality is also poor, leaving \emph{Tiingo} and \emph{Alpha Vantage} as the only major providers of free daily \emph{OHLC} stock prices.
      \vskip1ex
      But \href{https://www.quandl.com/}{Quandl} doesn't provide free \emph{ETF} prices, leaving \emph{Alpha Vantage} as the best provider of free daily \emph{ETF} prices.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Select ETF symbols for asset allocation
symbolv <- c("SPY", "VTI", "QQQ", "VEU", "EEM", "XLY", "XLP", 
"XLE", "XLF", "XLV", "XLI", "XLB", "XLK", "XLU", "VYM", "IVW", 
"IWB", "IWD", "IWF", "IEF", "TLT", "VNQ", "DBC", "GLD", "USO", 
"VXX", "SVXY", "MTUM", "IVE", "VLUE", "QUAL", "VTV", "USMV", "AIEQ")
library(rutils)  # Load package rutils
etfenv <- new.env()  # New environment for data
# Boolean vector of symbols already downloaded
isdown <- symbolv %in% ls(etfenv)
# Download data for symbolv using single command - creates pacing error
getSymbols.av(symbolv, adjust=TRUE, env=etfenv,
  output.size="full", api.key="T7JPW54ES8G75310")
# Download data from Alpha Vantage using while loop
nattempts <- 0  # number of download attempts
while ((sum(!isdown) > 0) & (nattempts < 10)) {
  # Download data and copy it into environment
  nattempts <- nattempts + 1
  cat("Download attempt = ", nattempts, "\n")
  for (symboln in na.omit(symbolv[!isdown][1:5])) {
    cat("Processing: ", symboln, "\n")
    tryCatch(  # With error handler
      quantmod::getSymbols.av(symboln, adjust=TRUE, env=etfenv, auto.assign=TRUE, output.size="full", api.key="T7JPW54ES8G75310"),
      # Error handler captures error condition
      error=function(msg) {
        print(paste0("Error handler: ", msg))
      },  # end error handler
      finally=print(paste0("Symbol = ", symboln))
    )  # end tryCatch
  }  # end for
  # Update vector of symbols already downloaded
  isdown <- symbolv %in% ls(etfenv)
  cat("Pausing 1 minute to avoid pacing...\n")
  Sys.sleep(65)
}  # end while
# Download all symbolv using single command - creates pacing error
# quantmod::getSymbols.av(symbolv, env=etfenv, adjust=TRUE, from="2005-01-03", output.size="full", api.key="T7NHW54ES8GG501C")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Inspecting ETF Prices in an Environment}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{get()} retrieves objects that are referenced using character strings, instead of their names.
      \vskip1ex
      The function \texttt{eapply()} is similar to \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
ls(etfenv)  # List files in etfenv
# Get class of object in etfenv
class(get(x=symbolv[1], envir=etfenv))
# Another way
class(etfenv$VTI)
colnames(etfenv$VTI)
# Get first 3 rows of data
head(etfenv$VTI, 3)
# Get last 11 rows of data
tail(etfenv$VTI, 11)
# Get class of all objects in etfenv
eapply(etfenv, class)
# Get class of all objects in R workspace
lapply(ls(), function(namev) class(get(namev)))
# Get end dates of all objects in etfenv
as.Date(sapply(etfenv, end))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Adjusting Stock Prices Using Package \protect\emph{quantmod}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Traded stock and bond prices experience jumps after splits and dividends, and must be adjusted to account for them.
      \vskip1ex
      The function \texttt{adjustOHLC()} adjusts \emph{OHLC} prices.
      \vskip1ex
      The function \texttt{get()} retrieves objects that are referenced using character strings, instead of their names.
      \vskip1ex
      The function \texttt{assign()} assigns a value to an object in a specified \emph{environment}, by referencing it using a character string (name).
      \vskip1ex
      The functions \texttt{get()} and \texttt{assign()} allow retrieving and assigning values to objects that are referenced using character strings.
      \vskip1ex
      The function \texttt{mget()} accepts a vector of strings and returns a list of the corresponding objects extracted from an \emph{environment}.
      \vskip1ex
      If the argument \texttt{"adjust"} in function \texttt{getSymbols()} is set to \texttt{TRUE}, then \texttt{getSymbols()} returns adjusted data.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(rutils)  # Load package rutils
# Check of object is an OHLC time series
is.OHLC(etfenv$VTI)
# Adjust single OHLC object using its name
etfenv$VTI <- adjustOHLC(etfenv$VTI, use.Adjusted=TRUE)

# Adjust OHLC object using string as name
assign(symbolv[1], adjustOHLC(
    get(x=symbolv[1], envir=etfenv), use.Adjusted=TRUE),
  envir=etfenv)

# Adjust objects in environment using vector of strings
for (symboln in ls(etfenv)) {
  assign(symboln,
         adjustOHLC(get(symboln, envir=etfenv), use.Adjusted=TRUE),
         envir=etfenv)
}  # end for
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Extracting Time Series from Environments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{mget()} accepts a vector of strings and returns a list of the corresponding objects extracted from an \emph{environment}.
      \vskip1ex
      The extractor (accessor) functions from package \emph{quantmod}: \texttt{Cl()}, \texttt{Vo()}, etc., extract columns from \emph{OHLC} data.
      \vskip1ex
      A list of \emph{xts} series can be flattened into a single \emph{xts} series using the function \texttt{do.call()}.
      \vskip1ex
      The function \texttt{do.call()} executes a function call using a function name and a list of arguments.
      \vskip1ex
      \texttt{do.call()} passes the list elements individually, instead of passing the whole list as one argument.
      \vskip1ex
      The function \texttt{eapply()} is similar to \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list.
      \vskip1ex
      Time series can also be extracted from an \emph{environment} by coercing it into a \texttt{list}, and then subsetting and merging it into an \emph{xts} series using the function \texttt{do.call()}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(rutils)  # Load package rutils
# Define ETF symbols
symbolv <- c("VTI", "VEU", "IEF", "VNQ")
# Extract symbolv from rutils::etfenv
pricev <- mget(symbolv, envir=rutils::etfenv)
# pricev is a list of xts series
class(pricev)
class(pricev[[1]])
tail(pricev[[1]])
# Extract close prices
pricev <- lapply(pricev, quantmod::Cl)
# Collapse list into time series the hard way
prices2 <- cbind(pricev[[1]], pricev[[2]], pricev[[3]], pricev[[4]])
class(price2)
dim(price2)
# Collapse list into time series using do.call()
pricev <- do.call(cbind, pricev)
all.equal(price2, pricev)
class(pricev)
dim(pricev)
# Or extract and cbind in single step
pricev <- do.call(cbind, lapply(
  mget(symbolv, envir=rutils::etfenv), quantmod::Cl))
# Or extract and bind all data, subset by symbolv
pricev <- lapply(symbolv, function(symboln) {
    quantmod::Cl(get(symboln, envir=rutils::etfenv))
})  # end lapply
# Or loop over etfenv without anonymous function
pricev <- do.call(cbind,
  lapply(as.list(rutils::etfenv)[symbolv], quantmod::Cl))
# Same, but works only for OHLC series - produces error
pricev <- do.call(cbind,
  eapply(rutils::etfenv, quantmod::Cl)[symbolv])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Managing Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Time series columns can be renamed, and then saved into \texttt{.csv} files.
      \vskip1ex
      The function \texttt{strsplit()} splits the elements of a character vector.
      \vskip1ex
      The package \emph{zoo} contains functions \texttt{write.zoo()} and \texttt{read.zoo()} for writing and reading \emph{zoo} time series from \texttt{.txt} and \texttt{.csv} files.
      \vskip1ex
      The function \texttt{eapply()} is similar to \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list.
      \vskip1ex
      The function \texttt{assign()} assigns a value to an object in a specified \emph{environment}, by referencing it using a character string (name).
      \vskip1ex
      The function \texttt{save()} writes objects to compressed binary \texttt{.RData} files.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Column names end with ".Close"
colnames(pricev)
strsplit(colnames(pricev), split="[.]")
do.call(rbind, strsplit(colnames(pricev), split="[.]"))
do.call(rbind, strsplit(colnames(pricev), split="[.]"))[, 1]
# Drop ".Close" from colnames
colnames(pricev) <- rutils::get_name(colnames(pricev))
# Or
# colnames(pricev) <- do.call(rbind,
#   strsplit(colnames(pricev), split="[.]"))[, 1]
tail(pricev, 3)
# Which objects in global environment are class xts?
unlist(eapply(globalenv(), is.xts))
# Save xts to csv file
write.zoo(pricev,
  file="/Users/jerzy/Develop/lecture_slides/data/etf_series.csv", sep=",")
# Copy prices into etfenv
etfenv$pricev <- pricev
# Or
assign("pricev", pricev, envir=etfenv)
# Save to .RData file
save(etfenv, file="etf_data.RData")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Calculating Percentage Returns from Close Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{quantmod::dailyReturn()} calculates the percentage daily returns from the \emph{Close} prices.
      \vskip1ex
      The \texttt{lapply()} and \texttt{sapply()} functionals perform a loop over the columns of \emph{zoo} and \emph{xts} series.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Extract VTI prices
pricev <- etfenv$prices[ ,"VTI"]
pricev <- na.omit(pricev)
# Calculate percentage returns "by hand"
pricel <- as.numeric(pricev)
pricel <- c(pricel[1], pricel[-NROW(pricel)])
pricel <- xts(pricel, zoo::index(pricev))
retp <- (pricev-pricel)/pricel
# Calculate percentage returns using dailyReturn()
retd <- quantmod::dailyReturn(pricev)
head(cbind(retd, retp))
all.equal(retd, retp, check.attributes=FALSE)
# Calculate returns for all prices in etfenv$prices
retp <- lapply(etfenv$prices, function(xtsv) {
  retd <- quantmod::dailyReturn(na.omit(xtsv))
  colnames(retd) <- names(xtsv)
  retd
})  # end lapply
# "retp" is a list of xts
class(retp)
class(retp[[1]])
# Flatten list of xts into a single xts
retp <- do.call(cbind, retp)
class(retp)
dim(retp)
# Copy retp into etfenv and save to .RData file
# assign("retp", retp, envir=etfenv)
etfenv$retp <- retp
save(etfenv, file="/Users/jerzy/Develop/lecture_slides/data/etf_data.RData")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Managing Data Inside Environments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{as.environment()} coerces objects (listv) into an environment.
      \vskip1ex
      The function \texttt{eapply()} is similar to \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list.
      \vskip1ex
      The function \texttt{mget()} accepts a vector of strings and returns a list of the corresponding objects extracted from an \emph{environment}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(rutils)
startd <- "2012-05-10"; endd <- "2013-11-20"
# Select all objects in environment and return as environment
newenv <- as.environment(eapply(etfenv, "[",
                  paste(startd, endd, sep="/")))
# Select only symbolv in environment and return as environment
newenv <- as.environment(
  lapply(as.list(etfenv)[symbolv], "[",
         paste(startd, endd, sep="/")))
# Extract and cbind Close prices and return to environment
assign("prices", rutils::do_call(cbind,
  lapply(ls(etfenv), function(symboln) {
    xtsv <- quantmod::Cl(get(symboln, etfenv))
    colnames(xtsv) <- symboln
    xtsv
  })), envir=newenv)
# Get sizes of OHLC xts series in etfenv
sapply(mget(symbolv, envir=etfenv), object.size)
# Extract and cbind adjusted prices and return to environment
colname <- function(xtsv)
  strsplit(colnames(xtsv), split="[.]")[[1]][1]
assign("prices", rutils::do_call(cbind,
               lapply(mget(etfenv$symbolv, envir=etfenv),
                      function(xtsv) {
                        xtsv <- Ad(xtsv)
                        colnames(xtsv) <- colname(xtsv)
                        xtsv
               })), envir=newenv)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Stock Databases And Survivorship Bias}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The file \texttt{sp500\_constituents.csv} contains a \emph{data frame} of over \texttt{700} present (and also some past) \emph{S\&P500} index constituents.
      \vskip1ex
      The file \texttt{sp500\_constituents.csv} is updated with stocks recently added to the \emph{S\&P500} index by downloading the
      \href{https://www.ssga.com/us/en/intermediary/etfs/funds/spdr-sp-500-etf-trust-spy}{\emph{SPY ETF Holdings}}.
      \vskip1ex
      But the file \texttt{sp500\_constituents.csv} doesn't include companies that have gone bankrupt.
      For example, it doesn't include Enron, which was in the \emph{S\&P500} index before it went bankrupt in 2001.
      \vskip1ex
      Most databases of stock prices don't include companies that have gone bankrupt or have been liquidated.
      \vskip1ex
      This introduces a \emph{survivorship bias} to the data, which can skew portfolio simulations and strategy backtests.
      \vskip1ex
      Accurate strategy simulations require starting with a portfolio of companies at a "point in time" in the past, and tracking them over time.
      \vskip1ex
      Research databases like the 
      \href{https://wrds-www.wharton.upenn.edu}{\emph{WRDS}} 
      database provide stock prices of companies that are no longer traded.
      \vskip1ex
      The stock tickers are stored in the column \texttt{"Ticker"} of the \texttt{sp500} \emph{data frame}.
      \vskip1ex
      Some tickers (like "BRK.B" and "BF.B") are not valid symbols in \emph{Tiingo}, so they must be renamed.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Load data frame of S&P500 constituents from CSV file
sp500 <- read.csv(file="/Users/jerzy/Develop/lecture_slides/data/sp500_constituents.csv")
# Inspect data frame of S&P500 constituents
dim(sp500)
colnames(sp500)
# Extract tickers from the column Ticker
symbolv <- sp500$Ticker
# Get duplicate tickers
tablev <- table(symbolv)
duplicatv <- tablev[tablev > 1]
duplicatv <- names(duplicatv)
# Get duplicate records (rows) of sp500
sp500[symbolv %in% duplicatv, ]
# Get unique tickers
symbolv <- unique(symbolv)
# Find index of ticker "BRK.B"
which(symbolv=="BRK.B")
# Rename "BRK.B" to "BRK-B" and "BF.B" to "BF-B"
symbolv[which(symbolv=="BRK.B")] <- "BRK-B"
symbolv[which(symbolv=="BF.B")] <- "BF-B"
@
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Coercing Date-time Indices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The date-time indices of the \emph{OHLC} stock prices are in the \texttt{POSIXct} format suitable for intraday prices, not daily prices.
      \vskip1ex
      The function \texttt{as.Date()} coerces \texttt{POSIXct} objects into \texttt{Date} objects.
      \vskip1ex
      The function \texttt{get()} retrieves objects that are referenced using character strings, instead of their names.
      \vskip1ex
      The function \texttt{assign()} assigns a value to an object in a specified \emph{environment}, by referencing it using a character string (name).
      \vskip1ex
      The functions \texttt{get()} and \texttt{assign()} allow retrieving and assigning values to objects that are referenced using character strings.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# The date-time index of AAPL is POSIXct
class(zoo::index(sp500env$AAPL))
# Coerce the date-time index of AAPL to Date
zoo::index(sp500env$AAPL) <- as.Date(zoo::index(sp500env$AAPL))
# Coerce all the date-time indices to Date
for (symboln in ls(sp500env)) {
  ohlc <- get(symboln, envir=sp500env)
  zoo::index(ohlc) <- as.Date(zoo::index(ohlc))
  assign(symboln, ohlc, envir=sp500env)
}  # end for
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Managing Exceptions in Stock Symbols}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The column names for symbol \texttt{"LOW"} (Lowe's company) must be renamed for the extractor function \texttt{quantmod::Lo()} to work properly.
      \vskip1ex
      Tickers which contain a dot in their name (like "BRK.B") are not valid symbols in \texttt{R}, so they must be downloaded separately and renamed.
      <<echo=TRUE,eval=FALSE>>=
# "LOW.Low" is a bad column name
colnames(sp500env$LOW)
strsplit(colnames(sp500env$LOW), split="[.]")
do.call(cbind, strsplit(colnames(sp500env$LOW), split="[.]"))
do.call(cbind, strsplit(colnames(sp500env$LOW), split="[.]"))[2, ]
# Extract proper names from column names
namev <- rutils::get_name(colnames(sp500env$LOW), field=2)
# Or
# namev <- do.call(rbind, strsplit(colnames(sp500env$LOW),
#                                   split="[.]"))[, 2]
# Rename "LOW" colnames to "LOWES"
colnames(sp500env$LOW) <- paste("LOWES", namev, sep=".")
sp500env$LOWES <- sp500env$LOW
rm(LOW, envir=sp500env)
# Rename BF-B colnames to "BFB"
colnames(sp500env$"BF-B") <- paste("BFB", namev, sep=".")
sp500env$BFB <- sp500env$"BF-B"
rm("BF-B", envir=sp500env)
# Rename BRK-B colnames
sp500env$BRKB <- sp500env$`BRK-B`
rm(`BRK-B`, envir=sp500env)
colnames(sp500env$BRKB) <- gsub("BRK-B", "BRKB", colnames(sp500env$BRKB))
# Save OHLC prices to .RData file
save(sp500env, file="/Users/jerzy/Develop/lecture_slides/data/sp500.RData")
# Download "BRK.B" separately with auto.assign=FALSE
# BRKB <- quantmod::getSymbols("BRK-B", auto.assign=FALSE, src="tiingo", adjust=TRUE, from="1990-01-01", api.key="j84ac2b9c5bde2d68e33034f65d838092c6c9f10")
# colnames(BRKB) <- paste("BRKB", namev, sep=".")
# sp500env$BRKB <- BRKB
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/lowes_stock.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot OHLC candlestick chart for LOWES
chart_Series(x=sp500env$LOWES["2019-12/"],
  TA="add_Vo()", name="LOWES OHLC Stock Prices")
# Plot dygraph
dygraphs::dygraph(sp500env$LOWES["2019-12/", -5], main="LOWES OHLC Stock Prices") %>%
  dyCandlestick()
      @

  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} Stock Index Constituent Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The file \texttt{sp500.RData} contains the \emph{environment} \texttt{sp500\_env} with \emph{OHLC} prices and trading volumes of \emph{S\&P500} stock index constituents.
      \vskip1ex
      The \emph{S\&P500} stock index constituent data is of poor quality before \texttt{2000}, so we'll mostly use the data after the year \texttt{2000}.
      <<echo=TRUE,eval=FALSE>>=
# Load S&P500 constituent stock prices
load("/Users/jerzy/Develop/lecture_slides/data/sp500.RData")
pricev <- eapply(sp500env, quantmod::Cl)
pricev <- rutils::do_call(cbind, pricev)
# Carry forward non-NA prices
pricev <- zoo::na.locf(pricev, na.rm=FALSE)
# Drop ".Close" from column names
colnames(pricev)
colnames(pricev) <- rutils::get_name(colnames(pricev))
# Or
# colnames(pricev) <- do.call(rbind,
#   strsplit(colnames(pricev), split="[.]"))[, 1]
# Calculate percentage returns of the S&P500 constituent stocks
# retp <- xts::diff.xts(log(pricev))
retp <- xts::diff.xts(pricev)/rutils::lagit(pricev, pad_zeros=FALSE)
set.seed(1121, "Mersenne-Twister", sample.kind="Rejection")
samplev <- sample(NCOL(retp), s=100, replace=FALSE)
prices100 <- pricev[, samplev]
returns100 <- retp[, samplev]
save(pricev, prices100,
  file="/Users/jerzy/Develop/lecture_slides/data/sp500_prices.RData")
save(retp, returns100,
  file="/Users/jerzy/Develop/lecture_slides/data/sp500_returns.RData")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/sp500_without_prices.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate number of constituents without prices
datav <- rowSums(is.na(pricev))
datav <- xts::xts(datav, order.by=zoo::index(pricev))
dygraphs::dygraph(datav, main="Number of S&P500 Constituents Without Prices") %>%
  dyOptions(colors="blue", strokeWidth=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} Stock Portfolio Index}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The price-weighted index of \emph{S\&P500} constituents closely follows the VTI \emph{ETF}.
      <<echo=TRUE,eval=FALSE>>=
# Calculate price weighted index of constituent
ncols <- NCOL(pricev)
pricev <- zoo::na.locf(pricev, fromLast=TRUE)
indeks <- xts(rowSums(pricev)/ncols, zoo::index(pricev))
colnames(indeks) <- "index"
# Combine index with VTI
datav <- cbind(indeks[zoo::index(etfenv$VTI)], etfenv$VTI[, 4])
colv <- c("index", "VTI")
colnames(datav) <- colv
# Plot index with VTI
endd <- rutils::calc_endpoints(datav, interval="weeks")
dygraphs::dygraph(log(datav)[endd],
  main="S&P 500 Price-weighted Index and VTI") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="red") %>%
  dySeries(name=colv[2], axis="y2", col="blue")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/sp500_portfolio_index.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing Time Series To Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The data from \emph{Tiingo} is downloaded as \texttt{xts} time series, with a date-time index of class \texttt{POSIXct} (not \texttt{Date}).
      \vskip1ex
      The function \texttt{save()} writes objects to compressed binary \texttt{.RData} files.
      \vskip1ex
      The easiest way to share data between \texttt{R} and \texttt{Excel} is through \texttt{.csv} files.
      \vskip1ex
      The package \emph{zoo} contains functions \texttt{write.zoo()} and \texttt{read.zoo()} for writing and reading \emph{zoo} time series from \texttt{.txt} and \texttt{.csv} files.
      \vskip1ex
      The function \texttt{data.table::fread()} reads from \texttt{.csv} files over \texttt{6} times faster than the function \texttt{read.csv()}!
      \vskip1ex
      The function \texttt{data.table::fwrite()} writes to \texttt{.csv} files over \texttt{12} times faster than the function \texttt{write.csv()}, and \texttt{278} times faster than function \texttt{cat()}!
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Save the environment to compressed .RData file
dirn <- "/Users/jerzy/Develop/lecture_slides/data/"
save(sp500env, file=paste0(dirn, "sp500.RData"))
# Save the ETF prices into CSV files
dirn <- "/Users/jerzy/Develop/lecture_slides/data/SP500/"
for (symboln in ls(sp500env)) {
  zoo::write.zoo(sp500env$symbol, file=paste0(dirn, symboln, ".csv"))
}  # end for
# Or using lapply()
filev <- lapply(ls(sp500env), function(symboln) {
  xtsv <- get(symboln, envir=sp500env)
  zoo::write.zoo(xtsv, file=paste0(dirn, symboln, ".csv"))
  symboln
})  # end lapply
unlist(filev)
# Or using eapply() and data.table::fwrite()
filev <- eapply(sp500env , function(xtsv) {
  filen <- rutils::get_name(colnames(xtsv)[1])
  data.table::fwrite(data.table::as.data.table(xtsv), file=paste0(dirn, filen, ".csv"))
  filen
})  # end eapply
unlist(filev)
@
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Reading Time Series from Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{load()} reads data from \texttt{.RData} files, and \emph{invisibly} returns a vector of names of objects created in the workspace.
      \vskip1ex
      The function \texttt{Sys.glob()} listv files matching names obtained from wildcard expansion.
      \vskip1ex
      The easiest way to share data between \texttt{R} and \texttt{Excel} is through \texttt{.csv} files.
      \vskip1ex
      The function \texttt{as.Date()} parses \texttt{character} strings, and coerces \texttt{numeric} and \texttt{POSIXct} objects into \texttt{Date} objects.
      \vskip1ex
      The function \texttt{data.table::setDF()} coerces a \emph{data table} object into a \emph{data frame} using a \emph{side effect}, without making copies of data.
      \vskip1ex
      The function \texttt{data.table::fread()} reads from \texttt{.csv} files over \texttt{6} times faster than the function \texttt{read.csv()}!
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Load the environment from compressed .RData file
dirn <- "/Users/jerzy/Develop/lecture_slides/data/"
load(file=paste0(dirn, "sp500.RData"))
# Get all the .csv file names in the directory
dirn <- "/Users/jerzy/Develop/lecture_slides/data/SP500/"
filev <- Sys.glob(paste0(dirn, "*.csv"))
# Create new environment for data
sp500env <- new.env()
for (filen in filev) {
  xtsv <- xts::as.xts(zoo::read.csv.zoo(filen))
  symboln <- rutils::get_name(colnames(xtsv)[1])
  # symboln <- strsplit(colnames(xtsv), split="[.]")[[1]][1]
  assign(symboln, xtsv, envir=sp500env)
}  # end for
# Or using fread()
for (filen in filev) {
  xtsv <- data.table::fread(filen)
  data.table::setDF(xtsv)
  xtsv <- xts::xts(xtsv[, -1], as.Date(xtsv[, 1]))
  symboln <- rutils::get_name(colnames(xtsv)[1])
  assign(symboln, xtsv, envir=sp500env)
}  # end for
@
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Calculating Prices and Returns From \protect\emph{OHLC} Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{na.locf()} from package \emph{zoo} replaces \texttt{NA} values with the most recent non-\texttt{NA} values prior to it.
      \vskip1ex
      The function \texttt{na.locf()} with argument \texttt{fromLast=TRUE} replaces \texttt{NA} values with non-\texttt{NA} values in reverse order, starting from the end.
      \vskip1ex
      The function \texttt{rutils::get\_name()} extracts symbol names (tickers) from a vector of character strings.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
# Calculate prices from OHLC data of the S&P500 stocks
pricev <- eapply(sp500env, quantmod::Cl)
pricev <- rutils::do_call(cbind, pricev)
# Carry forward non-NA prices
pricev <- zoo::na.locf(pricev, na.rm=FALSE)
# Get first column name
colnames(pricev[, 1])
rutils::get_name(colnames(pricev[, 1]))
# Modify column names
colnames(pricev) <- rutils::get_name(colnames(pricev))
# Or
# colnames(pricev) <- do.call(rbind,
#   strsplit(colnames(pricev), split="[.]"))[, 1]
# Calculate percentage returns
retp <- xts::diff.xts(pricev)/rutils::lagit(pricev, pad_zeros=FALSE)
# Select a random sample of 100 prices and returns
set.seed(1121, "Mersenne-Twister", sample.kind="Rejection")
samplev <- sample(NCOL(retp), s=100, replace=FALSE)
prices100 <- pricev[, samplev]
returns100 <- retp[, samplev]
# Save the data into binary files
save(pricev, prices100,
     file="/Users/jerzy/Develop/lecture_slides/data/sp500_prices.RData")
save(retp, returns100,
     file="/Users/jerzy/Develop/lecture_slides/data/sp500_returns.RData")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Calculating the Stock Alphas, Betas, and Other Performance Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package 
      \href{https://cran.r-project.org/web/packages/PerformanceAnalytics/index.html}{\emph{PerformanceAnalytics}} 
      contains functions for calculating risk and performance statistics, such as the \emph{variance}, \emph{skewness}, \emph{kurtosis}, \emph{beta}, \emph{alpha}, etc.
      \vskip1ex
      The function \texttt{PerformanceAnalytics::table.CAPM()} calculates the \emph{beta} $\beta$ and \emph{alpha} $\alpha$ values, the \emph{Treynor} ratio, and other performance statistics.
      \vskip1ex
      The function \texttt{PerformanceAnalytics::table.Stats()} calculates a data frame of risk and return statistics of the return distributions.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
# Extract Close prices
pricev <- eapply(etfenv, quantmod::Cl)
pricev <- do.call(cbind, pricev)
# Drop ".Close" from colnames
colnames(pricev) <- do.call(rbind, strsplit(colnames(pricev), split="[.]"))[, 1]
# Calculate the log returns
retp <- xts::diff.xts(log(pricev))
# Copy prices and returns into etfenv
etfenv$pricev <- pricev
etfenv$retp <- retp
# Copy symbolv into etfenv
etfenv$symbolv <- symbolv
# Calculate the risk-return statistics
riskstats <- PerformanceAnalytics::table.Stats(retp)
# Transpose the data frame
riskstats <- as.data.frame(t(riskstats))
# Add Name column
riskstats$Name <- rownames(riskstats)
# Copy riskstats into etfenv
etfenv$riskstats <- riskstats
# Calculate the beta, alpha, Treynor ratio, and other performance statistics
capmstats <- PerformanceAnalytics::table.CAPM(Ra=retp[, symbolv], 
                                               Rb=retp[, "VTI"], scale=252)
colv <- strsplit(colnames(capmstats), split=" ")
colv <- do.call(cbind, colv)[1, ]
colnames(capmstats) <- colv
capmstats <- t(capmstats)
capmstats <- capmstats[, -1]
colv <- colnames(capmstats)
whichv <- match(c("Annualized Alpha", "Information Ratio", "Treynor Ratio"), colv)
colv[whichv] <- c("Alpha", "Information", "Treynor")
colnames(capmstats) <- colv
capmstats <- capmstats[order(capmstats[, "Alpha"], decreasing=TRUE), ]
# Copy capmstats into etfenv
etfenv$capmstats <- capmstats
save(etfenv, file="/Users/jerzy/Develop/lecture_slides/data/etf_data.RData")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Downloading \protect\emph{VIX} Futures Files from CBOE}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The CFE (CBOE Futures Exchange) provides daily \href{https://markets.cboe.com/us/futures/market_statistics/historical_data/}{CBOE Historical Data for Volatility Futures}, including the \emph{VIX} futures.
      \vskip1ex
      The CBOE data incudes \emph{OHLC} prices and also the \emph{settlement} price (in column \texttt{"Settle"}).
      \vskip1ex
      The \emph{settlement} price is usually defined as the weighted average price (\emph{WAP}) or the midpoint price, and is different from the \emph{Close} price.
      \vskip1ex
      The \emph{settlement} price is used for calculating the daily \emph{mark to market} (value) of the futures contract.
      \vskip1ex
      Futures exchanges require that counterparties exchange (settle) the \emph{mark to market} value of the futures contract daily, to reduce counterparty default risk.
      \vskip1ex
      The function \texttt{download.file()} downloads files from the internet.
      \vskip1ex
      The function \texttt{tryCatch()} executes functions and expressions, and handles any \emph{exception conditions} produced when they are evaluated.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Read CBOE futures expiration dates
datev <- read.csv(file="/Users/jerzy/Develop/lecture_slides/data/futures_expiration_dates_codes.csv",
  row.names=1)
# Create directory for data
dirn <- "/Users/jerzy/Develop/data/vix_data"
dir.create(dirn)
namev <- rownames(datev)
filev <- file.path(dirn, paste0(namev, ".csv"))
filelog <- file.path(dirn, "log_file.txt")
urlcboe <- "https://markets.cboe.com/us/futures/market_statistics/historical_data/products/csv/VX/"
urlv <- paste0(urlcboe, datev[, 1])
# Download files in loop
for (it in seq_along(urlv)) {
    tryCatch(  # Warning and error handler
        download.file(urlv[it], destfile=filev[it], quiet=TRUE),
      # Warning handler captures warning condition
      warning=function(msg) {
        cat(paste0("Warning handler: ", msg, "\n"), file=filelog, append=TRUE)
      },  # end warning handler
      # Error handler captures error condition
      error=function(msg) {
        cat(paste0("Error handler: ", msg, "\n"), append=TRUE)
      },  # end error handler
      finally=cat(paste0("Processing file name = ", filev[it], "\n"), append=TRUE)
    )  # end tryCatch
}  # end for
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Downloading \protect\emph{VIX} Futures Data Into an Environment}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{quantmod::getSymbols()} with the parameter \texttt{src="cfe"} downloads CFE data into the specified \emph{environment}. (But this requires first loading the package \emph{qmao}.)
      \vskip1ex
      Currently \texttt{quantmod::getSymbols()} doesn't download the most recent data.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Create new environment for data
vixenv <- new.env()
# Download VIX data for the months 6, 7, and 8 in 2018
library(qmao)
quantmod::getSymbols("VX", Months=1:12,
  Years=2018, src="cfe", auto.assign=TRUE, env=vixenv)
# Or
qmao::getSymbols.cfe(Symbols="VX",
  Months=6:8, Years=2018, env=vixenv,
  verbose=FALSE, auto.assign=TRUE)
# Calculate the classes of all the objects
# In the environment vixenv
unlist(eapply(vixenv, function(x) {class(x)[1]}))
class(vixenv$VX_M18)
colnames(vixenv$VX_M18)
# Save the data to a binary file called "vix_cboe.RData".
save(vixenv,
  file="/Users/jerzy/Develop/data/vix_data/vix_cboe.RData")
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Risk and Performance Analysis}


%%%%%%%%%%%%%%%
\subsection{The Median Absolute Deviation Estimator of Dispersion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Median Absolute Deviation} (\emph{MAD}) is a nonparametric measure of dispersion (variability), defined using the median instead of the mean:
      \begin{displaymath}
        \operatorname{MAD} = \operatorname{median}(\operatorname{abs}(x_i - \operatorname{median}(\mathbf{x})))
      \end{displaymath}
      The advantage of \emph{MAD} is that it's always well defined, even for data that has infinite variance.
      \vskip1ex
      The \emph{MAD} for normally distributed data is equal to $\Phi^{-1}(0.75) \cdot \hat\sigma = 0.6745 \cdot \hat\sigma$.
      \vskip1ex
      The function \texttt{mad()} calculates the \emph{MAD} and divides it by $\Phi^{-1}(0.75)$ to make it comparable to the standard deviation.
      \vskip1ex
      For normally distributed data the \emph{MAD} has a larger standard error than the standard deviation.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Simulate normally distributed data
nrows <- 1000
datav <- rnorm(nrows)
sd(datav)
mad(datav)
median(abs(datav - median(datav)))
median(abs(datav - median(datav)))/qnorm(0.75)
# Bootstrap of sd and mad estimators
bootd <- sapply(1:10000, function(x) {
  samplev <- datav[sample.int(nrows, replace=TRUE)]
  c(sd=sd(samplev), mad=mad(samplev))
})  # end sapply
bootd <- t(bootd)
# Analyze bootstrapped variance
head(bootd)
sum(is.na(bootd))
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
# Parallel bootstrap under Windows
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
compclust <- makeCluster(ncores)  # Initialize compute cluster
bootd <- parLapply(compclust, 1:10000,
  function(x, datav) {
    samplev <- datav[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, datav=datav)  # end parLapply
# Parallel bootstrap under Mac-OSX or Linux
bootd <- mclapply(1:10000, function(x) {
    samplev <- datav[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, mc.cores=ncores)  # end mclapply
stopCluster(compclust)  # Stop R processes over cluster
bootd <- rutils::do_call(rbind, bootd)
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Median Absolute Deviation of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      For normally distributed data the \emph{MAD} has a larger standard error than the standard deviation.
      \vskip1ex
      But for distributions with fat tails (like asset returns), the standard deviation has a larger standard error than the \emph{MAD}.
      \vskip1ex
      The \emph{bootstrap} procedure performs a loop, which naturally lends itself to parallel computing.
      \vskip1ex
      The function \texttt{makeCluster()} starts running \texttt{R} processes on several CPU cores under \emph{Windows}.
      \vskip1ex
      The function \texttt{parLapply()} is similar to \texttt{lapply()}, and performs loops under \emph{Windows} using parallel computing on several CPU cores.
      \vskip1ex
      The \texttt{R} processes started by \texttt{makeCluster()} don't inherit any data from the parent \texttt{R} process.
      \vskip1ex
      Therefore the required data must be either passed into \texttt{parLapply()} via the dots \texttt{"..."} argument, or by calling the function \texttt{clusterExport()}.
      \vskip1ex
      The function \texttt{mclapply()} performs loops using parallel computing on several CPU cores under \emph{Mac-OSX} or \emph{Linux}.
      \vskip1ex
      The function \texttt{stopCluster()} stops the \texttt{R} processes running on several CPU cores.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI returns
retp <- na.omit(rutils::etfenv$returns$VTI)
nrows <- NROW(retp)
sd(retp)
mad(retp)
# Bootstrap of sd and mad estimators
bootd <- sapply(1:10000, function(x) {
  samplev <- retp[sample.int(nrows, replace=TRUE)]
  c(sd=sd(samplev), mad=mad(samplev))
})  # end sapply
bootd <- t(bootd)
# Means and standard errors from bootstrap
100*apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
# Parallel bootstrap under Windows
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
compclust <- makeCluster(ncores)  # Initialize compute cluster
clusterExport(compclust, c("nrows", "returns"))
bootd <- parLapply(compclust, 1:10000,
  function(x) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  })  # end parLapply
# Parallel bootstrap under Mac-OSX or Linux
bootd <- mclapply(1:10000, function(x) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, mc.cores=ncores)  # end mclapply
stopCluster(compclust)  # Stop R processes over cluster
bootd <- rutils::do_call(rbind, bootd)
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Downside Deviation of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Some investors argue that positive returns don't represent risk, only those returns less than the target rate of return $r_t$.
      \vskip1ex
      The \emph{Downside Deviation} (semi-deviation) $\sigma_{d}$ is equal to the standard deviation of returns less than the target rate of return $r_t$:
      \begin{displaymath}
        \sigma_{d} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} ([r_i-r_t]_{-})^2}
      \end{displaymath}
      The function \texttt{DownsideDeviation()} from package \emph{PerformanceAnalytics} calculates the downside deviation, for either the full time series (\texttt{method="full"}) or only for the subseries less than the target rate of return $r_t$ (\texttt{method="subset"}).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(PerformanceAnalytics)
# Define target rate of return of 50 bps
targetr <- 0.005
# Calculate the full downside returns
retsub <- (retp - targetr)
retsub <- ifelse(retsub < 0, retsub, 0)
nrows <- NROW(retsub)
# Calculate the downside deviation
all.equal(sqrt(sum(retsub^2)/nrows),
  drop(DownsideDeviation(retp, MAR=targetr, method="full")))
# Calculate the subset downside returns
retsub <- (retp - targetr)
retsub <- retsub[retsub < 0]
nrows <- NROW(retsub)
# Calculate the downside deviation
all.equal(sqrt(sum(retsub^2)/nrows),
  drop(DownsideDeviation(retp, MAR=targetr, method="subset")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Drawdown Risk}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{drawdown} is the drop in prices from their historical peak, and is equal to the difference between the prices minus the cumulative maximum of the prices.
      \vskip1ex
      \emph{Drawdown risk} determines the risk of liquidation due to stop loss limits.
      <<echo=TRUE,eval=FALSE>>=
# Calculate time series of VTI drawdowns
closep <- log(quantmod::Cl(rutils::etfenv$VTI))
drawdns <- (closep - cummax(closep))
# Extract the date index from the time series closep
datev <- zoo::index(closep)
# Calculate the maximum drawdown date and depth
indexmin <- which.min(drawdns)
datemin <- datev[indexmin]
maxdd <- drawdns[datemin]
# Calculate the drawdown start and end dates
startd <- max(datev[(datev < datemin) & (drawdns == 0)])
endd <- min(datev[(datev > datemin) & (drawdns == 0)])
# dygraph plot of VTI drawdowns
datav <- cbind(closep, drawdns)
colv <- c("VTI", "Drawdowns")
colnames(datav) <- colv
dygraphs::dygraph(datav, main="VTI Drawdowns") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2],
   valueRange=(1.2*range(drawdns)+0.1), independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue") %>%
  dySeries(name=colv[2], axis="y2", col="red") %>%
  dyEvent(startd, "start drawdown", col="blue") %>%
  dyEvent(datemin, "max drawdown", col="red") %>%
  dyEvent(endd, "end drawdown", col="green")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/drawdown_plot.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot VTI drawdowns using package quantmod
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("blue")
x11(width=6, height=5)
quantmod::chart_Series(x=closep, name="VTI Drawdowns", theme=plot_theme)
xval <- match(startd, datev)
yval <- max(closep)
abline(v=xval, col="blue")
text(x=xval, y=0.95*yval, "start drawdown", col="blue", cex=0.9)
xval <- match(datemin, datev)
abline(v=xval, col="red")
text(x=xval, y=0.9*yval, "max drawdown", col="red", cex=0.9)
xval <- match(endd, datev)
abline(v=xval, col="green")
text(x=xval, y=0.85*yval, "end drawdown", col="green", cex=0.9)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Drawdown Risk Using \texttt{PerformanceAnalytics::table.Drawdowns()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{table.Drawdowns()} from package \emph{PerformanceAnalytics} calculates a data frame of drawdowns.
      <<echo=TRUE,eval=FALSE>>=
library(xtable)
library(PerformanceAnalytics)
closep <- log(quantmod::Cl(rutils::etfenv$VTI))
retp <- rutils::diffit(closep)
# Calculate table of VTI drawdowns
tablev <- PerformanceAnalytics::table.Drawdowns(retp, geometric=FALSE)
# Convert dates to strings
tablev <- cbind(sapply(tablev[, 1:3], as.character), tablev[, 4:7])
# Print table of VTI drawdowns
print(xtable(tablev), comment=FALSE, size="tiny", include.rownames=FALSE)
      @
      <<echo=FALSE,eval=TRUE,size="tiny",results='asis'>>=
library(xtable)
library(PerformanceAnalytics)
closep <- log(quantmod::Cl(rutils::etfenv$VTI))
retp <- rutils::diffit(closep)
# Calculate table of VTI drawdowns
tablev <- PerformanceAnalytics::table.Drawdowns(retp, geometric=FALSE)
# Convert dates to strings
tablev <- cbind(sapply(tablev[, 1:3], as.character), tablev[, 4:7])
# Print table of VTI drawdowns
print(xtable(tablev), comment=FALSE, size="tiny", include.rownames=FALSE)
      @
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Loss Distribution of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The distribution of returns has a long left tail of negative returns representing the risk of loss.
      \vskip1ex
      The \emph{Value at Risk} ($\mathrm{VaR}$) is equal to the quantile of returns corresponding to a given confidence level $\alpha$.
      \vskip1ex
      The \emph{Conditional Value at Risk} ($\mathrm{CVaR}$) is equal to the average of negative returns less than the $\mathrm{VaR}$.
      \vskip1ex
      The function \texttt{hist()} calculates and plots a histogram, and returns its data \emph{invisibly}.
      \vskip1ex
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data.
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI percentage returns
retp <- na.omit(rutils::etfenv$returns$VTI)
confl <- 0.1
varisk <- quantile(retp, confl)
cvar <- mean(retp[retp <= varisk])
# Plot histogram of VTI returns
x11(width=6, height=5)
par(mar=c(3, 2, 1, 0), oma=c(0, 0, 0, 0))
histp <- hist(retp, col="lightgrey",
  xlab="returns", ylab="frequency", breaks=100,
  xlim=c(-0.05, 0.01), freq=FALSE, main="VTI Returns Histogram")
# Calculate density
densv <- density(retp, adjust=1.5)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_var.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot density
lines(densv, lwd=3, col="blue")
# Plot line for VaR
abline(v=varisk, col="red", lwd=3)
text(x=varisk, y=25, labels="VaR", lwd=2, pos=2)
# Plot polygon shading for CVaR
text(x=1.5*varisk, y=10, labels="CVaR", lwd=2, pos=2)
varmax <- -0.06
rangev <- (densv$x < varisk) &  (densv$x > varmax)
polygon(c(varmax, densv$x[rangev], varisk),
  c(0, densv$y[rangev], 0), col=rgb(1, 0, 0,0.5), border=NA)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Value at Risk (\protect\emph{VaR})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Value at Risk} ($\mathrm{VaR}$) is equal to the quantile of returns corresponding to a given confidence level $\alpha$:
      \begin{displaymath}
        \alpha = \int_{-\infty}^{\mathrm{VaR}(\alpha)} \operatorname{f}(r) \, \mathrm{d}r
      \end{displaymath}
      Where $\operatorname{f}(r)$ is the probability density (distribution) of returns.
      \vskip1ex
      At a high confidence level, the value of $\mathrm{VaR}$ is subject to estimation error, and various numerical methods are used to approximate it.
      \vskip1ex
      The function \texttt{quantile()} calculates the sample quantiles.  It uses interpolation to improve the accuracy.  Information about the different interpolation methods can be found by typing \texttt{?quantile}.
      \vskip1ex
      A simpler but less accurate way of calculating the quantile is by sorting and selecting the data closest to the quantile.
      \vskip1ex
      The function \texttt{VaR()} from package \emph{PerformanceAnalytics} calculates the \emph{Value at Risk} using several different methods.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI percentage returns
retp <- na.omit(rutils::etfenv$returns$VTI)
nrows <- NROW(retp)
confl <- 0.05
# Calculate VaR approximately by sorting
sortv <- sort(as.numeric(retp))
cutoff <- round(confl*nrows)
varisk <- sortv[cutoff]
# Calculate VaR as quantile
varisk <- quantile(retp, probs=confl)
# PerformanceAnalytics VaR
PerformanceAnalytics::VaR(retp, p=(1-confl), method="historical")
all.equal(unname(varisk),
  as.numeric(PerformanceAnalytics::VaR(retp,
  p=(1-confl), method="historical")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk (\protect\emph{CVaR})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Conditional Value at Risk} ($\mathrm{CVaR}$) is equal to the average of negative returns less than the $\mathrm{VaR}$:
      \begin{displaymath}
        \mathrm{CVaR} = \frac{1}{\alpha} \int_{0}^\alpha \mathrm{VaR}(p) \, \mathrm{d}p
      \end{displaymath}
      The \emph{Conditional Value at Risk} is also called the \emph{Expected Shortfall} (\emph{ES}), or the Expected Tail Loss (\emph{ETL}).
      \vskip1ex
      The function \texttt{ETL()} from package \emph{PerformanceAnalytics} calculates the \emph{Conditional Value at Risk} using several different methods.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VaR as quantile
varisk <- quantile(retp, confl)
# Calculate CVaR as expected loss
cvar <- mean(retp[retp <= varisk])
# PerformanceAnalytics VaR
PerformanceAnalytics::ETL(retp, p=(1-confl), method="historical")
all.equal(unname(cvar),
  as.numeric(PerformanceAnalytics::ETL(retp,
    p=(1-confl), method="historical")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk and Return Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{table.Stats()} from package \emph{PerformanceAnalytics} calculates a data frame of risk and return statistics of the return distributions.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the risk-return statistics
riskstats <-
  PerformanceAnalytics::table.Stats(rutils::etfenv$returns)
class(riskstats)
# Transpose the data frame
riskstats <- as.data.frame(t(riskstats))
# Add Name column
riskstats$Name <- rownames(riskstats)
# Add Sharpe ratio column
riskstats$"Arithmetic Mean" <-
  sapply(rutils::etfenv$returns, mean, na.rm=TRUE)
riskstats$Sharpe <-
  sqrt(252)*riskstats$"Arithmetic Mean"/riskstats$Stdev
# Sort on Sharpe ratio
riskstats <- riskstats[order(riskstats$Sharpe, decreasing=TRUE), ]
      @
    \column{0.5\textwidth}
      <<echo=FALSE,eval=TRUE,size="tiny">>=
# Copy from rutils to save time
riskstats <- rutils::etfenv$riskstats
# Add Sharpe ratio column
# riskstats$Sharpe <- riskstats$"Arithmetic Mean"/riskstats$Stdev
# Sort on Sharpe ratio
riskstats <- riskstats[order(riskstats$Sharpe, decreasing=TRUE), ]
# Print data frame
knitr::kable(riskstats[, c("Sharpe", "Skewness", "Kurtosis")])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Investor Risk and Return Preferences}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Investors typically prefer larger \emph{odd moments} of the return distribution (mean, skewness), and smaller \emph{even moments} (variance, kurtosis).
      \vskip1ex
      But positive skewness is often associated with lower returns, which can be observed in the \emph{VIX} volatility ETFs, \emph{VXX} and \emph{SVXY}.
      \vskip1ex
      The \emph{VXX} ETF is long the \emph{VIX} index (effectively long an option), so it has positive skewness and small kurtosis, but negative returns (it's short market risk).
      \vskip1ex
      Since the \emph{VXX} is effectively long an option, it pays option premiums so it has negative returns most of the time, with isolated periods of positive returns when markets drop.
      \vskip1ex
      The \emph{SVXY} ETF is short the \emph{VIX} index, so it has negative skewness and large kurtosis, but positive returns (it's long market risk).
      \vskip1ex
      Since the \emph{SVXY} is effectively short an option, it earns option premiums so it has positive returns most of the time, but it suffers sharp losses when markets drop.
    \column{0.5\textwidth}
    \vspace{1em}
      <<echo=FALSE,eval=TRUE,size="tiny">>=
# Print data frame
knitr::kable(riskstats[c("VXX", "SVXY"), c("Sharpe", "Skewness", "Kurtosis")])
      @
      \includegraphics[width=0.45\paperwidth]{figure/vix_vxx_svxy.png}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of VXX versus SVXY
pricev <- na.omit(rutils::etfenv$prices[, c("VXX", "SVXY")])
pricev <- pricev["2017/"]
colv <- c("VXX", "SVXY")
colnames(pricev) <- colv
dygraphs::dygraph(pricev, main="Prices of VXX and SVXY") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", strokeWidth=2, col="blue") %>%
  dySeries(name=colv[2], axis="y2", strokeWidth=2, col="green") %>%
  dyLegend(show="always", width=300) %>% dyLegend(show="always", width=300) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Skewness and Return Tradeoff}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Similarly to the \emph{VXX} and \emph{SVXY}, for most other ETFs positive skewness is often associated with lower returns.
      \vskip1ex
      Some of the exceptions are bond ETFs (like \emph{IEF}), which have both non-negative skewness and positive returns.
      \vskip1ex
      Another exception are commodity ETFs (like \emph{USO} oil), which have both negative skewness and negative returns.
      <<echo=TRUE,eval=FALSE>>=
# Remove VIX volatility ETF data
riskstats <- riskstats[-match(c("VXX", "SVXY"), riskstats$Name), ]
# Plot scatterplot of Sharpe vs Skewness
plot(Sharpe ~ Skewness, data=riskstats,
     ylim=1.1*range(riskstats$Sharpe),
     main="Sharpe vs Skewness")
# Add labels
text(x=riskstats$Skewness, y=riskstats$Sharpe,
          labels=riskstats$Name, pos=3, cex=0.8)
# Plot scatterplot of Kurtosis vs Skewness
x11(width=6, height=5)
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
plot(Kurtosis ~ Skewness, data=riskstats,
     ylim=c(1, max(riskstats$Kurtosis)),
     main="Kurtosis vs Skewness")
# Add labels
text(x=riskstats$Skewness, y=riskstats$Kurtosis,
          labels=riskstats$Name, pos=1, cex=0.5)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/etf_skew_sharp.png}
      % \includegraphics[width=0.45\paperwidth]{figure/etf_skew_kurtosis.png}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\subsection{Risk-adjusted Return Measures}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Sharpe ratio} $\mathrm{S_r}$ is equal to the excess returns (in excess of the risk-free rate $r_f$) divided by the standard deviation $\sigma$ of the returns:
      \begin{displaymath}
        \mathrm{S_r} = \frac{E[r-r_f]}{\sigma}
      \end{displaymath}
      The \emph{Sortino ratio} $\mathrm{{So}_r}$ is equal to the excess returns divided by the \emph{downside deviation} $\sigma_{d}$ (standard deviation of returns that are less than a target rate of return $r_t$):
      \begin{displaymath}
        \mathrm{{So}_r} = \frac{E[r-r_t]}{\sigma_{d}}
      \end{displaymath}
      The \emph{Calmar ratio} $\mathrm{C_r}$ is equal to the excess returns divided by the \emph{maximum drawdown} $\mathrm{DD}$ of the returns:
      \begin{displaymath}
        \mathrm{C_r} = \frac{E[r-r_f]}{\mathrm{DD}}
      \end{displaymath}
      The \emph{Dowd ratio} $\mathrm{D_r}$ is equal to the excess returns divided by the \emph{Value at Risk} ($\mathrm{VaR}$) of the returns:
      \begin{displaymath}
        \mathrm{D_r} = \frac{E[r-r_f]}{\mathrm{VaR}}
      \end{displaymath}
      The \emph{Conditional Dowd ratio} $\mathrm{{Dc}_r}$ is equal to the excess returns divided by the \emph{Conditional Value at Risk} ($\mathrm{CVaR}$) of the returns:
      \begin{displaymath}
        \mathrm{{Dc}_r} = \frac{E[r-r_f]}{\mathrm{CVaR}}
      \end{displaymath}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(PerformanceAnalytics)
retp <- rutils::etfenv$returns[, c("VTI", "IEF")]
retp <- na.omit(retp)
# Calculate the Sharpe ratio
confl <- 0.05
PerformanceAnalytics::SharpeRatio(retp, p=(1-confl),
  method="historical")
# Calculate the Sortino ratio
PerformanceAnalytics::SortinoRatio(retp)
# Calculate the Calmar ratio
PerformanceAnalytics::CalmarRatio(retp)
# Calculate the Dowd ratio
PerformanceAnalytics::SharpeRatio(retp, FUN="VaR",
  p=(1-confl), method="historical")
# Calculate the Dowd ratio from scratch
varisk <- sapply(retp, quantile, probs=confl)
-sapply(retp, mean)/varisk
# Calculate the Conditional Dowd ratio
PerformanceAnalytics::SharpeRatio(retp, FUN="ES",
  p=(1-confl), method="historical")
# Calculate the Conditional Dowd ratio from scratch
cvar <- sapply(retp, function(x) {
  mean(x[x < quantile(x, confl)])
})
-sapply(retp, mean)/cvar
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk and Return of Stocks Over Longer Holding Periods}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Stocks held over longer holding periods often have higher risk-adjusted returns than over shorter holding periods - provided the long-term stock returns are positive.
      \vskip1ex
      This is because returns are proportional to the holding period, while risk is proportional to the square root of the holding period.
      \vskip1ex
      Therefore investors with longer holding periods may choose to own a higher percentage of stocks than bonds.
      \vskip1ex
      The skewness of monthly returns is higher than for daily returns, but their kurtosis and tail risks are lower.
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI daily log returns
pricev <- log(drop(coredata(na.omit(rutils::etfenv$prices$VTI))))
retp <- rutils::diffit(pricev)
nrows <- NROW(retp)
# Calculate VTI monthly log returns
holdp <- 22 # Holding period in days
pricem <- pricev[rutils::calc_endpoints(pricev, holdp)]
retm <- rutils::diffit(pricem)
retm <- retm[-1] # Drop the first zero return
# Calculate the mean, standard deviation, skewness, and kurtosis
datav <- list(retp, retm)
names(datav) <- c("Daily", "Monthly")
do.call(cbind, lapply(datav, function(x) {
  # Standardize the returns
  meanv <- mean(x); stdev <- sd(x); x <- (x - meanv)/stdev
  c(mean=meanv, stdev=stdev, skew=mean(x^3), kurt=mean(x^4))
}))  # end lapply
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/riskret_aggregated.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the Sharpe and Dowd ratios
do.call(cbind, lapply(datav, function(x) {
  meanv <- mean(x); stdev <- sd(x)
  varisk <- unname(quantile(x, probs=0.02))
  cvar <- mean(x[x < varisk])
  # Annualize the ratios
  sqrt(252*NROW(x)/nrows)*mean(x)/c(Sharpe=stdev, Dowd=-varisk, DowdC=-cvar)
}))  # end lapply
# Plot the density of monthly returns
plot(density(retm), t="l", lwd=3, col="blue",
     xlab="returns", ylab="density", xlim=c(-4*mad(retm), 4*mad(retm)),
     main="Distribution of Monthly VTI Returns")
curve(expr=dnorm(x, mean=mean(retm), sd=sd(retm)), col="green", lwd=3, add=TRUE)
legend("topright", legend=c("Monthly", "Normal"), y.intersp=0.4, cex=1.1,
       inset=0.0, bg="white", lty=1, lwd=6, col=c("blue", "green"), bty="n")
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Evaluating Manager Skill}


%%%%%%%%%%%%%%%
\subsection{Tests for Market Timing Skill}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Market timing skill} a trading strategy is the ability to switch market positions, from long risk to short and vice versa, in anticipation of future market returns.
      \vskip1ex
      If a trading strategy has timing skill, then its returns have a positive convexity with respect to the market returns.  The beta-adjusted strategy returns are positive, both when the market returns are positive and when they are negative.
      \vskip1ex
      The \emph{market timing} skill can be measured by performing a \emph{linear regression} of a strategy's returns against a strategy with perfect \emph{market timing} skill.
      \vskip1ex
      The \emph{Merton-Henriksson} market timing test uses a linear \emph{market timing} term:
      \begin{displaymath}
        R - R_f = {\alpha} + \beta (R_m - R_f) + \gamma \max{(R_m - R_f, 0)} + {\varepsilon}
      \end{displaymath}
      Where $R$ are the strategy returns, $R_m$ are the market returns, and $R_f$ are the risk-free rates.
      \vskip1ex
      If the coefficient $\gamma$ is statistically significant, then it's very likely due to \emph{market timing} skill.
      \vskip1ex
      The \emph{market timing} regression is a generalization of the \emph{Capital Asset Pricing Model}.
      \vskip1ex
      The \emph{Treynor-Mazuy} test uses a quadratic term, which makes it more sensitive to the magnitude of returns:
      \begin{displaymath}
        R - R_f = {\alpha} + \beta (R_m - R_f) + \gamma (R_m - R_f)^2 + {\varepsilon}
      \end{displaymath}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Create a design matrix of IEF and VTI returns
desm <- na.omit(rutils::etfenv$returns[, c("IEF", "VTI")])
retvti <- desm$VTI
# Add returns with perfect timing skill
desm <- cbind(desm, 0.5*(retvti+abs(retvti)), retvti^2)
colnames(desm)[3:4] <- c("merton", "treynor")
# Perform Merton-Henriksson test regression
regmod <- lm(IEF ~ VTI + merton, data=desm); summary(regmod)
# Perform Treynor-Mazuy test regression
regmod <- lm(IEF ~ VTI + treynor, data=desm); summary(regmod)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Market Timing Skill of Bonds}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Even if a trading strategy has timing skill, it doesn't necessarily mean that its returns can be used to forecast the market returns.
      \vskip1ex
      The \emph{IEF} \texttt{10}-year Treasury bond ETF has a small market timing skill, because it has a slightly positive convexity with respect to the \emph{VTI} stock ETF.
      \vskip1ex
      The slight market timing ability of Treasury bonds is significant, because it contributes to their superior risk-adjusted returns.
      \vskip1ex
      As a general rule, trend-following and momentum strategies have positive timing skill.
      Because they buy stocks when their prices are rising and sell them when the prices are dropping, expecting that the trend will continue.
      \vskip1ex
      Contrarian strategies have negative timing skill.
      Because they buy stocks when their prices are dropping and sell them when the prices are rising, expecting that the trend will reverse.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/timing_skill_ief_vti.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot residual scatterplot
resids <- (desm$IEF - regmod$coeff["VTI"]*retvti)
plot.default(x=retvti, y=resids, xlab="VTI", ylab="IEF")
title(main="Treynor-Mazuy Market Timing Test\n for IEF vs VTI", line=0.5)
# Plot fitted (predicted) response values
coefreg <- summary(regmod)$coeff
fitv <- regmod$fitted.values - coefreg["VTI", "Estimate"]*retvti
tvalue <- round(coefreg["treynor", "t value"], 2)
points.default(x=retvti, y=fitv, pch=16, col="red")
text(x=0.0, y=0.8*max(resids), paste("Treynor test t-value =", tvalue))
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Rebalancing Strategies}


%%%%%%%%%%%%%%%
\subsection{Calculating Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Given a time series of asset prices $p_i$, the dollar returns $r^d_i$, the percentage returns $r^p_i$, and the log returns $r^l_i$ are defined as:
      \begin{displaymath}
        r^d_i = p_i - p_{i-1} \quad r^p_i = \frac{p_i - p_{i-1}}{p_{i-1}} \quad r^l_i = \log(\frac{p_i}{p_{i-1}})
      \end{displaymath}
      The initial returns are all equal to zero.
      \vskip1ex
      If the log returns are small $r^l \ll 1$, then they are approximately equal to the percentage returns: $r^l \approx r^p$.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(rutils)
# Extract the ETF prices from rutils::etfenv$prices
pricev <- rutils::etfenv$prices
pricev <- zoo::na.locf(pricev, na.rm=FALSE)
pricev <- zoo::na.locf(pricev, fromLast=TRUE)
datev <- zoo::index(pricev)
# Calculate the dollar returns
retd <- rutils::diffit(pricev)
# Or
# retd <- lapply(pricev, rutils::diffit)
# retd <- rutils::do_call(cbind, retd)
# Calculate the percentage returns
retp <- retd/rutils::lagit(pricev, lagg=1, pad_zeros=FALSE)
# Calculate the log returns
retl <- rutils::diffit(log(pricev))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Compounding Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The sum of the dollar returns:
      $\sum_{i=1}^n r^d_i$
      represents the wealth path from owning a \emph{fixed number of shares}.
      \vskip1ex
      The compounded percentage returns:
      $\prod_{i=1}^n (1 + r^p_i$)
      also represent the wealth path from owning a \emph{fixed number of shares}, initially equal to \texttt{\$1} dollar.
      \vskip1ex
      The sum of the percentage returns (without compounding):
      $\sum_{i=1}^n r^p_i$
      represents the wealth path from owning a \emph{fixed dollar amount} of stock.
      \vskip1ex
      Maintaining a \emph{fixed dollar amount} of stock requires periodic \emph{rebalancing} - selling shares when their price goes up, and vice versa.
      \vskip1ex
      This \emph{rebalancing} therefore acts as a mean reverting strategy.
      \vskip1ex
      The logarithm of the wealth of a \emph{fixed number of shares} is approximately equal to the sum of the percentage returns.
      <<echo=TRUE,eval=FALSE>>=
# Set the initial dollar returns
retd[1, ] <- pricev[1, ]
# Calculate the prices from dollar returns
pricen <- cumsum(retd)
all.equal(pricen, pricev)
# Compound the percentage returns
pricen <- cumprod(1 + retp)
# Set the initial prices
prici <- as.numeric(pricev[1, ])
pricen <- lapply(1:NCOL(pricen), function (i) prici[i]*pricen[, i])
pricen <- rutils::do_call(cbind, pricen)
# pricen <- t(t(pricen)*prici)
all.equal(pricen, pricev, check.attributes=FALSE)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_log_vti.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot log VTI prices
endd <- rutils::calc_endpoints(rutils::etfenv$VTI, interval="weeks")
dygraphs::dygraph(log(quantmod::Cl(rutils::etfenv$VTI)[endd]),
  main="Logarithm of VTI Prices") %>%
  dyOptions(colors="blue", strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Funding Costs of Single Asset Rebalancing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The rebalancing of stock requires borrowing from a \emph{margin account}, and it also incurs trading costs.
      \vskip1ex
      The wealth accumulated from owning a \emph{fixed dollar amount} of stock is equal to the cash earned from rebalancing, which is proportional to the sum of the percentage returns, and it's kept in a \emph{margin account}: $m_t = \sum_{i=1}^t r^p_i$.
      \vskip1ex
      The cash in the \emph{margin account} can be positive (accumulated profits) or negative (losses).
      \vskip1ex
      The \emph{funding costs} $c^f_t$ are approximately equal to the \emph{margin account} $m_t$ times the \emph{funding rate} $f$: $c^f_t = f \, m_t = f \, \sum_{i=1}^t r^p_i$.
      \vskip1ex
      Positive \emph{funding costs} represent interest profits earned on the \emph{margin account}, while negative costs represent the interest paid for funding stock purchases.
      \vskip1ex
      The \emph{cumulative funding costs} $\sum_{i=1}^t c^f_t$ must be added to the \emph{margin account}: $m_t + \sum_{i=1}^t c^f_t$.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the percentage VTI returns
pricev <- rutils::etfenv$prices$VTI
pricev <- na.omit(pricev)
retp <- rutils::diffit(pricev)/rutils::lagit(pricev, lagg=1, pad_zeros=FALSE)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_margin.png}
      <<echo=TRUE,eval=FALSE>>=
# Funding rate per day
ratef <- 0.01/252
# Margin account value
marginv <- cumsum(retp)
# Cumulative funding costs
costf <- cumsum(ratef*marginv)
# Add funding costs to margin account
marginv <- (marginv + costf)
# dygraph plot of margin and funding costs
datav <- cbind(marginv, costf)
colv <- c("Margin", "Cumulative Funding")
colnames(datav) <- colv
endd <- rutils::calc_endpoints(datav, interval="weeks")
dygraphs::dygraph(datav[endd], main="VTI Margin Funding Costs") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue") %>%
  dySeries(name=colv[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Transaction Costs of Trading}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The total \emph{transaction costs} are the sum of the \emph{broker commissions}, the \emph{bid-ask spread} (for market orders), \emph{lost trades} (for limit orders), and \emph{market impact}.
      \vskip1ex
      Broker commissions depend on the broker, the size of the trades, and on the type of investors, with institutional investors usually enjoying smaller commissions.
      \vskip1ex
      The \emph{bid-ask spread} is the percentage difference between the \emph{ask} (offer) minus the \emph{bid} prices, divided by the \emph{mid} price.
      \vskip1ex
      Market impact is the effect of large trades pushing the market prices (the limit order book) against the trades, making the filled price worse.
      \vskip1ex
      Limit orders are not subject to the bid-ask spread but they are exposed to \emph{lost trades}.
      \vskip1ex
      \emph{Lost trades} are limit orders that don't get executed, resulting in lost potential profits.
      \vskip1ex
      Limit orders may receive rebates from some exchanges, which may reduce transaction costs.
    \column{0.5\textwidth}
      The bid-ask spread for many liquid ETFs is about \texttt{1} basis point. For example the 
\href{https://www.ssga.com/us/en/intermediary/etfs/funds/the-technology-select-sector-spdr-fund-xlk}{\emph{XLK ETF}}
      \vskip1ex
      In reality the \emph{bid-ask spread} is not static and depends on many factors, such as market liquidity (trading volume), volatility, and the time of day.
      \vskip1ex
      The \emph{transaction costs} due to the \emph{bid-ask spread} are equal to the number of traded shares times their price, times half the \emph{bid-ask spread}.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Transaction Costs of Single Asset Rebalancing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Maintaining a \emph{fixed dollar amount} of stock requires periodic \emph{rebalancing}, selling shares when their price goes up, and vice versa.
      \vskip1ex
      The dollar amount of stock that must be traded in a given period is equal to the absolute of the percentage returns: $\left| r_t \right|$.
      \vskip1ex
      The \emph{transaction costs} $c^r_t$ due to rebalancing are equal to half the \emph{bid-ask spread} $\delta$ times the dollar amount of the traded stock: $c^r_t = \frac{\delta}{2} \left| r_t \right|$.
      \vskip1ex
      The \emph{cumulative transaction costs} $\sum_{i=1}^t c^r_t$ must be subtracted from the \emph{margin account} $m_t$: $m_t - \sum_{i=1}^t c^r_t$.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_single_transaction_costs.png}
      <<echo=TRUE,eval=FALSE>>=
# The bid-ask spread is equal to 1 bp for liquid ETFs
bidask <- 0.001
# Cumulative transaction costs
costv <- bidask*cumsum(abs(retp))/2
# Subtract transaction costs from margin account
marginv <- cumsum(retp)
marginv <- (marginv - costv)
# dygraph plot of margin and transaction costs
datav <- cbind(marginv, costv)
colv <- c("Margin", "Transaction Costs")
colnames(datav) <- colv
dygraphs::dygraph(datav[endd], main="VTI Transaction Costs") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue") %>%
  dySeries(name=colv[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Combining the Returns of Multiple Assets}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Multiplying the weights times the dollar returns is equivalent to buying a \emph{fixed number of shares} proportional to the weights (aka \emph{Fixed Share Allocation} or FSA).
      \vskip1ex
      Multiplying the weights times the percentage returns is equivalent to investing in \emph{fixed dollar amounts of stock} proportional to the weights (aka \emph{Fixed Dollar Allocation} or FDA).
      \vskip1ex
      The portfolio allocations must be periodically rebalanced to keep the dollar amounts of the stocks proportional to the weights.
      \vskip1ex
      This \emph{rebalancing} acts as a mean reverting strategy - selling shares when their price goes up, and vice versa.
      \vskip1ex
      The \emph{FDA} portfolio has a slightly higher Sharpe ratio than the \emph{FSA} portfolio.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the VTI and IEF dollar returns
pricev <- rutils::etfenv$prices[, c("VTI", "IEF")]
pricev <- na.omit(pricev)
retd <- rutils::diffit(pricev)
datev <- zoo::index(pricev)
# Calculate the VTI and IEF percentage returns
retp <- retd/rutils::lagit(pricev, lagg=1, pad_zeros=FALSE)
# Wealth of fixed shares equal to $0.5 each at start (without rebalancing)
weightv <- c(0.5, 0.5)  # dollar weights
wealthfs <- drop(cumprod(1 + retp) %*% weightv)
# Or using the dollar returns
prici <- as.numeric(pricev[1, ])
retd[1, ] <- pricev[1, ]
wealthfs2 <- cumsum(retd %*% (weightv/prici))
all.equal(wealthfs, drop(wealthfs2))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_weighted_wealth.png}
      <<echo=TRUE,eval=FALSE>>=
# Wealth of fixed dollars equal to $0.5 each (with rebalancing)
wealthfd <- cumsum(retp %*% weightv)
# Calculate the Sharpe and Sortino ratios
wealthv <- cbind(log(wealthfs), wealthfd)
wealthv <- xts::xts(wealthv, datev)
colnames(wealthv) <- c("Fixed shares", "Fixed dollars")
sqrt(252)*sapply(rutils::diffit(wealthv), function(x) 
  c(Sharpe=mean(x)/sd(x), Sortino=mean(x)/sd(x[x<0])))
# Plot the log wealth
colv <- colnames(wealthv)
endd <- rutils::calc_endpoints(retp, interval="weeks")
dygraphs::dygraph(wealthv[endd], main="Wealth of Weighted Portfolios") %>%
  dySeries(name=colv[1], col="blue", strokeWidth=2) %>%
  dySeries(name=colv[2], col="red", strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Transaction Costs of Weighted Portfolio Rebalancing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Maintaining a \emph{fixed dollar allocation} of stock requires periodic \emph{rebalancing}, selling shares when their price goes up, and vice versa.
      \vskip1ex
      Adding the weighted percentage returns is equivalent to investing in \emph{fixed dollar amounts of stock} proportional to the weights $w_1, w_2$.
      \vskip1ex
      The dollar amount of stock that must be traded in a given period is equal to the weighted sum of the absolute percentage returns: $w_1 \left| r^1_t \right| + w_2 \left| r^2_t \right|$.
      \vskip1ex
      The \emph{transaction costs} $c^r_t$ due to rebalancing are equal to half the \emph{bid-ask spread} $\delta$ times the dollar amount of the traded stock: $c^r_t = \frac{\delta}{2} (w_1 \left| r^1_t \right| + w_2 \left| r^2_t \right|)$.
      \vskip1ex
      The \emph{cumulative transaction costs} $\sum_{i=1}^t c^r_t$ must be subtracted from the \emph{margin account} $m_t$: $m_t - \sum_{i=1}^t c^r_t$.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_transaction_costs.png}
      <<echo=TRUE,eval=FALSE>>=
# Margin account for fixed dollars (with rebalancing)
marginv <- cumsum(retp %*% weightv)
# Cumulative transaction costs
costv <- bidask*cumsum(abs(retp) %*% weightv)/2
# Subtract transaction costs from margin account
marginv <- (marginv - costv)
# dygraph plot of margin and transaction costs
datav <- cbind(marginv, costv)
datav <- xts::xts(datav, datev)
colv <- c("Margin", "Transaction Costs")
colnames(datav) <- colv
dygraphs::dygraph(datav[endd], main="Fixed Dollar Portfolio Transaction Costs") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue") %>%
  dySeries(name=colv[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Proportional Wealth Allocations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In the \emph{proportional wealth allocation} strategy (\emph{PWA}), the total wealth $\Pi_t$ is allocated to the assets $\Pi_i$ proportional to the portfolio weights $w_i$: $\Pi_i = w_i \Pi_t$.
      \vskip1ex
      The total wealth $\Pi_t$ is not fixed and is equal to the portfolio market value $\Pi_t = \sum \Pi_i$, so there's no margin account.
      \vskip1ex
      The portfolio is rebalanced daily to maintain the dollar allocations $\Pi_i$ equal to the total wealth $\Pi_t = \sum \Pi_i$ times the portfolio weights: $w_i$: $\Pi_i = w_i \Pi_t$.
      \vskip1ex
      Let $r_t$ be the percentage returns, $w_i$ be the portfolio weights, and $\bar{r}_t = \sum_{i=1}^n w_i r_t$ be the weighted percentage returns at time $t$.
      \vskip1ex
      The total portfolio wealth at time $t$ is equal to the wealth at time $t-1$ multiplied by the weighted returns: $\Pi_t = \Pi_{t-1} (1 + \bar{r}_t)$.
      \vskip1ex
      The dollar amount of stock $i$ at time $t$ increases by $w_i r_t$ so it's equal to $w_i \Pi_{t-1} (1 + r_t)$, while the target amount is $w_i \Pi_t = w_i \Pi_{t-1} (1 + \bar{r}_t)$
      \vskip1ex
      The dollar amount of stock $i$ needed to trade to rebalance back to the target weight is equal to:
      \begin{flalign*}
        \varepsilon_i &= \left| w_i \Pi_{t-1} (1 + \bar{r}_t) - w_i \Pi_{t-1} (1 + r_t) \right|\\
        &= w_i \Pi_{t-1} \left| \bar{r}_t - r_t \right|
      \end{flalign*}
      If $\bar{r}_t > r_t$ then an amount $\varepsilon_i$ of the stock $i$ needs to be bought, and if $\bar{r}_t < r_t$ then it needs to be sold.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_proportional_allocations.png}
      <<echo=TRUE,eval=FALSE>>=
# Wealth of fixed shares (without rebalancing)
wealthfs <- cumsum(retd %*% (weightv/prici))
# Or compound the percentage returns
wealthfs <- drop(cumprod(1 + retp) %*% weightv)
# Wealth of proportional wealth strategy (with rebalancing)
wealthpr <- cumprod(1 + retp %*% weightv)
wealthv <- cbind(wealthfs, wealthpr)
wealthv <- xts::xts(wealthv, datev)
colnames(wealthv) <- c("Fixed shares", "Prop wealth")
wealthv <- log(wealthv)
# Calculate the Sharpe and Sortino ratios
sqrt(252)*sapply(rutils::diffit(wealthv), function(x) 
  c(Sharpe=mean(x)/sd(x), Sortino=mean(x)/sd(x[x<0])))
# Plot the log wealth
dygraphs::dygraph(wealthv[endd], 
  main="Wealth of Proportional Wealth Allocations") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Transaction Costs With Proportional Wealth Allocations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In each period the stocks must be rebalanced to maintain the proportional wealth allocations.
      \vskip1ex
      The total dollar amount of stocks that need to be traded to rebalance back to the target weight is equal to: $\sum_{i=1}^n \varepsilon_i = \Pi_{t-1} \sum_{i=1}^n w_i \left| \bar{r}_t - r_t \right|$
      \vskip1ex
      The \emph{transaction costs} $c^r_t$ are equal to half the \emph{bid-ask spread} $\delta$ times the dollar amount of the traded stock: $c^r_t = \frac{\delta}{2} \sum_{i=1}^n \varepsilon_i$.
      \vskip1ex
      The \emph{cumulative transaction costs} $\sum_{i=1}^t c^r_t$ must be subtracted from the \emph{wealth} $\Pi_t$: $\Pi_t - \sum_{i=1}^t c^r_t$.
      <<echo=TRUE,eval=FALSE>>=
# Returns in excess of weighted returns
retw <- retp %*% weightv
retx <- lapply(retp, function(x) (x - retw))
retx <- do.call(cbind, retx)
sum(retx %*% weightv)
# Calculate the weighted sum of absolute excess returns
retx <- abs(retx) %*% weightv
# Total dollar amount of stocks that need to be traded
retx <- retx*rutils::lagit(wealthpr)
# Cumulative transaction costs
costv <- bidask*cumsum(retx)/2
# Subtract transaction costs from wealth
wealthpr <- (wealthpr - costv)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_proportional_allocations_transaction_costs.png}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of wealth and transaction costs
wealthv <- cbind(wealthpr, costv)
wealthv <- xts::xts(wealthv, datev)
colv <- c("Wealth", "Transaction Costs")
colnames(wealthv) <- colv
dygraphs::dygraph(wealthv[endd], 
  main="Transaction Costs With Equal Wealths") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue") %>%
  dySeries(name=colv[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Proportional Target Allocation Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In the \emph{fixed share strategy} (\emph{FSA}), the number of shares is fixed, with their initial dollar value equal to the portfolio weights.
      \vskip1ex
      In the \emph{proportional wealth allocation} strategy (\emph{PWA}), the portfolio is rebalanced daily to maintain the dollar allocations $\Pi_i$ equal to the total wealth $\Pi_t = \sum \Pi_i$ times the portfolio weights: $w_i$: $\Pi_i = w_i \Pi_t$.
      \vskip1ex
      In the \emph{proportional target allocation} strategy (\emph{PTA}), the portfolio is rebalanced only if the dollar allocations $\Pi_i$ differ from their targets $w_i \Pi_t$ more than the threshold value $\tau$: $\frac{\sum \left| \Pi_i - w_i \Pi_t \right|}{\Pi_t} > \tau$.
      \vskip1ex
      The \emph{PTA} strategy is path-dependent so it must be simulated using an explicit loop. 
      \vskip1ex
      The \emph{PTA} strategy is contrarian, since it sells assets that have outperformed, and it buys assets that have underperformed.
      \vskip1ex
      If the threshold level is very small then the \emph{PTA} strategy rebalances daily and it's the same as the \emph{PWA}.
      \vskip1ex
      If the threshold level is very large then the \emph{PTA} strategy does not rebalance and it's the same as the \emph{FSA}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Wealth of fixed shares (without rebalancing)
wealthfs <- drop(cumprod(1 + retp) %*% weightv)-1
# Wealth of proportional wealth (with rebalancing)
wealthpr <- cumprod(1 + retp %*% weightv) - 1
# Wealth of proportional target allocation (with rebalancing)
retp <- zoo::coredata(retp)
threshv <- 0.05
wealthv <- matrix(nrow=NROW(retp), ncol=2)
colnames(wealthv) <- colnames(retp)
wealthv[1, ] <- weightv
for (it in 2:NROW(retp)) {
  # Accrue wealth without rebalancing
  wealthv[it, ] <- wealthv[it-1, ]*(1 + retp[it, ])
  # Rebalance if wealth allocations differ from weights
  if (sum(abs(wealthv[it, ] - sum(wealthv[it, ])*weightv))/sum(wealthv[it, ]) > threshv) {
    # cat("Rebalance at:", it, "\n")
    wealthv[it, ] <- sum(wealthv[it, ])*weightv
  } # end if
} # end for
wealthv <- rowSums(wealthv) - 1
wealthv <- cbind(wealthpr, wealthv)
wealthv <- xts::xts(wealthv, datev)
colnames(wealthv) <- c("Equal Wealths", "Proportional Target")
dygraphs::dygraph(wealthv, main="Wealth of Proportional Target Allocations") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Stock and Bond Portfolio With Proportional Wealth Allocations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Portfolios combining stocks and bonds can provide a much better risk versus return tradeoff than either of the assets separately, because the returns of stocks and bonds are usually negatively correlated, so they are natural hedges of each other.
      \vskip1ex
      The fixed portfolio weights represent the percentage dollar allocations to stocks and bonds, while the portfolio wealth grows over time.
      \vskip1ex
      The weights depend on the investment horizon, with a greater allocation to bonds for a shorter investment horizon.
      \vskip1ex
      Active investment strategies are expected to outperform static stock and bond portfolios.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the stock and bond returns
retp <- na.omit(rutils::etfenv$returns[, c("VTI", "IEF")])
weightv <- c(0.4, 0.6)
retp <- cbind(retp, retp %*% weightv)
colnames(retp)[3] <- "Combined"
# Calculate the correlations
cor(retp)
# Calculate the Sharpe ratios
sqrt(252)*sapply(retp, function(x) mean(x)/sd(x))
# Calculate the standard deviation, skewness, and kurtosis
sapply(retp, function(x) {
  # Calculate the standard deviation
  stdev <- sd(x)
  # Standardize the returns
  x <- (x - mean(x))/stdev
  c(stdev=stdev, skew=mean(x^3), kurt=mean(x^4))
})  # end sapply
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_proportional_stocks_bonds.png}
      <<echo=TRUE,eval=FALSE>>=
# Wealth of equal wealth strategy
wealthv <- cumsum(retp)
# Calculate the a vector of monthly end points
endd <- rutils::calc_endpoints(retp, interval="weeks")
# Plot cumulative log wealth
dygraphs::dygraph(wealthv[endd], 
  main="Stocks and Bonds With Equal Wealths") %>%
  dyOptions(colors=c("blue", "green", "blue", "red")) %>%
  dySeries("Combined", color="red", strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Stock and Bond Portfolio Allocations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The optimal stock and bond weights can be calculated using optimization.
      \vskip1ex
      Using the past \texttt{20} years of data, the optimal \emph{VTI} weight is about \texttt{0.28}.
      \vskip1ex
      The comments and conclusions in these slides are based on \texttt{20} years of very positive stock and bond returns, when stocks and bonds have been in a secular bull market.  The conclusions would not hold if stocks and bonds had suffered from a bear market (losses) over that time.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the Sharpe ratios
sqrt(252)*sapply(retp, function(x) mean(x)/sd(x))
# Calculate the Sharpe ratios for vector of weights
weightv <- seq(0.05, 0.95, 0.05)
sharpev <- sqrt(252)*sapply(weightv, function(weight) {
  weightv <- c(weight, 1-weight)
  retp <- (retp[, 1:2] %*% weightv)
  mean(retp)/sd(retp)
})  # end sapply
# Calculate the optimal VTI weight
weightm <- weightv[which.max(sharpev)]
# Calculate the optimal weight using optimization
calc_sharpe <- function(weight) {
  weightv <- c(weight, 1-weight)
  retp <- (retp[, 1:2] %*% weightv)
  -mean(retp)/sd(retp)
}  # end calc_sharpe
optv <- optimize(calc_sharpe, interval=c(0, 1))
weightm <- optv$minimum
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_sharpe_max.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot Sharpe ratios
plot(x=weightv, y=sharpev, 
     main="Sharpe Ratio as Function of VTI Weight",
     xlab="VTI weight", ylab="Sharpe Ratio", 
     t="l", lwd=3, col="blue")
abline(v=weightm, lty="dashed", lwd=1, col="blue")
text(x=weightm, y=0.7*max(sharpev), pos=4, cex=1.2, 
     labels=paste("optimal VTI weight =", round(weightm, 2)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Wealth Scenarios Using Block Bootstrap}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The past data represents only one possible market scenario.  We can generate more scenarios using bootstrap simulation.
      \vskip1ex
      In block bootstrap, multiple rows of the time series data are sampled to generate new data.
      \vskip1ex
      The bootstrap data represent the possible cumulative \emph{VTI} and \emph{IEF} returns over the given holding period, based on past history.
      \vskip1ex
      For sampling from rows of data, it's better to convert the time series to a matrix.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Coerce the log prices from xts time series to matrix 
pricev <- na.omit(rutils::etfenv$prices[, c("VTI", "IEF")])
pricev <- log(zoo::coredata(pricev))
nrows <- NROW(pricev)
holdp <- 10*252 # Holding period of 10 years in days
# Sample the start dates for the bootstrap
set.seed(1121, "Mersenne-Twister", sample.kind="Rejection")
startd <- sample.int(nrows-holdp, 1e3, replace=TRUE)
# Bootstrap the wealth
wealthv <- sapply(startd, function(x) {
  pricev[x+holdp-1, ] - pricev[x, ]
})  # end sapply
dim(wealthv)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Distributions of Terminal Wealth From Bootstrap}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The distribution of \emph{VTI} and \emph{IEF} wealths can be calculated from the bootstrap data.
      \vskip1ex
      The distribution of \emph{VTI} wealth is much wider than \emph{IEF}, but it has a much greater mean value.
      \vskip1ex
      The distributions of wealth are bimodal (have two maxima) because there have been two historical market regimes: bull and bear markets.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the means and standard deviations of the terminal wealths
apply(wealthv, 1, mean)
apply(wealthv, 1, sd)
# Extract the terminal wealths of VTI and IEF
vtiw <- wealthv["VTI", ]
iefw <- wealthv["IEF", ]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_wealth_vtiief.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the densities of the terminal wealths of VTI and IEF
vtim <- mean(vtiw); iefm <- mean(iefw)
vtid <- density(vtiw); iefd <- density(iefw)
plot(vtid, col="blue", lwd=3, xlab="wealth",
     xlim=c(0, 2*max(iefd$x)), ylim=c(0, max(iefd$y)), 
     main="Terminal Wealth Distributions of VTI and IEF")
lines(iefd, col="green", lwd=3)
abline(v=vtim, col="blue", lwd=2, lty="dashed")
text(x=vtim, y=0.5, labels="VTI mean", pos=4, cex=0.8)
abline(v=iefm, col="green", lwd=2, lty="dashed")
text(x=iefm, y=0.5, labels="IEF mean", pos=4, cex=0.8)
legend(x="topright", legend=c("VTI", "IEF"),
       inset=0.1, cex=1.0, bg="white", bty="n", y.intersp=0.5, 
       lwd=6, lty=1, col=c("blue", "green"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Distribution of Stock Wealth and Holding Period}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The distribution of stock wealth for short holding periods is close to symmetric.
      \vskip1ex
      The distributions for longer holding periods have larger means and standard deviations, and are more positively skewed, with a smaller kurtoisis.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the distributions of stock wealth
holdv <- nrows*seq(0.1, 0.5, 0.1)
wealthm <- sapply(holdv, function(holdp) {
  startd <- sample.int(nrows-holdp, 1e3, replace=TRUE)
  wealthv <- sapply(startd, function(x) {
    pricev[x+holdp-1, "VTI"] - pricev[x, "VTI"]
  })  # end sapply
})  # end sapply
dim(wealthm)
colnames(wealthm) <- paste0(round(holdv/252), "years")
# Calculate the skewness and kurtosis of the stock wealth distributions
apply(wealthm, 2, function(x) {
  # Standardize the returns
  x <- (x - mean(x))/sd(x)
  c(skew=mean(x^3), kurt=mean(x^4))
}) # end apply
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_wealth_longshort.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the stock wealth for long and short holding periods
wealth1 <- wealthm[, 5]
wealth2 <- wealthm[, 1]
mean1 <- mean(wealth1); mean2 <- mean(wealth2)
dens1 <- density(wealth1); dens2 <- density(wealth2)
plot(dens1, col="blue", lwd=3, xlab="wealth",
     xlim=c(0, 2.5*max(dens2$x)), ylim=c(0, max(dens2$y)), 
     main="Wealth Distributions for Long and Short Holding Periods")
lines(dens2, col="green", lwd=3)
abline(v=mean1, col="blue", lwd=2, lty="dashed")
text(x=mean1, y=0.5, labels="Long", pos=4, cex=0.8)
abline(v=mean2, col="green", lwd=2, lty="dashed")
text(x=mean2, y=0.5, labels="Short", pos=4, cex=0.8)
legend(x="topright", legend=c("Long", "Short"),
       inset=0.0, cex=1.0, bg="white", bty="n", y.intersp=0.5, 
       lwd=6, lty=1, col=c("blue", "green"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk-adjusted Stock Wealth and Holding Period}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The risk-adjusted wealth measure is equal to the mean wealth divided by its standard deviation.
      \vskip1ex
      During the bull market in the last \texttt{40} years, U.S. stocks have had higher risk-adjusted wealth for longer holding periods.
      <<echo=TRUE,eval=FALSE>>=
# Define the risk-adjusted wealth measure
riskretfun <- function(wealthv) {
  mean(wealthv)/sd(wealthv)
}  # end riskretfun
# Calculate the stock wealth risk-return ratios
riskrets <- apply(wealthm, 2, riskretfun)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_wealth_riskreturn.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the stock wealth risk-return ratios
plot(x=holdv, y=riskrets, 
     main="Stock Risk-Return Ratio as Function of Holding Period",
     xlab="Holding Period", ylab="Ratio", 
     t="l", lwd=3, col="blue")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Stock and Bond Portfolio Allocations From Bootstrap}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The optimal stock and bond weights can be calculated using block bootstrap simulation.
      \vskip1ex
      Bootstrapping the stock and bond returns over a \texttt{10} year holding period, the optimal \emph{VTI} weight is about \texttt{0.45}.
      \vskip1ex
      This weight is higher than the \texttt{0.28} calculated from the past \texttt{20} years of data, because the risk is measured as the standard deviation of the terminal wealth, not the standard deviation of the daily returns.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the distributions of portfolio wealth for different weights of VTI
weightv <- seq(0.05, 0.95, 0.05)
wealthm <- sapply(weightv, function(weight) {
  wealthv <- sapply(startd, function(x) {
    (pricev[x+holdp-1, ] - pricev[x, ]) %*% c(weight, 1-weight)
  })  # end sapply
})  # end sapply
dim(wealthm)
# Calculate the portfolio risk-return ratios
riskrets <- apply(wealthm, 2, riskretfun)
# Calculate the optimal VTI weight
weightm <- weightv[which.max(riskrets)]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_riskret_max.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the portfolio risk-return ratios
plot(x=weightv, y=riskrets, 
     main="Portfolio Risk-Return Ratio as Function of VTI Weight",
     xlab="VTI weight", ylab="Ratio", 
     t="l", lwd=3, col="blue")
abline(v=weightm, lty="dashed", lwd=1, col="blue")
text(x=weightm, y=0.5*max(riskrets), pos=3, cex=1.2, 
     labels=paste("optimal VTI weight =", round(weightm, 2)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{All-Weather} Portfolio}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{All-Weather} portfolio is a portfolio with proportional allocations of stocks ($30\%$), bonds ($55\%$), and commodities and precious metals ($15\%$) (approximately).
      \vskip1ex
      The \emph{All-Weather} portfolio was developed by 
      \href{https://www.bridgewater.com/research-and-insights}{\emph{Bridgewater Associates}}, the largest hedge fund in the world:\\
      {\tiny
      \url{https://www.bridgewater.com/research-library/the-all-weather-strategy/} \\
      \url{http://www.nasdaq.com/article/remember-the-allweather-portfolio-its-having-a-killer-year-cm685511} \\
      }
      The three different asset classes (stocks, bonds, commodities) provide positive returns under different economic conditions (recession, expansion, inflation).
      \vskip1ex
      The combination of bonds, stocks, and commodities in the \emph{All-Weather} portfolio is designed to provide positive returns under most economic conditions, without the costs of trading.
      <<echo=TRUE,eval=FALSE>>=
# Extract the ETF returns
symbolv <- c("VTI", "IEF", "DBC")
retp <- na.omit(rutils::etfenv$returns[, symbolv])
# Calculate the all-weather portfolio wealth
weightaw <- c(0.30, 0.55, 0.15)
retp <- cbind(retp, retp %*% weightaw)
colnames(retp)[4] <- "All Weather"
# Calculate the Sharpe ratios
sqrt(252)*sapply(retp, function(x) mean(x)/sd(x))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_all_weather.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the cumulative wealth from returns
wealthv <- cumsum(retp)
# Calculate the a vector of monthly end points
endd <- rutils::calc_endpoints(wealthv, interval="weeks")
# dygraph all-weather wealth
dygraphs::dygraph(wealthv[endd], main="All-Weather Portfolio") %>%
  dyOptions(colors=c("blue", "green", "orange", "red")) %>%
  dySeries("All Weather", color="red", strokeWidth=2) %>%
  dyLegend(show="always", width=400)
# Plot all-weather wealth
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue", "green", "red")
quantmod::chart_Series(wealthv, theme=plot_theme, lwd=c(2, 2, 2, 4),
             name="All-Weather Portfolio")
legend("topleft", legend=colnames(wealthv),
  inset=0.1, bg="white", lty=1, lwd=6, y.intersp=0.5, 
  col=plot_theme$col$line.col, bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Constant Proportion Portfolio Insurance Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Constant Proportion Portfolio Insurance} (CPPI) strategy rebalances its portfolio between stocks and zero-coupon bonds.
      \vskip1ex
      The CPPI strategy has a fixed maturity date, and it's designed to pay back the initial principal investment at maturity.
      \vskip1ex
      When stock prices are declining, the CPPI strategy sells its stocks and buys bonds, to protect against the loss of principal at maturity.
      \vskip1ex
      A zero-coupon bond pays no coupon, but it's bought at a discount to par ($\$100$), and pays par at maturity.  The investor receives capital appreciation instead of coupons.
      \vskip1ex
      The bond floor $F$ is set so that its value at maturity is equal to par - the initial principal investment.  
      \vskip1ex
      The value of the CPPI portfolio $P$, is equal to the sum of the stock $SV$ and bond $B$ values: $P = SV + B$.
      \vskip1ex
      The stock investment is levered by the \emph{CPPI multiplier} $C$ through borrowing.
      The amount invested in stocks $SI$ is equal to the \emph{cushion} $(P - F)$ times the multiplier $C$: $SI = \max(C * (P - F), 0)$.
      The remaining amount of the portfolio is invested in zero-coupon bonds and is equal to: $B = \max(P - C * (P - F), 0)$.
    \column{0.5\textwidth}
      \vspace{-1em}
      % The diagram was created in Pages and exported as a PDF file:
      % /Users/jerzy/Develop/lecture_slides/figure/CPPI.pages
      \includegraphics[width=0.35\paperwidth]{figure/portf_cppi_diagram.pdf}\\
      Additional stock purchases can be funded by borrowing from a margin account.
      \vskip1ex
      The stock investment $SI$ is the dollar amount of stocks owned by the CPPI strategy.
      The net value of the stocks $SV$ is equal to the stock investment $SI$ minus the borrowed amount $M$: $SV = SI - M$.
      If there's no borrowing, then the stock value is equal to the stock investment $SV = SI$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{CPPI Strategy Scenarios}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Assume a \emph{CPPI} strategy with a bond floor of $F = \$60$, and a multiplier of $C = 2$.
      The initial stock investment is: $SI = 2 * (\$100 - \$60) = \$80$, and the amount invested in bonds is: $B = \$100 - \$80 = \$20$.
      \vskip1ex
      Assume that stocks have a positive return of $20\%$, so that the stock value increases to $SV = \$80 * 1.2 = \$96$, while the bond value remains: $B = \$20$.
      So that the portfolio value (wealth) increases to: $P = SV + B = \$96 + \$20 = \$116$.
      \vskip1ex
      The stock investment $SI$ must increase to: $SI = 2 * (\$116 - \$60) = \$112$, while the bond investment must decrease to: $B = \$116 - \$112 = \$4$.
      The additional $\$16$ of stocks is purchased from the sale of the bonds.
      \vskip1ex
      Assume next that stocks have another positive return of $20\%$, so that the stock value increases to $SV = \$112 * 1.2 = \$134.4$, while the bond value remains: $B = \$4$.
      So that the wealth increases to $P = SV + B = \$134.4 + \$4 = \$138.4$.
      \vskip1ex
      The stock investment $SI$ must increase to: $SI = 2 * (\$134.4 - \$60) = \$148.8$, while the bond investment drops to zero: $B = \max(\$138.4 - \$148.8, 0) = \$0$.
      The additional $\$14.4$ of stocks is purchased from the sale of $\$4$ of the bonds plus $\$10.4$ of borrowed money.
    \column{0.5\textwidth}
      If stock prices keep rising, then the stock investment and the CPPI portfolio value both increase, and the bond investment decreases.
      \vskip1ex
      But if stock prices decline, then the stock investment and the CPPI portfolio value both decrease, and the CPPI strategy sells its stocks and buys bonds.
      \vskip1ex
      Assume that stocks have a negative return of $-20\%$, so that the stock value increases to $SV = \$80 * 0.8 = \$64$.
      Then the portfolio value (wealth) decreases to: $P = SV + B = \$64 + \$20 = \$84$.
      \vskip1ex
      The stock investment $SI$ must decrease to: $SI = 2 * (\$84 - \$60) = \$48$, while the bond investment must increase to: $B = \$84 - \$48 = \$36$.
      The additional $\$16$ of bonds is purchased from the sale of the stocks.
      \vskip1ex
      If stock prices keep declining and the portfolio value $P$ drops to the bond floor $F$, then all the stocks are sold, and only the zero-coupon bond remains, so that at maturity the investor is paid back at least the full initial principal $P = \$100$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{CPPI Strategy Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Simulating the CPPI strategy requires performing a \texttt{for()} loop over time, since the strategy is path-dependent.
      \vskip1ex
      At each time step, the stock price and portfolio value are updated based on the stock return.
      \vskip1ex
      Then the CPPI leverage is applied to the stock investment based on the updated portfolio value.
      \vskip1ex
      Applying the CPPI leverage may require borrowing money to buy more stocks (we assume zero borrowing costs).
      \vskip1ex
      The amount invested in stocks changes both because the stock price changes and because of additional CPPI leverage. 
      \vskip1ex
      The stock purchases are funded from the sale of bonds and with borrowing from a margin account.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the VTI returns
retp <- na.omit(rutils::etfenv$returns$VTI)
nrows <- NROW(retp)
# Bond floor
bfloor <- 60
# CPPI multiplier
coeff <- 2
# Portfolio market values
portfv <- numeric(nrows)
# Initial principal
portfv[1] <- 100
# Stock investment
stocki <- numeric(nrows)
stocki[1] <- max(coeff*(portfv[1] - bfloor), 0)
# Stock value
stockv <- numeric(nrows)
stockv[1] <- stocki[1]
# Bond value
bondv <- numeric(nrows)
bondv[1] <- max(portfv[1] - stocki[1], 0)
# Margin account
margv <- numeric(nrows)
# Simulate the CPPI strategy
for (t in 2:nrows) {
  # Update the portfolio value
  stocki[t] <- (1 + retp[t])*stocki[t-1]
  stockv[t] <- stocki[t] - margv[t-1]
  portfv[t] <- stockv[t] + bondv[t-1]
  # Update the CPPI leverage
  stockt <- max(coeff*(portfv[t] - bfloor), 0)
  bondv[t] <- max(portfv[t] - stockt, 0)
  margv[t] <- (bondv[t] - bondv[t-1]) + (stockt - stocki[t]) + margv[t-1]
  stocki[t] <- stockt
}  # end for
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{CPPI Strategy Dynamics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{CPPI} strategy is a \emph{trend following} strategy, buying stocks when their prices are rising, and selling when their prices are dropping.
      \vskip1ex
      The \emph{CPPI} strategy can be considered a dynamic replication of a portfolio with a zero-coupon bond and a stock call option.
      \vskip1ex
      The \emph{CPPI} strategy is exposed to \emph{gap risk}, if stock prices drop suddenly by a large amount.  
      The \emph{gap risk} is exacerbated by high leverage, when the multiplier $C$ is large, say greater than $5$.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_cppi_perf.png}
      <<echo=TRUE,eval=FALSE>>=
pricev <- 100*cumprod(1 + retp)
datav <- cbind(stockv, bondv, portfv, pricev)["2008/2009"]
colnames(datav) <- c("stocks", "bonds", "CPPI", "VTI")
endd <- rutils::calc_endpoints(datav, interval="weeks")
dygraphs::dygraph(datav[endd], main="CPPI Strategy") %>%
  dyOptions(colors=c("red", "green", "blue", "black"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{CPPI Strategy Performance}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The performance of the CPPI strategy depends on the level of the bond floor $F$ and the multiplier $C$, with larger returns for higher values of $C$, but also higher risk.
      \vskip1ex
      When stocks rally, the margin account grows and the bond allocation decreases.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_cppi_perffull.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the CPPI margin account
margv <- cbind(pricev, margv)
colnames(margv)[2] <- "margin"
endd <- rutils::calc_endpoints(margv, interval="weeks")
dygraphs::dygraph(margv[endd], main="CPPI Margin and VTI") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
# Calculate the Sharpe of CPPI wealth
wealthv <- cbind(pricev, portfv)
colnames(wealthv)[2] <- "CPPI"
sqrt(252)*sapply(rutils::diffit(wealthv), function(x)
  c(Sharpe=mean(x)/sd(x), Sortino=mean(x)/sd(x[x<0])))
# Plot the CPPI wealth
dygraphs::dygraph(log(wealthv[endd]), main="Wealth of CPPI and VTI") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk Parity Strategy For Stocks and Bonds}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The stock dollar amounts of the risk parity strategy are such that they have \emph{equal dollar volatilities}.
      \vskip1ex
      The stock dollar amounts must be inversely proportional to the dollar volatilities: $w_i \propto \frac{1}{\sigma_i}$.
      \vskip1ex
      The risk parity strategy has a higher Sharpe ratio than the fixed share strategy with equal initial dollar amounts because it's overweight bonds. 
      But it also has lower absolute returns.
      \vskip1ex
      The risk parity strategy was developed in the early \texttt{1990s} by \href{https://www.bridgewater.com/research-and-insights}{\emph{Bridgewater Associates}}.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the dollar and percentage returns of VTI and IEF
pricev <- na.omit(rutils::etfenv$prices[, c("VTI", "IEF")])
datev <- zoo::index(pricev)
retd <- rutils::diffit(pricev)
retd[1, ] <- retd[2, ]
retp <- retd/rutils::lagit(pricev, lagg=1, pad_zeros=FALSE)
# Calculate the risk parity weights
weightv <- 1/sapply(retd, sd)
weightv <- weightv/sum(weightv)
# Wealth of risk parity (fixed shares)
wealthrp <- drop(pricev %*% weightv)
# Wealth of equal dollar (fixed shares)
weightv <- 1/as.numeric(pricev[1, ])
weightv <- weightv/sum(weightv)
wealthed <- (pricev %*% weightv)
# Scale the wealth to start equal to wealthrp
wealthed <- wealthrp[1]*wealthed/wealthed[1]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_risk_parity_insample.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the Sharpe and Sortino ratios
wealthv <- xts::xts(cbind(wealthed, wealthrp), datev)
colnames(wealthv) <- c("Equal dollar", "Risk parity")
sqrt(252)*sapply(rutils::diffit(wealthv), function(x) 
  c(Sharpe=mean(x)/sd(x), Sortino=mean(x)/sd(x[x<0])))
# Plot the log wealth
endd <- rutils::calc_endpoints(wealthv, interval="weeks")
dygraphs::dygraph(log(wealthv[endd]), 
  main="Wealth of Equal Dollar And Risk parity") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Rolling Risk Parity Allocations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In practice, the dollar volatility $\sigma_t$ changes over time so it must be recalculated, and the weights must be updated: $w_t \propto \frac{1}{\sigma_t}$.
      \vskip1ex
      The stock allocations (\emph{dollar amounts}) increase when the volatility is low, and vice versa.
      \vskip1ex
      The function \texttt{HighFreq::run\_var()} calculates the trailing variance of returns $r_t$, by recursively weighting the past variance estimates $\sigma^2_{t-1}$, with the squared differences of the returns minus the trailing means $(r_t - \bar{r}_t)^2$, using the decay factor $\lambda$:
      \begin{flalign*}
        & \bar{r}_t = \lambda \bar{r}_{t-1} + (1 - \lambda) r_t \\
        & \sigma^2_t = \lambda^2 \sigma^2_{t-1} + (1 - \lambda^2) (r_t - \bar{r}_t)^2
      \end{flalign*}
      Where $\sigma^2_t$ is the trailing variance at time $t$.
      \vskip1ex
      The decay factor $\lambda$ determines how quickly the variance estimates are updated, with smaller values of $\lambda$ producing faster updating, giving more weight to recent returns, and vice versa.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_risk_parity_alloc.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the trailing dollar volatilities
lambdav <- 0.99
vold <- HighFreq::run_var(retd, lambda=lambdav)
vold <- sqrt(vold[, 3:4])
# Calculate the rolling risk parity weights
weightv <- ifelse(vold > 0, 1/vold, 1)
weightv <- weightv/rowSums(weightv)
# Calculate the risk parity allocations
pricerp <- pricev*weightv
# Plot the risk parity allocations
colnames(pricerp) <- c("Stocks", "Bonds")
dygraph(log(pricerp[endd]), main="Risk Parity Allocations") %>%
  dyOptions(colors=c("red", "blue"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Rolling Risk Parity Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In the \emph{Risk Parity} strategy the stock allocations are rebalanced daily so that their dollar volatilities remain equal.
      \vskip1ex
      The dollar returns of risk parity $r_d$ are equal to the percentage returns of the original prices $r_t$ times the stock allocations $p_a$: $r_d = r_t p_a$.
      \vskip1ex
      The risk parity strategy for stocks and bonds has a higher Sharpe ratio than the proportional wealth strategy. 
      But it also has lower absolute returns.
      \vskip1ex
      The absolute returns can be increased by increasing the leverage - buying more stocks and bonds with borrowed money.
      \vskip1ex
      Risk parity performs better for assets with negative or low correlations of returns, like stocks and bonds.
      \vskip1ex
      Risk parity performed poorly during the Covid crisis because of the 
      \href{https://tinyurl.com/bdhwp62n}{\emph{simultaneous losses of both stocks and bonds}} (positive correlations).
      <<echo=TRUE,eval=FALSE>>=
# Calculate the dollar returns of risk parity
retrp <- retp*rutils::lagit(pricerp)
retrp[1, ] <- pricerp[1, ]
# Calculate the wealth of risk parity
wealthrp <- cumsum(rowSums(retrp))
# Wealth of proportional wealth (with rebalancing)
wealthpr <- cumprod(1 + rowMeans(retp))
wealthpr <- wealthpr*wealthrp[1]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_risk_parity_wealth.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the Sharpe and Sortino ratios
wealthv <- cbind(wealthpr, wealthrp)
wealthv <- xts::xts(wealthv, datev)
colnames(wealthv) <- c("PropWealth", "Risk Parity")
sqrt(252)*sapply(rutils::diffit(wealthv), function(x) 
  c(Sharpe=mean(x)/sd(x), Sortino=mean(x)/sd(x[x<0])))
# Plot a dygraph of the log wealths
endd <- rutils::calc_endpoints(wealthv, interval="weeks")
dygraphs::dygraph(log(wealthv[endd]), 
  main="Log of Proportional Wealth vs Risk Parity") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk Parity Strategy Market Timing Skill}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The risk parity strategy reduces allocations to assets with higher volatilities, which is often accompanied by negative returns.
      \vskip1ex
      This allows the risk parity strategy to time the markets better - selling when prices are droppng and buying when prices are rising.  But only when the changes of the volatility are significant.
      \vskip1ex
      But the t-value of the risk parity strategy is negative, because it's contrarian when the volatility is stable.
      \vskip1ex
      The t-value of the proportional wealth allocation strategy is negative, because it's contrarian - it buys stocks when their prices drop.
      <<echo=TRUE,eval=FALSE>>=
# Test risk parity market timing of VTI using Treynor-Mazuy test
retrp <- rutils::diffit(wealthv)
retvti <- retp$VTI
desm <- cbind(retrp, retvti, retvti^2)
colnames(desm)[1:2] <- c("prop", "riskp")
colnames(desm)[4] <- "Treynor"
regmod <- lm(riskp ~ VTI + Treynor, data=desm)
summary(regmod)
# Plot residual scatterplot
resids <- regmod$residuals
plot.default(x=retvti, y=resids, xlab="VTI", ylab="residuals")
title(main="Treynor-Mazuy Market Timing Test\n for Risk Parity vs VTI", line=0.5)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_risk_parity_timing_skill.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot fitted (predicted) response values
coefreg <- summary(regmod)$coeff
fitv <- regmod$fitted.values - coefreg["VTI", "Estimate"]*retvti
tvalue <- round(coefreg["Treynor", "t value"], 2)
points.default(x=retvti, y=fitv, pch=16, col="red")
text(x=0.0, y=0.9*max(resids), paste("Risk Parity t-value =", tvalue))
# Test for equal wealth strategy market timing of VTI using Treynor-Mazuy test
regmod <- lm(prop ~ VTI + Treynor, data=desm)
summary(regmod)
# Plot fitted (predicted) response values
coefreg <- summary(regmod)$coeff
fitv <- regmod$fitted.values - coefreg["VTI", "Estimate"]*retvti
points.default(x=retvti, y=fitv, pch=16, col="blue")
text(x=0.0, y=0.7*max(resids), paste("Prop Wealth t-value =", round(coefreg["Treynor", "t value"], 2)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Transaction Costs of Risk Parity Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The risk parity strategy has higher transaction costs because it trades more shares than the proportional wealth strategy, and it may also use leverage to buy more shares.
      \vskip1ex
      But the higher transaction costs are not large enough to completely cancel the higher returns of the strategy.
      <<echo=TRUE,eval=FALSE>>=
# Total dollar amount of stocks that need to be traded
notx <- rutils::diffit(pricerp)
# The bid-ask spread is equal to 1 bp for liquid ETFs
bidask <- 0.001
# Calculate the cumulative transaction costs
costv <- 0.5*bidask*cumsum(rowSums(abs(notx)))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_risk_parity_transaction_costs.png}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of wealth and transaction costs
wealthv <- cbind(wealthrp, wealthrp-costv)
wealthv <- xts::xts(wealthv, datev)
colv <- c("Risk Parity", "With Costs")
colnames(wealthv) <- colv
dygraphs::dygraph(wealthv[endd], main="Risk Parity Including Transaction Costs") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=300)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}

%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\secname}
\vspace{-1em}
\begin{block}{Required}
  \begin{itemize}[]
    \item Study all the lecture slides in \texttt{FRE7241\_Lecture\_1.pdf}, and run all the code in \texttt{FRE7241\_Lecture\_1.R},
  \end{itemize}
\end{block}
\begin{block}{Recommended}
  \begin{itemize}[]
    \item Read the documentation for packages \texttt{rutils.pdf} and \texttt{HighFreq.pdf},
  \end{itemize}
\end{block}

\end{frame}



\end{document}
