% FRE7241_Lecture1
% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size="tiny", fig.width=4, fig.height=4)
options(width=80, dev="pdf")
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[9pt]{beamer}
\DeclareMathSizes{8pt}{6pt}{6pt}{5pt}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{mathtools}
% bbm and bbold packages for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{bbold}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
\usepackage{listings}
\usepackage{xcolor}
\definecolor{anti_flashwhite}{rgb}{0.95, 0.95, 0.96}
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE7241 Lecture\#1]{FRE7241 Algorithmic Portfolio Management}
\subtitle{Lecture\#1, Fall 2023}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color.png}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{September 5, 2023}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Introduction}


%%%%%%%%%%%%%%%
\subsection{Welcome Students!}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      My name is Jerzy Pawlowski \href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}
      \vskip1ex
      I'm an adjunct professor at NYU Tandon because I love teaching and I want to share my professional knowledge with young, enthusiastic students.
      \vskip1ex
      I'm interested in applications of \emph{machine learning} to \emph{systematic investing}.
      \vskip1ex
      I'm an advocate of \emph{open-source software}, and I share it on GitHub:\\
      \href{https://github.com/algoquant/}{\color{blue}{My GitHub account}} 
      \vskip1ex
      In my finance career, I have worked as a hedge fund \emph{portfolio manager}, \emph{CLO structurer} (banker), and \emph{quant analyst}.\\
      \href{https://www.linkedin.com/in/jerzypawlowski/}{\color{blue}{My LinkedIn profile}} 
    \column{0.5\textwidth}
    \includegraphics[width=0.5\paperwidth]{image/Jerzy_Pawlowski_linked.png}
    \includegraphics[width=0.5\paperwidth]{image/github_algoquant.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Course Description and Objectives}
\begin{frame}[t]{\subsecname}
\vspace{-2em}

\begin{block}{Course Description}
The course will apply the \texttt{R} programming language to \emph{trend following}, \emph{momentum trading}, \emph{statistical arbitrage} (pairs trading), and other active portfolio management strategies.  The course will implement volatility and price \emph{forecasting models}, asset pricing and \emph{factor models}, and \emph{portfolio optimization}.  The course will apply \emph{machine learning} techniques, such as \emph{parameter regularization} (shrinkage), \emph{bagging} and \emph{backtesting} (cross-validation).\\
\textbf{The course is challenging, so it requires devoting a significant amount of time!}
\end{block}
\pause

\begin{block}{Course Objectives}
Students will learn through \texttt{R} coding exercises how to:\\
\hskip1em - download data from external sources, and to scrub and format it.\\
\hskip1em - estimate time series parameters, and fit models such as \emph{ARIMA}, \emph{GARCH}, and factor models.\\
\hskip1em - optimize portfolios under different constraints and risk-return objectives.\\
\hskip1em - backtest active portfolio management strategies and evaluate their performance.\\
\end{block}
\pause

\begin{block}{Course Prerequisites}
  \emph{FRE6123 Financial Risk Management and Asset Pricing}.  The \texttt{R} language is considered to be challenging, so this course requires programming experience with other languages such as \texttt{C++} or \texttt{Python}.  Students with less programming experience are encouraged to first take \emph{FRE6871 R in Finance}, and also \emph{FRE6883 Financial Computing} by prof. Song Tang.  Students should also have knowledge of basic statistics (random variables, estimators, hypothesis testing, regression, etc.)
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Homeworks and Tests}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Homeworks and Tests}
Grading will be based on homeworks and tests.  There will be no final exam.
      \vskip1ex
The tests will be announced several days in advance.
      \vskip1ex
The homeworks and tests will require writing code, which should run directly when pasted into an \texttt{R} session, and should produce the required output, without any modifications.
      \vskip1ex
Students will be allowed to consult lecture slides, and to copy code from them, and to copy from books or any online sources, but they will be required to provide references to those external sources (such as links or titles and page numbers).
      \vskip1ex
The tests will be closely based on code contained in the lecture slides, so students are encouraged to become very familiar with those slides.
      \vskip1ex
Students will submit their homework and test files only through \emph{Brightspace} (not emails).
      \vskip1ex
Students will be required to bring their laptop computers to class and run the \texttt{R} Interpreter, and the \texttt{RStudio} Integrated Development Environment (\emph{IDE}), during the lecture.
      \vskip1ex
Homeworks will also include reading assignments designed to help prepare for tests.
\end{block}
\pause

\begin{block}{Graduate Assistant}
The graduate assistant (GA) will be Raunak Bhupal \href{mailto:rb4986@nyu.edu}{rb4986@nyu.edu}.\\
The GA will answer questions during office hours, or via \emph{Brightspace} forums, not via emails.  Please send emails regarding lecture matters from \emph{Brightspace} (not personal emails).
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Tips for Solving Homeworks and Tests}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
  \begin{block}{Tips for Solving Homeworks and Tests}
    The tests will require mostly copying code samples from the lecture slides, making some modifications to them, and combining them with other code samples.
    \vskip1ex
    Partial credit will be given even for code that doesn't produce the correct output, but that has elements of code that can be useful for producing the right answer.
    \vskip1ex
    So don't leave test assignments unanswered, and instead copy any code samples from the lecture slides that are related to the solution and make sense.
    \vskip1ex
    Contact the GA during office hours via text or phone, and submit questions to the GA or to me via \emph{Brightspace}.
  \end{block}
\pause
  \begin{block}{Please Submit \emph{Minimal Working Examples} With Your Questions}
    When submitting questions, please provide a \emph{minimal working example} that produces the error in \texttt{R}, with the following items:
      \begin{itemize}
        \item The \emph{complete} \texttt{R} code that produces the error, including the seed value for random numbers,
        \item The version of \texttt{R} (output of command: \texttt{sessionInfo()}), and the versions of \texttt{R} packages, 
        \item The type and version of your operating system (Windows or OSX),
        \item The dataset file used by the \texttt{R} code,
        \item The text or screenshots of error messages,
      \end{itemize}
    \vskip1ex
    You can read more about producing \emph{minimal working examples} here:
      \url{http://stackoverflow.com/help/mcve}\\
      \url{http://www.jaredknowles.com/journal/2013/5/27/writing-a-minimal-working-example-mwe-in-r}
  \end{block}
\end{frame}


%%%%%%%%%%%%%%%
\subsection{Course Grading Policies}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Numerical Scores}
  Homeworks and tests will be graded and assigned numerical scores.  
  Each part of homeworks and tests will be graded separately and assigned a numerical score.\\
  Maximum scores will be given only for complete code, that produces the correct output when it's pasted into an \texttt{R} session, without any modifications. 
  As long as the \texttt{R} code uses the required functions and produces the correct output, it will be given full credit.\\
  Partial credit will be given even for code that doesn't produce the correct output, but that has elements of code that can be useful for producing the right answer.
\end{block}
\pause

\begin{block}{Letter Grades}
  Letter grades for the course will be derived from the cumulative scores obtained for all the tests.  Very high numerical scores close to the maximum won't guarantee an A letter grade, since grading will also depend on the difficulty of the assignments.
\end{block}
\pause

\begin{block}{Plagiarism}
  Plagiarism (copying from other students) and cheating will be punished.\\
  But copying code from lecture slides, books, or any online sources is allowed and encouraged.\\
  Students must provide references to any external sources from which they copy code (such as links or titles and page numbers).
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Course Materials}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Lecture Slides}
The course will be mostly self-contained, using detailed lecture slides containing extensive, working \texttt{R} code examples.\\
The course will also utilize data and tutorials which are freely available on the internet.
\end{block}
\pause

\begin{block}{FRE7241 Recommended Textbooks}
\begin{itemize}[]
  \item \href{https://www.amazon.com/dp/1119482089/}{\emph{Advances in Financial Machine Learning}} by Marcos Lopez de Prado - Machine learning techniques applied to trading and portfolio management.
  
  \item \href{https://www.systematicmoney.org/systematic-trading}{\emph{Systematic Trading}} by Robert Carver - Practical trading knowledge by an experienced portfolio manager.
  
  \item \href{https://www.systematicmoney.org/smart}{\emph{Systematic Trading}} by Robert Carver - Practical investment knowledge by a successful investor.
  
  \item \href{https://quantstratbook.net}{\emph{Quantitative Trading}} by Xin Guo, Tze Leung Lai, Howard Shek, Samuel Po-Shing Wong - Advanced topics in quantitative trading by academic experts.
  
  \item \href{https://www.amazon.com/dp/331935731X/}{\emph{Financial Data and Models Using \texttt{R}}} by Clifford Ang - Good introduction to time series, portfolio optimization, and performance measures.
  
  \item \href{https://chrisconlan.com/automated-trading-r-apressspringer/}{\emph{Automated Trading}} by 
  \href{https://chrisconlan.com}{Chris Conlan} - How to implement practical computer trading systems.
  
  \item \href{https://people.orie.cornell.edu/davidr/SDAFE2/index.html}{\emph{Statistics and Data Analysis for Financial Engineering}} by David Ruppert - Introduces regression, cointegration, multivariate time series analysis, \emph{ARIMA}, \emph{GARCH}, \emph{CAPM}, and factor models, with examples in \texttt{R}.

  \item \href{https://www.pfaffikus.de/books/wiley/}{\emph{Financial Risk Modelling and Portfolio Optimization with \texttt{R}}} by Bernhard Pfaff - Introduces volatility models, portfolio optimization, and tactical asset allocation, with a great review of \texttt{R} packages and examples in \texttt{R}.

\end{itemize}

Many textbooks can be downloaded in electronic format from the 
\href{http://library.nyu.edu/}{\emph{NYU Library}}.

\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Supplementary Books}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{}
\begin{itemize}[]
  \item \href{https://www.statlearning.com}{\emph{Introduction to Statistical Learning}} by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, introduces machine learning techniques using \texttt{R}, but without deep learning.

  \item \href{https://press.princeton.edu/books/hardcover/9780691166278/quantitative-risk-management}{\emph{Quantitative Risk Management}} by Alexander J. McNeil, Rudiger Frey, and Paul Embrechts: review of Value at Risk, factor models, ARMA and GARCH, extreme value theory, and credit risk models.
  \item \href{http://eeecon.uibk.ac.at/~zeileis/teaching/AER/index.html}{\emph{Applied Econometrics with \texttt{R}}} by Christian Kleiber and Achim Zeileis, introduces advanced statistical models and econometrics.

  \item \href{http://it-ebooks.info/book/1734/}{\emph{The Art of \texttt{R} Programming}} by Norman Matloff, contains a good introduction to \texttt{R} and to statistical models.

  \item \href{http://adv-r.had.co.nz/}{\emph{Advanced \texttt{R}}} by Hadley Wickham, is the best book for learning the advanced features of \texttt{R}.

  \item \href{http://www.nr.com/}{\emph{Numerical Recipes in \texttt{C++}}} by William Press, Saul Teukolsky, William Vetterling, and Brian Flannery, is a great reference for linear algebra and numerical methods, implemented in working \texttt{C++} code.

  \item The books \href{http://www.statmethods.net/}{\emph{\texttt{R} in Action}} by Robert Kabacoff and \href{http://www.jaredlander.com/r-for-everyone/}{\emph{\texttt{R} for Everyone}} by Jared Lander, are good introductions to \texttt{R} and to statistical models.
  
  \item \href{https://smile.amazon.com/hz/wishlist/genericItemsPage/1C3R818RWTWNW}{\emph{Quant Finance books}} by Jerzy Pawlowski.
  
  \item \href{https://smile.amazon.com/hz/wishlist/genericItemsPage/1R44X8846DX3N}{\emph{Quant Trading books}} by Jerzy Pawlowski.

\end{itemize}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{FRE7241 Supplementary Materials}
\begin{frame}[t]{\subsecname}

\begin{block}{Robert Carver's trading blog}
Great blog about practical systematic trading and investments, with Python code:
\hskip1em\url{http://qoppac.blogspot.com/}
\end{block}

\begin{block}{Introduction to Computational Finance with \texttt{R}}
Good course by prof. Eric Zivot, with lots of \texttt{R} examples:
\hskip1em\url{https://www.datacamp.com/community/open-courses/computational-finance-and-financial-econometrics-with-r}
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      \texttt{Notepad++} is a free source code editor for \texttt{MS Windows}, that supports several programming languages, including \texttt{R}.
      \vskip1ex
      \texttt{Notepad++} has a very convenient and fast \emph{search and replace} function, that allows \emph{search and replace} in multiple files.\\
      \hskip1em\url{http://notepad-plus-plus.org/}
    \column{0.3\textwidth}
      \includegraphics[height=0.5\textwidth]{image/npp.jpg}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{\texttt{R} Help and Documentation}


%%%%%%%%%%%%%%%
\subsection{Internal \texttt{R} Help and Documentation}
\begin{frame}[fragile,t]{\subsecname}

\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{help()} displays documentation on a function or subject.\\
      \vskip1ex
      Preceding the keyword with a single \texttt{"?"} is equivalent to calling \texttt{help()}.
    \column{0.5\textwidth}
      \vspace{-1em}
% tidy=FALSE prevents translation of "?getwd" into "`?`(getwd)"
      <<echo=TRUE,eval=FALSE>>=
# Display documentation on function "getwd"
help(getwd)
# Equivalent to "help(getwd)"
?getwd
      @
  \end{columns}
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{help.start()} displays a page with links to internal documentation.
      \vskip1ex
      \texttt{R} documentation is also available in \texttt{RGui} under the help tab.
      \vskip1ex
      The \emph{pdf} files with \texttt{R} documentation are also available directly under:\\
%      \texttt{\color{blue}{C:/Program Files/R/R-3.1.2/bin/x64}}\\
      \href{C:/Program Files/R/R-3.1.2/doc/manual/}{C:/Program Files/R/R-3.1.2/doc/manual/}\\
      (the exact path will depend on the \texttt{R} version.)
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Open the hypertext documentation
help.start()
      @
      \vskip1ex
      \includegraphics[height=0.2\textwidth]{image/Rlogo.png}
  \end{columns}
\end{block}

\begin{block}{}
  \href{http://cran.r-project.org/doc/manuals/r-release/R-intro.pdf}{Introduction to \texttt{R}}
  by Venables and \texttt{R} Core Team.
  % \fullcite{website:rintro}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{R} Online Help and Documentation}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{\texttt{R} Cheat Sheets}
  \emph{Cheat Sheets} are a fast way to find what you want\\
  \hskip1em\url{https://www.rstudio.com/resources/cheatsheets/
}
\end{block}

\begin{block}{\texttt{R} Programming \texttt{Wikibook}}
  \texttt{Wikibooks} are crowdsourced textbooks\\
  \hskip1em\url{http://en.wikibooks.org/wiki/R_Programming/}\\
\end{block}

\begin{block}{\texttt{R FAQ}}
  Frequently Asked Questions about \texttt{R}\\
  \hskip1em\url{http://cran.r-project.org/doc/FAQ/R-FAQ.html}\\
\end{block}

\begin{block}{\texttt{R}-seek Online Search Tool}
  \texttt{R}-seek allows online searches specific to the \texttt{R} language\\
  \hskip1em\url{http://www.rseek.org/}
\end{block}

\begin{block}{\texttt{R}-help Mailing List}
  \texttt{R}-help is a very comprehensive Q\&A mailing list\\
  \hskip1em\url{https://stat.ethz.ch/mailman/listinfo/r-help}\\
  \texttt{R}-help has archives of past Q\&A - search it before you ask\\
  \hskip1em\url{https://stat.ethz.ch/pipermail/r-help/}\\
  GMANE allows searching the \texttt{R}-help archives using a usenet newsgroup style GUI\\
  \hskip1em\url{http://news.gmane.org/gmane.comp.lang.r.general}\\
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{R} Style Guides}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{DataCamp \texttt{R} style guide}
  The DataCamp \texttt{R} style guide is very close to what I have adopted:\\
  \hskip1em\href{https://www.datacamp.com/teach/documentation\#tab_style_guide_r}{DataCamp R style guide}
\end{block}

\begin{block}{Google \texttt{R} style guide}
  The Google \texttt{R} style guide is similar to DataCamp's:\\
  \hskip1em\href{https://google.github.io/styleguide/Rguide.xml}{Google R style guide}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Stack Exchange}
\begin{frame}[t]{\subsecname}

\begin{columns}[T]
  \column{0.5\textwidth}
    \begin{block}{Stack Overflow}
      Stack Overflow is a Q\&A forum for computer programming, and is part of Stack Exchange\\
%  Stack Overflow is a Q\&A forum for programmers (covers many different languages)\\
      \hskip1em\url{http://stackoverflow.com}\\
      \hskip1em\url{http://stackoverflow.com/questions/tagged/r}\\
      \hskip1em\url{http://stackoverflow.com/tags/r/info}\\
    \end{block}

    \begin{block}{Stack Exchange}
      Stack Exchange is a family of Q\&A forums in a variety of fields\\
      \hskip1em\url{http://stackexchange.com/}\\
      \hskip1em\url{http://stackexchange.com/sites\#technology}\\
      \hskip1em\url{http://quant.stackexchange.com/}\\
    \end{block}
  \column{0.5\textwidth}
    \includegraphics[height=0.9\textwidth]{image/stack_exchange2.png}
\end{columns}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{RStudio} Support}
\begin{frame}[t]{\subsecname}

\begin{block}{}
\emph{RStudio} has extensive online help, Q\&A database, and documentation\\
\hskip1em\url{https://support.rstudio.com/hc/en-us}\\
\vskip1ex
\hskip1em\url{https://support.rstudio.com/hc/en-us/sections/200107586-Using-RStudio}\\
\vskip1ex
\hskip1em\url{https://support.rstudio.com/hc/en-us/sections/200148796-Advanced-Topics}\\
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{R} Online Books and References}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}

\begin{block}{Hadley Wickham book \emph{Advanced \texttt{R}}}
The best book for learning the advanced features of \texttt{R}:
\hskip1em\url{http://adv-r.had.co.nz/}
\end{block}

\begin{block}{Cookbook for \texttt{R} by Winston Chang from \emph{RStudio}}
Good plotting, but not interactive:
\hskip1em\url{http://www.cookbook-r.com/}
\end{block}

\begin{block}{Efficient \texttt{R} programming by Colin Gillespie and Robin Lovelace}
Good tips for fast \texttt{R} programming:
\hskip1em\url{https://csgillespie.github.io/efficientR/programming.html}
\end{block}

\begin{block}{Endmemo web book}
Good, but not interactive:
\hskip1em\url{http://www.endmemo.com/program/R/}
\end{block}

\begin{block}{Quick-R by Robert Kabacoff}
Good, but not interactive:
\hskip1em\url{http://www.statmethods.net/}
\end{block}

\begin{block}{\texttt{R} for Beginners by Emmanuel Paradis}
Good, basic introduction to \texttt{R}:
\hskip1em\url{http://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{R} Online Interactive Courses}
\begin{frame}[fragile,t]{\subsecname}

\begin{block}{Datacamp Interactive Courses}
  Datacamp introduction to \texttt{R}:
  \hskip1em\url{https://www.datacamp.com/courses/introduction-to-r/}
  \vskip1ex
  Datacamp list of free courses:
  \hskip1em\url{https://www.datacamp.com/community/open-courses}
  \vskip1ex
  Datacamp basic statistics in \texttt{R}:
  \hskip1em\url{https://www.datacamp.com/community/open-courses/basic-statistics}
  \vskip1ex
  Datacamp computational finance in \texttt{R}:
  \hskip1em\url{https://www.datacamp.com/community/open-courses/computational-finance-and-financial-econometrics-with-r}
  \vskip1ex
  Datacamp machine learning in \texttt{R}:
  \hskip1em\url{https://www.datacamp.com/community/open-courses/kaggle-r-tutorial-on-machine-learning}
\end{block}

\begin{block}{Try \texttt{R}}
  Interactive \texttt{R} tutorial, but rather basic:
  \hskip1em\url{http://tryr.codeschool.com/}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{R} Blogs and Experts}
\begin{frame}[fragile,t]{\subsecname}

\begin{block}{R-Bloggers}
R-Bloggers is an aggregator of blogs dedicated to \texttt{R}\\
\hskip1em\url{http://www.r-bloggers.com/}\\
Tal Galili is the author of R-Bloggers and has his own excellent blog\\
\hskip1em\url{http://www.r-statistics.com/}\\
\end{block}

\begin{block}{Dirk Eddelbuettel}
Dirk is a \emph{Top Answerer} for \texttt{R} questions on Stackoverflow, the author of the \texttt{Rcpp} package, and the CRAN Finance View\\
\hskip1em\url{http://dirk.eddelbuettel.com/}\\
\hskip1em\url{http://dirk.eddelbuettel.com/code/}\\
\hskip1em\url{http://dirk.eddelbuettel.com/blog/}\\
\hskip1em\url{http://www.rinfinance.com/}\\
\end{block}

\begin{block}{Romain Frangois}
Romain is an \texttt{R} Enthusiast and \texttt{Rcpp} Hero\\
\hskip1em\url{http://romainfrancois.blog.free.fr/}\\
\hskip1em\url{http://romainfrancois.blog.free.fr/index.php?tag/graphgallery}\\
\hskip1em\url{http://blog.r-enthusiasts.com/}\\
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\begin{frame}[fragile,t]{More \subsecname}

\begin{block}{Revolution Analytics Blog}
\texttt{R} blog by Revolution Analytics software vendor\\
\hskip1em\url{http://blog.revolutionanalytics.com/}\\
\end{block}

\begin{block}{\emph{RStudio} Blog}
\texttt{R} blog by \emph{RStudio}\\
\hskip1em\url{http://blog.rstudio.org/}\\
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{GitHub} for Hosting Software Projects Online}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{GitHub} is an internet-based online service for hosting repositories of software projects.
      \vskip1ex
      \emph{GitHub} provides version control using \emph{git} (desved by Linus Torvalds).
      \vskip1ex
      Most \texttt{R} projects are now hosted on \emph{GitHub}.
      \vskip1ex
      \emph{Google} uses \emph{GitHub} to host its \emph{tensorflow} library for machine learning:\\
      \hskip1em\url{https://github.com/tensorflow/tensorflow}
      \vskip1ex
      All the \emph{FRE-7241} and \emph{FRE-6871} lectures are hosted on \emph{GitHub}:\\
      \hskip1em\url{https://github.com/algoquant/lecture_slides}\\
      \hskip1em\url{https://github.com/algoquant}
      \vskip1ex
      Hosting projects on \emph{Google} is a great way to advertize your skills and network with experts.
    \column{0.5\textwidth}
    \includegraphics[width=0.5\paperwidth]{image/github_algoquant.png}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Getting Started With \texttt{R}}


%%%%%%%%%%%%%%%
\subsection{What is \texttt{R}?}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{}
\begin{columns}[T]
  \column{0.7\textwidth}
    \begin{itemize}
      \item An open-source software environment for statistical computing and graphics.
      \item An interpreted language, that allows interactive code development.
      \item A functional language where every operator is an \texttt{R} function.
      \item A very expressive language that can perform complex operations with very few lines of code.
      \item A language with metaprogramming facilities that allow programming on the language.
      \item A language written in \texttt{C/C++}, which can easily call other \texttt{C/C++} programs.
      \item Can be easily extended with \emph{packages} (function libraries), providing the latest developments like \emph{Machine Learning}.
      \item Supports object-oriented programming with \emph{classes} and \emph{methods}.
      \item Vectorized functions written in \texttt{C/C++}, allow very fast execution of loops over vector elements.
    \end{itemize}
  \column{0.3\textwidth}
    \href{http://www.r-project.org/}{\includegraphics[height=0.2\textwidth]{image/Rlogo.png} Project}
    \vskip1ex
    \href{http://en.wikipedia.org/wiki/R_(programming_language)}{\includegraphics[height=0.2\textwidth]{image/Rlogo.png} Wikipedia}
%    \hskip1em\url{http://blog.revolutionanalytics.com/2011/08/what-language-is-r-written-in.html}\\
\end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Why is \texttt{R} More Difficult Than Other Languages?}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{}
\begin{columns}[T]
  \column{0.7\textwidth}
    \texttt{R} is more difficult than other languages because:
    \begin{itemize}
      \item \texttt{R} is a \emph{functional} language, which makes its syntax unfamiliar to users of procedural languages like \texttt{C/C++}.
      \item The huge number of user-created \emph{packages} makes it difficult to tell which are the best for particular applications.
      \item \texttt{R} can produce very cryptic \emph{warning} and \emph{error} messages, because it's a programming environment, so it performs many operations quietly, but those can sometimes fail.
      \item Fixing errors usually requires analyzing the complex structure of the \texttt{R} programming environment.
    \end{itemize}
    This course is designed to teach the most useful elements of \texttt{R} for financial analysis, through case studies and examples,
  \column{0.3\textwidth}
    \includegraphics[height=0.2\textwidth]{image/Rlogo.png}
\end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{What are the Best Ways to Use \texttt{R}?}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If used properly, \texttt{R} can be fast and interactive:
      \begin{itemize}
        \item Use \texttt{R} as an interface to libraries written in \texttt{C++}, \texttt{Java}, and \texttt{JavaScript}.
        \item Avoid using too many \texttt{R} function calls (every command in \texttt{R} is a function).
        \item Avoid using \texttt{apply()} and \texttt{for()} loops for large datasets.
        \item Use \texttt{R} functions which are \emph{compiled} \texttt{C++} code, instead of using interpreted \texttt{R} code.
        \item Use package \emph{data.table} for high performance data management.
        \item Use package \emph{shiny} for interactive charts of live models running in \texttt{R}.
        \item Use package \emph{dygraphs} for interactive time series plots.
        \item Use package \emph{knitr} for \emph{RMarkdown} documents.
        \item Pre-allocate memory for new objects.
        \item Write \texttt{C++} functions in \emph{Rcpp} and \emph{RcppArmadillo}.
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{image/Jeremy_Clarkson_Linus_Torvalds.jpg}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate cumulative sum of a vector
vectorv <- runif(1e5)
# Use compiled function
cumsumv <- cumsum(vectorv)
# Use for loop
cumsumv2 <- vectorv
for (i in 2:NROW(vectorv))
  cumsumv2[i] <- (vectorv[i] + cumsumv2[i-1])
# Compare the outputs of the two methods
all.equal(cumsumv, cumsumv2)
# Microbenchmark the two methods
library(microbenchmark)
summary(microbenchmark(
  cumsum=cumsum(vectorv), # Vectorized
  loop_alloc={cumsumv2 <- vectorv # Allocate memory to cumsumv3
    for (i in 2:NROW(vectorv))
cumsumv2[i] <- (vectorv[i] + cumsumv2[i-1])
  },
  loop_nalloc={cumsumv3 <- vectorv[1] # Doesn't allocate memory to cumsumv3
    for (i in 2:NROW(vectorv))
cumsumv3[i] <- (vectorv[i] + cumsumv3[i-1])
  }, times=10))[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{R} License}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      \texttt{R} is open-source software released under the GNU General Public License:
      \vskip1ex
      \hskip1em\url{http://www.r-project.org/Licenses}\\
    \column{0.3\textwidth}
      \includegraphics[height=0.2\textwidth]{image/GPLv3_Logo.png}
  \end{columns}
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      Some other \texttt{R} packages are released under the Creative Commons Attribution-ShareAlike License:
      \vskip1ex
      \hskip1em\url{http://creativecommons.org}\\
    \column{0.3\textwidth}
      \includegraphics[height=0.1\textwidth]{image/CC_License.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Installing \texttt{R} and \protect\emph{RStudio}}
\begin{frame}[t]{\subsecname}

\begin{block}{}
  Students will be required to bring their laptop computers to all the lectures, and to run the \texttt{R} Interpreter and \textbf{RStudio} RStudio during the lecture.
  \vskip1ex
  Laptop computers will be necessary for following the lectures, and for performing tests.
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      Students will be required to install and to become proficient with the \texttt{R} Interpreter.\\
      Students can download the \texttt{R} Interpreter from \texttt{CRAN} (Comprehensive \texttt{R} Archive Network):\\
      \hskip1em\url{http://cran.r-project.org/}
      \vskip1ex
      To invoke the \texttt{RGui} interface, click on:\\
      \href{C:/Program Files/R/R-3.1.2/bin/x64/RGui.exe}{C:/Program Files/R/R-3.1.2/bin/x64/RGui.exe}\\
    \column{0.3\textwidth}
      \includegraphics[height=0.2\textwidth]{image/Rlogo.png}
  \end{columns}
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      Students will be required to install and to become proficient with the \emph{RStudio} Integrated Development Environment (\emph{IDE}),\\
      \hskip1em\url{http://www.rstudio.com/products/rstudio/}
    \column{0.3\textwidth}
      \includegraphics[height=0.2\textwidth]{image/RStudio.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Using \protect\emph{RStudio}}
\begin{frame}[t]{\subsecname}

% Snapshot of \emph{RStudio} GUI
\includegraphics[height=0.6\textwidth]{image/RStudio_screen.png}

\end{frame}


%%%%%%%%%%%%%%%
% \section{First Steps in \texttt{R}}
\section{The \texttt{R} Environment}


%%%%%%%%%%%%%%%
\subsection{A First \texttt{R} Session}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Variables are created by an assignment operation, and they don't have to be declared.
      \vskip1ex
      The standard assignment operator in \texttt{R} is the arrow symbol \texttt{"<-"}.
      \vskip1ex
      \texttt{R} interretsp text in quotes ("") as character strings.
      \vskip1ex
      Text that is not in quotes ("") is interpreted as a \emph{symbol} or \emph{expression}.
      \vskip1ex
      Typing a \emph{symbol} or \emph{expression} evaluates it.
      \vskip1ex
      \texttt{R} uses the hash "\texttt{\#}" sign to mark text as comments.
      \vskip1ex
      All text after the hash "\texttt{\#}" sign is treated as a comment, and is not executed as code.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
# "<-" and "=" are valid assignment operators
myvar <- 3

# Typing a symbol or expression evaluates it
myvar

# Text in quotes is interpreted as a string
myvar <- "Hello World!"

# Typing a symbol or expression evaluates it
myvar

myvar  # Text after hash is treated as comment
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exploring an \texttt{R} Session}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}

\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{getwd()} returns a vector of length \texttt{1}, with the first element containing a string with the name of the current working directory (\texttt{cwd}).
      \vskip1ex
      The function \texttt{setwd()} accepts a character string as input (the name of the directory), and sets the working directory to that string.
      \vskip1ex
      \texttt{R} is a functional language, and \texttt{R} commands are functions, so they must be followed by parentheses \texttt{"()"}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
getwd()  # Get cwd
setwd("/Users/jerzy/Develop/R")  # Set cwd
getwd()  # Get cwd
      @
  \end{columns}
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Get system date and time
      \vskip4ex
      Just the date
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
Sys.time()  # Get date and time

Sys.Date()  # Get date only
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{R} Workspace}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}

\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The workspace is the current \texttt{R} working environment, which includes all user-defined objects and the command history.
      \vskip1ex
      The function \texttt{ls()} returns names of objects in the \texttt{R} workspace.
      \vskip1ex
      The function \texttt{rm()} removes objects from the \texttt{R} workspace.
      \vskip1ex
      The workspace can be saved into and loaded back from an \texttt{.RData} file (compressed binary file format).
      \vskip1ex
      The function \texttt{save.image()} saves the whole workspace.
      \vskip1ex
      The function \texttt{save()} saves just the selected objects.
      \vskip1ex
      The function \texttt{load()} reads data from \texttt{.RData} files, and \emph{invisibly} returns a vector of names of objects created in the workspace.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
rm(list=ls())
setwd("/Users/jerzy/Develop/lecture_slides/data")
var1 <- 3  # Define new object
ls()  # List all objects in workspace
# List objects starting with "v"
ls(pattern=glob2rx("v*"))
# Remove all objects starting with "v"
rm(list=ls(pattern=glob2rx("v*")))
save.image()  # Save workspace to file .RData in cwd
rm(var1)  # Remove object
ls()  # List objects
load(".RData")
ls()  # List objects
var2 <- 5  # Define another object
save(var1, var2,  # Save selected objects
     file="/Users/jerzy/Develop/lecture_slides/data/my_data.RData")
rm(list=ls())  # Remove all objects
ls()  # List objects
loadobj <- load(file="/Users/jerzy/Develop/lecture_slides/data/my_data.RData")
loadobj
ls()  # List objects
      @
  \end{columns}
\end{block}
% \pause

\end{frame}


%%%%%%%%%%%%%%%
\begin{frame}[fragile,t]{\subsecname \hskip0.5em (cont.)}
\vspace{-1em}

\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      When you quit \texttt{R} you'll be prompted "Save workspace image?"\\
      \vskip1ex
      If you answer $YES$ then the workspace will be saved into the \texttt{.RData} file in the \texttt{cwd}.\\
      \vskip1ex
      When you start \texttt{R} again, the workspace will be automatically loaded from the existing \texttt{.RData} file.\\
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
        q()  # quit R session
      @
  \end{columns}
\end{block}

\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{history()} displays recent commands.\\
      \vskip1ex
      You can also save and load the command history from a file.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
history(5)  # Display last 5 commands
savehistory(file="myfile")  # Default is ".Rhistory"
loadhistory(file="myfile")  # Default is ".Rhistory"
      @
  \end{columns}
\end{block}
% \pause

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{R} Session Info}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{sessionInfo()} returns information about the current \texttt{R} session.
      \begin{itemize}
        \item \texttt{R version},
        \item \texttt{OS platform},
        \item \texttt{locale} settings,
        \item list of packages that are loaded and attached to the search path,
        \item list of packages that are loaded, but \emph{not} attached to the search path,
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
sessionInfo()  # Get R version and other session info
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Global \protect\emph{Options} Settings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} uses a list of global \emph{options} which affect how \texttt{R} computes and displays results.
      \vskip1ex
      The function \texttt{options()} either sets or displays the values of global \emph{options}.
      \vskip1ex
      \texttt{options("globop")} displays the current value of option \texttt{"globop"}.
      \vskip1ex
      \texttt{getOption("globop")} displays the current value of option \texttt{"globop"}.
      \vskip1ex
      \texttt{options(globop=value)} sets the option \texttt{"globop"} equal to \texttt{"value"}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# ?options  # Long list of global options
# Interpret strings as characters, not factors
getOption("stringsAsFactors")  # Display option
options("stringsAsFactors")  # Display option
options(stringsAsFactors=FALSE)  # Set option
# Number of digits printed for numeric values
options(digits=3)
# Control exponential scientific notation of print method
# Positive "scipen" values bias towards fixed notation
# Negative "scipen" values bias towards scientific notation
options(scipen=100)
# Maximum number of items printed to console
options(max.print=30)
# Warning levels options
# Negative - warnings are ignored
options(warn=-1)
# zero - warnings are stored and printed after top-confl function has completed
options(warn=0)
# One - warnings are printed as they occur
options(warn=1)
# 2 or larger - warnings are turned into errors
options(warn=2)
# Save all options in variable
optionv <- options()
# Restore all options from variable
options(optionv)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\section{Environments in \texttt{R}}


%%%%%%%%%%%%%%%
\subsection{\secname}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Environments consist of a \emph{frame} (a set of symbol-value pairs) and an \emph{enclosure} (a pointer to an enclosing environment).
      \vskip1ex
      There are three system environments:
      \begin{itemize}
        \item \texttt{globalenv()} the user's workspace,
        \item \texttt{baseenv()} the environment of the base package,
        \item \texttt{emptyenv()} the only environment without an enclosure,
      \end{itemize}
      Environments form a tree structure of successive enclosures, with the empty environment at its root.
      \vskip1ex
      Packages have their own environments.
      \vskip1ex
      The enclosure of the base package is the empty environment.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
rm(list=ls())
# Get base environment
baseenv()
# Get global environment
globalenv()
# Get current environment
environment()
# Get environment class
class(environment())
# Define variable in current environment
globv <- 1
# Get objects in current environment
ls(environment())
# Create new environment
new_env <- new.env()
# Get calling environment of new environment
parent.env(new_env)
# Assign Value to Name
assign("new_var1", 3, envir=new_env)
# Create object in new environment
new_env$new_var2 <- 11
# Get objects in new environment
ls(new_env)
# Get objects in current environment
ls(environment())
# Environments are subset like listv
new_env$new_var1
# Environments are subset like listv
new_env[["new_var1"]]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{R} Search Path}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} evaluates variables using the search path, a series of environments:
      \begin{itemize}
        \item global environment,
        \item package environments,
        \item base environment,
      \end{itemize}
      The function \texttt{search()} returns the search path for \texttt{R} objects.
      \vskip1ex
      The function \texttt{attach()} attaches objects to the search path.
      \vskip1ex
      Using \texttt{attach()} allows referencing object components by their names alone, rather than as components of objects.
      \vskip1ex
      The function \texttt{detach()} detaches objects from the search path.
      \vskip1ex
      The function \texttt{find()} finds where objects are located on the search path.
      \vspace{-1em}
      \begin{block}{\color{red}{Rule of Thumb}}
        Be very careful with using \texttt{attach()}.
        \vskip1ex
        Make sure to \texttt{detach()} objects once they're not needed.
      \end{block}
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=TRUE>>=
search()  # Get search path for R objects
my_list <- list(flowers=c("rose", "daisy", "tulip"),
                trees=c("pine", "oak", "maple"))
my_list$trees
attach(my_list)
trees
search()  # Get search path for R objects
detach(my_list)
head(trees)  # "trees" is in datasets base package
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Extracting Time Series from Environments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{mget()} accepts a vector of strings and returns a list of the corresponding objects extracted from an \emph{environment}.
      \vskip1ex
      The extractor (accessor) functions from package \emph{quantmod}: \texttt{Cl()}, \texttt{Vo()}, etc., extract columns from \emph{OHLC} data.
      \vskip1ex
      A list of \emph{xts} series can be flattened into a single \emph{xts} series using the function \texttt{do.call()}.
      \vskip1ex
      The function \texttt{do.call()} executes a function call using a function name and a list of arguments.
      \vskip1ex
      \texttt{do.call()} passes the list elements individually, instead of passing the whole list as one argument.
      \vskip1ex
      The function \texttt{eapply()} is similar to \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list.
      \vskip1ex
      Time series can also be extracted from an \emph{environment} by coercing it into a \texttt{list}, and then subsetting and merging it into an \emph{xts} series using the function \texttt{do.call()}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(rutils)  # Load package rutils
# Define ETF symbols
symbolv <- c("VTI", "VEU", "IEF", "VNQ")
# Extract symbolv from rutils::etfenv
pricev <- mget(symbolv, envir=rutils::etfenv)
# prices is a list of xts series
class(pricev)
class(pricev[[1]])
# Extract Close prices
pricev <- lapply(pricev, quantmod::Cl)
# Collapse list into time series the hard way
xts1 <- cbind(pricev[[1]], pricev[[2]], pricev[[3]], pricev[[4]])
class(xts1)
dim(xts1)
# Collapse list into time series using do.call()
pricev <- do.call(cbind, pricev)
all.equal(xts1, pricev)
class(pricev)
dim(pricev)
# Extract and cbind in single step
pricev <- do.call(cbind, lapply(
  mget(symbolv, envir=rutils::etfenv), quantmod::Cl))
# Or
# Extract and bind all data, subset by symbolv
pricev <- lapply(symbolv, function(symbol) {
    quantmod::Cl(get(symbol, envir=rutils::etfenv))
})  # end lapply
# Same, but loop over etfenv without anonymous function
pricev <- do.call(cbind,
  lapply(as.list(rutils::etfenv)[symbolv], quantmod::Cl))
# Same, but works only for OHLC series - produces error
pricev <- do.call(cbind,
  eapply(rutils::etfenv, quantmod::Cl)[symbolv])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Managing Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Time series columns can be renamed, and then saved into \texttt{.csv} files.
      \vskip1ex
      The function \texttt{strsplit()} splits the elements of a character vector.
      \vskip1ex
      The package \emph{zoo} contains functions \texttt{write.zoo()} and \texttt{read.zoo()} for writing and reading \emph{zoo} time series from \texttt{.txt} and \texttt{.csv} files.
      \vskip1ex
      The function \texttt{eapply()} is similar to \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list.
      \vskip1ex
      The function \texttt{assign()} assigns a value to an object in a specified \emph{environment}, by referencing it using a character string (name).
      \vskip1ex
      The function \texttt{save()} writes objects to compressed binary \texttt{.RData} files.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Drop ".Close" from column names
colnames(pricev)
do.call(rbind, strsplit(colnames(pricev), split="[.]"))[, 1]
colnames(pricev) <- do.call(rbind, strsplit(colnames(pricev), split="[.]"))[, 1]
# Or
colnames(pricev) <- unname(sapply(colnames(pricev),
    function(colname) strsplit(colname, split="[.]")[[1]][1]))
tail(pricev, 3)
# Which objects in global environment are class xts?
unlist(eapply(globalenv(), is.xts))
# Save xts to csv file
write.zoo(pricev,
  file="/Users/jerzy/Develop/lecture_slides/data/etf_series.csv", sep=",")
# Copy prices into etfenv
etfenv$etf_list <- etf_list
# Or
assign("prices", pricev, envir=etfenv)
# Save to .RData file
save(etfenv, file="etf_data.RData")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Referencing Object Components Using \texttt{with()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{with()} evaluates an expression in an environment constructed from the data.
      \vskip1ex
      \texttt{with()} allows referencing object components by their names alone.
      \vskip1ex
      It's often better to use \texttt{with()} instead of \texttt{attach()}.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=TRUE>>=
# "trees" is in datasets base package
head(trees, 3)
colnames(trees)
mean(Girth)
mean(trees$Girth)
with(trees,
     c(mean(Girth), mean(Height), mean(Volume)))
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{\texttt{R} Packages}


%%%%%%%%%%%%%%%
\subsection{\secname}
\begin{frame}[fragile,t]{\subsecname}

\begin{block}{Types of \subsecname}
  \texttt{R} can run libraries of functions called packages,
  \vskip1ex
  \texttt{R} packages can can also  contain data,
  \vskip1ex
  Most packages need to be \emph{loaded} into \texttt{R} before they can be used,
  \vskip1ex
  \texttt{R} includes a number of \texttt{base} packages that are already installed and loaded,
  \vskip1ex
  There's also a special package called the \texttt{base} package, which is responsible for all the basic \texttt{R} functionality,
  \vskip1ex
  \texttt{datasets} is a \texttt{base} package containing various datasets, for example \texttt{EuStockMarkets},
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{base} Packages}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} includes a number of packages that are pre-installed (often called \emph{base} packages),\\
      Some \emph{base} packages:
      \begin{itemize}
        \item \emph{base} - basic \texttt{R} functionality,
        \item \emph{stats} - statistical functions and random number generation,
        \item \emph{graphics} - basic graphics,
        \item \emph{utils} - utility functions,
        \item \emph{datasets} - popular datasets,
        \item \emph{parallel} - support for parallel computation,
      \end{itemize}
    \column{0.5\textwidth}
      Very popular packages:
      \begin{itemize}
        \item \emph{MASS} - functions and datasets for "Modern Applied Statistics with S",
        \item \emph{ggplot2} - grammar of graphics plots,
        \item \emph{shiny} - interactive web graphics from R,
        \item \emph{slidify} - HTML5 slide shows from R,
        \item \emph{devtools} - create R packages,
        \item \emph{roxygen2} - document R packages,
        \item \emph{Rcpp} - integrate C++ code with R,
        \item \emph{RcppArmadillo} - interface to Armadillo linear algebra library,
        \item \emph{forecast} - linear models and forecasting,
        \item \emph{tseries} - time series analysis and computational finance,
        \item \emph{zoo} - time series and ordered objects,
        \item \emph{xts} - advanced time series objects,
        \item \emph{quantmod} - quantitative financial modeling framework,
        \item \emph{caTools} - moving window statistics for graphics and time series objects,
      \end{itemize}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CRAN} Package Views}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{columns}[T]
  \column{0.4\textwidth}
    \begin{block}{}
      \emph{CRAN} view for package \emph{AER}:\\
      \hskip1em\url{http://cran.r-project.org/web/packages/AER/}\\
    \end{block}
    \begin{block}{}
      Note:
      \begin{itemize}
        \item Authors,
        \item Version number,
        \item Reference manual,
        \item Vignettes,
        \item Dependencies on other packages.
      \end{itemize}
    \end{block}
    \begin{block}{}
      The package source code can be downloaded by clicking on the \href{package source}{package source} link,
    \end{block}
  \column{0.6\textwidth}
    \includegraphics[height=1.0\textwidth]{image/CRAN_Package.png}
\end{columns}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CRAN} Task Views}
\begin{frame}[fragile,t]{\subsecname}

\begin{columns}[T]
  \column{0.4\textwidth}
    \begin{block}{}
      \emph{CRAN} Finance Task View\\
      \hskip1em\url{http://cran.r-project.org//}\\
    \end{block}
    \begin{block}{}
      Note:
      \begin{itemize}
        \item Maintainer,
        \item Topics,
        \item List of packages.
      \end{itemize}
    \end{block}
  \column{0.6\textwidth}
    \vspace{-1em}
    \includegraphics[height=1.0\textwidth]{image/CRAN_Views.png}
\end{columns}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Installing Packages}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Most packages need to be \emph{installed} before they can be loaded and used.
      \vskip1ex
      Some packages like \emph{MASS} are installed with base \texttt{R} (but not loaded).
      \vskip1ex
      \emph{Installing} a package means downloading and saving its files to a local computer directory (hard disk), so they can be \emph{loaded} by the \texttt{R} system.
      \vskip1ex
      The function \texttt{install.packages()} installs packages from the \texttt{R} command line.
      \vskip1ex
      Most widely used packages are available on the \emph{CRAN} repository:\\
      \hskip1em\url{http://cran.r-project.org/web/packages/}
      \vskip1ex
      Or on \emph{R-Forge} or \emph{GitHub}:\\
      \hskip1em\url{https://r-forge.r-project.org/}\\
      \hskip1em\url{https://github.com/}
      \vskip1ex
      Packages can also be installed in \emph{RStudio} from the menu (go to \alert{Tools} and then \alert{Install packages}),\\
      \vskip1ex
      Packages residing on GitHub can be installed using the devtools packages.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
getOption("repos")  # get default package source
.libPaths()  # get package save directory
      @
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
install.packages("AER")  # install "AER" from CRAN
# install "PerformanceAnalytics" from R-Forge
install.packages(
  pkgs="PerformanceAnalytics",  # name
  lib="C:/Users/Jerzy/Downloads",  # directory
  repos="http://R-Forge.R-project.org")  # source
      @
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# install devtools from CRAN
install.packages("devtools")
# load devtools
library(devtools)
# install package "babynamesv" from GitHub
install_github(repo="hadley/babynamesv")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Installing Packages From Source}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Sometimes packages aren't available in compiled form, so it's necessary to install them from their source code.
      \vskip1ex
      To install a package from source, the user needs to first install compilers and development tools:\\
      \hskip1em For Windows install \texttt{Rtools}:\\
\url{https://cran.r-project.org/bin/windows/Rtools/}\\
      \hskip1em For Mac OSX install \texttt{XCode} developer tools:\\
\url{https://developer.apple.com/xcode/downloads/}
      \vskip1ex
      The function \texttt{install.packages()} with argument \texttt{type="source"} installs a package from source.
      \vskip1ex
      The function \texttt{download.packages()} downloads the package's installation files (compressed tar format) to a local directory.
      \vskip1ex
      The function \texttt{install.packages()} can then be used to install the package from the downloaded files.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE, eval=FALSE>>=
# install package "PortfolioAnalytics" from source
install.packages("PortfolioAnalytics",
  type="source",
  repos="http://r-forge.r-project.org")
# download files for package "PortfolioAnalytics"
download.packages(pkgs = "PortfolioAnalytics",
  destdir = ".",  # download to cwd
  type = "source",
  repos="http://r-forge.r-project.org")
# install "PortfolioAnalytics" from local tar source
install.packages(
  "C:/Users/Jerzy/Downloads/PortfolioAnalytics_0.9.3598.tar.gz",
  repos=NULL, type="source")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Installed Packages}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{defaultPackages} contains a list of packages loaded on startup by default.
      \vskip1ex
      The function \texttt{installed.packages()} returns a matrix of all packages installed on the system.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
getOption("defaultPackages")
# matrix of installed package information
pack_info <- installed.packages()
dim(pack_info)
# get all installed package names
sort(unname(pack_info[, "Package"]))
# get a few package names and their versions
pack_info[sample(x=1:100, 5), c("Package", "Version")]
# get info for package "xts"
t(pack_info["xts", ])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package Files and Directories}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Package installation files are organized into multiple directories, including some of the following:
      \begin{itemize}
        \item \texttt{\textasciitilde{}/R} containing \texttt{R} source code files,
        \item \texttt{\textasciitilde{}/src} containing \texttt{C++} and \texttt{Fortran} source code files,
        \item \texttt{\textasciitilde{}/data} containing datasets,
        \item \texttt{\textasciitilde{}/man} containing documentation files,
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE, eval=TRUE>>=
# list directories in "PortfolioAnalytics" sub-directory
gsub(
  "C:/Users/Jerzy/Documents/R/win-library/3.1",
  "~",
  list.dirs(
    file.path(
      .libPaths()[1],
      "PortfolioAnalytics")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Loading Packages}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Most packages need to be \emph{loaded} before they can be used in an \texttt{R} session.
      \vskip1ex
      Loading a package means attaching the package \emph{namespace} to the \emph{search path}, which allows \texttt{R} to call the package functions and data.
      \vskip1ex
      The functions \texttt{library()} and \texttt{require()} load packages, but in slightly different ways.
      \vskip1ex
      \texttt{library()} produces an \emph{error} (halts execution) if the package can't be loaded.
      \vskip1ex
      \texttt{require()} returns \texttt{TRUE} if the package is loaded successfully, and \texttt{FALSE} otherwise.
      \vskip1ex
      Therefore \texttt{library()} is usually used in script files that might be sourced, while \texttt{require()} is used inside functions.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# load package, produce error if can't be loaded
library(MASS)
# load package, return TRUE if loaded successfully
require(MASS)
# load quietly
library(MASS, quietly=TRUE)
# load without any messages
suppressMessages(library(MASS))
# remove package from search path
detach(MASS)
# install package if it can't be loaded successfully
if (!require("xts")) install.packages("xts")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Referencing Package Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      After a package is \emph{loaded}, the package functions and data can be accessed by name.
      \vskip1ex
      Package objects can also be accessed without \emph{loading} the package, by using the double-colon \texttt{"::"} reference operator.
      \vskip1ex
      For example, \texttt{TTR::VWAP()} references the function \texttt{VWAP()} from the package \emph{TTR}.
      \vskip1ex
      This way users don't have to load the package \emph{TTR} (with \texttt{library(TTR)}) to use functions from the package \emph{TTR}.
      \vskip1ex
      Using the \texttt{"::"} operator displays the source of objects, and makes \texttt{R} code easier to analyze.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# calculate VTI volume-weighted average price
vwapv <- TTR::VWAP(
  price=quantmod::Cl(rutils::etfenv$VTI), 
  volume=quantmod::Vo(rutils::etfenv$VTI), n=10)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exploring Packages}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{Ecdat} contains data sets for econometric analysis.
      \vskip1ex
      The data frame \texttt{Garch} contains daily currency prices.
      \vskip1ex
      The function \texttt{data()} loads external data or listv data sets in a package.
      \vskip1ex
      Some packages provide \emph{lazy loading} of their data sets, which means they automatically load their data sets when they're needed (when they are called by some operation).
      \vskip1ex
      The package's data isn't loaded into \texttt{R} memory when the package is \emph{loaded}, so it's not listed using \texttt{ls()}, but the package data is available without calling the function \texttt{data()}.
      \vskip1ex
      The function \texttt{data()} isn't required to load data sets that are set up for \emph{lazy loading}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library()  # list all packages installed on the system
search()  # list all loaded packages on search path

# get documentation for package "Ecdat"
packageDescription("Ecdat")  # get short description
help(package="Ecdat")  # load help page
library(Ecdat)  # load package "Ecdat"
data(package="Ecdat")  # list all datasets in "Ecdat"
ls("package:Ecdat")  # list all objects in "Ecdat"
browseVignettes("Ecdat")  # view package vignette
detach("package:Ecdat")  # remove Ecdat from search path
      @
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(Ecdat)  # load econometric data sets
class(Garch)  # Garch is a data frame from "Ecdat"
dim(Garch)  # daily currency prices
head(Garch[, -2])  # col 'dm' is Deutsch Mark
detach("package:Ecdat")  # remove Ecdat from search path
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package Namespaces}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Package \emph{namespaces}:
      \begin{itemize}
        \item Provide a mechanism for calling objects from a package,
        \item Hide functions and data internal to the package,
        \item Prevent naming conflicts between user and package names,
      \end{itemize}
      When a package is loaded using \texttt{library()} or \texttt{require()}, its \emph{namespace} is attached to the search path.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
rm(list=ls())
search()  # get search path for R objects
library(MASS)  # load package "MASS"
head(ls("package:MASS"))  # list some objects in "MASS"
detach("package:MASS")  # remove "MASS" from search path
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package Namespaces and the Search Path}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Packages may be loaded without their \emph{namespace} being attached to the search path.
      \vskip1ex
      When packages are loaded, then packages they depend on are also loaded, but their \emph{namespaces} aren't necessarily attached to the search path.
      \vskip1ex
      The function \texttt{loadedNamespaces()} listv all loaded \emph{namespaces}, including those that aren't on the search path.
      \vskip1ex
      The function \texttt{search()} returns the current search path for \texttt{R} objects.
      \vskip1ex
      \texttt{search()} returns many package \emph{namespaces}, but not all the loaded \emph{namespaces}.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
loadedNamespaces()  # get names of loaded namespaces

search()  # get search path for R objects
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Not Attached Namespaces}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{sessionInfo()} returns information about the current \texttt{R} session, including packages that are loaded, but \emph{not attached} to the search path.
      \vskip1ex
      \texttt{sessionInfo()} listv those packages as "loaded via a \emph{namespace} (and not attached)"
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# get session info,
# including packages not attached to the search path
sessionInfo()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Non-Visible Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Non-visible objects (variables or functions) are either:
      \begin{itemize}
        \item objects from \emph{not attached} \emph{namespaces},
        \item objects \emph{not exported} outside a package,
      \end{itemize}
      Objects from packages that aren't attached can be accessed using the double-colon \texttt{"::"} reference operator.
      \vskip1ex
      Objects that are \emph{not exported} outside a package can be accessed using the triple-colon \texttt{":::"} reference operator.
      \vskip1ex
      Colon operators automatically load the associated package.
      \vskip1ex
      Non-visible objects in namespaces often use the \texttt{".*"} name syntax.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
plot.xts  # package xts isn't loaded and attached
head(xts::plot.xts, 3)
methods("cbind")  # get all methods for function "cbind"
stats::cbind.ts  # cbind isn't exported from package stats
stats:::cbind.ts  # view the non-visible function
getAnywhere("cbind.ts")
library(MASS)  # load package 'MASS'
select  # code of primitive function from package 'MASS'
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exploring Namespaces and Non-Visible Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{getAnywhere()} displays information about \texttt{R} objects, including non-visible objects.
      \vskip1ex
      Objects referenced \emph{within} packages have different search paths than other objects:\\
      Their search path starts in the package \emph{namespace}, then the global environment and then finally the regular search path.
      \vskip1ex
      This way references to objects from \texttt{within} a package are resolved to the package, and they're not masked by objects of the same name in other environments.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
getAnywhere("cbind.ts")
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Writing Fast \texttt{R} Code Using Vectorized Operations}


%%%%%%%%%%%%%%%
\subsection{Benchmarking the Speed of \texttt{R} Code}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{system.time()} calculates the execution time (in seconds) used to evaluate a given expression.
      \vskip1ex
      \texttt{system.time()} returns the \emph{"user time"} (execution time of user instructions), the \emph{"system time"} (execution time of operating system calls), and \emph{"elapsed time"} (total execution time, including system latency waiting).
      \vskip1ex
      The function \texttt{microbenchmark()} from package \texttt{microbenchmark} calculates and compares the execution time of \texttt{R} expressions (in milliseconds), and is more accurate than \texttt{system.time()}.
      \vskip1ex
      The time it takes to execute an expression is not always the same, since it depends on the state of the processor, caching, etc.
      \vskip1ex
      \texttt{microbenchmark()} executes the expression many times, and returns the distribution of total execution times.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(microbenchmark)
vectorv <- runif(1e6)
# sqrt() and "^0.5" are the same
all.equal(sqrt(vectorv), vectorv^0.5)
# sqrt() is much faster than "^0.5"
system.time(vectorv^0.5)
microbenchmark(
  power = vectorv^0.5, 
  sqrt = sqrt(vectorv), 
  times=10)
      @
      The "\texttt{times}" parameter is the number of times the expression is evaluated.
      \vskip1ex
      The choice of the "\texttt{times}" parameter is a tradeoff between the time it takes to run \texttt{microbenchmark()}, and the desired accuracy,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Using \texttt{apply()} Instead of \texttt{for()} and \texttt{while()} Loops}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      All the different \texttt{R} loops have similar speed, with \texttt{apply()} the fastest, then \texttt{vapply()}, \texttt{lapply()} and \texttt{sapply()} slightly slower, and \texttt{for()} loops the slowest.
      \vskip1ex
      More importantly, the \texttt{apply()} syntax is more readable and concise, and fits the functional language paradigm of \texttt{R},  so it's preferred over \texttt{for()} loops.
      \vskip1ex
      Both \texttt{vapply()} and \texttt{lapply()} are \emph{compiled} (\emph{primitive}) functions, and therefore can be faster than other \texttt{apply()} functions.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate matrix of random data with 5,000 rows
matrixv <- matrix(rnorm(10000), ncol=2)
# Allocate memory for row sums
rowsumv <- numeric(NROW(matrixv))
summary(microbenchmark(
  rowsumv = rowSums(matrixv),  # end rowsumv
  applyloop = apply(matrixv, 1, sum),  # end apply
  applyloop = lapply(1:NROW(matrixv), function(indeks)
    sum(matrixv[indeks, ])),  # end lapply
  vapply = vapply(1:NROW(matrixv), function(indeks)
    sum(matrixv[indeks, ]),
    FUN.VALUE = c(sum=0)),  # end vapply
  sapply = sapply(1:NROW(matrixv), function(indeks)
    sum(matrixv[indeks, ])),  # end sapply
  forloop = for (i in 1:NROW(matrixv)) {
    rowsumv[i] <- sum(matrixv[i,])
  },  # end for
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Increasing Speed of Loops by Pre-allocating Memory}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} performs automatic memory management as users assign values to objects.
      \vskip1ex
      \texttt{R} doesn't require allocating the full memory for vectors or lists, and allows appending new data to existing objects ("growing" them).
      \vskip1ex
      For example, \texttt{R} allows assigning a value to a vector element that doesn't exist yet.
      \vskip1ex
      This forces \texttt{R} to allocate additional memory for that element, which carries a small speed penalty.
      \vskip1ex
      But when data is appended to an object using the functions \texttt{c()}, \texttt{append()}, \texttt{cbind()}, or \texttt{rbind()}, then \texttt{R} allocates memory for the whole new object and copies all the existing values, which is very memory intensive and slow.
      \vskip1ex
      It is therefore preferable to pre-allocate memory for large objects before performing loops.
      \vskip1ex
      The function \texttt{numeric(k)} returns a numeric vector of zeros of length \texttt{k}, while \texttt{numeric(0)} returns an empty (zero length) numeric vector (not to be confused with a \texttt{NULL} object).
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
vectorv <- rnorm(5000)
summary(microbenchmark(
# Allocate full memory for cumulative sum
  forloop = {cumsumv <- numeric(NROW(vectorv))
    cumsumv[1] <- vectorv[1]
    for (i in 2:NROW(vectorv)) {
      cumsumv[i] <- cumsumv[i-1] + vectorv[i]
    }},  # end for
# Allocate zero memory for cumulative sum
  grow_vec = {cumsumv <- numeric(0)
    cumsumv[1] <- vectorv[1]
    for (i in 2:NROW(vectorv)) {
# Add new element to "cumsumv" ("grow" it)
      cumsumv[i] <- cumsumv[i-1] + vectorv[i]
    }},  # end for
# Allocate zero memory for cumulative sum
  com_bine = {cumsumv <- numeric(0)
    cumsumv[1] <- vectorv[1]
    for (i in 2:NROW(vectorv)) {
# Add new element to "cumsumv" ("grow" it)
      cumsumv <- c(cumsumv, vectorv[i])
    }},  # end for
  times=10))[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vectorized Functions for Vector Computations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Vectorized} functions accept \texttt{vectors} as their arguments, and return a vector of the same length as their value.
      \vskip1ex
      Many \emph{vectorized} functions are also \emph{compiled} (they pass their data to compiled \texttt{C++} code), which makes them very fast.
      \vskip1ex
      The following \emph{vectorized compiled} functions calculate cumulative values over large vectors:
      \begin{itemize}
        \item \texttt{cummax()}
        \item \texttt{cummin()}
        \item \texttt{cumsum()}
        \item \texttt{cumprod()}
      \end{itemize}
      Standard arithmetic operations (\texttt{"+", "-"}, etc.) can be applied to \texttt{vectors}, and are implemented as \emph{vectorized compiled} functions.
      \vskip1ex
      \texttt{ifelse()} and \texttt{which()} are \emph{vectorized compiled} functions for logical operations.
      \vskip1ex
      But many \emph{vectorized} functions perform their calculations in \texttt{R} code, and are therefore slow, but convenient to use.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
vector1 <- rnorm(1000000)
vector2 <- rnorm(1000000)
big_vector <- numeric(1000000)
# Sum two vectors in two different ways
summary(microbenchmark(
  # Sum vectors using "for" loop
  rloop = (for (i in 1:NROW(vector1)) {
    big_vector[i] <- vector1[i] + vector2[i]
  }),
  # Sum vectors using vectorized "+"
  vectorvized = (vector1 + vector2),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
# Allocate memory for cumulative sum
cumsumv <- numeric(NROW(big_vector))
cumsumv[1] <- big_vector[1]
# Calculate cumulative sum in two different ways
summary(microbenchmark(
# Cumulative sum using "for" loop
  rloop = (for (i in 2:NROW(big_vector)) {
    cumsumv[i] <- cumsumv[i-1] + big_vector[i]
  }),
# Cumulative sum using "cumsum"
  vectorvized = cumsum(big_vector),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vectorized Functions for Matrix Computations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{apply()} loops are very inefficient for calculating statistics over rows and columns of very large matrices.
      \vskip1ex
      \texttt{R} has very fast \emph{vectorized compiled} functions for calculating sums and means of rows and columns:
      \begin{itemize}
        \item \texttt{rowSums()}
        \item \texttt{colSums()}
        \item \texttt{rowMeans()}
        \item \texttt{colMeans()}
      \end{itemize}
      These \emph{vectorized} functions are also \emph{compiled} functions, so they're very fast because they pass their data to compiled \texttt{C++} code, which performs the loop calculations.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Calculate matrix of random data with 5,000 rows
matrixv <- matrix(rnorm(10000), ncol=2)
# Calculate row sums two different ways
all.equal(rowSums(matrixv),
  apply(matrixv, 1, sum))
summary(microbenchmark(
  rowsumv = rowSums(matrixv),
  applyloop = apply(matrixv, 1, sum),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Fast \texttt{R} Code for Matrix Computations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functions \texttt{pmax()} and \texttt{pmin()} calculate the "parallel" maxima (minima) of multiple vector arguments.
      \vskip1ex
      \texttt{pmax()} and \texttt{pmin()} return a vector, whose \emph{n}-th element is equal to the maximum (minimum) of the \emph{n}-th elements of the arguments, with shorter vectors recycled if necessary.
      \vskip1ex
      \texttt{pmax.int()} and \texttt{pmin.int()} are methods of generic functions \texttt{pmax()} and \texttt{pmin()}, designed for atomic vectors.
      \vskip1ex
      \texttt{pmax()} can be used to quickly calculate the maximum values of rows of a matrix, by first converting the matrix columns into a list, and then passing them to \texttt{pmax()}.
      \vskip1ex
      \texttt{pmax.int()} and \texttt{pmin.int()} are very fast because they are \emph{compiled} functions (compiled from \texttt{C++} code).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(microbenchmark)
str(pmax)
# Calculate row maximums two different ways
summary(microbenchmark(
  pmax=do.call(pmax.int,
      lapply(seq_along(matrixv[1, ]),
        function(indeks) matrixv[, indeks])),
  applyloop=unlist(lapply(seq_along(matrixv[, 1]),
        function(indeks) max(matrixv[indeks, ]))),
  times=10))[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \texttt{matrixStats} for Fast Matrix Computations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package
      \href{https://cran.r-project.org/web/packages/matrixStats/index.html}{\color{blue}{\emph{matrixStats}}}
      contains functions for calculating aggregations over matrix columns and rows, and other matrix computations, such as:
      \begin{itemize}
        \item estimating location and scale: \texttt{rowRanges()}, \texttt{colRanges()}, and \texttt{rowMaxs()}, \texttt{rowMins()}, etc.,
        \item testing and counting values: \texttt{colAnyMissings()}, \texttt{colAnys()}, etc.,
        \item cumulative functions: \texttt{colCumsums()}, \texttt{colCummins()}, etc.,
        \item binning and differencing: \texttt{binCounts()}, \texttt{colDiffs()}, etc.,
      \end{itemize}
      A summary of \texttt{matrixStats} functions can be found under:\\
      \url{https://cran.r-project.org/web/packages/matrixStats/vignettes/matrixStats-methods.html}
      \vskip1ex
      The \texttt{matrixStats} functions are very fast because they are \emph{compiled} functions (compiled from \texttt{C++} code).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
install.packages("matrixStats")  # Install package matrixStats
library(matrixStats)  # Load package matrixStats
# Calculate row min values three different ways
summary(microbenchmark(
  rowmins = rowMins(matrixv),
  pmin =
    do.call(pmin.int,
            lapply(seq_along(matrixv[1, ]),
                   function(indeks)
                     matrixv[, indeks])),
  as_dframe =
    do.call(pmin.int,
            as.data.frame.matrix(matrixv)),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \texttt{Rfast} for Fast Matrix and Numerical Computations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package
      \href{https://cran.r-project.org/web/packages/Rfast}{\color{blue}{\emph{Rfast}}}
      contains functions for fast matrix and numerical computations, such as:
      \begin{itemize}
        \item \texttt{colMedians()} and \texttt{rowMedians()} for matrix column and row medians,
        \item \texttt{colCumSums()}, \texttt{colCumMins()} for cumulative sums and min/max,
        \item \texttt{eigen.sym()} for performing eigenvalue matrix decomposition,
      \end{itemize}
      The \texttt{Rfast} functions are very fast because they are \emph{compiled} functions (compiled from \texttt{C++} code).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
install.packages("Rfast")  # Install package Rfast
library(Rfast)  # Load package Rfast
# Benchmark speed of calculating ranks
vectorv <- 1e3
all.equal(rank(vectorv), Rfast::Rank(vectorv))
library(microbenchmark)
summary(microbenchmark(
  rcode = rank(vectorv),
  Rfast = Rfast::Rank(vectorv),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
# Benchmark speed of calculating column medians
matrixv <- matrix(1e4, nc=10)
all.equal(matrixStats::colMedians(matrixv), Rfast::colMedians(matrixv))
summary(microbenchmark(
  matrixStats = matrixStats::colMedians(matrixv),
  Rfast = Rfast::colMedians(matrixv),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing Fast \texttt{R} Code Using Vectorized Operations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R}-style code is code that relies on \emph{vectorized compiled} functions, instead of \texttt{for()} loops.
      \vskip1ex
      \texttt{for()} loops in \texttt{R} are slow because they call functions multiple times, and individual function calls are compute-intensive and slow.
      \vskip1ex
      The brackets \texttt{"[]"} operator is a \emph{vectorized compiled} function, and is therefore very fast.
      \vskip1ex
      Vectorized assignments using brackets \texttt{"[]"} and \texttt{Boolean} or \texttt{integer} vectors to subset vectors or matrices are therefore preferable to \texttt{for()} loops.
      \vskip1ex
      \texttt{R} code that uses \emph{vectorized compiled} functions can be as fast as \texttt{C++} code.
      \vskip1ex
      \texttt{R}-style code is also very \emph{expressive}, i.e. it allows performing complex operations with very few lines of code.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
summary(microbenchmark(  # Assign values to vector three different ways
# Fast vectorized assignment loop performed in C using brackets "[]"
  brackets = {vectorv <- numeric(10)
    vectorv[] <- 2},
# Slow because loop is performed in R
  forloop = {vectorv <- numeric(10)
    for (indeks in seq_along(vectorv))
      vectorv[indeks] <- 2},
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
summary(microbenchmark(  # Assign values to vector two different ways
# Fast vectorized assignment loop performed in C using brackets "[]"
  brackets = {vectorv <- numeric(10)
    vectorv[4:7] <- rnorm(4)},
# Slow because loop is performed in R
  forloop = {vectorv <- numeric(10)
    for (indeks in 4:7)
      vectorv[indeks] <- rnorm(1)},
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vectorized Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Functions which use vectorized operations and functions are automatically \emph{vectorized} themselves.
      \vskip1ex
      Functions which only call other compiled \texttt{C++} vectorized functions, are also very fast.
      \vskip1ex
      But not all functions are vectorized, or they're not vectorized with respect to their \emph{parameters}.
      \vskip1ex
      Some \emph{vectorized} functions perform their calculations in \texttt{R} code, and are therefore slow, but convenient to use.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define function vectorized automatically
my_fun <- function(input, param) {
  param*input
}  # end my_fun
# "input" is vectorized
my_fun(input=1:3, param=2)
# "param" is vectorized
my_fun(input=10, param=2:4)
# Define vectors of parameters of rnorm()
stdevs <- structure(1:3, names=paste0("sd=", 1:3))
means <- structure(-1:1, names=paste0("mean=", -1:1))
# "sd" argument of rnorm() isn't vectorized
rnorm(1, sd=stdevs)
# "mean" argument of rnorm() isn't vectorized
rnorm(1, mean=means)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performing \texttt{sapply()} Loops Over Function Parameters}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Many functions aren't vectorized with respect to their \emph{parameters}.
      \vskip1ex
      Performing \texttt{sapply()} loops over a function's parameters produces vector output.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Loop over stdevs produces vector output
set.seed(1121)
sapply(stdevs, function(stdev) rnorm(n=2, sd=stdev))
# Same
set.seed(1121)
sapply(stdevs, rnorm, n=2, mean=0)
# Loop over means
set.seed(1121)
sapply(means, function(meanv) rnorm(n=2, mean=meanv))
# Same
set.seed(1121)
sapply(means, rnorm, n=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Creating Vectorized Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In order to \emph{vectorize} a function with respect to one of its \emph{parameters}, it's necessary to perform a loop over it.
      \vskip1ex
      The function \texttt{Vectorize()} performs an \texttt{apply()} loop over the arguments of a function, and returns a vectorized version of the function.
      \vskip1ex
      \texttt{Vectorize()} vectorizes the arguments passed to \texttt{"vectorize.args"}.
      \vskip1ex
      \texttt{Vectorize()} is an example of a \emph{higher order} function: it accepts a function as its argument and returns a function as its value.
      \vskip1ex
      Functions that are vectorized using \texttt{Vectorize()} or \texttt{apply()} loops are just as slow as \texttt{apply()} loops, but convenient to use.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# rnorm() vectorized with respect to "stdev"
vec_rnorm <- function(n, mean=0, sd=1) {
  if (NROW(sd)==1)
    rnorm(n=n, mean=mean, sd=sd)
  else
    sapply(sd, rnorm, n=n, mean=mean)
}  # end vec_rnorm
set.seed(1121)
vec_rnorm(n=2, sd=stdevs)
# rnorm() vectorized with respect to "mean" and "sd"
vec_rnorm <- Vectorize(FUN=rnorm,
              vectorize.args=c("mean", "sd")
)  # end Vectorize
set.seed(1121)
vec_rnorm(n=2, sd=stdevs)
set.seed(1121)
vec_rnorm(n=2, mean=means)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{mapply()} Functional}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{mapply()} functional is a multivariate version of \texttt{sapply()}, that allows calling a non-vectorized function in a vectorized way.
      \vskip1ex
      \texttt{mapply()} accepts a multivariate function passed to the \texttt{"FUN"} argument and any number of vector arguments passed to the dots \texttt{"..."}.
      \vskip1ex
      \texttt{mapply()} calls \texttt{"FUN"} on the vectors passed to the dots \texttt{"..."}, one element at a time:
      \begin{multline*}
        mapply(FUN=fun, vec1, vec2, \ldots) = \\
        [ fun(vec_{1,1}, vec_{2,1}, \ldots), \ldots, \\
        fun(vec_{1,i}, vec_{2,i}, \ldots), \ldots ]
      \end{multline*}
      \texttt{mapply()} passes the first vector to the first argument of \texttt{"FUN"}, the second vector to the second argument, etc.
      \vskip1ex
      The first element of the output vector is equal to \texttt{"FUN"} called on the first elements of the input vectors, the second element is \texttt{"FUN"} called on the second elements, etc.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
str(sum)
# na.rm is bound by name
mapply(sum, 6:9, c(5, NA, 3), 2:6, na.rm=TRUE)
str(rnorm)
# mapply vectorizes both arguments "mean" and "sd"
mapply(rnorm, n=5, mean=means, sd=stdevs)
mapply(function(input, e_xp) input^e_xp,
       1:5, seq(from=1, by=0.2, length.out=5))
      @
      The output of \texttt{mapply()} is a vector of length equal to the longest vector passed to the dots \texttt{"..."} argument, with the elements of the other vectors recycled if necessary,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vectorizing Functions Using \texttt{mapply()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{mapply()} functional is a multivariate version of \texttt{sapply()}, that allows calling a non-vectorized function in a vectorized way.
      \vskip1ex
      \texttt{mapply()} can be used to vectorize several function arguments simultaneously.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# rnorm() vectorized with respect to "mean" and "sd"
vec_rnorm <- function(n, mean=0, sd=1) {
  if (NROW(mean)==1 && NROW(sd)==1)
    rnorm(n=n, mean=mean, sd=sd)
  else
    mapply(rnorm, n=n, mean=mean, sd=sd)
}  # end vec_rnorm
# Call vec_rnorm() on vector of "sd"
vec_rnorm(n=2, sd=stdevs)
# Call vec_rnorm() on vector of "mean"
vec_rnorm(n=2, mean=means)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vectorized \texttt{if-else} Statements Using Function \texttt{ifelse()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{ifelse()} performs \emph{vectorized} \texttt{if-else} statements on vectors.
      \vskip1ex
      \texttt{ifelse()} is much faster than performing an element-wise loop in \texttt{R}.
        <<func_ifelse,eval=FALSE,echo=TRUE,fig.show='hide'>>=
# Create two numeric vectors
vector1 <- sin(0.25*pi*1:20)
vector2 <- cos(0.25*pi*1:20)
# Create third vector using 'ifelse'
vector3 <- ifelse(vector1 > vector2, vector1, vector2)
# cbind all three together
vector3 <- cbind(vector1, vector2, vector3)
colnames(vector3)[3] <- "Max"
# Set plotting parameters
x11(width=6, height=7)
par(oma=c(0, 1, 1, 1), mar=c(0, 2, 2, 1), 
    mgp=c(2, 1, 0), cex.lab=0.5, cex.axis=1.0, cex.main=1.8, cex.sub=0.5)
# Plot matrix
zoo::plot.zoo(vector3, lwd=2, ylim=c(-1, 1), 
  xlab="", col=c("green", "blue", "red"), 
  main="ifelse() Calculates The Max of Two Data Sets")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/ifelse_example.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{It's \protect\emph{Always} Important to Write Fast \texttt{R} Code}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      How to write fast \texttt{R} code:
      \begin{itemize}
        \item Avoid using \texttt{apply()} and \texttt{for()} loops for large datasets.
        \item Use \texttt{R} functions which are \emph{compiled} \texttt{C++} code, instead of using interpreted \texttt{R} code.
        \item Avoid using too many \texttt{R} function calls (every command in \texttt{R} is a function).
        \item Pre-allocate memory for new objects, instead of appending to them ("growing" them).
        \item Write \texttt{C++} functions in \emph{Rcpp} and \emph{RcppArmadillo}.
        \item Use \emph{function methods} directly instead of using \emph{generic functions}.
        \item Create specialized functions by extracting only the essential \texttt{R} code from \emph{function methods}.
        \item \emph{Byte-compile} \texttt{R} functions using the \emph{byte compiler} in package \emph{compiler}.
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{image/Jeremy_Clarkson_Linus_Torvalds.jpg}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate cumulative sum of a vector
vectorv <- runif(1e5)
# Use compiled function
cumsumv <- cumsum(vectorv)
# Use for loop
cumsumv2 <- vectorv
for (i in 2:NROW(vectorv))
  cumsumv2[i] <- (vectorv[i] + cumsumv2[i-1])
# Compare the outputs of the two methods
all.equal(cumsumv, cumsumv2)
# Microbenchmark the two methods
library(microbenchmark)
summary(microbenchmark(
  cumsum=cumsum(vectorv), # Vectorized
  loop_alloc={cumsumv2 <- vectorv # Allocate memory to cumsumv3
    for (i in 2:NROW(vectorv))
cumsumv2[i] <- (vectorv[i] + cumsumv2[i-1])
  },
  loop_nalloc={cumsumv3 <- vectorv[1] # Doesn't allocate memory to cumsumv3
    for (i in 2:NROW(vectorv))
cumsumv3[i] <- (vectorv[i] + cumsumv3[i-1])
  }, times=10))[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Parallel Computing}


%%%%%%%%%%%%%%%
\subsection{Parallel Computing in \texttt{R}}
\begin{frame}[t]{\subsecname}
\vspace{-1em}

\begin{block}{Parallel Computing in \texttt{R}}
      Parallel computing means splitting a computing task into separate sub-tasks, and then simultaneously computing the sub-tasks on several computers or CPU cores.
      \vskip1ex
      There are many different packages that allow parallel computing in \texttt{R}, most importantly package \emph{parallel}, and packages \texttt{foreach}, \texttt{doParallel}, and related packages:\\
      \hskip1em\url{http://cran.r-project.org/web/views/HighPerformanceComputing.html}\\
      \hskip1em\url{http://blog.revolutionanalytics.com/high-performance-computing/}\\
      \hskip1em\url{http://gforge.se/2015/02/how-to-go-parallel-in-r-basics-tips/}\\
\end{block}

\begin{block}{\texttt{R} Base Package \emph{parallel}}
  The package \emph{parallel} provides functions for parallel computing using multiple cores of CPUs,
  \vskip1ex
  The package \emph{parallel} is part of the standard \texttt{R} distribution, so it doesn't need to be installed.\\
  \hskip1em\url{http://adv-r.had.co.nz/Profiling.html\#parallelise}\\
  \hskip1em\url{https://github.com/tobigithub/R-parallel/wiki/R-parallel-package-overview}\\
\end{block}

\begin{block}{Packages \texttt{foreach}, \texttt{doParallel}, and Related Packages}
      \hskip1em\url{http://blog.revolutionanalytics.com/2015/10/updates-to-the-foreach-package-and-its-friends.html}\\
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Parallel Computing Using Package \protect\emph{parallel}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{parallel} provides functions for parallel computing using multiple cores of CPUs.
      \vskip1ex
      The package \emph{parallel} is part of the standard \texttt{R} distribution, so it doesn't need to be installed.
      \vskip1ex
      Different functions from package \emph{parallel} need to be called depending on the operating system (\emph{Windows}, \emph{Mac-OSX}, or \emph{Linux}).
      \vskip1ex
      Parallel computing requires additional resources and time for distributing the computing tasks and collecting the output, which produces a computing overhead.
      \vskip1ex
      Therefore parallel computing can actually be slower for small computations, or for computations that can't be naturally separated into sub-tasks.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # Load package parallel
# Get short description
packageDescription("parallel")
# Load help page
help(package="parallel")
# List all objects in "parallel"
ls("package:parallel")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performing Parallel Loops Using Package \protect\emph{parallel}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Some computing tasks naturally lend themselves to parallel computing, like for example performing loops.
      \vskip1ex
      Different functions from package \emph{parallel} need to be called depending on the operating system (\emph{Windows}, \emph{Mac-OSX}, or \emph{Linux}).
      \vskip1ex
      The function \texttt{mclapply()} performs loops (similar to \texttt{lapply()}) using parallel computing on several CPU cores under \emph{Mac-OSX} or \emph{Linux}.
      \vskip1ex
      Under \emph{Windows}, a cluster of \texttt{R} processes (one per each CPU core) need to be started first, by calling the function \texttt{makeCluster()}.
      \vskip1ex
      \emph{Mac-OSX} and \emph{Linux} don't require calling the function \texttt{makeCluster()}.
      \vskip1ex
      The function \texttt{parLapply()} is similar to \texttt{lapply()}, and performs loops under \emph{Windows} using parallel computing on several CPU cores.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define function that pauses execution
paws <- function(x, sleep_time=0.01) {
  Sys.sleep(sleep_time)
  x
}  # end paws
library(parallel)  # Load package parallel
# Calculate number of available cores
ncores <- detectCores() - 1
# Initialize compute cluster under Windows
cluster <- makeCluster(ncores)
# Perform parallel loop under Windows
outv <- parLapply(cluster, 1:10, paws)
# Perform parallel loop under Mac-OSX or Linux
outv <- mclapply(1:10, paws, mc.cores=ncores)
library(microbenchmark)  # Load package microbenchmark
# Compare speed of lapply versus parallel computing
summary(microbenchmark(
  standard = lapply(1:10, paws),
  parallel = parLapply(cluster, 1:10, paws),
  times=10)
)[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Computing Advantage of Parallel Computing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Parallel computing provides an increasing advantage for larger number of loop iterations. 
      \vskip1ex
      The function \texttt{stopCluster()} stops the \texttt{R} processes running on several CPU cores.
      \vskip1ex
      The function \texttt{plot()} by default plots a scatterplot, but can also plot lines using the argument \texttt{type="l"}.
      \vskip1ex
      The function \texttt{lines()} adds lines to a plot.
      \vskip1ex
      The function \texttt{legend()} adds a legend to a plot.
      <<echo=TRUE,eval=FALSE>>=
# Compare speed of lapply with parallel computing
iterations <- 3:10
compute_times <- sapply(iterations,
  function(max_iterations) {
    summary(microbenchmark(
      standard = lapply(1:max_iterations, paws),
      parallel = parLapply(cluster, 1:max_iterations, paws),
      times=10))[, 4]
    })  # end sapply
compute_times <- t(compute_times)
colnames(compute_times) <- c("standard", "parallel")
rownames(compute_times) <- iterations
# Stop R processes over cluster under Windows
stopCluster(cluster)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/parallel_plot.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
x11(width=6, height=5)
plot(x=rownames(compute_times),
     y=compute_times[, "standard"],
     type="l", lwd=2, col="blue",
     main="Compute times",
     xlab="number of iterations in loop", ylab="",
     ylim=c(0, max(compute_times[, "standard"])))
lines(x=rownames(compute_times),
      y=compute_times[, "parallel"], lwd=2, col="green")
legend(x="topleft", legend=colnames(compute_times),
       inset=0.1, cex=1.0, bg="white",
       lwd=2, lty=1, col=c("blue", "green"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Parallel Computing Over Matrices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Very often we need to perform time consuming calculations over columns of matrices.
      \vskip1ex
      The function \texttt{parCapply()} performs an apply loop over columns of matrices using parallel computing on several CPU cores.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:5)),eval=FALSE>>=
library(parallel)  # Load package parallel
# Calculate number of available cores
ncores <- detectCores() - 1
# Initialize compute cluster under Windows
cluster <- makeCluster(ncores)
# Calculate matrix of random data
matrixv <- matrix(rnorm(1e5), ncol=100)
# Define aggregation function over column of matrix
aggfun <- function(column) {
  output <- 0
  for (indeks in 1:NROW(column))
    output <- output + column[indeks]
  output
}  # end aggfun
# Perform parallel aggregations over columns of matrix
aggs <- parCapply(cluster, matrixv, aggfun)
# Compare speed of apply with parallel computing
summary(microbenchmark(
  applyloop=apply(matrixv, MARGIN=2, aggfun),
  parapplyloop=parCapply(cluster, matrixv, aggfun),
  times=10)
)[, c(1, 4, 5)]
# Stop R processes over cluster under Windows
stopCluster(cluster)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Initializing Parallel Clusters Under \protect\emph{Windows}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Under \emph{Windows} the child processes in the parallel compute cluster don't inherit data and objects from their parent process.
      \vskip1ex
      Therefore the required data must be either passed into \texttt{parLapply()} via the dots \texttt{"..."} argument, or by calling the function \texttt{clusterExport()}.
      \vskip1ex
      Objects from packages must be either referenced using the double-colon operator \texttt{"::"}, or the packages must be loaded in the child processes.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:5)),eval=FALSE>>=
library(parallel)  # Load package parallel
# Calculate number of available cores
ncores <- detectCores() - 1
# Initialize compute cluster under Windows
cluster <- makeCluster(ncores)
basep <- 2
# Fails because child processes don't know basep:
parLapply(cluster, 2:4,
          function(exponent) basep^exponent)
# basep passed to child via dots ... argument:
parLapply(cluster, 2:4,
          function(exponent, basep) basep^exponent,
          basep=basep)
# basep passed to child via clusterExport:
clusterExport(cluster, "basep")
parLapply(cluster, 2:4,
          function(exponent) basep^exponent)
# Fails because child processes don't know zoo::index():
parSapply(cluster, c("VTI", "IEF", "DBC"),
          function(symbol)
            NROW(zoo::index(get(symbol, envir=rutils::etfenv))))
# zoo function referenced using "::" in child process:
parSapply(cluster, c("VTI", "IEF", "DBC"),
          function(symbol)
            NROW(zoo::index(get(symbol, envir=rutils::etfenv))))
# Package zoo loaded in child process:
parSapply(cluster, c("VTI", "IEF", "DBC"),
          function(symbol) {
            stopifnot("package:zoo" %in% search() || require("zoo", quietly=TRUE))
            NROW(zoo::index(get(symbol, envir=rutils::etfenv)))
          })  # end parSapply
# Stop R processes over cluster under Windows
stopCluster(cluster)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Reproducible Parallel Simulations Under \protect\emph{Windows}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Simulations use pseudo-random number generators, and in order to perform reproducible results, they must set the \emph{seed} value, so that the number generators produce the same sequence of pseudo-random numbers.
      \vskip1ex
      The function \texttt{set.seed()} initializes the random number generator by specifying the \emph{seed} value, so that the number generator produces the same sequence of numbers for a given \emph{seed} value.
      \vskip1ex
      But under \emph{Windows} \texttt{set.seed()} doesn't initialize the random number generators of child processes, and they don't produce the same sequence of numbers.
      \vskip1ex
      The function \texttt{clusterSetRNGStream()} initializes the random number generators of child processes under \emph{Windows}.
      \vskip1ex
      The function \texttt{set.seed()} does initialize the random number generators of child processes under \emph{Mac-OSX} and \emph{Linux}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # Load package parallel
# Calculate number of available cores
ncores <- detectCores() - 1
# Initialize compute cluster under Windows
cluster <- makeCluster(ncores)
# Set seed for cluster under Windows
# Doesn't work: set.seed(1121)
clusterSetRNGStream(cluster, 1121)
# Perform parallel loop under Windows
output <- parLapply(cluster, 1:70, rnorm, n=100)
sum(unlist(output))
# Stop R processes over cluster under Windows
stopCluster(cluster)
# Perform parallel loop under Mac-OSX or Linux
output <- mclapply(1:10, rnorm, mc.cores=ncores, n=100)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Simulation}


%%%%%%%%%%%%%%%
\subsection{Monte Carlo Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Monte Carlo} simulation consists of generating random samples from a given probability distribution.
      \vskip1ex
      The \emph{Monte Carlo} data samples can then used to calculate different parameters of the probability distribution (moments, quantiles, etc.), and its functionals.
      \vskip1ex
      The \emph{quantile} of a probability distribution is the value of the \emph{random variable} \texttt{x}, such that the probability of values less than \texttt{x} is equal to the given \emph{probability} $p$.
      \vskip1ex
      The \emph{quantile} of a data sample can be calculated by first sorting the sample, and then finding the value corresponding closest to the given \emph{probability} $p$.
      \vskip1ex
      The function \texttt{quantile()} calculates the sample quantiles.  It uses interpolation to improve the accuracy.  Information about the different interpolation methods can be found by typing \texttt{?quantile}.
      \vskip1ex
      The function \texttt{sort()} returns a vector sorted into ascending order.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
nrows <- 1000
datav <- rnorm(nrows)
# Sample mean - MC estimate
mean(datav)
# Sample standard deviation - MC estimate
sd(datav)
# Monte Carlo estimate of cumulative probability
pnorm(-2)
sum(datav < (-2))/nrows
# Monte Carlo estimate of quantile
confl <- 0.02
qnorm(confl)  # Exact value
cutoff <- confl*nrows
datav <- sort(datav)
datav[cutoff]  # Naive Monte Carlo value
quantile(datav, probs=confl)
# Analyze the source code of quantile()
stats:::quantile.default
# Microbenchmark quantile
library(microbenchmark)
summary(microbenchmark(
  monte_carlo = datav[cutoff],
  quantv = quantile(datav, probs=confl),
  times=100))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of Estimators Using Bootstrap Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{bootstrap} procedure uses \emph{Monte Carlo} simulation to generate a distribution of estimator values.
      \vskip1ex
      The \emph{bootstrap} procedure generates new data by randomly sampling with replacement from the observed (empirical) data set.
      \vskip1ex
      If the original data consists of simulated random numbers then we simply simulate another set of these random numbers.
      \vskip1ex
      The \emph{bootstrapped} datasets are used to recalculate the estimator many times, to provide a distribution of the estimator and its standard error.
      \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Sample from Standard Normal Distribution
nrows <- 1000; datav <- rnorm(nrows)
# Sample mean and standard deviation
mean(datav); sd(datav)
# Bootstrap of sample mean and median
nboot <- 10000
bootd <- sapply(1:nboot, function(x) {
  # Sample from Standard Normal Distribution
  samplev <- rnorm(nrows)
  c(mean=mean(samplev), median=median(samplev))
})  # end sapply
bootd[, 1:3]
bootd <- t(bootd)
# Standard error from formula
sd(datav)/sqrt(nrows)
# Standard error of mean from bootstrap
sd(bootd[, "mean"])
# Standard error of median from bootstrap
sd(bootd[, "median"])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Distribution of Estimators Using Bootstrap Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The standard errors of estimators can be calculated using a \emph{bootstrap} simulation.
      \vskip1ex
      The \emph{bootstrap} procedure generates new data by randomly sampling with replacement from the observed (empirical) data set.
      \vskip1ex
      The \emph{bootstrapped} dataset is used to recalculate the estimator many times.
      \vskip1ex
      The \emph{bootstrapped} estimator values are then used to calculate the probability distribution of the estimator and its standard error.
      \vskip1ex
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data.
      \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/boot_median.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the densities of the bootstrap data
x11(width=6, height=5)
plot(density(bootd[, "mean"]), lwd=3, xlab="Estimator Value",
     main="Distribution of Bootstrapped Mean and Median", col="green")
lines(density(bootd[, "median"]), lwd=3, col="blue")
abline(v=mean(bootd[, "mean"]), lwd=2, col="red")
legend("topright", inset=0.05, cex=0.8, title=NULL,
       leg=c("mean", "median"), bty="n",
       lwd=6, bg="white", col=c("green", "blue"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping Using Vectorized Operations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Bootstrap simulations can be accelerated by using vectorized operations instead of \texttt{R} loops.       \vskip1ex
      But using vectorized operations requires calculating a matrix of random data, instead of calculating random vectors in a loop.
      \vskip1ex
      This is another example of the tradeoff between speed and memory usage in simulations.
      \vskip1ex
      Faster code often requires more memory than slower code.
      \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
nrows <- 1000
# Bootstrap of sample mean and median
nboot <- 100
bootd <- sapply(1:nboot, function(x) median(rnorm(nrows)))
# Perform vectorized bootstrap
set.seed(1121)  # Reset random number generator
# Calculate matrix of random data
samplev <- matrix(rnorm(nboot*nrows), ncol=nboot)
bootv <- matrixStats::colMedians(samplev)
all.equal(bootd, bootv)
# Compare speed of loops with vectorized R code
library(microbenchmark)
summary(microbenchmark(
  loop = sapply(1:nboot, function(x) median(rnorm(nrows))),
  cpp = {
    samplev <- matrix(rnorm(nboot*nrows), ncol=nboot)
    matrixStats::colMedians(samplev)
    },
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping Standard Errors Using Parallel Computing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{bootstrap} procedure performs a loop, which naturally lends itself to parallel computing.
      \vskip1ex
      Different functions from package \emph{parallel} need to be called depending on the operating system (\emph{Windows}, \emph{Mac-OSX}, or \emph{Linux}).
      \vskip1ex
      The function \texttt{makeCluster()} starts running \texttt{R} processes on several CPU cores under \emph{Windows}.
      \vskip1ex
      The function \texttt{parLapply()} is similar to \texttt{lapply()}, and performs loops under \emph{Windows} using parallel computing on several CPU cores.
      \vskip1ex
      The \texttt{R} processes started by \texttt{makeCluster()} don't inherit any data from the parent \texttt{R} process.
      \vskip1ex
      Therefore the required data must be either passed into \texttt{parLapply()} via the dots \texttt{"..."} argument, or by calling the function \texttt{clusterExport()}.
      \vskip1ex
      The function \texttt{mclapply()} performs loops using parallel computing on several CPU cores under \emph{Mac-OSX} or \emph{Linux}.
      \vskip1ex
      The function \texttt{stopCluster()} stops the \texttt{R} processes running on several CPU cores.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster under Windows
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
nrows <- 1000
# Bootstrap mean and median under Windows
nboot <- 10000
bootd <- parLapply(cluster, 1:nboot,
  function(x, datav, nrows) {
  samplev <- rnorm(nrows)
  c(mean=mean(samplev), median=median(samplev))
  }, datav=datav, nrows*nrows)  # end parLapply
# Bootstrap mean and median under Mac-OSX or Linux
bootd <- mclapply(1:nboot,
  function(x) {
  samplev <- rnorm(nrows)
  c(mean=mean(samplev), median=median(samplev))
  }, mc.cores=ncores)  # end mclapply
bootd <- rutils::do_call(rbind, bootd)
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x) 
  c(mean=mean(x), stderror=sd(x)))
# Standard error from formula
sd(datav)/sqrt(nrows)
stopCluster(cluster)  # Stop R processes over cluster under Windows
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Parallel Bootstrapping of the \protect\emph{Median Absolute Deviation}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Median Absolute Deviation} (\emph{MAD}) is a robust measure of dispersion (variability), defined using the median instead of the mean:
      \begin{displaymath}
        \operatorname{MAD} = \operatorname{median}(\operatorname{abs}(x_i - \operatorname{median}(\mathbf{x})))
      \end{displaymath}
      The advantage of \emph{MAD} is that it's always well defined, even for data that has infinite variance.
      \vskip1ex
      For normally distributed data the \emph{MAD} has a larger standard error than the standard deviation.
      \vskip1ex
      But for distributions with fat tails (like asset returns), the standard deviation has a larger standard error than the \emph{MAD}.
      \vskip1ex
      The \emph{MAD} for normally distributed data is equal to $\Phi^{-1}(0.75) \cdot \hat\sigma = 0.6745 \cdot \hat\sigma$.
      \vskip1ex
      The function \texttt{mad()} calculates the \emph{MAD} and divides it by $\Phi^{-1}(0.75)$ to make it comparable to the standard deviation.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
nrows <- 1000
datav <- rnorm(nrows)
sd(datav); mad(datav)
median(abs(datav - median(datav)))
median(abs(datav - median(datav)))/qnorm(0.75)
# Bootstrap of sd and mad estimators
nboot <- 10000
bootd <- sapply(1:nboot, function(x) {
  samplev <- rnorm(nrows)
  c(sd=sd(samplev), mad=mad(samplev))
})  # end sapply
bootd <- t(bootd)
# Analyze bootstrapped variance
head(bootd)
sum(is.na(bootd))
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x) 
  c(mean=mean(x), stderror=sd(x)))
# Parallel bootstrap under Windows
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster
bootd <- parLapply(cluster, 1:nboot,
  function(x, datav) {
    samplev <- rnorm(nrows)
    c(sd=sd(samplev), mad=mad(samplev))
  }, datav=datav)  # end parLapply
# Parallel bootstrap under Mac-OSX or Linux
bootd <- mclapply(1:nboot, function(x) {
  samplev <- rnorm(nrows)
  c(sd=sd(samplev), mad=mad(samplev))
}, mc.cores=ncores)  # end mclapply
stopCluster(cluster)  # Stop R processes over cluster
bootd <- rutils::do_call(rbind, bootd)
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x) 
  c(mean=mean(x), stderror=sd(x)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Resampling From Empirical Datasets}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Resampling is randomly selecting data from an existing dataset, to create a new dataset with similar properties to the existing dataset.
      \vskip1ex
      Resampling is usually performed with replacement, so that each draw is independent from the others.
      \vskip1ex
      Resampling is performed when it's not possible or convenient to obtain another set of empirical data, so we simulate a new data set by randomly sampling from the existing data.
      \vskip1ex
      The function \texttt{sample()} selects a random sample from a vector of data elements.
      \vskip1ex
      The function \texttt{sample.int()} is a \emph{method} that selects a random sample of \emph{integers}.
      \vskip1ex
      The function \texttt{sample.int()} with argument \texttt{replace=TRUE} selects a sample with replacement (the \emph{integers} can repeat).
      \vskip1ex
      The function \texttt{sample.int()} is a little faster than \texttt{sample()}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate time series of VTI returns
library(rutils)
retp <- rutils::etfenv$returns$VTI
retp <- na.omit(retp)
nrows <- NROW(retp)
# Sample from VTI returns
samplev <- retp[sample.int(nrows, replace=TRUE)]
c(sd=sd(samplev), mad=mad(samplev))
# sample.int() is a little faster than sample()
library(microbenchmark)
summary(microbenchmark(
  sample.int = sample.int(1e3), 
  sample = sample(1e3), 
  times=10))[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping From Empirical Datasets}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Bootstrapping is usually performed by resampling from an observed (empirical) dataset.
      \vskip1ex
      Resampling consists of randomly selecting data from an existing dataset, with replacement.
      \vskip1ex
      Resampling produces a new \emph{bootstrapped} dataset with similar properties to the existing dataset.
      \vskip1ex
      The \emph{bootstrapped} dataset is used to recalculate the estimator many times.
      \vskip1ex
      The \emph{bootstrapped} estimator values are then used to calculate the probability distribution of the estimator and its standard error.
      \vskip1ex
      Bootstrapping shows that for asset returns, the \emph{Median Absolute Deviation} (\emph{MAD}) has a smaller relative standard error than the standard deviation.
      \vskip1ex
      Bootstrapping doesn't provide accurate estimates for estimators which are sensitive to the ordering and correlations in the data.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Sample from time series of VTI returns
library(rutils)
retp <- rutils::etfenv$returns$VTI
retp <- na.omit(retp)
nrows <- NROW(retp)
# Bootstrap sd and MAD under Windows
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster under Windows
clusterSetRNGStream(cluster, 1121)  # Reset random number generator in all cores
nboot <- 10000
bootd <- parLapply(cluster, 1:nboot,
  function(x, retp, nrows) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, retp=retp, nrows*nrows)  # end parLapply
# Bootstrap sd and MAD under Mac-OSX or Linux
bootd <- mclapply(1:nboot, function(x) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, mc.cores=ncores)  # end mclapply
stopCluster(cluster)  # Stop R processes over cluster under Windows
bootd <- rutils::do_call(rbind, bootd)
# Standard error assuming normal distribution of returns
sd(retp)/sqrt(nboot)
# Means and standard errors from bootstrap
stderrors <- apply(bootd, MARGIN=2,
  function(x) c(mean=mean(x), stderror=sd(x)))
stderrors
# Relative standard errors
stderrors[2, ]/stderrors[1, ]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of Regression Coefficients Using Bootstrap}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The standard errors of the regression coefficients can be calculated using a \emph{bootstrap} simulation.
      \vskip1ex
      The \emph{bootstrap} procedure creates new design matrices by randomly sampling with replacement from the regression design matrix.
      \vskip1ex
      Regressions are performed on the \emph{bootstrapped} design matrices, and the regression coefficients are saved into a matrix of \emph{bootstrapped} coefficients.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Initialize random number generator
set.seed(1121)
# Define explanatory and response variables
nrows <- 100
predm <- rnorm(nrows, mean=2)
noise <- rnorm(nrows)
respv <- (-3 + 2*predm + noise)
desv <- cbind(respv, predm)
# Calculate alpha and beta regression coefficients
betav <- cov(desv[, 1], desv[, 2])/var(desv[, 2])
alpha <- mean(desv[, 1]) - betav*mean(desv[, 2])
x11(width=6, height=5)
plot(respv ~ predm, data=desv)
abline(a=alpha, b=betav, lwd=3, col="blue")
# Bootstrap of beta regression coefficient
nboot <- 100
bootd <- sapply(1:nboot, function(x) {
  samplev <- sample.int(nrows, replace=TRUE)
  desv <- desv[samplev, ]
  cov(desv[, 1], desv[, 2])/var(desv[, 2])
})  # end sapply
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Bootstrapped Regression Coefficients}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{bootstrapped} coefficient values can be used to calculate the probability distribution of the coefficients and their standard errors,
      \vskip1ex
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data.
      \vskip1ex
      \texttt{abline()} plots a straight line on the existing plot.
      \vskip1ex
      The function \texttt{text()} draws text on a plot, and can be used to draw plot labels.
        <<eval=FALSE,echo=(-(1:2))>>=
x11(width=6, height=5)
par(oma=c(1, 2, 1, 0), mgp=c(2, 1, 0), mar=c(1, 1, 1, 1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
# Mean and standard error of beta regression coefficient
c(mean=mean(bootd), stderror=sd(bootd))
# Plot density of bootstrapped beta coefficients
plot(density(bootd), lwd=2, xlab="Regression slopes",
     main="Bootstrapped Regression Slopes")
# Add line for expected value
abline(v=mean(bootd), lwd=2, col="red")
text(x=mean(bootd)-0.01, y=1.0, labels="expected value",
     lwd=2, srt=90, pos=3)
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/boot_reg.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping Regressions Using Parallel Computing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{bootstrap} procedure performs a loop, which naturally lends itself to parallel computing.
      \vskip1ex
      Different functions from package \emph{parallel} need to be called depending on the operating system (\emph{Windows}, \emph{Mac-OSX}, or \emph{Linux}).
      \vskip1ex
      The function \texttt{makeCluster()} starts running \texttt{R} processes on several CPU cores under \emph{Windows}.
      \vskip1ex
      The function \texttt{parLapply()} is similar to \texttt{lapply()}, and performs loops under \emph{Windows} using parallel computing on several CPU cores.
      \vskip1ex
      The \texttt{R} processes started by \texttt{makeCluster()} don't inherit any data from the parent \texttt{R} process.
      \vskip1ex
      Therefore the required data must be passed into \texttt{parLapply()} via the dots \texttt{"..."} argument.
      \vskip1ex
      The function \texttt{mclapply()} performs loops using parallel computing on several CPU cores under \emph{Mac-OSX} or \emph{Linux}.
      \vskip1ex
      The function \texttt{stopCluster()} stops the \texttt{R} processes running on several CPU cores.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster under Windows
# Bootstrap of regression under Windows
bootd <- parLapply(cluster, 1:1000,
  function(x, desv) {
    samplev <- sample.int(nrows, replace=TRUE)
    desv <- desv[samplev, ]
    cov(desv[, 1], desv[, 2])/var(desv[, 2])
  }, design=desv)  # end parLapply
# Bootstrap of regression under Mac-OSX or Linux
bootd <- mclapply(1:1000,
  function(x) {
    samplev <- sample.int(nrows, replace=TRUE)
    desv <- desv[samplev, ]
    cov(desv[, 1], desv[, 2])/var(desv[, 2])
  }, mc.cores=ncores)  # end mclapply
stopCluster(cluster)  # Stop R processes over cluster under Windows
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Analyzing the Bootstrap Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{bootstrap} loop produces a \emph{list} which can be collapsed into a vector.
      \vskip1ex
      The function \texttt{unlist()} collapses a list with atomic elements into a vector (which can cause type coercion).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Collapse the bootstrap list into a vector
class(bootd)
bootd <- unlist(bootd)
# Mean and standard error of beta regression coefficient
c(mean=mean(bootd), stderror=sd(bootd))
# Plot density of bootstrapped beta coefficients
plot(density(bootd),
     lwd=2, xlab="Regression slopes",
     main="Bootstrapped Regression Slopes")
# Add line for expected value
abline(v=mean(bootd), lwd=2, col="red")
text(x=mean(bootd)-0.01, y=1.0, labels="expected value",
     lwd=2, srt=90, pos=3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Brownian Motion Using \texttt{while()} Loops}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{while()} loops are often used in simulations, when the number of required loops is unknown in advance.
      \vskip1ex
      Below is an example of a simulation of the path of \emph{Brownian Motion} crossing a barrier level.
        <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
barl <- 20  # Barrier level
nrows <- 1000  # Number of simulation steps
pathv <- numeric(nrows)  # Allocate path vector
pathv[1] <- rnorm(1)  # Initialize path
it <- 2  # Initialize simulation index
while ((it <= nrows) && (pathv[it - 1] < barl)) {
# Simulate next step
  pathv[it] <- pathv[it - 1] + rnorm(1)
  it <- it + 1  # Advance index
}  # end while
# Fill remaining path after it crosses barl
if (it <= nrows)
  pathv[it:nrows] <- pathv[it - 1]
# Plot the Brownian motion
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 1, 1))
plot(pathv, type="l", col="black",
     lty="solid", lwd=2, xlab="", ylab="")
abline(h=barl, lwd=3, col="red")
title(main="Brownian Motion Crossing a Barrier Level", line=0.5)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/simu_brown_barrier.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Brownian Motion Using Vectorized Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Simulations in \texttt{R} can be accelerated by pre-computing a vector of random numbers, instead of generatng them one at a time in a loop.
      \vskip1ex
      Vectors of random numbers allow using \emph{vectorized} functions, instead of inefficient (slow) \texttt{while()} loops.
        <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
barl <- 20  # Barrier level
nrows <- 1000  # Number of simulation steps
# Simulate path of Brownian motion
pathv <- cumsum(rnorm(nrows))
# Find index when path crosses barl
crossp <- which(pathv > barl)
# Fill remaining path after it crosses barl
if (NROW(crossp)>0) {
  pathv[(crossp[1]+1):nrows] <- pathv[crossp[1]]
}  # end if
# Plot the Brownian motion
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 1, 1))
plot(pathv, type="l", col="black",
     lty="solid", lwd=2, xlab="", ylab="")
abline(h=barl, lwd=3, col="red")
title(main="Brownian Motion Crossing a Barrier Level", line=0.5)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/simu_brown_barrier.png}
      The tradeoff between speed and memory usage: more memory may be used than necessary, since the simulation may stop before all the pre-computed random numbers are used up.
      \vskip1ex
      But the simulation is much faster because the path is simulated using \emph{vectorized} functions,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Estimating the Statistics of Brownian Motion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The statistics of Brownian motion can be estimated by simulating multiple paths.
      \vskip1ex
      An example of a statistic is the expected value of Brownian motion at a fixed time horizon,  which is the option payout for the strike price $k$: $\mathbb{E}[(p_t - k)_{+}]$.
      \vskip1ex
      Another statistic is the probability of Brownian motion crossing a boundary (barrier) $b$: $\mathbb{E}[\mathbbm{1}(p_t - b)]$.
      <<echo=TRUE,eval=FALSE>>=
# Define Brownian motion parameters
sigmav <- 1.0  # Volatility
drift <- 0.0  # Drift
nrows <- 1000  # Number of simulation steps
nsimu <- 100  # Number of simulations
# Simulate multiple paths of Brownian motion
set.seed(1121)
pathm <- rnorm(nsimu*nrows, mean=drift, sd=sigmav)
pathm <- matrix(pathm, nc=nsimu)
pathm <- matrixStats::colCumsums(pathm)
# Final distribution of paths
mean(pathm[nrows, ]) ; sd(pathm[nrows, ])
# Calculate option payout at maturity
strikep <- 50  # Strike price
payouts <- (pathm[nrows, ] - strikep)
sum(payouts[payouts > 0])/nsimu
# Calculate probability of crossing the barrier at any point
barl <- 50
crossi <- (colSums(pathm > barl) > 0)
sum(crossi)/nsimu
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/simu_brown_multiple.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot in window
x11(width=6, height=5)
par(mar=c(4, 3, 2, 2), oma=c(0, 0, 0, 0), mgp=c(2.5, 1, 0))
# Select and plot full range of paths
ordern <- order(pathm[nrows, ])
pathm[nrows, ordern]
indeks <- ordern[seq(1, 100, 9)]
zoo::plot.zoo(pathm[, indeks], main="Paths of Brownian Motion",
  xlab="time steps", ylab=NA, plot.type="single")
abline(h=strikep, col="red", lwd=3)
text(x=(nrows-60), y=strikep, labels="strike price", pos=3, cex=1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping From Time Series of Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Bootstrapping from a time series of prices requires first converting the prices to \emph{percentage} returns, then bootstrapping the returns, and finally converting them back to prices.
      \vskip1ex
      Bootstrapping from \emph{percentage} returns ensures that the bootstrapped prices are not negative.
      \vskip1ex
      Below is a simulation of the frequency of bootstrapped prices crossing a barrier level.
      <<echo=TRUE,eval=FALSE>>=
# Calculate percentage returns from VTI prices
library(rutils)
pricev <- quantmod::Cl(rutils::etfenv$VTI)
startd <- as.numeric(pricev[1, ])
retp <- rutils::diffit(log(pricev))
class(retp); head(retp)
sum(is.na(retp))
nrows <- NROW(retp)
# Define barrier level with respect to prices
barl <- 1.5*max(pricev)
# Calculate single bootstrap sample
samplev <- retp[sample.int(nrows, replace=TRUE)]
# Calculate prices from percentage returns
samplev <- startd*exp(cumsum(samplev))
# Calculate if prices crossed barrier
sum(samplev > barl) > 0
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster under Windows
# Perform parallel bootstrap under Windows
clusterSetRNGStream(cluster, 1121)  # Reset random number generator in all cores
clusterExport(cluster, c("startd", "barl"))
nboot <- 10000
bootd <- parLapply(cluster, 1:nboot,
  function(x, retp, nrows) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    # Calculate prices from percentage returns
    samplev <- startd*exp(cumsum(samplev))
    # Calculate if prices crossed barrier
    sum(samplev > barl) > 0
  }, retp=retp, nrows*nrows)  # end parLapply
# Perform parallel bootstrap under Mac-OSX or Linux
bootd <- mclapply(1:nboot, function(x) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    # Calculate prices from percentage returns
    samplev <- startd*exp(cumsum(samplev))
    # Calculate if prices crossed barrier
    sum(samplev > barl) > 0
  }, mc.cores=ncores)  # end mclapply
stopCluster(cluster)  # Stop R processes over cluster under Windows
bootd <- rutils::do_call(rbind, bootd)
# Calculate frequency of crossing barrier
sum(bootd)/nboot
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping From \protect\emph{OHLC} Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Bootstrapping from \emph{OHLC} prices requires updating all the price columns, not just the \emph{Close} prices.
      \vskip1ex
      The \emph{Close} prices are bootstrapped first, and then the other columns are updated using the differences of the \emph{OHLC} price columns.
      \vskip1ex
      Below is a simulation of the frequency of the \emph{High} prices crossing a barrier level.
      <<echo=TRUE,eval=FALSE>>=
# Calculate percentage returns from VTI prices
library(rutils)
ohlc <- rutils::etfenv$VTI
pricev <- as.numeric(ohlc[, 4])
startd <- pricev[1]
retp <- rutils::diffit(log(pricev))
nrows <- NROW(retp)
# Calculate difference of OHLC price columns
ohlc_diff <- ohlc[, 1:3] - pricev
class(retp); head(retp)
# Calculate bootstrap prices from percentage returns
datav <- sample.int(nrows, replace=TRUE)
boot_pricev <- startd*exp(cumsum(retp[datav]))
boot_ohlc <- ohlc_diff + boot_prices
boot_ohlc <- cbind(boot_ohlc, boot_pricev)
# Define barrier level with respect to prices
barl <- 1.5*max(pricev)
# Calculate if High bootstrapped prices crossed barrier level
sum(boot_ohlc[, 2] > barl) > 0
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster under Windows
# Perform parallel bootstrap under Windows
clusterSetRNGStream(cluster, 1121)  # Reset random number generator in all cores
clusterExport(cluster, c("startd", "barl", "ohlc_diff"))
nboot <- 10000
bootd <- parLapply(cluster, 1:nboot,
  function(x, retp, nrows) {
    # Calculate OHLC prices from percentage returns
    datav <- sample.int(nrows, replace=TRUE)
    boot_pricev <- startd*exp(cumsum(retp[datav]))
    boot_ohlc <- ohlc_diff + boot_prices
    boot_ohlc <- cbind(boot_ohlc, boot_pricev)
    # Calculate statistic
    sum(boot_ohlc[, 2] > barl) > 0
  }, retp=retp, nrows*nrows)  # end parLapply
# Perform parallel bootstrap under Mac-OSX or Linux
bootd <- mclapply(1:nboot, function(x) {
    # Calculate OHLC prices from percentage returns
    datav <- sample.int(nrows, replace=TRUE)
    boot_pricev <- startd*exp(cumsum(retp[datav]))
    boot_ohlc <- ohlc_diff + boot_prices
    boot_ohlc <- cbind(boot_ohlc, boot_pricev)
    # Calculate statistic
    sum(boot_ohlc[, 2] > barl) > 0
  }, mc.cores=ncores)  # end mclapply
stopCluster(cluster)  # Stop R processes over cluster under Windows
bootd <- rutils::do_call(rbind, bootd)
# Calculate frequency of crossing barrier
sum(bootd)/nboot
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Market Databases}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{ETF} Database}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Exchange-traded Funds (\emph{ETFs}) are funds which invest in portfolios of assets, such as stocks, commodities, or bonds.
      \vskip1ex
      \emph{ETFs} are shares in portfolios of assets, and they are traded just like stocks.
      \vskip1ex
      \emph{ETFs} provide investors with convenient, low cost, and liquid instruments to invest in various portfolios of assets.
      \vskip1ex
      The file \texttt{etf\_list.csv} contains a database of exchange-traded funds (\emph{ETFs}) and exchange traded notes (\emph{ETNs}).
      \vskip1ex
      We will select a portfolio of \emph{ETFs} for illustrating various investment strategies.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=TRUE,size="tiny">>=
# Select ETF symbols for asset allocation
symbolv <- c("VTI", "VEU", "EEM", "XLY", "XLP", "XLE", "XLF",
 "XLV", "XLI", "XLB", "XLK", "XLU", "VYM", "IVW", "IWB", "IWD",
 "IWF", "IEF", "TLT", "VNQ", "DBC", "GLD", "USO", "VXX", "SVXY",
 "MTUM", "IVE", "VLUE", "QUAL", "VTV", "USMV", "AIEQ", "QQQ")
# Read etf database into data frame
etflist <- read.csv(file="/Users/jerzy/Develop/lecture_slides/data/etf_list.csv")
rownames(etflist) <- etflist$Symbol
# Select from etflist only those ETF's in symbolv
etflist <- etflist[symbolv, ]
# Shorten names
etfnames <- sapply(etflist$Name, function(name) {
  namesplit <- strsplit(name, split=" ")[[1]]
  namesplit <- namesplit[c(-1, -NROW(namesplit))]
  name_match <- match("Select", namesplit)
  if (!is.na(name_match))
    namesplit <- namesplit[-name_match]
  paste(namesplit, collapse=" ")
})  # end sapply
etflist$Name <- etfnames
etflist["IEF", "Name"] <- "10 year Treasury Bond Fund"
etflist["TLT", "Name"] <- "20 plus year Treasury Bond Fund"
etflist["XLY", "Name"] <- "Consumer Discr. Sector Fund"
etflist["EEM", "Name"] <- "Emerging Market Stock Fund"
etflist["MTUM", "Name"] <- "Momentum Factor Fund"
etflist["SVXY", "Name"] <- "Short VIX Futures"
etflist["VXX", "Name"] <- "Long VIX Futures"
etflist["DBC", "Name"] <- "Commodity Futures Fund"
etflist["USO", "Name"] <- "WTI Oil Futures Fund"
etflist["GLD", "Name"] <- "Physical Gold Fund"
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{ETF} Database for Investment Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The database contains \emph{ETFs} representing different \emph{industry sectors} and \emph{investment styles}.
      \vskip1ex
      The \emph{ETFs} with names \emph{X*} represent industry \emph{sector funds} (energy, financial, etc.)
      \vskip1ex
      The \emph{ETFs} with names \emph{I*} represent \emph{style funds} (value, growth, size).
      \vskip1ex
      \emph{IWB} is the Russell 1000 small-cap fund.
      \vskip1ex
      The 
      \href{https://www.ssga.com/us/en/intermediary/etfs/funds/spdr-sp-500-etf-trust-spy}{\emph{SPY ETF}}
      owns the \emph{S\&P500} index constituents.
      \emph{SPY} is the biggest, the most liquid, and the oldest ETF. 
      SPY has over \texttt{\$400} billion of shares outstanding, and trades over \texttt{\$20} billion per day, at a bid-ask spread of only one tick (\texttt{\$0.01}, or about \texttt{0.0022\%}).
      \vskip1ex
      The 
      \href{https://www.invesco.com/qqq-etf/en/home.html}{\emph{QQQ ETF}}
      owns the \emph{Nasdaq-100} index constituents.
      \vskip1ex
      \emph{MTUM} is an \emph{ETF} which owns a stock portfolio representing the \emph{momentum factor}.
      \vskip1ex
      \emph{DBC} is an \emph{ETF} providing the total return on a portfolio of commodity futures.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=FALSE,eval=TRUE,results='asis'>>=
print(xtable::xtable(etflist), comment=FALSE, size="tiny", include.rownames=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exchange Traded Notes (\protect\emph{ETNs})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{ETNs} are similar to \emph{ETFs}, with the difference that \emph{ETFs} are shares in a fund which owns the underlying assets, while \emph{ETNs} are notes from issuers which promise payouts according to a formula tied to the underlying asset.
      \vskip1ex
      \emph{ETFs} are similar to mutual funds, while \emph{ETNs} are similar to corporate bonds.
      \vskip1ex
      \emph{ETNs} are technically unsecured corporate debt, but instead of fixed coupons, they promise to provide returns on a market index or futures contract.
      \vskip1ex
      The \emph{ETN} issuer promises the payout and is responsible for tracking the index.
      \vskip1ex
      The \emph{ETN} investor has counterparty credit risk to the \emph{ETN} issuer.
    \column{0.5\textwidth}
      \emph{VXX} is an \emph{ETN} providing the total return of \emph{long VIX} futures contracts (specifically the \emph{S\&P} VIX Short-Term Futures Index).
      \vskip1ex
      \emph{VXX} is \emph{bearish} because it's \emph{long} VIX futures, and the VIX \emph{rises} when stock prices \emph{drop}.
      \vskip1ex
      \emph{SVXY} is an \emph{ETF} providing the total return of \emph{short VIX} futures contracts.
      \vskip1ex
      \emph{SVXY} is \emph{bullish} because it's \emph{short} VIX futures, and the VIX \emph{drops} when stock prices \emph{rise}.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Stock Databases And Survivorship Bias}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The file \texttt{sp500\_constituents.csv} contains a \emph{data frame} of over \texttt{700} present (and also some past) \emph{S\&P500} index constituents.
      \vskip1ex
      The file \texttt{sp500\_constituents.csv} is updated with stocks recently added to the \emph{S\&P500} index by downloading the
      \href{https://www.ssga.com/us/en/intermediary/etfs/funds/spdr-sp-500-etf-trust-spy}{\emph{SPY ETF Holdings}}.
      \vskip1ex
      But the file \texttt{sp500\_constituents.csv} doesn't include companies that have gone bankrupt.
      For example, it doesn't include Enron, which was in the \emph{S\&P500} index before it went bankrupt in 2001.
      \vskip1ex
      Most databases of stock prices don't include companies that have gone bankrupt or have been liquidated.
      \vskip1ex
      This introduces a \emph{survivorship bias} to the data, which can skew portfolio simulations and strategy backtests.
      \vskip1ex
      Accurate strategy simulations require starting with a portfolio of companies at a "point in time" in the past, and tracking them over time.
      \vskip1ex
      Research databases like the 
      \href{https://wrds-www.wharton.upenn.edu}{\emph{WRDS}} 
      database provide stock prices of companies that are no longer traded.
      \vskip1ex
      The stock tickers are stored in the column \texttt{"Ticker"} of the \texttt{sp500} \emph{data frame}.
      \vskip1ex
      Some tickers (like "BRK.B" and "BF.B") are not valid symbols in \emph{Tiingo}, so they must be renamed.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Load data frame of S&P500 constituents from CSV file
sp500 <- read.csv(file="/Users/jerzy/Develop/lecture_slides/data/sp500_constituents.csv")
# Inspect data frame of S&P500 constituents
dim(sp500)
colnames(sp500)
# Extract tickers from the column Ticker
symbolv <- sp500$Ticker
# Get duplicate tickers
tablev <- table(symbolv)
duplicates <- tablev[tablev>1]
duplicates <- names(duplicates)
# Get duplicate records (rows) of sp500
sp500[symbolv %in% duplicates, ]
# Get unique tickers
symbolv <- unique(symbolv)
# Find index of ticker "BRK.B"
which(symbolv=="BRK.B")
# Rename "BRK.B" to "BRK-B" and "BF.B" to "BF-B"
symbolv[which(symbolv=="BRK.B")] <- "BRK-B"
symbolv[which(symbolv=="BF.B")] <- "BF-B"
@
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Wharton Research Data Services \protect\emph{WRDS}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Wharton Research Data Services (\href{https://wrds-www.wharton.upenn.edu}{\emph{WRDS}}) is a distributor of premium third party data for the academic and research communities.
      \vskip1ex
      \emph{WRDS} provides time series of security prices and fundamental company data, and other financial, econometric, and social datasets.
      \vskip1ex
      \emph{WRDS} provides stock pricev, options and implied volatilities, stock fundamentals, financial ratios, zoo::indexes, earnings estimates, analyst ratings, etc.
      \vskip1ex
      \emph{WRDS} redistributes fundamental company data from \href{http://www.compustat.com}{\emph{Compustat}}, \href{http://www.capitaliq.com}{\emph{S\&P Capital IQ}}, \href{https://www.thomsonreuters.com/en.html}{\emph{Thomson Reuters}}, \href{http://www.factset.com/}{\emph{FactSet}}, \emph{Hedge Fund Research}, \href{https://ihsmarkit.com/index.html}{\emph{Markit}}, etc.
      \vskip1ex
      NYU students can obtain user accounts for \emph{WRDS} data.
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/wrds_home.pdf}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Modeling and Fitting Asset Returns}


%%%%%%%%%%%%%%%
\subsection{Kernel Density of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The kernel density is proportional to the number of data points close to a given point.
      \vskip1ex
      The kernel density is analogous to a histogram, but it provides more detailed information about the distribution of the data.
      \vskip1ex
      The smoothing kernel $K(x)$ is a symmetric function which decreases with the distance $x$.
      \vskip1ex
      The kernel density $d_r$ at a point $r$ is equal to the sum over the kernel function $K(x)$:
      \begin{displaymath}
        d_r = \sum_{j=1}^n {K(r - r_j)}
      \end{displaymath}
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data.
      \vskip1ex
      The parameter \emph{smoothing bandwidth} is the standard deviation of the smoothing kernel $K(x)$. 
      \vskip1ex
      The function \texttt{density()} returns a vector of densities at equally spaced points, not for the original data points.
      \vskip1ex
      The function \texttt{approx()} interpolates a vector of data into another vector.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(rutils)  # Load package rutils
# Calculate VTI percentage returns
retp <- rutils::etfenv$returns$VTI
retp <- drop(coredata(na.omit(retp)))
nrows <- NROW(retp)
# Mean and standard deviation of returns
c(mean(retp), sd(retp))
# Calculate the smoothing bandwidth as the MAD of returns 10 points apart
retp <- sort(retp)
bwidth <- 10*mad(rutils::diffit(retp, lagg=10))
# Calculate the kernel density
densv <- sapply(1:nrows, function(it) {
  sum(dnorm(retp-retp[it], sd=bwidth))
})  # end sapply
madv <- mad(retp)
plot(retp, densv, xlim=c(-5*madv, 5*madv),
     t="l", col="blue", lwd=3,
     xlab="returns", ylab="density",
     main="Density of VTI Returns")
# Calculate the kernel density using density()
densv <- density(retp, bw=bwidth)
NROW(densv$y)
x11(width=6, height=5)
plot(densv, xlim=c(-5*madv, 5*madv),
     xlab="returns", ylab="density",
     col="blue", lwd=3, main="Density of VTI Returns")
# Interpolate the densv vector into returns
densv <- approx(densv$x, densv$y, xout=retp)
all.equal(densv$x, retp)
plot(densv, xlim=c(-5*madv, 5*madv),
     xlab="returns", ylab="density",
     t="l", col="blue", lwd=3,
     main="Density of VTI Returns")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Asset returns are usually not normally distributed and they exhibit \emph{leptokurtosis} (large kurtosis, or fat tails).
      \vskip1ex
      The function \texttt{hist()} calculates and plots a histogram, and returns its data \emph{invisibly}.
      \vskip1ex
      The parameter \texttt{breaks} is the number of cells of the histogram.
      \vskip1ex
      The function \texttt{lines()} draws a line through specified points.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/hist_vti_dens.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot histogram
histp <- hist(retp, breaks=100, freq=FALSE,
  xlim=c(-5*madv, 5*madv), xlab="", ylab="",
  main="VTI Return Distribution")
# Draw kernel density of histogram
lines(densv, col="red", lwd=2)
# Add density of normal distribution
curve(expr=dnorm(x, mean=mean(retp), sd=sd(retp)),
      add=TRUE, lwd=2, col="blue")
# Add legend
legend("topright", inset=0.05, cex=0.8, title=NULL,
       leg=c("VTI", "Normal"), bty="n",
       lwd=6, bg="white", col=c("red", "blue"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Quantile-Quantile Plot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{Quantile-Quantile} (\emph{Q-Q}) plot is a plot of points with the same \emph{quantiles}, from two probability distributions.
      \vskip1ex
      If the two distributions are similar then all the points in the \emph{Q-Q} plot lie along the diagonal.
      \vskip1ex
      The \emph{VTI} \emph{Q-Q} plot shows that the \emph{VTI} return distribution has fat tails.
      \vskip1ex
      The \emph{p}-value of the \emph{Shapiro-Wilk} test is very close to zero, which shows that the \emph{VTI} returns are very unlikely to be normal.
      \vskip1ex
      The function \texttt{shapiro.test()} performs the \emph{Shapiro-Wilk} test of normality.
      \vskip1ex
      The function \texttt{qqnorm()} produces a normal \emph{Q-Q} plot.
      \vskip1ex
      The function \texttt{qqline()} fits a line to the normal quantiles.
      <<echo=TRUE,eval=FALSE>>=
# Create normal Q-Q plot
qqnorm(retp, ylim=c(-0.1, 0.1), main="VTI Q-Q Plot",
       xlab="Normal Quantiles")
# Fit a line to the normal quantiles
qqline(retp, col="red", lwd=2)
# Perform Shapiro-Wilk test
shapiro.test(retp[1:499])
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/qq_plot.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Boxplots of Distributions of Values}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Box-and-whisker plots (\emph{boxplots}) are graphical representations of a distribution of values.
      \vskip1ex
      The bottom and top box edges (\emph{hinges}) are equal to the first and third quartiles, and the \emph{box} width is equal to the interquartile range (\emph{IQR}).
      \vskip1ex
      The nominal range is equal to 1.5 times the \emph{IQR} above and below the box \emph{hinges}.
      \vskip1ex
      The \emph{whiskers} are dashed vertical lines representing values beyond the first and third quartiles, but within the nominal range.
      \vskip1ex
      The \emph{whiskers} end at the last values within the nominal range, while the open circles represent outlier values beyond the nominal range.
      \vskip1ex
      The function \texttt{boxplot()} has two \texttt{methods}: one for \texttt{formula} objects (for categorical variables), and another for \texttt{data frames}.
      <<box_plots,eval=FALSE>>=
# Boxplot method for formula
boxplot(formula=mpg ~ cyl, data=mtcars,
        main="Mileage by number of cylinders",
        xlab="Cylinders", ylab="Miles per gallon")
# Boxplot method for data frame of EuStockMarkets percentage returns
boxplot(x=diff(log(EuStockMarkets)))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/box_plots-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Higher Moments of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The estimators of moments of a probability distribution are given by:
      \vskip1ex
      Sample mean: $\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$
      \vskip1ex
      Sample variance: $\hat\sigma^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i-\bar{x})^2$
      \vskip1ex
      With their expected values equal to the population mean and standard deviation:\\
      $\mathbb{E}[\bar{x}] = \mu$ \hskip0.5em and \hskip0.5em $\mathbb{E}[\hat\sigma] = \sigma$
      \vskip1ex
      The sample skewness (third moment):
      \begin{displaymath}
        \varsigma = \frac{n}{(n-1)(n-2)} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\hat\sigma})^3
      \end{displaymath}
      The sample kurtosis (fourth moment):
      \begin{displaymath}
        \kappa = \frac{n(n+1)}{(n-1)(n-2)(n-3)} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\hat\sigma})^4
      \end{displaymath}
      The normal distribution has skewness equal to $0$ and kurtosis equal to $3$.
      \vskip1ex
      Stock returns typically have negative skewness and kurtosis much greater than $3$.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Calculate VTI percentage returns
retp <- na.omit(rutils::etfenv$returns$VTI)
# Number of observations
nrows <- NROW(retp)
# Mean of VTI returns
retm <- mean(retp)
# Standard deviation of VTI returns
stdev <- sd(retp)
# Skewness of VTI returns
nrows/((nrows-1)*(nrows-2))*sum(((retp - retm)/stdev)^3)
# Kurtosis of VTI returns
nrows*(nrows+1)/((nrows-1)^3)*sum(((retp - retm)/stdev)^4)
# Random normal returns
retp <- rnorm(nrows, sd=stdev)
# Mean and standard deviation of random normal returns
retm <- mean(retp)
stdev <- sd(retp)
# Skewness of random normal returns
nrows/((nrows-1)*(nrows-2))*sum(((retp - retm)/stdev)^3)
# Kurtosis of random normal returns
nrows*(nrows+1)/((nrows-1)^3)*sum(((retp - retm)/stdev)^4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Functions for Calculating Skew and Kurtosis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} provides an easy way for users to write functions.
      \vskip1ex
      The function \texttt{calc\_skew()} calculates the skew of returns, and \texttt{calc\_kurt()} calculates the kurtosis.
      \vskip1ex
      Functions return the value of the last expression that is evaluated.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# calc_skew() calculates skew of returns
calc_skew <- function(retp) {
  retp <- na.omit(retp)
  sum(((retp - mean(retp))/sd(retp))^3)/NROW(retp)
}  # end calc_skew
# calc_kurt() calculates kurtosis of returns
calc_kurt <- function(retp) {
  retp <- na.omit(retp)
  sum(((retp - mean(retp))/sd(retp))^4)/NROW(retp)
}  # end calc_kurt
# Calculate skew and kurtosis of VTI returns
calc_skew(retp)
calc_kurt(retp)
# calcmom() calculates the moments of returns
calcmom <- function(retp, moment=3) {
  retp <- na.omit(retp)
  sum(((retp - mean(retp))/sd(retp))^moment)/NROW(retp)
}  # end calcmom
# Calculate skew and kurtosis of VTI returns
calcmom(retp, moment=3)
calcmom(retp, moment=4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of Estimators}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Statistical estimators are functions of samples (which are random variables), and therefore are themselves \emph{random variables}.
      \vskip1ex
      The \emph{standard error} (SE) of an estimator is defined as its \emph{standard deviation} (not to be confused with the \emph{population standard deviation} of the underlying random variable).
      \vskip1ex
      For example, the \emph{standard error} of the estimator of the mean is equal to:
      \begin{displaymath}
        \sigma_{\mu} = \frac{\sigma}{\sqrt{n}}
      \end{displaymath}
      Where $\sigma$ is the \emph{population standard deviation} (which is usually unkown).
      \vskip1ex
      The \emph{estimator} of this \emph{standard error} is equal to:
      \begin{displaymath}
        SE_{\mu} = \frac{\hat\sigma}{\sqrt{n}}
      \end{displaymath}
      where: $\hat\sigma^2=\frac{1}{n-1} \sum_{i=1}^n (x_i-\bar{x})^2$ is the sample standard deviation (the estimator of the population standard deviation).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
nrows <- 1000
datav <- rnorm(nrows)
# Sample mean
mean(datav)
# Sample standard deviation
sd(datav)
# Standard error of sample mean
sd(datav)/sqrt(nrows)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Normal (Gaussian)} Probability Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Normal (Gaussian)} probability density function is given by:
      \begin{displaymath}
        \phi(x, \mu, \sigma) = \frac{e^{-(x-\mu)^2/{2 \sigma^2}}}{\sigma \sqrt{2 \pi}}
      \end{displaymath}
      The \emph{Standard Normal} distribution $\phi(0, 1)$ is a special case of the \emph{Normal} $\phi(\mu, \sigma)$ with $\mu=0$ and $\sigma=1$.
      \vskip1ex
      The function \texttt{dnorm()} calculates the \emph{Normal} probability density.
      <<echo=TRUE,eval=FALSE>>=
xvar <- seq(-5, 7, length=100)
yvar <- dnorm(xvar, mean=1.0, sd=2.0)
plot(xvar, yvar, type="l", lty="solid", xlab="", ylab="")
title(main="Normal Density Function", line=0.5)
startp <- 3; endd <- 5  # Set lower and upper bounds
# Set polygon base
subv <- ((xvar >= startp) & (xvar <= endd))
polygon(c(startp, xvar[subv], endd),  # Draw polygon
        c(-1, yvar[subv], -1), col="red")
      @
    \column{0.5\textwidth}
    \includegraphics[width=0.45\paperwidth]{figure/norm_dist}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Normal (Gaussian)} Probability Distributions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Plots of several \emph{Normal} distributions with different values of $\sigma$, using the function \texttt{curve()} for plotting functions given by their name.
      <<norm_dist_mult_curves,eval=FALSE,echo=(-(1:1)),fig.show="hide">>=
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
sigmavs <- c(0.5, 1, 1.5, 2)  # Sigma values
# Create plot colors
colorv <- c("red", "black", "blue", "green")
# Create legend labels
labelv <- paste("sigma", sigmavs, sep="=")
for (it in 1:4) {  # Plot four curves
  curve(expr=dnorm(x, sd=sigmavs[it]),
        xlim=c(-4, 4), xlab="", ylab="", lwd=2,
        col=colorv[it], add=as.logical(it-1))
}  # end for
# Add title
title(main="Normal Distributions", line=0.5)
# Add legend
legend("topright", inset=0.05, title="Sigmas",
       labelv, cex=0.8, lwd=2, lty=1, bty="n", col=colorv)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/norm_dist_mult_curves-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Student's \protect\emph{t-distribution}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Let $z_{1},\ldots , z_{\nu}$ be independent standard normal random variables, with sample mean: $\bar{z}=\frac{1}{\nu} \sum_{i=1}^{\nu} z_i$ ($\mathbb{E}[\bar{z}]=\mu$) and sample variance: $\hat\sigma^2=\frac{1}{\nu-1} \sum_{i=1}^{\nu} (z_i-\bar{z})^2$
      \vskip1ex
      Then the random variable (\emph{t-ratio}):
      \begin{displaymath}
        t = \frac{\bar{z} - \mu}{\hat\sigma / \sqrt{\nu}}
      \end{displaymath}
      Follows the \emph{t-distribution} with $\nu$ degrees of freedom, with the probability density function:
      \begin{displaymath}
        f(t) = \frac{\Gamma((\nu+1)/2)}{\sqrt{\pi \nu}\,\Gamma(\nu/2)}\, (1 + t^2/\nu)^{-(\nu+1)/2}
      \end{displaymath}
      \vspace{-1em}
        <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=5)
par(mar=c(2, 2, 2, 1), oma=c(1, 1, 1, 1))
degf <- c(3, 6, 9)  # Df values
colorv <- c("black", "red", "blue", "green")
labelv <- c("normal", paste("df", degf, sep="="))
# Plot a Normal probability distribution
curve(expr=dnorm, xlim=c(-4, 4), xlab="", ylab="", lwd=2)
for (it in 1:3) {  # Plot three t-distributions
  curve(expr=dt(x, df=degf[it]), xlab="", ylab="",
        lwd=2, col=colorv[it+1], add=TRUE)
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/t_dist_mult.png}\\
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Add title
title(main="t-distributions", line=0.5)
# Add legend
legend("topright", inset=0.05, bty="n",
       title="Degrees\n of freedom", labelv,
       cex=0.8, lwd=6, lty=1, col=colorv)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Mixture Models of Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Mixture models} are produced by randomly sampling data from different distributions.
      \vskip1ex
      The mixture of two normal distributions with different variances produces a distribution with \emph{leptokurtosis} (large kurtosis, or fat tails).
      \vskip1ex
      Student's \emph{t-distribution} has fat tails because the sample variance in the denominator of the \emph{t-ratio} is variable.
      \vskip1ex
      The time-dependent volatility of asset returns is referred to as \emph{heteroskedasticity}.
      \vskip1ex
      Random processes with \emph{heteroskedasticity} can be considered a type of mixture model.
      \vskip1ex
      The \emph{heteroskedasticity} produces \emph{leptokurtosis} (large kurtosis, or fat tails).
      <<echo=TRUE,eval=FALSE>>=
# Mixture of two normal distributions with sd=1 and sd=2
nrows <- 1e5
retp <- c(rnorm(nrows/2), 2*rnorm(nrows/2))
retp <- (retp-mean(retp))/sd(retp)
# Kurtosis of normal
calc_kurt(rnorm(nrows))
# Kurtosis of mixture
calc_kurt(retp)
# Or
nrows*sum(retp^4)/(nrows-1)^2
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/mix_normal.png}
      \vspace{-1em}
        <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=5)
par(mar=c(2, 2, 2, 1), oma=c(1, 1, 1, 1))
# Plot the distributions
plot(density(retp), xlab="", ylab="",
  main="Mixture of Normal Returns",
  xlim=c(-3, 3), type="l", lwd=3, col="red")
curve(expr=dnorm, lwd=2, col="blue", add=TRUE)
curve(expr=dt(x, df=3), lwd=2, col="green", add=TRUE)
# Add legend
legend("topright", inset=0.05, lty=1, lwd=6, bty="n",
  legend=c("Mixture", "Normal", "t-distribution"),
  col=c("red", "blue", "green"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Non-standard Student's \protect\emph{t-distribution}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The non-standard Student's \emph{t-distribution} has the probability density function:
      \begin{displaymath}
        f(t) = \frac{\Gamma((\nu+1)/2)}{\sqrt{\pi \nu} \, \sigma \, \Gamma(\nu/2)} \, (1 + (\frac{t - \mu}{\sigma})^2/\nu)^{-(\nu+1)/2}
      \end{displaymath}
       It has non-zero mean equal to the location parameter $\mu$, and a standard deviation proportional to the scale parameter $\sigma$.
        <<echo=TRUE,eval=FALSE>>=
dev.new(width=6, height=5, noRStudioGD=TRUE)
# x11(width=6, height=5)
# Define density of non-standard t-distribution
tdistr <- function(x, dfree, locv=0, scalev=1) {
  dt((x-locv)/scalev, df=dfree)/scalev
}  # end tdistr
# Or
tdistr <- function(x, dfree, locv=0, scalev=1) {
  gamma((dfree+1)/2)/(sqrt(pi*dfree)*gamma(dfree/2)*scalev)*
    (1+((x-locv)/scalev)^2/dfree)^(-(dfree+1)/2)
}  # end tdistr
# Calculate vector of scale values
scalev <- c(0.5, 1.0, 2.0)
colorv <- c("blue", "black", "red")
labelv <- paste("scale", format(scalev, digits=2), sep="=")
# Plot three t-distributions
for (it in 1:3) {
  curve(expr=tdistr(x, dfree=3, scalev=scalev[it]), xlim=c(-3, 3),
        xlab="", ylab="", lwd=2, col=colorv[it], add=(it>1))
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/t_dist_scale.png}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Add title
title(main="t-distributions with Different Scale Parameters", line=0.5)
# Add legend
legend("topright", inset=0.05, bty="n", title="Scale Parameters", labelv,
       cex=0.8, lwd=6, lty=1, col=colorv)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Shapiro-Wilk} Test of Normality}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Shapiro-Wilk} test is designed to test the \emph{null hypothesis} that a sample: $\{x_1, \ldots, x_n\}$ is from a normally distributed population.
      \vskip1ex
      The test statistic is equal to:
      \begin{displaymath}
        W = \frac {(\sum_{i=1}^n a_i x_{(i)})^2} {\sum_{i=1}^n (x_i-\bar{x})^2}
      \end{displaymath}
      Where the: $\{a_1, \ldots, a_n\}$ are proportional to the \emph{order statistics} of random variables from the normal distribution.
      \vskip1ex
      $x_{(k)}$ is the \emph{k}-th \emph{order statistic}, and is equal to the \emph{k}-th smallest value in the sample: $\{x_1, \ldots, x_n\}$.
      \vskip1ex
      The \emph{Shapiro-Wilk} statistic follows its own distribution, and is less than or equal to $1$.
      \vskip1ex
      The \emph{Shapiro-Wilk} statistic is close to $1$ for samples from normal distributions.
      \vskip1ex
      The \emph{p}-value for \emph{VTI} returns is extremely small, and we conclude that the \emph{null hypothesis} is \texttt{FALSE}, and the \emph{VTI} returns are not from a normally distributed population.
      \vskip1ex
      The \emph{Shapiro-Wilk} test is not reliable for large sample sizes, so it's limited to less than \texttt{5000} sample size.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
# Calculate VTI percentage returns
library(rutils)
retp <- as.numeric(na.omit(rutils::etfenv$returns$VTI))[1:499]
# Reduce number of output digits
ndigits <- options(digits=5)
# Shapiro-Wilk test for normal distribution
nrows <- NROW(retp)
shapiro.test(rnorm(nrows))
# Shapiro-Wilk test for VTI returns
shapiro.test(retp)
# Shapiro-Wilk test for uniform distribution
shapiro.test(runif(nrows))
# Restore output digits
options(digits=ndigits$digits)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Jarque-Bera} Test of Normality}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Jarque-Bera} test is designed to test the \emph{null hypothesis} that a sample: $\{x_1, \ldots, x_n\}$ is from a normally distributed population.
      \vskip1ex
      The test statistic is equal to:
      \begin{displaymath}
        JB = \frac{n}{6} (\varsigma^2 + \frac{1}{4} (\kappa - 3)^2)
      \end{displaymath}
      Where the \emph{skewness} and \emph{kurtosis} are defined as:
      \begin{align*}
        \varsigma = \frac{1}{n} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\hat\sigma})^3
      &&
        \kappa = \frac{1}{n} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\hat\sigma})^4
      \end{align*}
      The \emph{Jarque-Bera} statistic asymptotically follows the \emph{chi-squared} distribution with  \texttt{2} degrees of freedom.
      \vskip1ex
      The \emph{Jarque-Bera} statistic is small for samples from normal distributions.
      \vskip1ex
      The \emph{p}-value for \emph{VTI} returns is extremely small, and we conclude that the \emph{null hypothesis} is \texttt{FALSE}, and the \emph{VTI} returns are not from a normally distributed population.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
library(tseries)  # Load package tseries
# Jarque-Bera test for normal distribution
jarque.bera.test(rnorm(nrows))
# Jarque-Bera test for VTI returns
jarque.bera.test(retp)
# Jarque-Bera test for uniform distribution
jarque.bera.test(runif(NROW(retp)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Kolmogorov-Smirnov} Test for Probability Distributions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Kolmogorov-Smirnov} test \emph{null hypothesis} is that two samples: $\{x_1, \ldots , x_n\}$ and $\{y_1, \ldots , y_n\}$ were obtained from the same probability distribution.
      \vskip1ex
      The \emph{Kolmogorov-Smirnov} statistic depends on the maximum difference between two empirical cumulative distribution functions (cumulative frequencies):
      \begin{displaymath}
        D = \sup_i | P(x_i) - P(y_i) |
      \end{displaymath}
      The function \texttt{ks.test()} performs the \emph{Kolmogorov-Smirnov} test and returns the statistic and its \emph{p}-value \emph{invisibly}.
      \vskip1ex
      The second argument to \texttt{ks.test()} can be either a \texttt{numeric} vector of data values, or a name of a cumulative distribution function.
      \vskip1ex
      The \emph{Kolmogorov-Smirnov} test can be used as a \emph{goodness of fit} test, to test if a set of observations fits a probability distribution.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# KS test for normal distribution
ks_test <- ks.test(rnorm(100), pnorm)
ks_test$p.value
# KS test for uniform distribution
ks.test(runif(100), pnorm)
# KS test for two shifted normal distributions
ks.test(rnorm(100), rnorm(100, mean=0.1))
ks.test(rnorm(100), rnorm(100, mean=1.0))
# KS test for two different normal distributions
ks.test(rnorm(100), rnorm(100, sd=2.0))
# KS test for VTI returns vs normal distribution
retp <- as.numeric(na.omit(rutils::etfenv$returns$VTI))
retp <- (retp - mean(retp))/sd(retp)
ks.test(retp, pnorm)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Chi-squared} Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Let $z_1, \ldots , z_k$ be independent standard \emph{Normal} random variables.
      \vskip1ex
      Then the random variable $X = \sum_{i=1}^k z^2_i$ is distributed according to the \emph{Chi-squared} distribution with $k$ degrees of freedom: $X \sim \chi_k^2$, and its probability density function is given by:
      \begin{displaymath}
        f(x) = \frac{x^{k/2-1}\,e^{-x/2}}{2^{k/2}\, \Gamma(k/2)}
      \end{displaymath}
      \vskip1ex
      The \emph{Chi-squared} distribution with $k$ degrees of freedom has mean equal to $k$ and variance equal to $2k$.
      <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=5)
par(mar=c(2, 2, 2, 1), oma=c(1, 1, 1, 1))
# Degrees of freedom
degf <- c(2, 5, 8, 11)
# Plot four curves in loop
colorv <- c("red", "black", "blue", "green")
for (it in 1:4) {
  curve(expr=dchisq(x, df=degf[it]),
        xlim=c(0, 20), ylim=c(0, 0.3),
        xlab="", ylab="", col=colorv[it],
        lwd=2, add=as.logical(it-1))
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/chisq_dist_mult.png}\\
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Add title
title(main="Chi-squared Distributions", line=0.5)
# Add legend
labelv <- paste("df", degf, sep="=")
legend("topright", inset=0.05, bty="n",
       title="Degrees of freedom", labelv,
       cex=0.8, lwd=6, lty=1, col=colorv)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Chi-squared} Test for the Goodness of Fit}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Goodness of Fit} tests are designed to test if a set of observations fits an assumed theoretical probability distribution.
      \vskip1ex
      The \emph{Chi-squared} test tests if a frequency of counts fits the specified distribution.
      \vskip1ex
      The \emph{Chi-squared} statistic is the sum of squared differences between the observed frequencies $o_i$ and the theoretical frequencies $p_i$:
      \begin{displaymath}
        \chi^2 = N \sum_{i=1}^{n} {\frac{(o_i - p_i )^2}{p_i}}
      \end{displaymath}
      Where $N$ is the total number of observations.
      \vskip1ex
      The \emph{null hypothesis} is that the observed frequencies are consistent with the theoretical distribution.
      \vskip1ex
      The function \texttt{chisq.test()} performs the \emph{Chi-squared} test and returns the statistic and its \emph{p}-value \emph{invisibly}.
      \vskip1ex
      The parameter \texttt{breaks} in the function \texttt{hist()} should be chosen large enough to capture the shape of the frequency distribution.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Observed frequencies from random normal data
histp <- hist(rnorm(1e3, mean=0), breaks=100, plot=FALSE)
countsn <- histp$counts
# Theoretical frequencies
countst <- rutils::diffit(pnorm(histp$breaks))
# Perform Chi-squared test for normal data
chisq.test(x=countsn, p=countst, rescale.p=TRUE, simulate.p.value=TRUE)
# Return p-value
chisq_test <- chisq.test(x=countsn, p=countst, rescale.p=TRUE, simulate.p.value=TRUE)
chisq_test$p.value
# Observed frequencies from shifted normal data
histp <- hist(rnorm(1e3, mean=2), breaks=100, plot=FALSE)
countsn <- histp$counts/sum(histp$counts)
# Theoretical frequencies
countst <- rutils::diffit(pnorm(histp$breaks))
# Perform Chi-squared test for shifted normal data
chisq.test(x=countsn, p=countst, rescale.p=TRUE, simulate.p.value=TRUE)
# Calculate histogram of VTI returns
histp <- hist(retp, breaks=100, plot=FALSE)
countsn <- histp$counts
# Calculate cumulative probabilities and then difference them
countst <- pt((histp$breaks-locv)/scalev, df=2)
countst <- rutils::diffit(countst)
# Perform Chi-squared test for VTI returns
chisq.test(x=countsn, p=countst, rescale.p=TRUE, simulate.p.value=TRUE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Likelihood Function of Student's \protect\emph{t-distribution}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The non-standard Student's \emph{t-distribution} is:
      \begin{displaymath}
        f(t) = \frac{\Gamma((\nu+1)/2)}{\sqrt{\pi \nu} \, \sigma \, \Gamma(\nu/2)} \, (1 + (\frac{t - \mu}{\sigma})^2/\nu)^{-(\nu+1)/2}
      \end{displaymath}
       It has non-zero mean equal to the location parameter $\mu$, and a standard deviation proportional to the scale parameter $\sigma$.
      \vskip1ex
      The negative logarithm of the probability density is equal to:
      \begin{multline*}
        -\log(f(t)) = -\log(\frac{\Gamma((\nu+1)/2)}{\sqrt{\pi \nu} \, \Gamma(\nu/2)}) + \log(\sigma) + \\
        \frac{\nu+1}{2} \, \log(1 + (\frac{t - \mu}{\sigma})^2/\nu)
      \end{multline*}
      The \emph{likelihood} function $\mathcal{L}(\theta|\bar{x})$ is a function of the model parameters $\theta$, given the observed values $\bar{x}$, under the model's probability distribution $f(x|\theta)$:
      \begin{displaymath}
        \mathcal{L}(\theta|x) = \prod_{i=1}^{n} f(x_i|\theta)
      \end{displaymath}
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Objective function from function dt()
likefun <- function(par, dfree, data) {
  -sum(log(dt(x=(data-par[1])/par[2], df=dfree)/par[2]))
}  # end likefun
# Demonstrate equivalence with log(dt())
likefun(c(1, 0.5), 2, 2:5)
-sum(log(dt(x=(2:5-1)/0.5, df=2)/0.5))
# Objective function is negative log-likelihood
likefun <- function(par, dfree, data) {
  sum(-log(gamma((dfree+1)/2)/(sqrt(pi*dfree)*gamma(dfree/2))) +
    log(par[2]) + (dfree+1)/2*log(1+((data-par[1])/par[2])^2/dfree))
}  # end likefun
      @
      The \emph{likelihood} function measures how \emph{likely} are the parameters, given the observed values $\bar{x}$.
      \vskip1ex
      The \emph{maximum-likelihood} estimate (\emph{MLE}) of the parameters are those that maximize the \emph{likelihood} function:
      \begin{displaymath}
        \theta_{MLE} = \operatorname*{arg\,max}_{\theta} {\mathcal{L}(\theta|x)}
      \end{displaymath}
      In practice the logarithm of the \emph{likelihood} $\log(\mathcal{L})$ is maximized, instead of the \emph{likelihood} itself.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Fitting Asset Returns into Student's \protect\emph{t-distribution}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{fitdistr()} from package \emph{MASS} fits a univariate distribution to a sample of data, by performing \emph{maximum likelihood} optimization.
      \vskip1ex
      The function \texttt{fitdistr()} performs a \emph{maximum likelihood} optimization to find the non-standardized Student's \emph{t-distribution} location and scale parameters.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI percentage returns
retp <- as.numeric(na.omit(rutils::etfenv$returns$VTI))
# Fit VTI returns using MASS::fitdistr()
fitobj <- MASS::fitdistr(retp, densfun="t", df=3)
summary(fitobj)
# Fitted parameters
fitobj$estimate
locv <- fitobj$estimate[1]
scalev <- fitobj$estimate[2]
locv; scalev
# Standard errors of parameters
fitobj$sd
# Log-likelihood value
fitobj$value
# Fit distribution using optim()
initp <- c(mean=0, scale=0.01)  # Initial parameters
fitobj <- optim(par=initp,
  fn=likefun, # Log-likelihood function
  data=retp,
  dfree=3, # Degrees of freedom
  method="L-BFGS-B", # Quasi-Newton method
  upper=c(1, 0.1), # Upper constraint
  lower=c(-1, 1e-7)) # Lower constraint
# Optimal parameters
locv <- fitobj$par["mean"]
scalev <- fitobj$par["scale"]
locv; scalev
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Student's \protect\emph{t-distribution} Fitted to Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Asset returns typically exhibit \emph{negative skewness} and \emph{large kurtosis} (leptokurtosis), or fat tails.
      \vskip1ex
      Stock returns fit the non-standard \emph{t-distribution} with \texttt{3} degrees of freedom quite well.
      \vskip1ex
      The function \texttt{hist()} calculates and plots a histogram, and returns its data \emph{invisibly}.
      \vskip1ex
      The parameter \texttt{breaks} is the number of cells of the histogram.
        <<echo=TRUE,eval=FALSE>>=
dev.new(width=6, height=5, noRStudioGD=TRUE)
# x11(width=6, height=5)
# Plot histogram of VTI returns
madv <- mad(retp)
histp <- hist(retp, col="lightgrey",
  xlab="returns", breaks=100, xlim=c(-5*madv, 5*madv),
  ylab="frequency", freq=FALSE, main="Histogram of VTI Returns")
lines(density(retp, adjust=1.5), lwd=3, col="blue")
# Plot the Normal probability distribution
curve(expr=dnorm(x, mean=mean(retp),
  sd=sd(retp)), add=TRUE, lwd=3, col="green")
# Define non-standard t-distribution
tdistr <- function(x, dfree, locv=0, scalev=1) {
  dt((x-locv)/scalev, df=dfree)/scalev
}  # end tdistr
# Plot t-distribution function
curve(expr=tdistr(x, dfree=3, locv=locv, scalev=scalev), col="red", lwd=3, add=TRUE)
# Add legend
legend("topright", inset=0.05, bty="n",
  leg=c("density", "t-distr", "normal"),
  lwd=6, lty=1, col=c("blue", "red", "green"))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/t_dist_rets.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Goodness of Fit of Student's \protect\emph{t-distribution} Fitted to Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Q-Q} plot illustrates the relative distributions of two samples of data.
      \vskip1ex
      The \emph{Q-Q} plot shows that stock returns fit the non-standard \emph{t-distribution} with \texttt{3} degrees of freedom quite well.
      \vskip1ex
      The function \texttt{qqplot()} produces a \emph{Q-Q} plot for two samples of data.
      \vskip1ex
      The function \texttt{ks.test()} performs the \emph{Kolmogorov-Smirnov} test for the similarity of two distributions.
      \vskip1ex
      The \emph{null hypothesis} of the \emph{Kolmogorov-Smirnov} test is that the two samples were obtained from the same probability distribution.
      \vskip1ex
      The \emph{Kolmogorov-Smirnov} test rejects the \emph{null hypothesis} that stock returns follow closely the non-standard \emph{t-distribution} with \texttt{3} degrees of freedom.
        <<echo=TRUE,eval=FALSE>>=
# Calculate sample from non-standard t-distribution with df=3
tdata <- scalev*rt(NROW(retp), df=3) + locv
# Q-Q plot of VTI Returns vs non-standard t-distribution
qqplot(tdata, retp, xlab="t-Dist Quantiles", ylab="VTI Quantiles", 
       main="Q-Q plot of VTI Returns vs Student's t-distribution")
# Calculate quartiles of the distributions
probs <- c(0.25, 0.75)
qrets <- quantile(retp, probs)
qtdata <- quantile(tdata, probs)
# Calculate slope and plot line connecting quartiles
slope <- diff(qrets)/diff(qtdata)
intercept <- qrets[1]-slope*qtdata[1]
abline(intercept, slope, lwd=2, col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/t_dist_qq.png}
        <<echo=TRUE,eval=FALSE>>=
# KS test for VTI returns vs t-distribution data
ks.test(retp, tdata)
# Define cumulative distribution of non-standard t-distribution
ptdistr <- function(x, dfree, locv=0, scalev=1) {
  pt((x-locv)/scalev, df=dfree)
}  # end ptdistr
# KS test for VTI returns vs cumulative t-distribution
ks.test(sample(retp, replace=TRUE), ptdistr, dfree=3, locv=locv, scalev=scalev)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Leptokurtosis Fat Tails of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The probability under the \emph{normal} distribution decreases exponentially for large values of $x$:
      \begin{displaymath}
        \phi(x) \propto e^{-{x^2/2\sigma^2}} \qquad (as \, {\left| x \right|} \to \infty)
      \end{displaymath}
      This is because a normal variable can be thought of as the sum of a large number of independent binomial variables of equal size.
      \vskip1ex
      So large values are produced only when all the contributing binomial variables are of the same sign, which is very improbable, so it produces extremely low tail probabilities (thin tails),
      \vskip1ex
      But in reality, the probability of large negative asset returns decreases much slower, as the negative power of the returns (fat tails).
      \vskip1ex
      The probability under Student's \emph{t-distribution} decreases as a power for large values of $x$:
      \begin{displaymath}
        f(x) \propto {\left| x \right|}^{-(\nu+1)} \qquad (as \, {\left| x \right|} \to \infty)
      \end{displaymath}
      This is because a \emph{t-variable} can be thought of as the sum of normal variables with different volatilities (different sizes).
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/stock_fat_tails.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot log density of VTI returns
plot(density(retp, adjust=4), xlab="VTI Returns", ylab="Density",
     main="Fat Left Tail of VTI Returns (density in log scale)", 
     type="l", lwd=3, col="blue", xlim=c(min(retp), -0.02), log="y")
# Plot t-distribution function
curve(expr=dt((x-locv)/scalev, df=3)/scalev, lwd=3, col="red", add=TRUE, log="y")
# Plot the Normal probability distribution
curve(expr=dnorm(x, mean=mean(retp), sd=sd(retp)), lwd=3, col="green", add=TRUE, log="y")
# Add legend
legend("topleft", inset=0.01, bty="n", y.intersp=c(0.25, 0.25, 0.25),
  leg=c("density", "t-distr", "normal"),
  lwd=6, lty=1, col=c("blue", "red", "green"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Trading Volumes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The average trading volumes have increased significantly since the 2008 crisis, mostly because of high frequency trading (HFT).
      \vskip1ex
      Higher levels of volatility coincide with higher \emph{trading volumes}.
      \vskip1ex
      The time-dependent volatility of asset returns (\emph{heteroskedasticity}) produces their fat tails (\emph{leptokurtosis}).
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI returns and trading volumes
ohlc <- rutils::etfenv$VTI
closep <- drop(coredata(quantmod::Cl(ohlc)))
retp <- rutils::diffit(log(closep))
volumv <- coredata(quantmod::Vo(ohlc))
# Calculate trailing variance
look_back <- 121
varv <- HighFreq::roll_var_ohlc(log(ohlc), method="close", look_back=look_back, scale=FALSE)
varv[1:look_back, ] <- varv[look_back+1, ]
# Calculate trailing average volume
volumr <- HighFreq::roll_var(volumv, look_back=look_back)/look_back
# dygraph plot of VTI variance and trading volumes
datav <- xts::xts(cbind(varv, volumr), zoo::index(ohlc))
colnamev <- c("variance", "volume")
colnames(datav) <- colnamev
dygraphs::dygraph(datav, main="VTI Variance and Trading Volumes") %>%
  dyAxis("y", label=colnamev[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colnamev[2], independentTicks=TRUE) %>%
  dySeries(name=colnamev[1], strokeWidth=2, axis="y", col="blue") %>%
  dySeries(name=colnamev[2], strokeWidth=2, axis="y2", col="red") %>%
  dyLegend(show="always", width=500)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/volume_volat_dyg.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Asset Returns in Trading Time}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The time-dependent volatility of asset returns (\emph{heteroskedasticity}) produces their fat tails (\emph{leptokurtosis}).
      \vskip1ex
      If asset returns were measured at fixed intervals of \emph{trading volumes} (\emph{trading time} instead of clock time), then the volatility would be lower and less time-dependent.
      \vskip1ex
      The asset returns can be adjusted to \emph{trading time} by dividing them by the \emph{square root of the trading volumes}, to obtain scaled returns over equal trading volumes.
      \vskip1ex
      The scaled returns have a more positive \emph{skewness} and a smaller \emph{kurtosis} than unscaled returns.
      <<echo=TRUE,eval=FALSE>>=
# Scale returns using volume (volume clock)
retsc <- ifelse(volumv > 0, sqrt(volumr)*retp/sqrt(volumv), 0)
retsc <- sd(retp)*retsc/sd(retsc)
# retsc <- ifelse(volumv > 1e4, retp/volumv, 0)
# Calculate moments of scaled returns
nrows <- NROW(retp)
sapply(list(retp=retp, retsc=retsc),
  function(rets) {sapply(c(skew=3, kurt=4),
           function(x) sum((rets/sd(rets))^x)/nrows)
})  # end sapply
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vti_scaled.png}
      <<echo=TRUE,eval=FALSE>>=
# x11(width=6, height=5)
dev.new(width=6, height=5, noRStudioGD=TRUE)
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 1, 1))
# Plot densities of SPY returns
madv <- mad(retp)
# bwidth <- mad(rutils::diffit(retp))
plot(density(retp, bw=madv/10), xlim=c(-5*madv, 5*madv),
     lwd=3, mgp=c(2, 1, 0), col="blue",
     xlab="returns (standardized)", ylab="frequency",
     main="Density of Volume-scaled VTI Returns")
lines(density(retsc, bw=madv/10), lwd=3, col="red")
curve(expr=dnorm(x, mean=mean(retp), sd=sd(retp)),
      add=TRUE, lwd=3, col="green")
# Add legend
legend("topright", inset=0.05, bty="n",
  leg=c("unscaled", "scaled", "normal"),
  lwd=6, lty=1, col=c("blue", "red", "green"))
quartz.save("figure/vti_scaled.png", type="png", width=6, height=5)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Risk and Performance Analysis}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{PerformanceAnalytics} for Risk and Performance Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package 
      \href{https://cran.r-project.org/web/packages/PerformanceAnalytics/index.html}{\emph{PerformanceAnalytics}} 
      contains functions for calculating risk and performance statistics, such as the variance, skewness, kurtosis, beta, alpha, etc.
      \vskip1ex
      The function \texttt{data()} loads external data or listv data sets in a package.
      \vskip1ex
      \texttt{managers} is an \emph{xts} time series containing monthly percentage returns of six asset managers (HAM1 through HAM6), the EDHEC Long-Short Equity hedge fund index, the \texttt{S\&P 500}, and US Treasury 10-year bond and 3-month bill total returns.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Load package PerformanceAnalytics
library(PerformanceAnalytics)
# Get documentation for package PerformanceAnalytics
# Get short description
packageDescription("PerformanceAnalytics")
# Load help page
help(package="PerformanceAnalytics")
# List all objects in PerformanceAnalytics
ls("package:PerformanceAnalytics")
# List all datasets in PerformanceAnalytics
data(package="PerformanceAnalytics")
# Remove PerformanceAnalytics from search path
detach("package:PerformanceAnalytics")
      @
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
perf_data <- unclass(data(
    package="PerformanceAnalytics"))$results[, -(1:2)]
apply(perf_data, 1, paste, collapse=" - ")
# Load "managers" data set
data(managers)
class(managers)
dim(managers)
head(managers, 3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plots of Cumulative Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{chart.CumReturns()} from package \emph{PerformanceAnalytics} plots the cumulative returns of a time series of returns.
      <<echo=TRUE,eval=FALSE>>=
# Load package "PerformanceAnalytics"
library(PerformanceAnalytics)
# Calculate ETF returns
retp <- rutils::etfenv$returns[, c("VTI", "DBC", "IEF")]
retp <- na.omit(retp)
# Plot cumulative ETF returns
x11(width=6, height=5)
chart.CumReturns(retp, lwd=2, ylab="",
  legend.loc="topleft", main="ETF Cumulative Returns")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/perf_analytics_cum_returns.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Distribution of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{chart.Histogram()} from package \emph{PerformanceAnalytics} plots the histogram (frequency distribution) and the density of returns.
      <<echo=TRUE,eval=FALSE>>=
retp <- na.omit(rutils::etfenv$returns$VTI)
chart.Histogram(retp, xlim=c(-0.04, 0.04),
  colorset = c("lightgray", "red", "blue"), lwd=3,
  main=paste("Distribution of", colnames(retp), "Returns"),
  methods = c("add.density", "add.normal"))
legend("topright", inset=0.05, bty="n",
       leg=c("VTI Density", "Normal"),
       lwd=6, lty=1, col=c("red", "blue"))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/returns_histogram.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Boxplots of Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{chart.Boxplot()} from package \emph{PerformanceAnalytics} plots a box-and-whisker plot for a distribution of returns.
      \vskip1ex
      The function \texttt{chart.Boxplot()} is a wrapper and calls the function \texttt{graphics::boxplot()} to plot the box plots.
      \vskip1ex
      A \emph{box plot} (box-and-whisker plot) is a graphical display of a distribution of data: \\
      The \emph{box} represents the upper and lower quartiles, \\
      The vertical lines (whiskers) represent values beyond the quartiles, \\
      Open circles represent values beyond the nominal range (outliers).
      <<echo=TRUE,eval=FALSE>>=
retp <- rutils::etfenv$returns[,
  c("VTI", "IEF", "IVW", "VYM", "IWB", "DBC", "VXX")]
x11(width=6, height=5)
chart.Boxplot(names=FALSE, retp)
par(cex.lab=0.8, cex.axis=0.8)
axis(side=2, at=(1:NCOL(retp))/7.5-0.05,labels=colnames(retp))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/perf_analytics_box_plot.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Median Absolute Deviation Estimator of Dispersion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Median Absolute Deviation} (\emph{MAD}) is a nonparametric measure of dispersion (variability), defined using the median instead of the mean:
      \begin{displaymath}
        \operatorname{MAD} = \operatorname{median}(\operatorname{abs}(x_i - \operatorname{median}(\mathbf{x})))
      \end{displaymath}
      The advantage of \emph{MAD} is that it's always well defined, even for data that has infinite variance.
      \vskip1ex
      The \emph{MAD} for normally distributed data is equal to $\Phi^{-1}(0.75) \cdot \hat\sigma = 0.6745 \cdot \hat\sigma$.
      \vskip1ex
      The function \texttt{mad()} calculates the \emph{MAD} and divides it by $\Phi^{-1}(0.75)$ to make it comparable to the standard deviation.
      \vskip1ex
      For normally distributed data the \emph{MAD} has a larger standard error than the standard deviation.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Simulate normally distributed data
nrows <- 1000
datav <- rnorm(nrows)
sd(datav)
mad(datav)
median(abs(datav - median(datav)))
median(abs(datav - median(datav)))/qnorm(0.75)
# Bootstrap of sd and mad estimators
bootd <- sapply(1:10000, function(x) {
  samplev <- datav[sample.int(nrows, replace=TRUE)]
  c(sd=sd(samplev), mad=mad(samplev))
})  # end sapply
bootd <- t(bootd)
# Analyze bootstrapped variance
head(bootd)
sum(is.na(bootd))
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
# Parallel bootstrap under Windows
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster
bootd <- parLapply(cluster, 1:10000,
  function(x, datav) {
    samplev <- datav[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, datav=datav)  # end parLapply
# Parallel bootstrap under Mac-OSX or Linux
bootd <- mclapply(1:10000, function(x) {
    samplev <- datav[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, mc.cores=ncores)  # end mclapply
stopCluster(cluster)  # Stop R processes over cluster
bootd <- rutils::do_call(rbind, bootd)
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Median Absolute Deviation of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      For normally distributed data the \emph{MAD} has a larger standard error than the standard deviation.
      \vskip1ex
      But for distributions with fat tails (like asset returns), the standard deviation has a larger standard error than the \emph{MAD}.
      \vskip1ex
      The \emph{bootstrap} procedure performs a loop, which naturally lends itself to parallel computing.
      \vskip1ex
      The function \texttt{makeCluster()} starts running \texttt{R} processes on several CPU cores under \emph{Windows}.
      \vskip1ex
      The function \texttt{parLapply()} is similar to \texttt{lapply()}, and performs loops under \emph{Windows} using parallel computing on several CPU cores.
      \vskip1ex
      The \texttt{R} processes started by \texttt{makeCluster()} don't inherit any data from the parent \texttt{R} process.
      \vskip1ex
      Therefore the required data must be either passed into \texttt{parLapply()} via the dots \texttt{"..."} argument, or by calling the function \texttt{clusterExport()}.
      \vskip1ex
      The function \texttt{mclapply()} performs loops using parallel computing on several CPU cores under \emph{Mac-OSX} or \emph{Linux}.
      \vskip1ex
      The function \texttt{stopCluster()} stops the \texttt{R} processes running on several CPU cores.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI returns
retp <- na.omit(rutils::etfenv$returns$VTI)
nrows <- NROW(retp)
sd(retp)
mad(retp)
# Bootstrap of sd and mad estimators
bootd <- sapply(1:10000, function(x) {
  samplev <- retp[sample.int(nrows, replace=TRUE)]
  c(sd=sd(samplev), mad=mad(samplev))
})  # end sapply
bootd <- t(bootd)
# Means and standard errors from bootstrap
100*apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
# Parallel bootstrap under Windows
library(parallel)  # Load package parallel
ncores <- detectCores() - 1  # Number of cores
cluster <- makeCluster(ncores)  # Initialize compute cluster
clusterExport(cluster, c("nrows", "returns"))
bootd <- parLapply(cluster, 1:10000,
  function(x) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  })  # end parLapply
# Parallel bootstrap under Mac-OSX or Linux
bootd <- mclapply(1:10000, function(x) {
    samplev <- retp[sample.int(nrows, replace=TRUE)]
    c(sd=sd(samplev), mad=mad(samplev))
  }, mc.cores=ncores)  # end mclapply
stopCluster(cluster)  # Stop R processes over cluster
bootd <- rutils::do_call(rbind, bootd)
# Means and standard errors from bootstrap
apply(bootd, MARGIN=2, function(x)
  c(mean=mean(x), stderror=sd(x)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Downside Deviation of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Some investors argue that positive returns don't represent risk, only those returns less than the target rate of return $r_t$.
      \vskip1ex
      The \emph{Downside Deviation} (semi-deviation) $\sigma_{d}$ is equal to the standard deviation of returns less than the target rate of return $r_t$:
      \begin{displaymath}
        \sigma_{d} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} ([r_i-r_t]_{-})^2}
      \end{displaymath}
      The function \texttt{DownsideDeviation()} from package \emph{PerformanceAnalytics} calculates the downside deviation, for either the full time series (\texttt{method="full"}) or only for the subseries less than the target rate of return $r_t$ (\texttt{method="subset"}).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(PerformanceAnalytics)
# Define target rate of return of 50 bps
targetr <- 0.005
# Calculate the full downside returns
returns_sub <- (retp - targetr)
returns_sub <- ifelse(returns_sub < 0, returns_sub, 0)
nrows <- NROW(returns_sub)
# Calculate the downside deviation
all.equal(sqrt(sum(returns_sub^2)/nrows),
  drop(DownsideDeviation(retp, MAR=targetr, method="full")))
# Calculate the subset downside returns
returns_sub <- (retp - targetr)
returns_sub <- returns_sub[returns_sub < 0]
nrows <- NROW(returns_sub)
# Calculate the downside deviation
all.equal(sqrt(sum(returns_sub^2)/nrows),
  drop(DownsideDeviation(retp, MAR=targetr, method="subset")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Drawdown Risk}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{drawdown} is the drop in prices from their historical peak, and is equal to the difference between the prices minus the cumulative maximum of the prices.
      \vskip1ex
      \emph{Drawdown risk} determines the risk of liquidation due to stop loss limits.
      <<echo=TRUE,eval=FALSE>>=
# Calculate time series of VTI drawdowns
closep <- log(quantmod::Cl(rutils::etfenv$VTI))
drawdns <- (closep - cummax(closep))
# Extract the date index from the time series closep 
datev <- zoo::index(closep)
# Calculate the maximum drawdown date and depth
indexmin <- which.min(drawdns)
datemin <- datev[indexmin]
maxdd <- drawdns[datemin]
# Calculate the drawdown start and end dates
startd <- max(datev[(datev < datemin) & (drawdns == 0)])
endd <- min(datev[(datev > datemin) & (drawdns == 0)])
# dygraph plot of VTI drawdowns
datav <- cbind(closep, drawdns)
colnamev <- c("VTI", "Drawdowns")
colnames(datav) <- colnamev
dygraphs::dygraph(datav, main="VTI Drawdowns") %>%
  dyAxis("y", label=colnamev[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colnamev[2], 
   valueRange=(1.2*range(drawdns)+0.1), independentTicks=TRUE) %>%
  dySeries(name=colnamev[1], axis="y", col="blue") %>%
  dySeries(name=colnamev[2], axis="y2", col="red") %>%
  dyEvent(startd, "start drawdown", col="blue") %>%
  dyEvent(datemin, "max drawdown", col="red") %>%
  dyEvent(endd, "end drawdown", col="green")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/drawdown_plot.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot VTI drawdowns using package quantmod
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("blue")
x11(width=6, height=5)
quantmod::chart_Series(x=closep, name="VTI Drawdowns", theme=plot_theme)
xval <- match(startd, datev)
yval <- max(closep)
abline(v=xval, col="blue")
text(x=xval, y=0.95*yval, "start drawdown", col="blue", cex=0.9)
xval <- match(datemin, datev)
abline(v=xval, col="red")
text(x=xval, y=0.9*yval, "max drawdown", col="red", cex=0.9)
xval <- match(endd, datev)
abline(v=xval, col="green")
text(x=xval, y=0.85*yval, "end drawdown", col="green", cex=0.9)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Drawdown Risk Using \texttt{PerformanceAnalytics::table.Drawdowns()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{table.Drawdowns()} from package \emph{PerformanceAnalytics} calculates a data frame of drawdowns.
      <<echo=TRUE,eval=FALSE>>=
library(xtable)
library(PerformanceAnalytics)
closep <- log(quantmod::Cl(rutils::etfenv$VTI))
retp <- rutils::diffit(closep)
# Calculate table of VTI drawdowns
tablev <- PerformanceAnalytics::table.Drawdowns(retp, geometric=FALSE)
# Convert dates to strings
tablev <- cbind(sapply(tablev[, 1:3], as.character), tablev[, 4:7])
# Print table of VTI drawdowns
print(xtable(tablev), comment=FALSE, size="tiny", include.rownames=FALSE)
      @
      <<echo=FALSE,eval=TRUE,size="tiny",results='asis'>>=
library(xtable)
library(PerformanceAnalytics)
closep <- log(quantmod::Cl(rutils::etfenv$VTI))
retp <- rutils::diffit(closep)
# Calculate table of VTI drawdowns
tablev <- PerformanceAnalytics::table.Drawdowns(retp, geometric=FALSE)
# Convert dates to strings
tablev <- cbind(sapply(tablev[, 1:3], as.character), tablev[, 4:7])
# Print table of VTI drawdowns
print(xtable(tablev), comment=FALSE, size="tiny", include.rownames=FALSE)
      @
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{PerformanceSummary} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{charts.PerformanceSummary()} from package \emph{PerformanceAnalytics} plots three charts: cumulative returns, return bars, and drawdowns, for time series of returns.
      <<echo=(-(1:1)),eval=FALSE>>=
# Load "managers" data set
data(managers)
charts.PerformanceSummary(ham1,
  main="", lwd=2, ylog=TRUE)
      @
    \column{0.5\textwidth}
    \vspace{-3em}
      \includegraphics[width=0.45\paperwidth]{figure/performance_summary-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Loss Distribution of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The distribution of returns has a long left tail of negative returns representing the risk of loss.
      \vskip1ex
      The \emph{Value at Risk} ($\mathrm{VaR}$) is equal to the quantile of returns corresponding to a given confidence level $\alpha$.
      \vskip1ex
      The \emph{Conditional Value at Risk} ($\mathrm{CVaR}$) is equal to the average of negative returns less than the $\mathrm{VaR}$.
      \vskip1ex
      The function \texttt{hist()} calculates and plots a histogram, and returns its data \emph{invisibly}.
      \vskip1ex
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data.
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI percentage returns
retp <- na.omit(rutils::etfenv$returns$VTI)
confl <- 0.1
varisk <- quantile(retp, confl)
cvar <- mean(retp[retp <= varisk])
# Plot histogram of VTI returns
x11(width=6, height=5)
par(mar=c(3, 2, 1, 0), oma=c(0, 0, 0, 0))
histp <- hist(retp, col="lightgrey",
  xlab="returns", ylab="frequency", breaks=100,
  xlim=c(-0.05, 0.01), freq=FALSE, main="VTI Returns Histogram")
# Calculate density
densv <- density(retp, adjust=1.5)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_var.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot density
lines(densv, lwd=3, col="blue")
# Plot line for VaR
abline(v=varisk, col="red", lwd=3)
text(x=varisk, y=25, labels="VaR", lwd=2, pos=2)
# Plot polygon shading for CVaR
text(x=1.5*varisk, y=10, labels="CVaR", lwd=2, pos=2)
varmax <- -0.06
rangev <- (densv$x < varisk) &  (densv$x > varmax)
polygon(c(varmax, densv$x[rangev], varisk),
  c(0, densv$y[rangev], 0), col=rgb(1, 0, 0,0.5), border=NA)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Value at Risk (\protect\emph{VaR})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Value at Risk} ($\mathrm{VaR}$) is equal to the quantile of returns corresponding to a given confidence level $\alpha$:
      \begin{displaymath}
        \alpha = \int_{-\infty}^{\mathrm{VaR}(\alpha)} \operatorname{f}(r) \, \mathrm{d}r
      \end{displaymath}
      Where $\operatorname{f}(r)$ is the probability density (distribution) of returns.
      \vskip1ex
      At a high confidence level, the value of $\mathrm{VaR}$ is subject to estimation error, and various numerical methods are used to approximate it.
      \vskip1ex
      The function \texttt{quantile()} calculates the sample quantiles.  It uses interpolation to improve the accuracy.  Information about the different interpolation methods can be found by typing \texttt{?quantile}.
      \vskip1ex
      A simpler but less accurate way of calculating the quantile is by sorting and selecting the data closest to the quantile.
      \vskip1ex
      The function \texttt{VaR()} from package \emph{PerformanceAnalytics} calculates the \emph{Value at Risk} using several different methods.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI percentage returns
retp <- na.omit(rutils::etfenv$returns$VTI)
nrows <- NROW(retp)
confl <- 0.05
# Calculate VaR approximately by sorting
sortv <- sort(as.numeric(retp))
cutoff <- round(confl*nrows)
varisk <- sortv[cutoff]
# Calculate VaR as quantile
varisk <- quantile(retp, probs=confl)
# PerformanceAnalytics VaR
PerformanceAnalytics::VaR(retp, p=(1-confl), method="historical")
all.equal(unname(varisk),
  as.numeric(PerformanceAnalytics::VaR(retp,
  p=(1-confl), method="historical")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk (\protect\emph{CVaR})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Conditional Value at Risk} ($\mathrm{CVaR}$) is equal to the average of negative returns less than the $\mathrm{VaR}$:
      \begin{displaymath}
        \mathrm{CVaR} = \frac{1}{\alpha} \int_{0}^\alpha \mathrm{VaR}(p) \, \mathrm{d}p
      \end{displaymath}
      The \emph{Conditional Value at Risk} is also called the \emph{Expected Shortfall} (\emph{ES}), or the Expected Tail Loss (\emph{ETL}).
      \vskip1ex
      The function \texttt{ETL()} from package \emph{PerformanceAnalytics} calculates the \emph{Conditional Value at Risk} using several different methods.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VaR as quantile
varisk <- quantile(retp, confl)
# Calculate CVaR as expected loss
cvar <- mean(retp[retp <= varisk])
# PerformanceAnalytics VaR
PerformanceAnalytics::ETL(retp, p=(1-confl), method="historical")
all.equal(unname(cvar),
  as.numeric(PerformanceAnalytics::ETL(retp,
    p=(1-confl), method="historical")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk and Return Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{table.Stats()} from package \emph{PerformanceAnalytics} calculates a data frame of risk and return statistics of the return distributions.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the risk-return statistics
riskstats <-
  PerformanceAnalytics::table.Stats(rutils::etfenv$returns)
class(riskstats)
# Transpose the data frame
riskstats <- as.data.frame(t(riskstats))
# Add Name column
riskstats$Name <- rownames(riskstats)
# Add Sharpe ratio column
riskstats$Sharpe <- riskstats$"Arithmetic Mean"/riskstats$Stdev
# Sort on Sharpe ratio
riskstats <- riskstats[order(riskstats$Sharpe, decreasing=TRUE), ]
      @
    \column{0.5\textwidth}
      <<echo=FALSE,eval=TRUE,size="tiny">>=
# Copy from rutils to save time
riskstats <- rutils::etfenv$riskstats
# Add Sharpe ratio column
riskstats$Sharpe <- riskstats$"Arithmetic Mean"/riskstats$Stdev
# Sort on Sharpe ratio
riskstats <- riskstats[order(riskstats$Sharpe, decreasing=TRUE), ]
# Print data frame
knitr::kable(riskstats[, c("Sharpe", "Skewness", "Kurtosis")])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Investor Risk and Return Preferences}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Investors typically prefer larger \emph{odd moments} of the return distribution (mean, skewness), and smaller \emph{even moments} (variance, kurtosis).
      \vskip1ex
      But positive skewness is often associated with lower returns, which can be observed in the \emph{VIX} volatility ETFs, \emph{VXX} and \emph{SVXY}.
      \vskip1ex
      The \emph{VXX} ETF is long the \emph{VIX} index (effectively long an option), so it has positive skewness and small kurtosis, but negative returns (it's short market risk).
      \vskip1ex
      Since the \emph{VXX} is effectively long an option, it pays option premiums so it has negative returns most of the time, with isolated periods of positive returns when markets drop.
      \vskip1ex
      The \emph{SVXY} ETF is short the \emph{VIX} index, so it has negative skewness and large kurtosis, but positive returns (it's long market risk).
      \vskip1ex
      Since the \emph{SVXY} is effectively short an option, it earns option premiums so it has positive returns most of the time, but it suffers sharp losses when markets drop.
    \column{0.5\textwidth}
    \vspace{1em}
      <<echo=FALSE,eval=TRUE,size="tiny">>=
# Print data frame
knitr::kable(riskstats[c("VXX", "SVXY"), c("Sharpe", "Skewness", "Kurtosis")])
      @
      \includegraphics[width=0.45\paperwidth]{figure/vix_vxx_svxy.png}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of VXX versus SVXY
pricev <- na.omit(rutils::etfenv$pricev[, c("VXX", "SVXY")])
pricev <- pricev["2017/"]
colnamev <- c("VXX", "SVXY")
colnames(pricev) <- colnamev
dygraphs::dygraph(pricev, main="Prices of VXX and SVXY") %>%
  dyAxis("y", label=colnamev[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colnamev[2], independentTicks=TRUE) %>%
  dySeries(name=colnamev[1], axis="y", strokeWidth=2, col="blue") %>%
  dySeries(name=colnamev[2], axis="y2", strokeWidth=2, col="green") %>%
  dyLegend(show="always", width=500) %>% dyLegend(show="always", width=500) %>%
  dyLegend(show="always", width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Skewness and Return Tradeoff}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Similarly to the \emph{VXX} and \emph{SVXY}, for most other ETFs positive skewness is often associated with lower returns.
      \vskip1ex
      Some of the exceptions are bond ETFs (like \emph{IEF}), which have both non-negative skewness and positive returns.
      \vskip1ex
      Another exception are commodity ETFs (like \emph{USO} oil), which have both negative skewness and negative returns.
      <<echo=TRUE,eval=FALSE>>=
# Remove VIX volatility ETF data
riskstats <- riskstats[-match(c("VXX", "SVXY"), riskstats$Name), ]
# Plot scatterplot of Sharpe vs Skewness
plot(Sharpe ~ Skewness, data=riskstats,
     ylim=1.1*range(riskstats$Sharpe),
     main="Sharpe vs Skewness")
# Add labels
text(x=riskstats$Skewness, y=riskstats$Sharpe,
          labels=riskstats$Name, pos=3, cex=0.8)
# Plot scatterplot of Kurtosis vs Skewness
x11(width=6, height=5)
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
plot(Kurtosis ~ Skewness, data=riskstats,
     ylim=c(1, max(riskstats$Kurtosis)),
     main="Kurtosis vs Skewness")
# Add labels
text(x=riskstats$Skewness, y=riskstats$Kurtosis,
          labels=riskstats$Name, pos=1, cex=0.8)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/etf_skew_sharp.png}
      % \includegraphics[width=0.45\paperwidth]{figure/etf_skew_kurtosis.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk-adjusted Return Measures}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Sharpe ratio} $\mathrm{S_r}$ is equal to the excess returns (in excess of the risk-free rate $r_f$) divided by the standard deviation $\sigma$ of the returns:
      \begin{displaymath}
        \mathrm{S_r} = \frac{E[r-r_f]}{\sigma}
      \end{displaymath}
      The \emph{Sortino ratio} $\mathrm{{So}_r}$ is equal to the excess returns divided by the \emph{downside deviation} $\sigma_{d}$ (standard deviation of returns that are less than a target rate of return $r_t$):
      \begin{displaymath}
        \mathrm{{So}_r} = \frac{E[r-r_t]}{\sigma_{d}}
      \end{displaymath}
      The \emph{Calmar ratio} $\mathrm{C_r}$ is equal to the excess returns divided by the \emph{maximum drawdown} $\mathrm{DD}$ of the returns:
      \begin{displaymath}
        \mathrm{C_r} = \frac{E[r-r_f]}{\mathrm{DD}}
      \end{displaymath}
      The \emph{Dowd ratio} $\mathrm{D_r}$ is equal to the excess returns divided by the \emph{Value at Risk} ($\mathrm{VaR}$) of the returns:
      \begin{displaymath}
        \mathrm{D_r} = \frac{E[r-r_f]}{\mathrm{VaR}}
      \end{displaymath}
      The \emph{Conditional Dowd ratio} $\mathrm{{Dc}_r}$ is equal to the excess returns divided by the \emph{Conditional Value at Risk} ($\mathrm{CVaR}$) of the returns:
      \begin{displaymath}
        \mathrm{{Dc}_r} = \frac{E[r-r_f]}{\mathrm{CVaR}}
      \end{displaymath}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(PerformanceAnalytics)
retp <- rutils::etfenv$returns[, c("VTI", "IEF")]
retp <- na.omit(retp)
# Calculate the Sharpe ratio
confl <- 0.05
PerformanceAnalytics::SharpeRatio(retp, p=(1-confl), 
  method="historical")
# Calculate the Sortino ratio
PerformanceAnalytics::SortinoRatio(retp)
# Calculate the Calmar ratio
PerformanceAnalytics::CalmarRatio(retp)
# Calculate the Dowd ratio
PerformanceAnalytics::SharpeRatio(retp, FUN="VaR", 
  p=(1-confl), method="historical")
# Calculate the Dowd ratio from scratch
varisk <- sapply(retp, quantile, probs=confl)
-sapply(retp, mean)/varisk
# Calculate the Conditional Dowd ratio
PerformanceAnalytics::SharpeRatio(retp, FUN="ES", 
  p=(1-confl), method="historical")
# Calculate the Conditional Dowd ratio from scratch
cvar <- sapply(retp, function(x) {
  mean(x[x < quantile(x, confl)])
})
-sapply(retp, mean)/cvar
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk of Aggregated Stock Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Stock returns aggregated over longer holding periods are closer to normally distributed, and their skewness, kurtosis, and tail risks are significantly lower than for daily returns.
      \vskip1ex
      Stocks become less risky over longer holding periods, so investors may choose to own a higher percentage of stocks, provided they hold them for a longer period of time.
      <<echo=TRUE,eval=FALSE>>=
# Calculate VTI daily percentage returns
retp <- na.omit(rutils::etfenv$returns$VTI)
nrows <- NROW(retp)
# Bootstrap aggregated annual VTI returns
holdp <- 252
reta <- sqrt(holdp)*sapply(1:nrows, function(x) {
    mean(retp[sample.int(nrows, size=holdp, replace=TRUE)])
})  # end sapply
# Calculate mean, standard deviation, skewness, and kurtosis
datav <- cbind(retp, reta)
colnames(datav) <- c("VTI", "Agg")
sapply(datav, function(x) {
  # Standardize the returns
  meanv <- mean(x); stdev <- sd(x); x <- (x - meanv)/stdev
  c(mean=meanv, stdev=stdev, skew=mean(x^3), kurt=mean(x^4))
})  # end sapply
# Calculate the Sharpe and Dowd ratios
confl <- 0.02
ratiom <- sapply(datav, function(x) {
  stdev <- sd(x)
  varisk <- unname(quantile(x, probs=confl))
  cvar <- mean(x[x < varisk])
  mean(x)/c(Sharpe=stdev, Dowd=-varisk, DowdC=-cvar)
})  # end sapply
# Annualize the daily risk
ratiom[, 1] <- sqrt(252)*ratiom[, 1]
ratiom
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/risk_aggregated.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the densities of returns
plot(density(retp), t="l", lwd=3, col="blue",
     xlab="returns", ylab="density", xlim=c(-0.04, 0.04),
     main="Distribution of Aggregated Stock Returns")
lines(density(reta), t="l", col="red", lwd=3)
curve(expr=dnorm(x, mean=mean(reta), sd=sd(reta)), col="green", lwd=3, add=TRUE)
legend("topright", legend=c("VTI Daily", "Aggregated", "Normal"), y.intersp=0.4,
       inset=-0.1, bg="white", lty=1, lwd=6, col=c("blue", "red", "green"), bty="n")
      @
  \end{columns}
\end{block}

\end{frame}




%%%%%%%%%%%%%%%
\section{Homework Assignment}

%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\secname}
\vspace{-1em}
\begin{block}{Required}
  \begin{itemize}[]
    \item Study all the lecture slides in \texttt{FRE7241\_Lecture\_1.pdf}, and run all the code in \texttt{FRE7241\_Lecture\_1.R},
  \end{itemize}
\end{block}
\begin{block}{Recommended}
  \begin{itemize}[]
    \item Read the documentation for packages \texttt{rutils.pdf} and \texttt{HighFreq.pdf},
  \end{itemize}
\end{block}

\end{frame}



\end{document}
