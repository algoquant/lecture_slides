% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size="tiny", fig.width=4, fig.height=4)
options(digits=3)
options(width=80, dev="pdf")
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[9pt]{beamer}
\DeclareMathSizes{8pt}{6pt}{6pt}{5pt}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
% \usepackage{mathtools}
\usepackage[latin1]{inputenc}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}



% Title page setup
\title[Time Series Multivariate]{Time Series Multivariate}
\subtitle{FRE6871 \& FRE7241, Spring 2022}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color.png}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{\today}



%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Asset Pricing Models}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Alpha} and \protect\emph{Beta} of Stock Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Capital Asset Pricing Model} decomposes asset returns into \emph{systematic} returns (proportional to the market returns) and \emph{idiosyncratic} returns (uncorrelated to market returns):
      \begin{displaymath}
        R - R_f = {\alpha} + \beta (R_m - R_f) + {\varepsilon}
      \end{displaymath}
      The returns of \emph{XLP} and \emph{VTI} are highly correlated because they are driven by common market factors of returns.
      \vskip1ex
      The \emph{t}-statistic (\emph{t}-value) is the ratio of the estimated value divided by its standard error.
      \vskip1ex
      The \emph{p}-value is the probability of obtaining values exceeding the \emph{t}-statistic, assuming the \emph{null hypothesis} is true.
      \vskip1ex
      A small \emph{p}-value means that the regression coefficients are very unlikely to be zero (given the data).
      <<echo=TRUE,eval=TRUE>>=
# Perform regression using formula
model <- lm(XLP ~ VTI, data=rutils::etfenv$returns)
# Get regression coefficients
coef(summary(model))
# Get alpha and beta
coef(summary(model))[, 1]
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.4\paperwidth]{figure/reg_rets.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot scatterplot of returns with aspect ratio 1
plot(XLP ~ VTI, data=rutils::etfenv$returns,
     xlim=c(-0.1, 0.1), ylim=c(-0.1, 0.1), 
     asp=1, main="Regression XLP ~ VTI")
# Add regression line and perpendicular line
abline(model, lwd=2, col="red")
abline(a=0, b=-1/coef(summary(model))[2, 1], 
       lwd=2, col="blue")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Statistical Significance of \protect\emph{Alpha} and \protect\emph{Beta}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{beta} $\beta$ values of stock returns are very statistically significant, but the \emph{alpha} $\alpha$ values are mostly not significant.
      \vskip1ex
      In addition, the \emph{Durbin-Watson} test shows that the regression residuals are autocorrelated which means that the regression \emph{p}-values may be smaller than the reported values.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
# Get regression coefficients
coef(summary(model))
# Calculate regression coefficients from scratch
design <- na.omit(rutils::etfenv$returns[, c("XLP", "VTI")])
betav <- drop(cov(design$XLP, design$VTI)/var(design$VTI))
alpha <- drop(mean(design$XLP) - betav*mean(design$VTI))
c(alpha, betav)
# Calculate the residuals
residuals <- (design$XLP - (alpha + betav*design$VTI))
# Calculate the standard deviation of residuals
nrows <- NROW(residuals)
residsd <- sqrt(sum(residuals^2)/(nrows - 2))
# Calculate the standard errors of beta and alpha
sum2 <- sum((design$VTI - mean(design$VTI))^2)
betasd <- residsd/sqrt(sum2)
alphasd <- residsd*sqrt(1/nrows + mean(design$VTI)^2/sum2)
c(alphasd, betasd)
# Perform the Durbin-Watson test of autocorrelation of residuals
lmtest::dwtest(model)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Alpha} and \protect\emph{Beta} of ETF Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.55\textwidth}
      The \emph{beta} $\beta$ values of ETF returns are very statistically significant, but the \emph{alpha} $\alpha$ values are mostly not significant.
      \vskip1ex
      Some of the ETFs with significant \emph{alpha} $\alpha$ values are the bond ETFs \emph{IEF} and \emph{TLT} (which have performed very well), and the natural resource ETFs \emph{USO} and \emph{DBC} (which have performed very poorly).
      <<echo=(-(1:1)),eval=TRUE>>=
library(rutils)  # Load rutils
retsp <- rutils::etfenv$returns
symbolv <- colnames(retsp)
symbolv <- symbolv[symbolv != "VTI"]
# Perform regressions and collect statistics
betasetf <- sapply(symbolv, function(symbol) {
# Specify regression formula
  formulav <- as.formula(paste(symbol, "~ VTI"))
# Perform regression
  model <- lm(formulav, data=retsp)
# Get regression summary
  modelsum <- summary(model)
# Collect regression statistics
  with(modelsum, 
    c(beta=coefficients[2, 1], 
      pbeta=coefficients[2, 4],
      alpha=coefficients[1, 1], 
      palpha=coefficients[1, 4], 
      pdw=lmtest::dwtest(model)$p.value))
})  # end sapply
betasetf <- t(betasetf)
# Sort by palpha
betasetf <- betasetf[order(betasetf[, "palpha"]), ]
      @
    \column{0.45\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
betasetf
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Capital Asset Pricing Model (\protect\emph{CAPM})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Capital Asset Pricing Model} decomposes asset returns into \emph{systematic} returns (proportional to the market returns) and \emph{idiosyncratic} returns (uncorrelated to market returns):
      \begin{displaymath}
        R - R_f = {\alpha} + \beta (R_m - R_f) + {\varepsilon}
      \end{displaymath}
      Where $R_m$ are the market returns, and $R_f$ are the risk-free returns.
      \vskip1ex
      The \emph{systematic} returns are proportional to $\beta$.
      \vskip1ex
      The \emph{idiosyncratic} returns are equal to the sum of $\alpha$ plus $\varepsilon$.
      \vskip1ex
      The \emph{alpha} $\alpha$ are the returns in excess of \emph{systematic} returns, that may be attributed to portfolio selection or active manager performance.
      \vskip1ex
      The \emph{idiosyncratic} risk (equal to $\varepsilon$) is uncorrelated to the \emph{systematic} risk, and can be reduced through portfolio diversification.
      \vskip1ex
      The $\beta$ is proportional to the correlation of returns between the asset and the market:
      \begin{displaymath}
        \beta = \frac{\sum_{i=1}^n (R_i-\bar{R}) (R_{i,m}-\bar{R_m})}{\sum_{i=1}^n (R_{i,m}-\bar{R_m})^2} = \rho \frac{\sigma}{\sigma_m}
      \end{displaymath}
      The \emph{CAPM} model states that if an asset has higher $\beta$ risk, then it earns higher \emph{systematic} returns.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
library(PerformanceAnalytics)
retsp <- na.omit(retsp[, c("XLP", "XLF", "VTI")])
# Calculate XLP beta
PerformanceAnalytics::CAPM.beta(Ra=retsp$XLP, Rb=retsp$VTI)
# Or
betav <- cov(retsp)[1, 2]/var(retsp$VTI)[1]
# Calculate XLP bull beta
PerformanceAnalytics::CAPM.beta.bull(Ra=retsp$XLP, Rb=retsp$VTI)
# Calculate XLP bear beta
PerformanceAnalytics::CAPM.beta.bear(Ra=retsp$XLP, Rb=retsp$VTI)
# Calculate XLP alpha
PerformanceAnalytics::CAPM.alpha(Ra=retsp$XLP, Rb=retsp$VTI)
# Or
mean(retsp$XLP - betav*retsp$VTI)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Security Market Line for ETFs}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      According to the \emph{CAPM} model, assets should earn a \emph{systematic} return proportional to their \emph{systematic} risk $\beta$.
      \vskip1ex
      The \emph{Security Market Line} (SML) represents the linear relationship between \emph{systematic} risk $\beta$ and return, for different stocks.
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
betasetf <- sapply(retsp[, colnames(retsp)!="VXX"], CAPM.beta, Rb=retsp$VTI)
retsann <- sapply(retsp[, colnames(retsp)!="VXX"], Return.annualized)
# Plot scatterplot
plot(retsann ~ betasetf, xlab="betas", 
            ylab="ann. rets", xlim=c(-0.25, 1.6))
points(x=1, y=retsann["VTI"], col="red", lwd=3, pch=21)
abline(a=0, b=retsann["VTI"])
labelv <- rownames(betasetf)[1:13]
# Add labels
text(x=1, y=retsann["VTI"], labels="VTI", pos=2)
text(x=betasetf[labelv], y=retsann[labelv], 
     labels=labelv, pos=2, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-4em}
      \includegraphics[width=0.5\paperwidth]{figure/capm_scatter-1}\\
    \vspace{-1em}
      A scatterplot of asset returns versus their $\beta$ shows which assets earn a positive $\alpha$, and which don't.
      \vskip1ex
      If an asset lies on the \emph{SML}, then its returns are mostly \emph{systematic}, and its $\alpha$ is equal to zero.
      \vskip1ex
      Assets above the \emph{SML} have a positive $\alpha$, and those below have a negative $\alpha$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: The Security Market Line for Stocks}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      According to the \emph{CAPM} model, assets should earn a \emph{systematic} return proportional to their \emph{systematic} risk $\beta$.
      \vskip1ex
      The \emph{Security Market Line} (SML) represents the linear relationship between \emph{systematic} risk $\beta$ and return, for different stocks.
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
betasetf <- sapply(retsp[, colnames(retsp)!="VXX"], 
                    CAPM.beta, Rb=retsp$VTI)
retsann <- sapply(retsp[, colnames(retsp)!="VXX"], 
                      Return.annualized)
# Plot scatterplot
plot(retsann ~ betasetf, xlab="betas", 
            ylab="ann. rets", xlim=c(-0.25, 1.6))
points(x=1, y=retsann["VTI"], col="red", lwd=3, pch=21)
abline(a=0, b=retsann["VTI"])
labelv <- rownames(betasetf)[1:13]
# Add labels
text(x=1, y=retsann["VTI"], labels="VTI", pos=2)
text(x=betasetf[labelv], y=retsann[labelv], 
     labels=labelv, pos=2, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-4em}
      \includegraphics[width=0.5\paperwidth]{figure/capm_scatter-1}\\
    \vspace{-1em}
      A scatterplot of asset returns versus their $\beta$ shows which assets earn a positive $\alpha$, and which don't.
      \vskip1ex
      If an asset lies on the \emph{SML}, then its returns are mostly \emph{systematic}, and its $\alpha$ is equal to zero.
      \vskip1ex
      Assets above the \emph{SML} have a positive $\alpha$, and those below have a negative $\alpha$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Beta-adjusted Performance Measurement}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Treynor} ratio measures the excess returns per unit of the \emph{systematic} risk \emph{beta} $\beta$, and is equal to the excess returns (over a risk-free return) divided by the $\beta$:
      \begin{displaymath}
        T_r=\frac{E[R-R_f]}{\beta}
      \end{displaymath}
      The \emph{Treynor} ratio is similar to the \emph{Sharpe} ratio, with the difference that its denominator represents only \emph{systematic} risk, not total risk.
      \vskip1ex
      The \emph{Information} ratio is equal to the excess returns (over a benchmark) divided by the \emph{tracking error} (standard deviation of excess returns):
      \begin{displaymath}
        I_r = \frac{E[R-R_b]} {\sqrt{\sum_{i=1}^n (R_i-R_{i,b})^2}}
      \end{displaymath}
      The \emph{Information} ratio measures the amount of outperformance versus the benchmark, and the consistency of outperformance.
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
library(PerformanceAnalytics)
# Calculate XLP Treynor ratio
TreynorRatio(Ra=retsp$XLP, Rb=retsp$VTI)
# Calculate XLP Information ratio
InformationRatio(Ra=retsp$XLP, Rb=retsp$VTI)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CAPM} Summary Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.55\textwidth}
      \texttt{PerformanceAnalytics::table.CAPM()} calculates the \emph{beta} $\beta$ and \emph{alpha} $\alpha$ values, the \emph{Treynor} ratio, and other performance statistics.
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
PerformanceAnalytics::table.CAPM(Ra=retsp[, c("XLP", "XLF")], 
                                 Rb=retsp$VTI, scale=252)
      @
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
capmstats <- table.CAPM(Ra=retsp[, symbolv], 
              Rb=retsp$VTI, scale=252)
colnamev <- strsplit(colnames(capmstats), split=" ")
colnamev <- do.call(cbind, colnamev)[1, ]
colnames(capmstats) <- colnamev
capmstats <- t(capmstats)
capmstats <- capmstats[, -1]
colnamev <- colnames(capmstats)
whichv <- match(c("Annualized Alpha", "Information Ratio", "Treynor Ratio"), colnamev)
colnamev[whichv] <- c("Alpha", "Information", "Treynor")
colnames(capmstats) <- colnamev
capmstats <- capmstats[order(capmstats[, "Alpha"], decreasing=TRUE), ]
# Copy capmstats into etfenv and save to .RData file
etfenv <- rutils::etfenv
etfenv$capmstats <- capmstats
save(etfenv, file="/Users/jerzy/Develop/lecture_slides/data/etf_data.RData")
      @
    \column{0.45\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
rutils::etfenv$capmstats[, c("Beta", "Alpha", "Information", "Treynor")]
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Factor Analysis}


%%%%%%%%%%%%%%%
\subsection{Rolling Beta Regressions Over Time}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The rolling beta of \emph{XLP} versus \emph{VTI} changes over time, with lower beta in periods of \emph{VTI} selloffs.
      \vskip1ex
      The function \texttt{roll\_reg()} from package \emph{HighFreq} performs rolling regressions in \texttt{C++} (\emph{RcppArmadillo}), so it's therefore much faster than equivalent \texttt{R} code.
      <<echo=TRUE,eval=FALSE>>=
# Calculate XLP and VTI returns
retsp <- na.omit(rutils::etfenv$returns[, c("XLP", "VTI")])
# Calculate monthly end points
endp <- xts::endpoints(retsp, on="months")[-1]
# Calculate start points from look-back interval
look_back <- 12  # Look back 12 months
startp <- c(rep(1, look_back), endp[1:(NROW(endp)-look_back)])
head(cbind(endp, startp), look_back+2)
# Calculate rolling beta regressions every month in R
formulav <- XLP ~ VTI  # Specify regression formula
betas_r <- sapply(1:NROW(endp), FUN=function(ep) {
    datav <- retsp[startp[ep]:endp[ep], ]
    # coef(lm(formulav, data=datav))[2]
    drop(cov(datav[, 1], datav[, 2])/var(datav[, 2]))
  })  # end sapply
# Calculate rolling betas using RcppArmadillo
reg_stats <- HighFreq::roll_reg(response=retsp[, 1], design=retsp[, 2], endp=(endp-1), startp=(startp-1))
betas <- reg_stats[, 2]
all.equal(betas, betas_r)
# Compare the speed of RcppArmadillo with R code
library(microbenchmark)
summary(microbenchmark(
  Rcpp=HighFreq::roll_reg(response=retsp[, 1], design=retsp[, 2], endp=(endp-1), startp=(startp-1)),
  Rcode=sapply(1:NROW(endp), FUN=function(ep) {
    datav <- retsp[startp[ep]:endp[ep], ]
    drop(cov(datav[, 1], datav[, 2])/var(datav[, 2]))
  }),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/rolling_betas.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of rolling XLP beta and VTI prices
dates <- zoo::index(retsp[endp, ])
pricets <- rutils::etfenv$prices$VTI[dates]
datav <- cbind(pricets, betas)
colnamev <- colnames(datav)
dygraphs::dygraph(datav, main="XLP Rolling 12-month Beta and VTI Prices") %>%
  dyAxis("y", label=colnamev[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colnamev[2], independentTicks=TRUE) %>%
  dySeries(name=colnamev[1], axis="y", col="blue") %>%
  dySeries(name=colnamev[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Engle-Granger Two-step Procedure for Cointegration}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{ADF} test can be applied to test for the cointegration of time series of prices.
      \vskip1ex
      The Engle-Granger two-step procedure for two time series consists of:
      \begin{itemize}
        \item Performing a regression to calculate the cointegrating factor $\beta$,
        \item Applying the \emph{ADF} test to the residuals of the regression to determine that they don't have a unit root (they are mean reverting).
      \end{itemize}
      The regression of prices is not statistically valid because they are not normally distributed.
      <<echo=TRUE,eval=FALSE>>=
# Calculate XLB and XLE prices
pricets <- na.omit(rutils::etfenv$prices[, c("XLB", "XLE")])
cor(rutils::diffit(log(pricets)))
xlb <- drop(zoo::coredata(pricets$XLB))
xle <- drop(zoo::coredata(pricets$XLE))
# Calculate regression coefficients of XLB ~ XLE
betav <- cov(xlb, xle)/var(xle)
alpha <- (mean(xlb) - betav*mean(xle))
# Calculate regression residuals
fittedv <- (alpha + betav*xle)
residuals <- (xlb - fittedv)
# Perform ADF test on residuals
tseries::adf.test(residuals, k=1)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/coint_prices.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot prices
dygraphs::dygraph(pricets, main="XLB and XLE Prices") %>%
  dyOptions(colors=c("blue", "red"))
# Plot cointegration residuals
residuals <- xts::xts(residuals, zoo::index(pricets))
dygraphs::dygraph(residuals, main="XLB and XLE Cointegration Residuals")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Principal Components} of \protect\emph{S\&P500} Stock Constituents}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{PCA} standard deviations are the volatilities of the \emph{principal component} time series.
      \vskip1ex
      The original time series of returns can be calculated approximately from the first few \emph{principal components} with the largest standard deviations.
      \vskip1ex
      The \emph{Kaiser-Guttman} rule uses only \emph{principal components} with \emph{variance} greater than $1$.
      \vskip1ex
      Another rule of thumb is to use the \emph{principal components} with the largest standard deviations which sum up to \texttt{80\%} of the total variance of returns.
      <<echo=TRUE,eval=FALSE>>=
# Load S&P500 constituent stock prices
load("/Users/jerzy/Develop/lecture_slides/data/sp500_prices.RData")
# Calculate stock prices and percentage returns
pricets <- zoo::na.locf(pricets, na.rm=FALSE)
pricets <- zoo::na.locf(pricets, fromLast=TRUE)
retsp <- rutils::diffit(log(pricets))
# Standardize (de-mean and scale) the returns
retsp <- lapply(retsp, function(x) {(x - mean(x))/sd(x)})
retsp <- rutils::do_call(cbind, retsp)
# Perform principal component analysis PCA
pcad <- prcomp(retsp, scale=TRUE)
# Find number of components with variance greater than 2
ncomp <- which(pcad$sdev^2 < 2)[1]
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_scree.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot standard deviations of principal components
barplot(pcad$sdev[1:ncomp], 
        names.arg=colnames(pcad$rotation[, 1:ncomp]), 
        las=3, xlab="", ylab="", 
        main="Volatilities of S&P500 Principal Components")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Principal Component} Loadings (Weights)}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Principal component} loadings are the weights of \emph{principal component} portfolios.
      \vskip1ex
      The \emph{principal component} portfolios have mutually orthogonal returns
      represent the different orthogonal modes of the return variance.
      <<echo=TRUE,eval=FALSE>>=
# Calculate principal component loadings (weights)
# Plot barplots with PCA weights in multiple panels
ncomps <- 6
par(mfrow=c(ncomps/2, 2))
par(mar=c(4, 2, 2, 1), oma=c(0, 0, 0, 0))
# First principal component weights
weights <- sort(pcad$rotation[, 1], decreasing=TRUE)
barplot(weights[1:6], las=3, xlab="", ylab="", main="")
title(paste0("PC", 1), line=-2.0, col.main="red")
for (ordern in 2:ncomps) {
  weights <- sort(pcad$rotation[, ordern], decreasing=TRUE)
  barplot(weights[c(1:3, 498:500)], las=3, xlab="", ylab="", main="")
  title(paste0("PC", ordern), line=-2.0, col.main="red")
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_loadings.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Principal Component} Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The time series of the \emph{principal components} can be calculated by multiplying the loadings (weights) times the original data.
      \vskip1ex
      Higher order \emph{principal components} are gradually less volatile.
      <<echo=TRUE,eval=FALSE>>=
# Calculate principal component time series
retspca <- xts(retsp %*% pcad$rotation[, 1:ncomps], 
                order.by=dates)
round(cov(retspca), 3)
pcacum <- cumsum(retspca)
# Plot principal component time series in multiple panels
par(mfrow=c(ncomps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
rangev <- range(pcacum)
for (ordern in 1:ncomps) {
  plot.zoo(pcacum[, ordern], ylim=rangev, xlab="", ylab="")
  title(paste0("PC", ordern), line=-2.0)
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_series.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} Factor Model From \protect\emph{Principal Components}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      By inverting the \emph{PCA} analysis, the \emph{S\&P500} constituent returns can be calculated from the first \texttt{k} \emph{principal components} under a \emph{factor model}: 
      \begin{displaymath}
        \mathbf{r}_i = \alpha_i + \sum_{j=1}^k {\beta_{ji} \, \mathbf{F}_j} + \varepsilon_i
      \end{displaymath}
      The \emph{principal components} are interpreted as \emph{market factors}: $\mathbf{F}_j = \mathbf{pc}_j$.
      \vskip1ex
      The \emph{market betas} are the inverse of the \emph{principal component loadings}: $\beta_{ji} = w_{ij}$.
      \vskip1ex
      The $\varepsilon_i$ are the \emph{idiosyncratic} returns, which should be mutually independent and uncorrelated to the \emph{market factor} returns.
      <<echo=(-(1:2)),eval=FALSE>>=
par(mfrow=c(ncomps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
# Invert principal component time series
invmat <- solve(pcad$rotation)
all.equal(invmat, t(pcad$rotation))
solved <- retspca %*% invmat[1:ncomps, ]
solved <- xts::xts(solved, dates)
solved <- cumsum(solved)
retc <- cumsum(retsp)
# Plot the solved returns
symbolv <- c("MSFT", "XOM", "JPM", "AAPL", "BRK_B", "JNJ")
for (symbol in symbolv) {
  plot.zoo(cbind(retc[, symbol], solved[, symbol]), 
    plot.type="single", col=c("black", "blue"), xlab="", ylab="")
  legend(x="topleft", bty="n",
         legend=paste0(symbol, c("", " solved")),
         title=NULL, inset=0.05, cex=1.0, lwd=6,
         lty=1, col=c("black", "blue"))
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_series_solved.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Factor Model} Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The original time series of returns can be calculated exactly from the time series of all the \emph{principal components}, by inverting the loadings matrix.
      \vskip1ex
      The original time series of returns can be calculated approximately from just the first few \emph{principal components}, which demonstrates that \emph{PCA} is a form of \emph{dimension reduction}.
      \vskip1ex
      The function \texttt{solve()} solves systems of linear equations, and also inverts square matrices.
      <<echo=(-(1:2)),eval=FALSE>>=
par(mfrow=c(ncomps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
# Perform ADF unit root tests on original series and residuals
sapply(symbolv, function(symbol) {
  c(series=tseries::adf.test(retc[, symbol])$p.value,
    resid=tseries::adf.test(retc[, symbol] - solved[, symbol])$p.value)
})  # end sapply
# Plot the residuals
for (symbol in symbolv) {
  plot.zoo(retc[, symbol] - solved[, symbol], 
    plot.type="single", col="blue", xlab="", ylab="")
  legend(x="topleft", bty="n", legend=paste(symbol, "residuals"),
         title=NULL, inset=0.05, cex=1.0, lwd=6, lty=1, col="blue")
}  # end for
# Perform ADF unit root test on principal component time series
retspca <- xts(retsp %*% pcad$rotation, order.by=dates)
pcacum <- cumsum(retspca)
adf_pvalues <- sapply(1:NCOL(pcacum), function(ordern)
  tseries::adf.test(pcacum[, ordern])$p.value)
# AdF unit root test on stationary time series
tseries::adf.test(rnorm(1e5))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_residuals.png}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\subsection{Correlation and Factor Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<corr_plot,echo=(-(1:1)),eval=FALSE,fig.show='hide'>>=
library(quantmod)
### Perform pair-wise correlation analysis
# Calculate correlation matrix
cormat <- cor(retsp)
colnames(cormat) <- colnames(retsp)
rownames(cormat) <- colnames(retsp)
# Reorder correlation matrix based on clusters
# Calculate permutation vector
library(corrplot)
ordern <- corrMatOrder(cormat, order="hclust", 
              hclust.method="complete")
# Apply permutation vector
cormat <- cormat[ordern, ordern]
# Plot the correlation matrix
colors <- colorRampPalette(c("red", "white", "blue"))
corrplot(cormat, tl.col="black", tl.cex=0.8, 
    method="square", col=colors(8), 
    cl.offset=0.75, cl.cex=0.7, 
    cl.align.text="l", cl.ratio=0.25)
# draw rectangles on the correlation matrix plot
corrRect.hclust(cormat, k=NROW(cormat) %/% 2, 
                method="complete", col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Hierarchical Clustering Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{as.dist()} converts a matrix representing the \emph{distance} (dissimilarity) between elements, into a list of class \texttt{"dist"}.
      \vskip1ex
      For example, \texttt{as.dist()} converts \texttt{(1-correlation)} to distance.
      \vskip1ex
      The function \texttt{hclust()} recursively combines elements into clusters based on their mutual \emph{distance}.
      \vskip1ex
      First \texttt{hclust()} combines individual elements that are closest to each other.
      \vskip1ex
      Then it combines elements to the closest clusters, then clusters with other clusters, until all elements are combined into one cluster.
      \vskip1ex
      This process of recursive clustering can be represented as a \emph{dendrogram} (tree diagram).
      \vskip1ex
      Branches of a \emph{dendrogram} represent clusters.
      \vskip1ex
      Neighboring branches contain elements that are close to each other (have small distance).
      \vskip1ex
      Neighboring branches combine into larger branches, that then combine with their closest branches, etc.
    \column{0.5\textwidth}
      \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/cluster_plot-1}
      \vspace{-4em}
      <<cluster_plot,echo=TRUE,eval=FALSE,fig.width=6,fig.height=6,fig.show='hide'>>=
# Convert correlation matrix into distance object
dis_tance <- as.dist(1-cormat)
# Perform hierarchical clustering analysis
cluster <- hclust(dis_tance)
plot(cluster, ann=FALSE, xlab="", ylab="")
title("Dendrogram representing hierarchical clustering
      \nwith dissimilarity = 1-correlation", line=-0.5)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: \protect\emph{Principal Component} Returns Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
\vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PerformanceAnalytics)  # Load package "PerformanceAnalytics"
# PC returns from rotation and scaled returns
retscaled <- apply(retsp, 2, scale)
retspca <- retscaled %*% pcad$rotation
# "x" matrix contains time series of PC returns
dim(pcad$x)
class(pcad$x)
head(pcad$x[, 1:3], 3)
# Convert PC matrix to xts and rescale to decimals
retspca <- xts(pcad$x/100, order.by=zoo::index(retsp))
      @
\vspace{-1em}
      <<pca_retc,echo=(-1),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)  # Load package "PerformanceAnalytics"
chart.CumReturns(
  retspca[, 1:3], lwd=2, ylab="", 
  legend.loc="topright", main="")
# Add title
title(main="ETF cumulative returns", line=-1)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/pca_cum_returns-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: \protect\emph{Principal Component} Returns Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
# Calculate PC correlation matrix
cormat <- cor(retspca)
colnames(cormat) <- colnames(retspca)
rownames(cormat) <- colnames(retspca)
cormat[1:3, 1:3]
table.CAPM(Ra=retspca[, 1:3], Rb=retsp$VTI, scale=252)
      @
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Principal Component Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_plot,echo=(-(1:2)),fig.height=5,fig.show='hide',eval=FALSE>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # Set plot panels
### Perform principal component analysis PCA
retsp <- na.omit(rutils::etfenv$returns)
pcad <- prcomp(retsp, center=TRUE, scale=TRUE)
barplot(pcad$sdev[1:10], 
        names.arg=colnames(pcad$rotation)[1:10], 
        las=3, ylab="STDEV", xlab="PCVec", 
        main="PCA Explain VAR")
# Show first three principal component loadings
head(pcad$rotation[,1:3], 3)
# Permute second principal component loadings by size
pca2 <- as.matrix(
  pcad$rotation[order(pcad$rotation[, 2], 
  decreasing=TRUE), 2])
colnames(pca2) <- "pca2"
head(pca2, 3)
# The option las=3 rotates the names.arg labels
barplot(as.vector(pca2), 
        names.arg=rownames(pca2), 
        las=3, ylab="Loadings", 
        xlab="Symbol", main="Loadings pca2")
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/pca_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Principal Component Vectors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_vec,echo=(-(1:2)),eval=FALSE,fig.height=5,fig.show='hide'>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(3,1))  # Set plot panels
# Get list of principal component vectors
pca_vecs <- lapply(1:3, function(ordern) {
  pca_vec <- as.matrix(
    pcad$rotation[
    order(pcad$rotation[, ordern], 
    decreasing=TRUE), ordern])
  colnames(pca_vec) <- paste0("pca", ordern)
  pca_vec
})  # end lapply
names(pca_vecs) <- c("pca1", "pca2", "pca3")
# The option las=3 rotates the names.arg labels
for (ordern in 1:3) {
  barplot(as.vector(pca_vecs[[ordern]]), 
        names.arg=rownames(pca_vecs[[ordern]]), 
        las=3, xlab="", ylab="", 
        main=paste("Loadings", 
          colnames(pca_vecs[[ordern]])))
}  # end for
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/pca_vec-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Package \protect\emph{factorAnalytics}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The package \emph{factorAnalytics} performs estimation and risk analysis of linear factor models for portfolio asset returns.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(factorAnalytics)  # Load package "factorAnalytics"
# Get documentation for package "factorAnalytics"
packageDescription("factorAnalytics")  # Get short description
help(package="factorAnalytics")  # Load help page
      @
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE,tidy=TRUE>>=
options(width=50)
library(factorAnalytics)  # Load package "factorAnalytics"
# List all objects in "factorAnalytics"
ls("package:factorAnalytics")

# List all datasets in "factorAnalytics"
# data(package="factorAnalytics")

# Remove factorAnalytics from search path
detach("package:factorAnalytics")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Fitting Factor Models Using PCA}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(factorAnalytics)
# Fit a three-factor model using PCA
factpca <- fitSfm(rutils::etfenv$returns, k=3)
head(factpca$loadings, 3)  # Factor loadings
# Factor realizations (time series)
head(factpca$factors)
# Residuals from regression
factpca$residuals[1:3, 1:3]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(factorAnalytics)
factpca$alpha  # Estimated alphas
factpca$r2  # R-squared regression
# Covariance matrix estimated by factor model
factpca$Omega[1:3, 4:6]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Factor Loadings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      <<fact_load,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=10,fig.show='hide'>>=
library(factorAnalytics)
# load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
plot(factpca, which.plot.group=3, n.max=30, loop=FALSE)
# ?plot.sfm
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_load-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Time Series of Factors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_tsplot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot factor cumulative returns
chart.CumReturns(factpca$factors, 
    lwd=2, ylab="", legend.loc="topleft", main="")

# Plot time series of factor returns
# Plot(factpca, which.plot.group=2, 
#   loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_tsplot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Asset Correlations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_corr_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=7,fig.show='hide'>>=
# Asset correlations "hclust" hierarchical clustering order
plot(factpca, which.plot.group=7, loop=FALSE, 
     order="hclust", method="ellipse")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Time Series of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot residual cumulative returns
chart.CumReturns(factpca$residuals[, c("IEF", "DBC", "XLF")], 
  lwd=2, ylab="", legend.loc="topleft", main="")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Residual Returns Histogram}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_hist,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot residual histogram with normal curve
plot(factpca, asset.name="VTI", 
     which.plot.single=8, 
     plot.single=TRUE, loop=FALSE, 
     xlim=c(-0.007, 0.007))
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_hist-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Residual Returns and the Q-Q Plot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_qq,eval=FALSE,echo=(-1),fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Residual Q-Q plot
plot(factpca, asset.name="VTI", 
     which.plot.single=9, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_qq-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Autocorrelation of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_autocorr,eval=FALSE,echo=TRUE,fig.width=7,fig.height=9,fig.show='hide'>>=
# SACF and PACF of residuals
plot(factpca, asset.name="VTI", 
     which.plot.single=5, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_autocorr-1}
  \end{columns}
\end{block}

\end{frame}



\end{document}
