% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='tiny', fig.width=4, fig.height=4)
options(digits=3)
options(width=80, dev='pdf')
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
% \usepackage{mathtools}
\usepackage[latin1]{inputenc}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}



% Title page setup
\title[Time Series Multivariate]{Time Series Multivariate}
\subtitle{FRE6871 \& FRE7241, Spring 2021}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{\today}



%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Asset Pricing Models}


%%%%%%%%%%%%%%%
\subsection{Linear Regression of Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The returns of \emph{XLP} and \emph{VTI} are highly correlated because they are driven by common market factors of returns.
      \vskip1ex
      The \emph{t}-statistic (\emph{t}-value) is the ratio of the estimated value divided by its standard error.
      \vskip1ex
      The \emph{p}-value is the probability of obtaining values exceeding the \emph{t}-statistic, assuming the \emph{null hypothesis} is true.
      \vskip1ex
      A small \emph{p}-value means that the regression coefficients are very unlikely to be zero (given the data).
      \vspace{-1em}
      <<echo=(-(1:1)),eval=TRUE>>=
library(rutils)
# Specify formula and perform regression
mod_el <- lm(XLP ~ VTI, data=rutils::etf_env$re_turns)
# Get regression coefficients
coef(summary(mod_el))
# Durbin-Watson test of autocorrelation of residuals
lmtest::dwtest(mod_el)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/reg_rets.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot scatterplot of returns with aspect ratio 1
plot(for_mula, data=rutils::etf_env$re_turns,
     xlim=c(-0.1, 0.1), ylim=c(-0.1, 0.1), 
     asp=1, main="Regression XLP ~ VTI")
# Add regression line and perpendicular line
abline(mod_el, lwd=2, col="red")
abline(a=0, b=-1/coef(summary(mod_el))[2, 1], 
       lwd=2, col="blue")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Beta} and \protect\emph{Alpha} of ETF Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.55\textwidth}
      The \emph{beta} $\beta$ values of ETF returns are very statistically significant, but the \emph{alpha} $\alpha$ values are mostly not significant.
      \vskip1ex
      Some of the ETFs with significant \emph{alpha} $\alpha$ values are the bond ETFs \emph{IEF} and \emph{TLT} (which have performed very well), and the natural resource ETFs \emph{USO} and \emph{DBC} (which have performed very poorly).
      <<echo=(-(1:1)),eval=TRUE>>=
library(rutils)  # Load rutils
re_turns <- rutils::etf_env$re_turns
symbol_s <- colnames(re_turns)
symbol_s <- symbol_s[symbol_s != "VTI"]
# Perform regressions and collect statistics
etf_betas <- sapply(symbol_s, function(sym_bol) {
# Specify regression formula
  for_mula <- as.formula(paste(sym_bol, "~ VTI"))
# Perform regression
  mod_el <- lm(for_mula, data=re_turns)
# Get regression summary
  model_sum <- summary(mod_el)
# Collect regression statistics
  with(model_sum, 
    c(beta=coefficients[2, 1], 
      p_beta=coefficients[2, 4],
      alpha=coefficients[1, 1], 
      p_alpha=coefficients[1, 4], 
      p_dw=lmtest::dwtest(mod_el)$p.value))
})  # end sapply
etf_betas <- t(etf_betas)
# Sort by p_alpha
etf_betas <- etf_betas[order(etf_betas[, "p_alpha"]), ]
      @
    \column{0.45\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
etf_betas
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Capital Asset Pricing Model (\protect\emph{CAPM})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Capital Asset Pricing Model} decomposes asset returns into \emph{systematic} returns (proportional to the market returns) and \emph{idiosyncratic} returns (uncorrelated to market returns):
      \begin{displaymath}
        R - R_f = {\alpha} + \beta (R_m - R_f) + {\varepsilon}
      \end{displaymath}
      Where $R_m$ are the market returns, and $R_f$ are the risk-free returns.
      \vskip1ex
      The \emph{systematic} risk and returns are proportional to $\beta$.
      \vskip1ex
      The $\beta$ can be obtained from linear regression, and is proportional to the correlation of returns between the asset and the market:
      \begin{displaymath}
        \beta = \frac{\sum_{i=1}^n (R_i-\bar{R}) (R_{i,m}-\bar{R_m})} {\sum_{i=1}^n (R_{i,m}-\bar{R_m})^2}
      \end{displaymath}
      The \emph{CAPM} model states that if an asset has higher $\beta$ risk, then it should earn higher \emph{systematic} returns.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
library(PerformanceAnalytics)
# Calculate XLP beta
CAPM.beta(Ra=re_turns[, "XLP"], Rb=re_turns[, "VTI"])
# Calculate XLP bull beta
CAPM.beta.bull(Ra=re_turns[, "XLP"], Rb=re_turns[, "VTI"])
# Calculate XLP bear beta
CAPM.beta.bear(Ra=re_turns[, "XLP"], Rb=re_turns[, "VTI"])
# Calculate XLP alpha
CAPM.alpha(Ra=re_turns[, "XLP"], Rb=re_turns[, "VTI"])
      @
      The \emph{idiosyncratic} returns are equal to the sum of $\alpha$ plus $\varepsilon$.
      \vskip1ex
      The \emph{alpha} $\alpha$ are the returns in excess of \emph{systematic} returns, that may be attributed to portfolio selection or active manager performance.
      \vskip1ex
      The \emph{idiosyncratic} risk (equal to $\varepsilon$) is uncorrelated to the \emph{systematic} risk, and can be reduced through portfolio diversification.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Security Market Line for ETFs}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      According to the \emph{CAPM} model, assets should earn a \emph{systematic} return proportional to their \emph{systematic} risk $\beta$.
      \vskip1ex
      The \emph{Security Market Line} (SML) represents the linear relationship between \emph{systematic} risk $\beta$ and return, for different stocks.
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
etf_betas <- sapply(re_turns[, colnames(re_turns)!="VXX"], 
  CAPM.beta, Rb=re_turns[, "VTI"])
etf_annrets <- sapply(re_turns[, colnames(re_turns)!="VXX"], 
  Return.annualized)
# Plot scatterplot
plot(etf_annrets ~ etf_betas, xlab="betas", 
            ylab="ann. rets", xlim=c(-0.25, 1.6))
points(x=1, y=etf_annrets["VTI"], col="red", lwd=3, pch=21)
abline(a=0, b=etf_annrets["VTI"])
label_names <- rownames(etf_betas)[1:13]
# Add labels
text(x=1, y=etf_annrets["VTI"], labels="VTI", pos=2)
text(x=etf_betas[label_names], y=etf_annrets[label_names], 
     labels=label_names, pos=2, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-4em}
      \includegraphics[width=0.5\paperwidth]{figure/capm_scatter-1}\\
    \vspace{-1em}
      A scatterplot of asset returns versus their $\beta$ shows which assets earn a positive $\alpha$, and which don't.
      \vskip1ex
      If an asset lies on the \emph{SML}, then its returns are mostly \emph{systematic}, and its $\alpha$ is equal to zero.
      \vskip1ex
      Assets above the \emph{SML} have a positive $\alpha$, and those below have a negative $\alpha$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: The Security Market Line for Stocks}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      According to the \emph{CAPM} model, assets should earn a \emph{systematic} return proportional to their \emph{systematic} risk $\beta$.
      \vskip1ex
      The \emph{Security Market Line} (SML) represents the linear relationship between \emph{systematic} risk $\beta$ and return, for different stocks.
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
etf_betas <- sapply(
  re_turns[, colnames(re_turns)!="VXX"], 
  CAPM.beta, Rb=re_turns[, "VTI"])
etf_annrets <- sapply(
  re_turns[, colnames(re_turns)!="VXX"], 
  Return.annualized)
# Plot scatterplot
plot(etf_annrets ~ etf_betas, xlab="betas", 
            ylab="ann. rets", xlim=c(-0.25, 1.6))
points(x=1, y=etf_annrets["VTI"], col="red", 
       lwd=3, pch=21)
abline(a=0, b=etf_annrets["VTI"])
label_names <- rownames(etf_betas)[1:13]
# Add labels
text(x=1, y=etf_annrets["VTI"], labels="VTI", 
     pos=2)
text(x=etf_betas[label_names], 
     y=etf_annrets[label_names], 
     labels=label_names, pos=2, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-4em}
      \includegraphics[width=0.5\paperwidth]{figure/capm_scatter-1}\\
    \vspace{-1em}
      A scatterplot of asset returns versus their $\beta$ shows which assets earn a positive $\alpha$, and which don't.
      \vskip1ex
      If an asset lies on the \emph{SML}, then its returns are mostly \emph{systematic}, and its $\alpha$ is equal to zero.
      \vskip1ex
      Assets above the \emph{SML} have a positive $\alpha$, and those below have a negative $\alpha$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Beta-adjusted Performance Measurement}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Treynor} ratio measures the excess returns per unit of the \emph{systematic} risk \emph{beta} $\beta$, and is equal to the excess returns (over a risk-free return) divided by the $\beta$:
      \begin{displaymath}
        T_r=\frac{E[R-R_f]}{\beta}
      \end{displaymath}
      The \emph{Treynor} ratio is similar to the \emph{Sharpe} ratio, with the difference that its denominator represents only \emph{systematic} risk, not total risk.
      \vskip1ex
      The \emph{Information} ratio is equal to the excess returns (over a benchmark) divided by the \emph{tracking error} (standard deviation of excess returns):
      \begin{displaymath}
        I_r = \frac{E[R-R_b]} {\sqrt{\sum_{i=1}^n (R_i-R_{i,b})^2}}
      \end{displaymath}
      The \emph{Information} ratio measures the amount of outperformance versus the benchmark, and the consistency of outperformance.
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
library(PerformanceAnalytics)
# Calculate XLP Treynor ratio
TreynorRatio(Ra=re_turns[, "XLP"], Rb=re_turns[, "VTI"])
# Calculate XLP Information ratio
InformationRatio(Ra=re_turns[, "XLP"], Rb=re_turns[, "VTI"])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CAPM} Summary Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.55\textwidth}
      \texttt{PerformanceAnalytics::table.CAPM()} calculates the \emph{beta} $\beta$ and \emph{alpha} $\alpha$ values, the \emph{Treynor} ratio, and other performance statistics.
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
PerformanceAnalytics::table.CAPM(Ra=re_turns[, c("XLP", "XLF")], 
                                 Rb=re_turns[, "VTI"], scale=252)
      @
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
capm_stats <- table.CAPM(Ra=re_turns[, symbol_s], 
              Rb=re_turns[, "VTI"], scale=252)
col_names <- strsplit(colnames(capm_stats), split=" ")
col_names <- do.call(cbind, col_names)[1, ]
colnames(capm_stats) <- col_names
capm_stats <- t(capm_stats)
capm_stats <- capm_stats[, -1]
col_names <- colnames(capm_stats)
whi_ch <- match(c("Annualized Alpha", "Information Ratio", "Treynor Ratio"), col_names)
col_names[whi_ch] <- c("Alpha", "Information", "Treynor")
colnames(capm_stats) <- col_names
capm_stats <- capm_stats[order(capm_stats[, "Alpha"], decreasing=TRUE), ]
# Copy capm_stats into etf_env and save to .RData file
etf_env <- rutils::etf_env
etf_env$capm_stats <- capm_stats
save(etf_env, file="C:/Develop/lecture_slides/data/etf_data.RData")
      @
    \column{0.45\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
rutils::etf_env$capm_stats[, c("Beta", "Alpha", "Information", "Treynor")]
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Factor Analysis}


%%%%%%%%%%%%%%%
\subsection{Rolling Beta Regressions Over Time}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The rolling beta of \emph{XLP} versus \emph{VTI} changes over time, with lower beta in periods of \emph{VTI} selloffs.
      \vskip1ex
      The function \texttt{roll\_reg()} from package \emph{HighFreq} performs rolling regressions in \texttt{C++} (\emph{RcppArmadillo}), so it's therefore much faster than equivalent \texttt{R} code.
      <<echo=TRUE,eval=FALSE>>=
# Calculate XLP and VTI returns
re_turns <- na.omit(rutils::etf_env$re_turns[, c("XLP", "VTI")])
# Calculate monthly end points
end_p <- xts::endpoints(re_turns, on="months")[-1]
# Calculate start points from look-back interval
look_back <- 12  # Look back 12 months
start_p <- c(rep(1, look_back), end_p[1:(NROW(end_p)-look_back)])
head(cbind(end_p, start_p), look_back+2)
# Calculate rolling beta regressions every month in R
for_mula <- XLP ~ VTI  # Specify regression formula
betas_r <- sapply(1:NROW(end_p), FUN=function(ep) {
    da_ta <- re_turns[start_p[ep]:end_p[ep], ]
    # coef(lm(for_mula, data=da_ta))[2]
    drop(cov(da_ta[, 1], da_ta[, 2])/var(da_ta[, 2]))
  })  # end sapply
# Calculate rolling betas using RcppArmadillo
reg_stats <- HighFreq::roll_reg(response=re_turns[, 1], design=re_turns[, 2], endp=(end_p-1), startp=(start_p-1))
beta_s <- reg_stats[, 2]
all.equal(beta_s, betas_r)
# Compare the speed of RcppArmadillo with R code
library(microbenchmark)
summary(microbenchmark(
  Rcpp=HighFreq::roll_reg(response=re_turns[, 1], design=re_turns[, 2], endp=(end_p-1), startp=(start_p-1)),
  Rcode=sapply(1:NROW(end_p), FUN=function(ep) {
    da_ta <- re_turns[start_p[ep]:end_p[ep], ]
    drop(cov(da_ta[, 1], da_ta[, 2])/var(da_ta[, 2]))
  }),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/rolling_betas.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of rolling XLP beta and VTI prices
date_s <- zoo::index(re_turns[end_p, ])
price_s <- rutils::etf_env$price_s$VTI[date_s]
da_ta <- cbind(price_s, beta_s)
col_names <- colnames(da_ta)
dygraphs::dygraph(da_ta, main="XLP Rolling 12-month Beta and VTI Prices") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="blue") %>%
  dySeries(name=col_names[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Engle-Granger Two-step Procedure for Cointegration}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{ADF} test can be applied to test for the cointegration of time series of prices.
      \vskip1ex
      The Engle-Granger two-step procedure for two time series consists of:
      \begin{itemize}
        \item Performing a regression to calculate the cointegrating factor $\beta$,
        \item Applying the \emph{ADF} test to the residuals of the regression to determine that they don't have a unit root (they are mean-reverting).
      \end{itemize}
      The regression of prices is not statistically valid because they are not normally distributed.
      <<echo=TRUE,eval=FALSE>>=
# Calculate XLB and XLE prices
price_s <- na.omit(rutils::etf_env$price_s[, c("XLB", "XLE")])
cor(rutils::diff_it(log(price_s)))
xl_b <- drop(zoo::coredata(price_s$XLB))
xl_e <- drop(zoo::coredata(price_s$XLE))
# Calculate regression coefficients of XLB ~ XLE
be_ta <- cov(xl_b, xl_e)/var(xl_e)
al_pha <- (mean(xl_b) - be_ta*mean(xl_e))
# Calculate regression residuals
fit_ted <- (al_pha + be_ta*xl_e)
residual_s <- (xl_b - fit_ted)
# Perform ADF test on residuals
tseries::adf.test(residual_s, k=1)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/coint_prices.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot prices
dygraphs::dygraph(price_s, main="XLB and XLE Prices") %>%
  dyOptions(colors=c("blue", "red"))
# Plot cointegration residuals
residual_s <- xts::xts(residual_s, index(price_s))
dygraphs::dygraph(residual_s, main="XLB and XLE Cointegration Residuals")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Principal Components} of \protect\emph{S\&P500} Stock Constituents}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{PCA} standard deviations are the volatilities of the \emph{principal component} time series.
      \vskip1ex
      The original time series of returns can be calculated approximately from the first few \emph{principal components} with the largest standard deviations.
      \vskip1ex
      The \emph{Kaiser-Guttman} rule uses only \emph{principal components} with \emph{variance} greater than $1$.
      \vskip1ex
      Another rule of thumb is to use the \emph{principal components} with the largest standard deviations which sum up to \texttt{80\%} of the total variance of returns.
      <<echo=TRUE,eval=FALSE>>=
# Load S&P500 constituent stock prices
load("C:/Develop/lecture_slides/data/sp500_prices.RData")
# Calculate stock prices and percentage returns
price_s <- zoo::na.locf(price_s, na.rm=FALSE)
price_s <- zoo::na.locf(price_s, fromLast=TRUE)
re_turns <- rutils::diff_it(log(price_s))
# Standardize (de-mean and scale) the returns
re_turns <- lapply(re_turns, function(x) {(x - mean(x))/sd(x)})
re_turns <- rutils::do_call(cbind, re_turns)
# Perform principal component analysis PCA
pc_a <- prcomp(re_turns, scale=TRUE)
# Find number of components with variance greater than 2
n_comp <- which(pc_a$sdev^2 < 2)[1]
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_scree.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot standard deviations of principal components
barplot(pc_a$sdev[1:n_comp], 
        names.arg=colnames(pc_a$rotation[, 1:n_comp]), 
        las=3, xlab="", ylab="", 
        main="Volatilities of S&P500 Principal Components")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Principal Component} Loadings (Weights)}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Principal component} loadings are the weights of \emph{principal component} portfolios.
      \vskip1ex
      The \emph{principal component} portfolios have mutually orthogonal returns
      represent the different orthogonal modes of the return variance.
      <<echo=TRUE,eval=FALSE>>=
# Calculate principal component loadings (weights)
# Plot barplots with PCA weights in multiple panels
n_comps <- 6
par(mfrow=c(n_comps/2, 2))
par(mar=c(4, 2, 2, 1), oma=c(0, 0, 0, 0))
# First principal component weights
weight_s <- sort(pc_a$rotation[, 1], decreasing=TRUE)
barplot(weight_s[1:6], las=3, xlab="", ylab="", main="")
title(paste0("PC", 1), line=-2.0, col.main="red")
for (or_der in 2:n_comps) {
  weight_s <- sort(pc_a$rotation[, or_der], decreasing=TRUE)
  barplot(weight_s[c(1:3, 498:500)], las=3, xlab="", ylab="", main="")
  title(paste0("PC", or_der), line=-2.0, col.main="red")
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_loadings.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Principal Component} Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The time series of the \emph{principal components} can be calculated by multiplying the loadings (weights) times the original data.
      \vskip1ex
      Higher order \emph{principal components} are gradually less volatile.
      <<echo=TRUE,eval=FALSE>>=
# Calculate principal component time series
pca_rets <- xts(re_turns %*% pc_a$rotation[, 1:n_comps], 
                order.by=date_s)
round(cov(pca_rets), 3)
pca_ts <- cumsum(pca_rets)
# Plot principal component time series in multiple panels
par(mfrow=c(n_comps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
rang_e <- range(pca_ts)
for (or_der in 1:n_comps) {
  plot.zoo(pca_ts[, or_der], ylim=rang_e, xlab="", ylab="")
  title(paste0("PC", or_der), line=-2.0)
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_series.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} Factor Model From \protect\emph{Principal Components}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      By inverting the \emph{PCA} analysis, the \emph{S\&P500} constituent returns can be calculated from the first \texttt{k} \emph{principal components} under a \emph{factor model}: 
      \begin{displaymath}
        \mathbf{r}_i = \alpha_i + \sum_{j=1}^k {\beta_{ji} \, \mathbf{F}_j} + \varepsilon_i
      \end{displaymath}
      The \emph{principal components} are interpreted as \emph{market factors}: $\mathbf{F}_j = \mathbf{pc}_j$.
      \vskip1ex
      The \emph{market betas} are the inverse of the \emph{principal component loadings}: $\beta_{ji} = w_{ij}$.
      \vskip1ex
      The $\varepsilon_i$ are the \emph{idiosyncratic} returns, which should be mutually independent and uncorrelated to the \emph{market factor} returns.
      <<echo=(-(1:2)),eval=FALSE>>=
par(mfrow=c(n_comps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
# Invert principal component time series
inv_rotation <- solve(pc_a$rotation)
all.equal(inv_rotation, t(pc_a$rotation))
sol_ved <- pca_rets %*% inv_rotation[1:n_comps, ]
sol_ved <- xts::xts(sol_ved, date_s)
sol_ved <- cumsum(sol_ved)
cum_returns <- cumsum(re_turns)
# Plot the solved returns
sym_bols <- c("MSFT", "XOM", "JPM", "AAPL", "BRK_B", "JNJ")
for (sym_bol in sym_bols) {
  plot.zoo(cbind(cum_returns[, sym_bol], sol_ved[, sym_bol]), 
    plot.type="single", col=c("black", "blue"), xlab="", ylab="")
  legend(x="topleft", bty="n",
         legend=paste0(sym_bol, c("", " solved")),
         title=NULL, inset=0.05, cex=1.0, lwd=6,
         lty=1, col=c("black", "blue"))
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_series_solved.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Factor Model} Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The original time series of returns can be calculated exactly from the time series of all the \emph{principal components}, by inverting the loadings matrix.
      \vskip1ex
      The original time series of returns can be calculated approximately from just the first few \emph{principal components}, which demonstrates that \emph{PCA} is a form of \emph{dimension reduction}.
      \vskip1ex
      The function \texttt{solve()} solves systems of linear equations, and also inverts square matrices.
      <<echo=(-(1:2)),eval=FALSE>>=
par(mfrow=c(n_comps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
# Perform ADF unit-root tests on original series and residuals
sapply(sym_bols, function(sym_bol) {
  c(series=tseries::adf.test(cum_returns[, sym_bol])$p.value,
    resid=tseries::adf.test(cum_returns[, sym_bol] - sol_ved[, sym_bol])$p.value)
})  # end sapply
# Plot the residuals
for (sym_bol in sym_bols) {
  plot.zoo(cum_returns[, sym_bol] - sol_ved[, sym_bol], 
    plot.type="single", col="blue", xlab="", ylab="")
  legend(x="topleft", bty="n", legend=paste(sym_bol, "residuals"),
         title=NULL, inset=0.05, cex=1.0, lwd=6, lty=1, col="blue")
}  # end for
# Perform ADF unit-root test on principal component time series
pca_rets <- xts(re_turns %*% pc_a$rotation, order.by=date_s)
pca_ts <- cumsum(pca_rets)
adf_pvalues <- sapply(1:NCOL(pca_ts), function(or_der)
  tseries::adf.test(pca_ts[, or_der])$p.value)
# AdF unit-root test on stationary time series
tseries::adf.test(rnorm(1e5))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/pca_sp500_residuals.png}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\subsection{Correlation and Factor Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<corr_plot,echo=(-(1:1)),eval=FALSE,fig.show='hide'>>=
library(quantmod)
### Perform pair-wise correlation analysis
# Calculate correlation matrix
cor_mat <- cor(re_turns)
colnames(cor_mat) <- colnames(re_turns)
rownames(cor_mat) <- colnames(re_turns)
# Reorder correlation matrix based on clusters
# Calculate permutation vector
library(corrplot)
or_der <- corrMatOrder(cor_mat, order="hclust", 
              hclust.method="complete")
# Apply permutation vector
cor_mat <- cor_mat[or_der, or_der]
# Plot the correlation matrix
col_ors <- colorRampPalette(c("red", "white", "blue"))
corrplot(cor_mat, tl.col="black", tl.cex=0.8, 
    method="square", col=col_ors(8), 
    cl.offset=0.75, cl.cex=0.7, 
    cl.align.text="l", cl.ratio=0.25)
# draw rectangles on the correlation matrix plot
corrRect.hclust(cor_mat, k=NROW(cor_mat) %/% 2, 
                method="complete", col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Hierarchical Clustering Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{as.dist()} converts a matrix representing the \emph{distance} (dissimilarity) between elements, into a list of class \texttt{"dist"}.
      \vskip1ex
      For example, \texttt{as.dist()} converts \texttt{(1-correlation)} to distance.
      \vskip1ex
      The function \texttt{hclust()} recursively combines elements into clusters based on their mutual \emph{distance}.
      \vskip1ex
      First \texttt{hclust()} combines individual elements that are closest to each other.
      \vskip1ex
      Then it combines elements to the closest clusters, then clusters with other clusters, until all elements are combined into one cluster.
      \vskip1ex
      This process of recursive clustering can be represented as a \emph{dendrogram} (tree diagram).
      \vskip1ex
      Branches of a \emph{dendrogram} represent clusters.
      \vskip1ex
      Neighboring branches contain elements that are close to each other (have small distance).
      \vskip1ex
      Neighboring branches combine into larger branches, that then combine with their closest branches, etc.
    \column{0.5\textwidth}
      \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/cluster_plot-1}
      \vspace{-4em}
      <<cluster_plot,echo=TRUE,eval=FALSE,fig.width=6,fig.height=6,fig.show='hide'>>=
# Convert correlation matrix into distance object
dis_tance <- as.dist(1-cor_mat)
# Perform hierarchical clustering analysis
clus_ter <- hclust(dis_tance)
plot(clus_ter, ann=FALSE, xlab="", ylab="")
title("Dendrogram representing hierarchical clustering
      \nwith dissimilarity = 1-correlation", line=-0.5)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: \protect\emph{Principal Component} Returns Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
\vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PerformanceAnalytics)  # Load package "PerformanceAnalytics"
# PC returns from rotation and scaled re_turns
re_turns_scaled <- apply(re_turns, 2, scale)
pca_rets <- re_turns_scaled %*% pc_a$rotation
# "x" matrix contains time series of PC returns
dim(pc_a$x)
class(pc_a$x)
head(pc_a$x[, 1:3], 3)
# Convert PC matrix to xts and rescale to decimals
pca_rets <- xts(pc_a$x/100, 
    order.by=index(re_turns))
      @
\vspace{-1em}
      <<pca_cum_returns,echo=(-1),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)  # Load package "PerformanceAnalytics"
chart.CumReturns(
  pca_rets[, 1:3], lwd=2, ylab="", 
  legend.loc="topright", main="")
# Add title
title(main="ETF cumulative returns", line=-1)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/pca_cum_returns-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: \protect\emph{Principal Component} Returns Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
# Calculate PC correlation matrix
cor_mat <- cor(pca_rets)
colnames(cor_mat) <- colnames(pca_rets)
rownames(cor_mat) <- colnames(pca_rets)
cor_mat[1:3, 1:3]
table.CAPM(Ra=pca_rets[, 1:3], 
    Rb=re_turns[, "VTI"], scale=252)
      @
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Principal Component Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_plot,echo=(-(1:2)),fig.height=5,fig.show='hide',eval=FALSE>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # Set plot panels
### Perform principal component analysis PCA
re_turns <- na.omit(rutils::etf_env$re_turns)
pc_a <- prcomp(re_turns, center=TRUE, scale=TRUE)
barplot(pc_a$sdev[1:10], 
        names.arg=colnames(pc_a$rotation)[1:10], 
        las=3, ylab="STDEV", xlab="PCVec", 
        main="PCA Explain VAR")
# Show first three principal component loadings
head(pc_a$rotation[,1:3], 3)
# Permute second principal component loadings by size
pca_vec2 <- as.matrix(
  pc_a$rotation[order(pc_a$rotation[, 2], 
  decreasing=TRUE), 2])
colnames(pca_vec2) <- "pca2"
head(pca_vec2, 3)
# The option las=3 rotates the names.arg labels
barplot(as.vector(pca_vec2), 
        names.arg=rownames(pca_vec2), 
        las=3, ylab="Loadings", 
        xlab="Symbol", main="Loadings pca2")
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/pca_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Principal Component Vectors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_vec,echo=(-(1:2)),eval=FALSE,fig.height=5,fig.show='hide'>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(3,1))  # Set plot panels
# Get list of principal component vectors
pca_vecs <- lapply(1:3, function(or_der) {
  pca_vec <- as.matrix(
    pc_a$rotation[
    order(pc_a$rotation[, or_der], 
    decreasing=TRUE), or_der])
  colnames(pca_vec) <- paste0("pca", or_der)
  pca_vec
})  # end lapply
names(pca_vecs) <- c("pca1", "pca2", "pca3")
# The option las=3 rotates the names.arg labels
for (or_der in 1:3) {
  barplot(as.vector(pca_vecs[[or_der]]), 
        names.arg=rownames(pca_vecs[[or_der]]), 
        las=3, xlab="", ylab="", 
        main=paste("Loadings", 
          colnames(pca_vecs[[or_der]])))
}  # end for
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/pca_vec-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Package \protect\emph{factorAnalytics}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The package \emph{factorAnalytics} performs estimation and risk analysis of linear factor models for portfolio asset returns.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(factorAnalytics)  # Load package "factorAnalytics"
# Get documentation for package "factorAnalytics"
packageDescription("factorAnalytics")  # Get short description
help(package="factorAnalytics")  # Load help page
      @
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE,tidy=TRUE>>=
options(width=50)
library(factorAnalytics)  # Load package "factorAnalytics"
# List all objects in "factorAnalytics"
ls("package:factorAnalytics")

# List all datasets in "factorAnalytics"
# data(package="factorAnalytics")

# Remove factorAnalytics from search path
detach("package:factorAnalytics")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Fitting Factor Models Using PCA}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(factorAnalytics)
# Fit a three-factor model using PCA
factor_pca <- fitSfm(rutils::etf_env$re_turns, k=3)
head(factor_pca$loadings, 3)  # Factor loadings
# Factor realizations (time series)
head(factor_pca$factors)
# Residuals from regression
factor_pca$residuals[1:3, 1:3]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(factorAnalytics)
factor_pca$alpha  # Estimated alphas
factor_pca$r2  # R-squared regression
# Covariance matrix estimated by factor model
factor_pca$Omega[1:3, 4:6]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Factor Loadings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      <<fact_load,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=10,fig.show='hide'>>=
library(factorAnalytics)
# load(file="C:/Develop/lecture_slides/data/portf_optim.RData")
plot(factor_pca, which.plot.group=3, 
     n.max=30, loop=FALSE)
# ?plot.sfm
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_load-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Time Series of Factors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_tsplot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot factor cumulative returns
chart.CumReturns(factor_pca$factors, 
    lwd=2, ylab="", legend.loc="topleft", 
    main="")

# Plot time series of factor returns
# Plot(factor_pca, which.plot.group=2, 
#   loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_tsplot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Asset Correlations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_corr_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=7,fig.show='hide'>>=
# Asset correlations "hclust" hierarchical clustering order
plot(factor_pca, which.plot.group=7, 
     loop=FALSE, order="hclust", 
     method="ellipse")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Time Series of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot residual cumulative returns
chart.CumReturns(
  factor_pca$residuals[, c("IEF", 
                  "DBC", "XLF")], 
  lwd=2, ylab="", legend.loc="topleft", 
  main="")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Residual Returns Histogram}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_hist,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot residual histogram with normal curve
plot(factor_pca, asset.name="VTI", 
     which.plot.single=8, 
     plot.single=TRUE, loop=FALSE, 
     xlim=c(-0.007, 0.007))
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_hist-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Residual Returns and the Q-Q Plot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_qq,eval=FALSE,echo=(-1),fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Residual Q-Q plot
plot(factor_pca, asset.name="VTI", 
     which.plot.single=9, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_qq-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Autocorrelation of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_autocorr,eval=FALSE,echo=TRUE,fig.width=7,fig.height=9,fig.show='hide'>>=
# SACF and PACF of residuals
plot(factor_pca, asset.name="VTI", 
     which.plot.single=5, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/fact_resid_autocorr-1}
  \end{columns}
\end{block}

\end{frame}



\end{document}
