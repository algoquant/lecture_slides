% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size="tiny", fig.width=4, fig.height=4)
options(digits=3)
options(width=80, dev="pdf")
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[9pt]{beamer}
\DeclareMathSizes{8pt}{6pt}{6pt}{5pt}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
% \usepackage{mathtools}
\usepackage[latin1]{inputenc}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
% \addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}



% Title page setup
\title[Time Series Multivariate]{Time Series Multivariate}
\subtitle{FRE6871 \& FRE7241, Spring 2025}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color.png}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{\today}



%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Asset Pricing Models}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Alpha} and \protect\emph{Beta} of Stock Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The daily stock returns $r_i - r_f$ in excess of the risk-free rate $r_f$, can be decomposed into \emph{systematic} returns $\beta (r_m - r_f)$ (where $r_m - r_f$ are the excess market returns) plus \emph{idiosyncratic} returns $\alpha + \varepsilon_i$ (which are uncorrelated to the market returns):
      \begin{displaymath}
        r_i - r_f = \alpha + \beta (r_m - r_f) + \varepsilon_i
      \end{displaymath}
      The \emph{alpha} $\alpha$ are the abnormal returns in excess of the risk premium, and $\varepsilon_i$ are the regression residuals with zero mean.
      \vskip1ex
      The \emph{idiosyncratic} risk (equal to $\varepsilon_i$) is uncorrelated to the \emph{systematic} risk, and can be reduced through portfolio diversification.
      <<echo=TRUE,eval=TRUE>>=
# Perform regression using formula
retp <- na.omit(rutils::etfenv$returns[, c("XLP", "VTI")])
raterf <- 0.03/252
retp <- (retp - raterf)
regmod <- lm(XLP ~ VTI, data=retp)
regsum <- summary(regmod)
# Get regression coefficients
coef(regsum)
# Get alpha and beta
coef(regsum)[, 1]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.4\paperwidth]{figure/reg_rets.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot scatterplot of returns with aspect ratio 1
plot(XLP ~ VTI, data=rutils::etfenv$returns, main="Regression XLP ~ VTI",
     xlim=c(-0.1, 0.1), ylim=c(-0.1, 0.1), pch=1, col="blue", asp=1)
# Add regression line and perpendicular line
abline(regmod, lwd=2, col="red")
abline(a=0, b=-1/coef(regsum)[2, 1], lwd=2, col="blue")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Statistical Significance of \protect\emph{Alpha} and \protect\emph{Beta}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The stock $\beta$ is independent of the risk-free rate $r_f$:
      \begin{displaymath}
        \beta = \frac{\mathrm{Cov}(r_i, r_m)}{\mathrm{Var}(r_m)}
      \end{displaymath}
      The \emph{t}-statistic (\emph{t}-value) is the ratio of the estimated value divided by its standard error.
      \vskip1ex
      The \emph{p}-value is the probability of obtaining values exceeding the \emph{t}-statistic, assuming the \emph{null hypothesis} is true.
      \vskip1ex
      A small \emph{p}-value means that the regression coefficients are very unlikely to be zero (given the data).
      \vskip1ex
      The \emph{beta} $\beta$ values of stock returns are very statistically significant, but the \emph{alpha} $\alpha$ values are mostly not significant.
      \vskip1ex
      The \emph{p}-value of the \emph{Durbin-Watson} test is large, which indicates that the regression residuals are not autocorrelated.
      \vskip1ex
      In practice, the $\alpha$, $\beta$, and the risk-free rate $r_f$, depend on the time interval of the data, so they're time dependent.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
# Get regression coefficients
coef(regsum)
# Calculate regression coefficients from scratch
betac <- drop(cov(retp$XLP, retp$VTI)/var(retp$VTI))
alphac <- drop(mean(retp$XLP) - betac*mean(retp$VTI))
c(alphac, betac)
# Calculate the residuals
residuals <- (retp$XLP - (alphac + betac*retp$VTI))
# Calculate the standard deviation of residuals
nrows <- NROW(residuals)
residsd <- sqrt(sum(residuals^2)/(nrows - 2))
# Calculate the standard errors of beta and alpha
sum2 <- sum((retp$VTI - mean(retp$VTI))^2)
betasd <- residsd/sqrt(sum2)
alphasd <- residsd*sqrt(1/nrows + mean(retp$VTI)^2/sum2)
c(alphasd, betasd)
# Perform the Durbin-Watson test of autocorrelation of residuals
lmtest::dwtest(regmod)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Alpha} and \protect\emph{Beta} of ETF Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{beta} $\beta$ values of ETF returns are very statistically significant, but the \emph{alpha} $\alpha$ values are mostly not significant.
      \vskip1ex
      Some of the ETFs with significant \emph{alpha} $\alpha$ values are the bond ETFs \emph{IEF} and \emph{TLT} (which have performed very well), and the natural resource ETFs \emph{USO} and \emph{DBC} (which have performed very poorly).
      <<echo=TRUE,eval=TRUE>>=
retp <- rutils::etfenv$returns
symbolv <- colnames(retp)
symbolv <- symbolv[symbolv != "VTI"]
# Perform regressions and collect statistics
betam <- sapply(symbolv, function(symbol) {
# Specify regression formula
  formulav <- as.formula(paste(symbol, "~ VTI"))
# Perform regression
  regmod <- lm(formulav, data=retp)
# Get regression summary
  regsum <- summary(regmod)
# Collect regression statistics
  with(regsum, 
    c(beta=coefficients[2, 1], 
      pbeta=coefficients[2, 4],
      alpha=coefficients[1, 1], 
      palpha=coefficients[1, 4], 
      pdw=lmtest::dwtest(regmod)$p.value))
})  # end sapply
betam <- t(betam)
# Sort by palpha
betam <- betam[order(betam[, "palpha"]), ]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
betam
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Capital Asset Pricing Model (\protect\emph{CAPM})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{CAPM} model states that the expected return for stock $n$: $\mathbbm{E}[R_n]$ is proportional to its beta $\beta_n$ times the expected excess return of the market $\mathbbm{E}[R_m] - r_f$:
      \begin{displaymath}
        \mathbbm{E}[R_n] = r_f + \beta_n (\mathbbm{E}[R_m] - r_f)
      \end{displaymath}
      The \emph{CAPM} model states that if a stock has a higher beta then it's also expected to earn higher returns.
      \vskip1ex
      According to the \emph{CAPM} model, assets are on average expected to earn only a \emph{systematic} return proportional to their \emph{systematic} risk.
      \vskip1ex
      The \emph{CAPM} model is not a regression model.
      \vskip1ex
      The \emph{CAPM} model depends on the choice of the risk-free rate $r_f$.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
library(PerformanceAnalytics)
# Calculate XLP beta
PerformanceAnalytics::CAPM.beta(Ra=retp$XLP, Rb=retp$VTI)
# Or
retxlp <- na.omit(retp[, c("XLP", "VTI")])
betac <- drop(cov(retxlp$XLP, retxlp$VTI)/var(retxlp$VTI))
betac
# Calculate XLP alpha
PerformanceAnalytics::CAPM.alpha(Ra=retp$XLP, Rb=retp$VTI)
# Or
mean(retp$XLP - betac*retp$VTI)
# Calculate XLP bull beta
PerformanceAnalytics::CAPM.beta.bull(Ra=retp$XLP, Rb=retp$VTI)
# Calculate XLP bear beta
PerformanceAnalytics::CAPM.beta.bear(Ra=retp$XLP, Rb=retp$VTI)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Security Market Line for ETFs}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Security Market Line} (SML) represents the linear relationship between expected stock returns and their \emph{systematic} risk $\beta$.
      \vskip1ex
      The \emph{SML} depends on the choice of the risk-free rate $r_f$, with a steeper \emph{SML} line for lower risk-free rates $r_f$.
      \vskip1ex
      All the different \emph{SML} lines pass through the point $(\beta=1, r=R_m)$ corresponding to the market, and they intersect the y-axis at the risk-free point $(\beta=0, r=r_f)$. 
      \vskip1ex
      A scatterplot of asset returns versus their $\beta$ shows which assets earn a positive $\alpha$, and which don't.
      \vskip1ex
      If an asset lies on the \emph{SML}, then its returns are mostly \emph{systematic}, and its $\alpha$ is equal to zero.
      \vskip1ex
      Assets above the \emph{SML} have a positive $\alpha$, and those below have a negative $\alpha$.
      <<echo=TRUE,eval=FALSE>>=
symbolv <- rownames(betam)
betac <- betam[-match(c("VXX", "SVXY", "MTUM", "USMV", "QUAL"), symbolv), 1]
betac <- c(1, betac)
names(betac)[1] <- "VTI"
retsann <- sapply(retp[, names(betac)], PerformanceAnalytics::Return.annualized)
# Plot scatterplot of returns vs betas
minrets <- min(retsann)
plot(retsann ~ betac, xlab="betas", ylab="returns", 
     ylim=c(minrets, -minrets), main="Security Market Line for ETFs")
retvti <- retsann["VTI"]
points(x=1, y=retvti, col="red", lwd=3, pch=21)
# Plot Security Market Line
raterf <- 0.01
abline(a=raterf, b=(retvti-raterf), col="green", lwd=2)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/capm_sml_etf.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Add labels
text(x=betac, y=retsann, labels=names(betac), pos=2, cex=0.8)
# Find optimal risk-free rate by minimizing residuals
rss <- function(raterf) {
  sum((retsann - raterf - betac*(retvti-raterf))^2)
}  # end rss
optimrss <- optimize(rss, c(-1, 1))
raterf <- optimrss$minimum
# Or simply
retsadj <- (retsann - retvti*betac)
betadj <- (1-betac)
raterf <- sum(retsadj*betadj)/sum(betadj^2)
abline(a=raterf, b=(retvti-raterf), col="blue", lwd=2)
legend(x="topleft", bty="n", title="Security Market Line",
       legend=c("optimal fit", "raterf=0.01"),
       y.intersp=0.5, cex=1.0, lwd=6, lty=1, col=c("blue", "green"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Security Market Line for Stocks}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The best fitting \emph{Security Market Line} (SML) for stocks is almost flat, which shows that stocks with higher $\beta$ don't earn higher returns.
      \vskip1ex
      This is called the \emph{low beta anomaly}.
      <<echo=TRUE,eval=FALSE>>=
# Load S&P500 constituent stock returns
load("/Users/jerzy/Develop/lecture_slides/data/sp500_returns.RData")
retvti <- na.omit(rutils::etfenv$returns$VTI)
retp <- retstock[index(retvti), ]
nrows <- NROW(retp)
# Calculate stock betas
betac <- sapply(retp, function(x) {
  retp <- na.omit(cbind(x, retvti))
  drop(cov(retp[, 1], retp[, 2])/var(retp[, 2]))
})  # end sapply
mean(betac)
# Calculate annual stock returns
retsann <- retp
retsann[1, ] <- 0
retsann <- zoo::na.locf(retsann, na.rm=FALSE)
retsann <- 252*sapply(retsann, sum)/nrows
# Remove stocks with zero returns
sum(retsann == 0)
betac <- betac[retsann > 0]
retsann <- retsann[retsann > 0]
retvti <- 252*mean(retvti)
# Plot scatterplot of returns vs betas
plot(retsann ~ betac, xlab="betas", ylab="returns", 
     main="Security Market Line for Stocks")
points(x=1, y=retvti, col="red", lwd=3, pch=21)
# Plot Security Market Line
raterf <- 0.01
abline(a=raterf, b=(retvti-raterf), col="green", lwd=2)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/capm_sml_stocks.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Find optimal risk-free rate by minimizing residuals
retsadj <- (retsann - retvti*betac)
betadj <- (1-betac)
raterf <- sum(retsadj*betadj)/sum(betadj^2)
abline(a=raterf, b=(retvti-raterf), col="blue", lwd=2)
legend(x="topleft", bty="n", title="Security Market Line",
       legend=c("optimal fit", "raterf=0.01"),
       y.intersp=0.5, cex=1.0, lwd=6, lty=1, col=c("blue", "green"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Beta-adjusted Performance Measurement}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Treynor} ratio measures the excess returns per unit of the \emph{systematic} risk \emph{beta} $\beta$, and is equal to the excess returns (over a risk-free rate) divided by the $\beta$:
      \begin{displaymath}
        T_r=\frac{E[R-r_f]}{\beta}
      \end{displaymath}
      The \emph{Treynor} ratio is similar to the \emph{Sharpe} ratio, with the difference that its denominator represents only \emph{systematic} risk, not total risk.
      \vskip1ex
      The \emph{Information} ratio is equal to the excess returns (over a benchmark) divided by the \emph{tracking error} (standard deviation of excess returns):
      \begin{displaymath}
        I_r = \frac{E[R-R_b]} {\sqrt{\sum_{i=1}^n (R_i-R_{i,b})^2}}
      \end{displaymath}
      The \emph{Information} ratio measures the amount of outperformance versus the benchmark, and the consistency of outperformance.
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
library(PerformanceAnalytics)
# Calculate XLP Treynor ratio
TreynorRatio(Ra=retp$XLP, Rb=retp$VTI)
# Calculate XLP Information ratio
InformationRatio(Ra=retp$XLP, Rb=retp$VTI)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CAPM} Summary Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.55\textwidth}
      \texttt{PerformanceAnalytics::table.CAPM()} calculates the \emph{beta} $\beta$ and \emph{alpha} $\alpha$ values, the \emph{Treynor} ratio, and other performance statistics.
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
PerformanceAnalytics::table.CAPM(Ra=retp[, c("XLP", "XLF")], 
                                 Rb=retp$VTI, scale=252)
      @
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
capmstats <- table.CAPM(Ra=retp[, symbolv], 
              Rb=retp$VTI, scale=252)
colv <- strsplit(colnames(capmstats), split=" ")
colv <- do.call(cbind, colv)[1, ]
colnames(capmstats) <- colv
capmstats <- t(capmstats)
capmstats <- capmstats[, -1]
colv <- colnames(capmstats)
whichv <- match(c("Annualized Alpha", "Information Ratio", "Treynor Ratio"), colv)
colv[whichv] <- c("Alpha", "Information", "Treynor")
colnames(capmstats) <- colv
capmstats <- capmstats[order(capmstats[, "Alpha"], decreasing=TRUE), ]
# Copy capmstats into etfenv and save to .RData file
etfenv <- rutils::etfenv
etfenv$capmstats <- capmstats
save(etfenv, file="/Users/jerzy/Develop/lecture_slides/data/etf_data.RData")
      @
    \column{0.45\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
rutils::etfenv$capmstats[, c("Beta", "Alpha", "Information", "Treynor")]
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Factor Analysis}


%%%%%%%%%%%%%%%
\subsection{Trailing Stock Beta Over Time}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The trailing beta of \emph{XLP} versus \emph{VTI} changes over time, with lower beta in periods of stock selloffs.
      \vskip1ex
      The function \texttt{roll\_reg()} from package \emph{HighFreq} performs trailing regressions in \texttt{C++} (\emph{RcppArmadillo}), so it's therefore much faster than equivalent \texttt{R} code.
      <<echo=TRUE,eval=FALSE>>=
# Calculate XLP and VTI returns
retp <- na.omit(rutils::etfenv$returns[, c("XLP", "VTI")])
# Calculate monthly end points
endd <- xts::endpoints(retp, on="months")[-1]
# Calculate start points from look-back interval
lookb <- 12  # Look back 12 months
startp <- c(rep(1, lookb), endd[1:(NROW(endd)-lookb)])
head(cbind(endd, startp), lookb+2)
# Calculate trailing beta regressions every month in R
formulav <- XLP ~ VTI  # Specify regression formula
betar <- sapply(1:NROW(endd), FUN=function(tday) {
    datav <- retp[startp[tday]:endd[tday], ]
    # coef(lm(formulav, data=datav))[2]
    drop(cov(datav$XLP, datav$VTI)/var(datav$VTI))
  })  # end sapply
# Calculate trailing betas using RcppArmadillo
controll <- HighFreq::param_reg()
reg_stats <- HighFreq::roll_reg(respv=retp$XLP, predm=retp$VTI, 
  startp=(startp-1), endp=(endd-1), controll=controll)
betac <- reg_stats[, 2]
all.equal(betac, betar)
# Compare the speed of RcppArmadillo with R code
library(microbenchmark)
summary(microbenchmark(
  Rcpp=HighFreq::roll_reg(respv=retp$XLP, predm=retp$VTI, startp=(startp-1), endp=(endd-1), controll=controll),
  Rcode=sapply(1:NROW(endd), FUN=function(tday) {
    datav <- retp[startp[tday]:endd[tday], ]
    drop(cov(datav$XLP, datav$VTI)/var(datav$VTI))
  }),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/trailing_betas.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of trailing XLP beta and VTI prices
datev <- zoo::index(retp[endd, ])
pricev <- rutils::etfenv$prices$VTI[datev]
datav <- cbind(pricev, betac)
colnames(datav)[2] <- "beta"
colv <- colnames(datav)
dygraphs::dygraph(datav, main="XLP Trailing 12-month Beta and VTI Prices") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue") %>%
  dySeries(name=colv[2], axis="y2", col="red", strokeWidth=2) %>%
  dyLegend(show="always", width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Trailing Stock Beta Over Time}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The trailing beta of \emph{XLP} versus \emph{VTI} changes over time, with lower beta in periods of stock selloffs.
      \vskip1ex
      The function \texttt{roll\_reg()} from package \emph{HighFreq} performs trailing regressions in \texttt{C++} (\emph{RcppArmadillo}), so it's therefore much faster than equivalent \texttt{R} code.
      <<echo=TRUE,eval=FALSE>>=
# Calculate XLP and VTI returns
retp <- na.omit(rutils::etfenv$returns[, c("XLP", "VTI")])
# Calculate monthly end points
endd <- rutils::calc_endpoints(retp, interval="months")[-1]
# Calculate start points from look-back interval
lookb <- 12  # Look back 12 months
startp <- c(rep(1, lookb), endd[1:(NROW(endd)-lookb)])
head(cbind(endd, startp), lookb+2)
# Calculate trailing beta regressions every month in R
formulav <- XLP ~ VTI  # Specify regression formula
betar <- sapply(1:NROW(endd), FUN=function(tday) {
    datav <- retp[startp[tday]:endd[tday], ]
    # coef(lm(formulav, data=datav))[2]
    drop(cov(datav$XLP, datav$VTI)/var(datav$VTI))
  })  # end sapply
# Calculate trailing betas using RcppArmadillo
controll <- HighFreq::param_reg()
reg_stats <- HighFreq::roll_reg(respv=retp$XLP, predm=retp$VTI, 
  startp=(startp-1), endp=(endd-1), controll=controll)
betac <- reg_stats[, 2]
all.equal(betac, betar)
# Compare the speed of RcppArmadillo with R code
library(microbenchmark)
summary(microbenchmark(
  Rcpp=HighFreq::roll_reg(respv=retp$XLP, predm=retp$VTI, startp=(startp-1), endp=(endd-1), controll=controll),
  Rcode=sapply(1:NROW(endd), FUN=function(tday) {
    datav <- retp[startp[tday]:endd[tday], ]
    drop(cov(datav$XLP, datav$VTI)/var(datav$VTI))
  }),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/trailing_betas.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of trailing XLP beta and VTI prices
datev <- zoo::index(retp[endd, ])
pricev <- log(rutils::etfenv$prices$VTI[datev])
datav <- cbind(pricev, betac)
colnames(datav)[2] <- "beta"
colv <- colnames(datav)
dygraphs::dygraph(datav, main="XLP Trailing 12-month Beta and VTI Prices") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue", strokeWidth=2) %>%
  dySeries(name=colv[2], axis="y2", col="red", strokeWidth=2) %>%
  dyLegend(show="always", width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Recursive Trailing Stock Beta}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The trailing beta $\beta$ of a stock with returns $r_t$ with respect to a stock index with returns $R_t$ can be updated using these recursive formulas with the decay factor $\lambda$:
      \begin{flalign*}
        & \bar{r}_t = \lambda \bar{r}_{t-1} + (1-\lambda) r_t \\
        & \bar{R}_t = \lambda \bar{R}_{t-1} + (1-\lambda) R_t \\
        & \sigma^2_t = \lambda \sigma^2_{t-1} + (1-\lambda) (R_t - \bar{R}_t)^2 \\
        & \operatorname{cov}_t = \lambda \operatorname{cov}_{t-1} + (1-\lambda) (r_t - \bar{r}_t) (R_t - \bar{R}_t) \\
        & \beta_t = \frac{\operatorname{cov}_t}{\sigma^2_t}
      \end{flalign*}
      The parameter $\lambda$ determines the rate of decay of the weight of past returns.
      If $\lambda$ is close to \texttt{1} then the decay is weak and past returns have a greater weight, and the trailing mean values have a stronger dependence on past returns.  This is equivalent to a long look-back interval.
      And vice versa if $\lambda$ is close to \texttt{0}.
      \vskip1ex
      The function \texttt{HighFreq::run\_covar()} calculates the trailing variances, covariances, and means of two \emph{time series}.
      <<echo=TRUE,eval=FALSE>>=
# Calculate the trailing betas
lambdaf <- 0.99
covarv <- HighFreq::run_covar(retp, lambdaf)
betac <- covarv[, 1]/covarv[, 3]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/trailing_betas_rec.png}
      <<echo=TRUE,eval=FALSE>>=
# dygraph plot of trailing XLP beta and VTI prices
datav <- cbind(pricev, betac[endd])[-(1:11)] # Remove warmup period
colnames(datav)[2] <- "beta"
colv <- colnames(datav)
dygraphs::dygraph(datav, main="XLP Trailing 12-month Beta and VTI Prices") %>%
  dyAxis("y", label=colv[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=colv[2], independentTicks=TRUE) %>%
  dySeries(name=colv[1], axis="y", col="blue", strokeWidth=2) %>%
  dySeries(name=colv[2], axis="y2", col="red", strokeWidth=2) %>%
  dyLegend(show="always", width=500)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Principal Components} of \protect\emph{S\&P500} Stock Constituents}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{PCA} standard deviations are the volatilities of the \emph{principal component} time series.
      \vskip1ex
      The original time series of returns can be calculated approximately from the first few \emph{principal components} with the largest standard deviations.
      \vskip1ex
      The \emph{Kaiser-Guttman} rule uses only \emph{principal components} with \emph{variance} greater than $1$.
      \vskip1ex
      Another rule of thumb is to use the \emph{principal components} with the largest standard deviations which sum up to \texttt{80\%} of the total variance of returns.
      <<echo=TRUE,eval=FALSE>>=
# Load S&P500 constituent stock prices
load("/Users/jerzy/Develop/lecture_slides/data/sp500_prices.RData")
# Calculate stock prices and percentage returns
pricets <- zoo::na.locf(pricets, na.rm=FALSE)
pricets <- zoo::na.locf(pricets, fromLast=TRUE)
retp <- rutils::diffit(log(pricev))
# Standardize (center and scale) the returns
retp <- lapply(retp, function(x) {(x - mean(x))/sd(x)})
retp <- rutils::do_call(cbind, retp)
# Perform principal component analysis PCA
pcad <- prcomp(retp, scale=TRUE)
# Find number of components with variance greater than 2
ncomp <- which(pcad$sdev^2 < 2)[1]
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/pca_sp500_scree.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot standard deviations of principal components
barplot(pcad$sdev[1:ncomp], 
        names.arg=colnames(pcad$rotation[, 1:ncomp]), 
        las=3, xlab="", ylab="", 
        main="Volatilities of S&P500 Principal Components")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Principal Component} Loadings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Principal component} loadings are the weights of \emph{principal component} portfolios.
      \vskip1ex
      The \emph{principal component} portfolios have mutually orthogonal returns
      represent the different orthogonal modes of the return variance.
      <<echo=TRUE,eval=FALSE>>=
# Calculate principal component loadings (weights)
# Plot barplots with PCA weights in multiple panels
ncomps <- 6
par(mfrow=c(ncomps/2, 2))
par(mar=c(4, 2, 2, 1), oma=c(0, 0, 0, 0))
# First principal component weights
weightv <- sort(pcad$rotation[, 1], decreasing=TRUE)
barplot(weightv[1:6], las=3, xlab="", ylab="", main="")
title(paste0("PC", 1), line=-2.0, col.main="red")
for (ordern in 2:ncomps) {
  weightv <- sort(pcad$rotation[, ordern], decreasing=TRUE)
  barplot(weightv[c(1:3, 498:500)], las=3, xlab="", ylab="", main="")
  title(paste0("PC", ordern), line=-2.0, col.main="red")
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/pca_sp500_loadings.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Principal Component} Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The time series of the \emph{principal components} can be calculated by multiplying the loadings (weights) times the original data.
      \vskip1ex
      Higher order \emph{principal components} are gradually less volatile.
      <<echo=TRUE,eval=FALSE>>=
# Calculate principal component time series
retpca <- xts(retp %*% pcad$rotation[, 1:ncomps], order.by=datev)
round(cov(retpca), 3)
retpcac <- cumsum(retpca)
# Plot principal component time series in multiple panels
par(mfrow=c(ncomps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
rangev <- range(retpcac)
for (ordern in 1:ncomps) {
  plot.zoo(retpcac[, ordern], ylim=rangev, xlab="", ylab="")
  title(paste0("PC", ordern), line=-2.0)
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/pca_sp500_series.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} Factor Model From \protect\emph{Principal Components}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      By inverting the \emph{PCA} analysis, the \emph{S\&P500} constituent returns can be calculated from the first \texttt{k} \emph{principal components} under a \emph{factor model}: 
      \begin{displaymath}
        \mathbf{r}_i = \alpha_i + \sum_{j=1}^k {\beta_{ji} \, \mathbf{F}_j} + \varepsilon_i
      \end{displaymath}
      The \emph{principal components} are interpreted as \emph{market factors}: $\mathbf{F}_j = \mathbf{pc}_j$.
      \vskip1ex
      The \emph{market betas} are the inverse of the \emph{principal component loadings}: $\beta_{ji} = w_{ij}$.
      \vskip1ex
      The $\varepsilon_i$ are the \emph{idiosyncratic} returns, which should be mutually independent and uncorrelated to the \emph{market factor} returns.
      <<echo=(-(1:2)),eval=FALSE>>=
par(mfrow=c(ncomps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
# Invert principal component time series
pcinv <- solve(pcad$rotation)
all.equal(pcinv, t(pcad$rotation))
solved <- retpca %*% pcinv[1:ncomps, ]
solved <- xts::xts(solved, datev)
solved <- cumsum(solved)
retc <- cumsum(retp)
# Plot the solved returns
symbolv <- c("MSFT", "XOM", "JPM", "AAPL", "BRK_B", "JNJ")
for (symbol in symbolv) {
  plot.zoo(cbind(retc[, symbol], solved[, symbol]), 
    plot.type="single", col=c("black", "blue"), xlab="", ylab="")
  legend(x="topleft", bty="n",
         legend=paste0(symbol, c("", " solved")),
         title=NULL, inset=0.05, cex=1.0, lwd=6,
         lty=1, col=c("black", "blue"))
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/pca_sp500_series_solved.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{S\&P500} \protect\emph{Factor Model} Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The original time series of returns can be calculated exactly from the time series of all the \emph{principal components}, by inverting the loadings matrix.
      \vskip1ex
      The original time series of returns can be calculated approximately from just the first few \emph{principal components}, which demonstrates that \emph{PCA} is a form of \emph{dimension reduction}.
      \vskip1ex
      The function \texttt{solve()} solves systems of linear equations, and also inverts square matrices.
      <<echo=(-(1:2)),eval=FALSE>>=
par(mfrow=c(ncomps/2, 2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
# Perform ADF unit root tests on original series and residuals
sapply(symbolv, function(symbol) {
  c(series=tseries::adf.test(retc[, symbol])$p.value,
    resid=tseries::adf.test(retc[, symbol] - solved[, symbol])$p.value)
})  # end sapply
# Plot the residuals
for (symbol in symbolv) {
  plot.zoo(retc[, symbol] - solved[, symbol], 
    plot.type="single", col="blue", xlab="", ylab="")
  legend(x="topleft", bty="n", legend=paste(symbol, "residuals"),
         title=NULL, inset=0.05, cex=1.0, lwd=6, lty=1, col="blue")
}  # end for
# Perform ADF unit root test on principal component time series
retpca <- xts(retp %*% pcad$rotation, order.by=datev)
retpcac <- cumsum(retpca)
adf_pvalues <- sapply(1:NCOL(retpcac), function(ordern)
  tseries::adf.test(retpcac[, ordern])$p.value)
# AdF unit root test on stationary time series
tseries::adf.test(rnorm(1e5))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/pca_sp500_residuals.png}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\subsection{Correlation and Factor Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<corr_plot,echo=(-(1:1)),eval=FALSE,fig.show='hide'>>=
library(quantmod)
### Perform pair-wise correlation analysis
# Calculate correlation matrix
cormat <- cor(retp)
colnames(cormat) <- colnames(retp)
rownames(cormat) <- colnames(retp)
# Reorder correlation matrix based on clusters
# Calculate permutation vector
library(corrplot)
ordern <- corrMatOrder(cormat, order="hclust", 
              hclust.method="complete")
# Apply permutation vector
cormat <- cormat[ordern, ordern]
# Plot the correlation matrix
colorv <- colorRampPalette(c("red", "white", "blue"))
corrplot(cormat, tl.col="black", tl.cex=0.8, 
    method="square", col=colorv(8), 
    cl.offset=0.75, cl.cex=0.7, 
    cl.align.text="l", cl.ratio=0.25)
# draw rectangles on the correlation matrix plot
corrRect.hclust(cormat, k=NROW(cormat) %/% 2, 
                method="complete", col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Hierarchical Clustering Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{as.dist()} converts a matrix representing the \emph{distance} (dissimilarity) between elements, into a list of class \texttt{"dist"}.
      \vskip1ex
      For example, \texttt{as.dist()} converts \texttt{(1-correlation)} to distance.
      \vskip1ex
      The function \texttt{hclust()} recursively combines elements into clusters based on their mutual \emph{distance}.
      \vskip1ex
      First \texttt{hclust()} combines individual elements that are closest to each other.
      \vskip1ex
      Then it combines elements to the closest clusters, then clusters with other clusters, until all elements are combined into one cluster.
      \vskip1ex
      This process of recursive clustering can be represented as a \emph{dendrogram} (tree diagram).
      \vskip1ex
      Branches of a \emph{dendrogram} represent clusters.
      \vskip1ex
      Neighboring branches contain elements that are close to each other (have small distance).
      \vskip1ex
      Neighboring branches combine into larger branches, that then combine with their closest branches, etc.
    \column{0.5\textwidth}
      \vspace{-2em}
      \includegraphics[width=0.45\paperwidth]{figure/cluster_plot-1}
      \vspace{-4em}
      <<cluster_plot,echo=TRUE,eval=FALSE,fig.width=6,fig.height=6,fig.show='hide'>>=
# Convert correlation matrix into distance object
distancev <- as.dist(1-cormat)
# Perform hierarchical clustering analysis
compclust <- hclust(distancev)
plot(compclust, ann=FALSE, xlab="", ylab="")
title("Dendrogram representing hierarchical clustering
      \nwith dissimilarity = 1-correlation", line=-0.5)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: \protect\emph{Principal Component} Returns Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
\vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PerformanceAnalytics)  # Load package "PerformanceAnalytics"
# PC returns from rotation and scaled returns
retsc <- apply(retp, 2, scale)
retpca <- retsc %*% pcad$rotation
# "x" matrix contains time series of PC returns
dim(pcad$x)
class(pcad$x)
head(pcad$x[, 1:3], 3)
# Convert PC matrix to xts and rescale to decimals
retpca <- xts(pcad$x/100, order.by=zoo::index(retp))
      @
\vspace{-1em}
      <<pca_retc,echo=(-1),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)  # Load package "PerformanceAnalytics"
chart.CumReturns(
  retpca[, 1:3], lwd=2, ylab="", 
  legend.loc="topright", main="")
# Add title
title(main="ETF cumulative returns", line=-1)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.45\paperwidth]{figure/pca_cum_returns-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: \protect\emph{Principal Component} Returns Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
# Calculate PC correlation matrix
cormat <- cor(retpca)
colnames(cormat) <- colnames(retpca)
rownames(cormat) <- colnames(retpca)
cormat[1:3, 1:3]
table.CAPM(Ra=retpca[, 1:3], Rb=retp$VTI, scale=252)
      @
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Principal Component Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_plot,echo=(-(1:2)),fig.height=5,fig.show='hide',eval=FALSE>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # Set plot panels
### Perform principal component analysis PCA
retp <- na.omit(rutils::etfenv$returns)
pcad <- prcomp(retp, center=TRUE, scale=TRUE)
barplot(pcad$sdev[1:10], 
        names.arg=colnames(pcad$rotation)[1:10], 
        las=3, ylab="STDEV", xlab="PCVec", 
        main="PCA Explain VAR")
# Show first three principal component loadings
head(pcad$rotation[,1:3], 3)
# Permute second principal component loadings by size
pca2 <- as.matrix(
  pcad$rotation[order(pcad$rotation[, 2], 
  decreasing=TRUE), 2])
colnames(pca2) <- "pca2"
head(pca2, 3)
# The option las=3 rotates the names.arg labels
barplot(as.vector(pca2), 
        names.arg=rownames(pca2), 
        las=3, ylab="Loadings", 
        xlab="Symbol", main="Loadings pca2")
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.45\paperwidth]{figure/pca_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Principal Component Vectors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_vec,echo=(-(1:2)),eval=FALSE,fig.height=5,fig.show='hide'>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(3,1))  # Set plot panels
# Get list of principal component vectors
pca_vecs <- lapply(1:3, function(ordern) {
  pca_vec <- as.matrix(
    pcad$rotation[
    order(pcad$rotation[, ordern], 
    decreasing=TRUE), ordern])
  colnames(pca_vec) <- paste0("pca", ordern)
  pca_vec
})  # end lapply
names(pca_vecs) <- c("pca1", "pca2", "pca3")
# The option las=3 rotates the names.arg labels
for (ordern in 1:3) {
  barplot(as.vector(pca_vecs[[ordern]]), 
        names.arg=rownames(pca_vecs[[ordern]]), 
        las=3, xlab="", ylab="", 
        main=paste("Loadings", 
          colnames(pca_vecs[[ordern]])))
}  # end for
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.45\paperwidth]{figure/pca_vec-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Package \protect\emph{factorAnalytics}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The package \emph{factorAnalytics} performs estimation and risk analysis of linear factor models for portfolio asset returns.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(factorAnalytics)  # Load package "factorAnalytics"
# Get documentation for package "factorAnalytics"
packageDescription("factorAnalytics")  # Get short description
help(package="factorAnalytics")  # Load help page
      @
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE,tidy=TRUE>>=
options(width=50)
library(factorAnalytics)  # Load package "factorAnalytics"
# List all objects in "factorAnalytics"
ls("package:factorAnalytics")

# List all datasets in "factorAnalytics"
# data(package="factorAnalytics")

# Remove factorAnalytics from search path
detach("package:factorAnalytics")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Fitting Factor Models Using PCA}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(factorAnalytics)
# Fit a three-factor model using PCA
factpca <- fitSfm(rutils::etfenv$returns, k=3)
head(factpca$loadings, 3)  # Factor loadings
# Factor realizations (time series)
head(factpca$factors)
# Residuals from regression
factpca$residuals[1:3, 1:3]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(factorAnalytics)
factpca$alpha  # Estimated alphas
factpca$r2  # R-squared regression
# Covariance matrix estimated by factor model
factpca$Omega[1:3, 4:6]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Factor Loadings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      <<fact_load,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=10,fig.show='hide'>>=
library(factorAnalytics)
# load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
plot(factpca, which.plot.group=3, n.max=30, loop=FALSE)
# ?plot.sfm
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/fact_load-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Time Series of Factors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_tsplot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot factor cumulative returns
chart.CumReturns(factpca$factors, 
    lwd=2, ylab="", legend.loc="topleft", main="")

# Plot time series of factor returns
# Plot(factpca, which.plot.group=2, 
#   loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.45\paperwidth]{figure/fact_tsplot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Asset Correlations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_corr_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=7,fig.show='hide'>>=
# Asset correlations "hclust" hierarchical clustering order
plot(factpca, which.plot.group=7, loop=FALSE, 
     order="hclust", method="ellipse")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/fact_corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Time Series of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot residual cumulative returns
chart.CumReturns(factpca$residuals[, c("IEF", "DBC", "XLF")], 
  lwd=2, ylab="", legend.loc="topleft", main="")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/fact_resid_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Residual Returns Histogram}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_hist,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot residual histogram with normal curve
plot(factpca, asset.name="VTI", 
     which.plot.single=8, 
     plot.single=TRUE, loop=FALSE, 
     xlim=c(-0.007, 0.007))
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/fact_resid_hist-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Residual Returns and the Q-Q Plot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_qq,eval=FALSE,echo=(-1),fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Residual Q-Q plot
plot(factpca, asset.name="VTI", 
     which.plot.single=9, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/fact_resid_qq-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{depr: Autocorrelation of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_autocorr,eval=FALSE,echo=TRUE,fig.width=7,fig.height=9,fig.show='hide'>>=
# SACF and PACF of residuals
plot(factpca, asset.name="VTI", 
     which.plot.single=5, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/fact_resid_autocorr-1}
  \end{columns}
\end{block}

\end{frame}



\end{document}
