% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size="tiny", fig.width=4, fig.height=4)
options(digits=3)
options(width=80, dev="pdf")
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[9pt]{beamer}
\DeclareMathSizes{8pt}{6pt}{6pt}{5pt}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{mathtools}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}



% Title page setup
\title[Portfolio Construction]{Portfolio Construction}
\subtitle{FRE6871 \& FRE7241, Spring 2022}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color.png}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{\today}



%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle



%%%%%%%%%%%%%%%
\section{Asset Allocation and Portfolio Construction}


%%%%%%%%%%%%%%%
\subsection{draft: Stock Selection}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Demonstrate that picking a portfolio that outperforms the stock index requires great skill, because most random portfolios underperform the index
      \vskip1ex
      So the proper benchmark for a stock picker is the median of random portfolios, not the stock index.
      \vskip1ex
      Asset allocation means dividing an investment portfolio among different asset classes, such as large company stocks, small company stocks, international stocks, bonds, commodities, cash, etc.
      <<echo=TRUE,eval=FALSE>>=
# Summary: Calculate the performance of random sub-portfolios
# of S&P500 constituent stocks.

# 1. (20pts) Load the file sp500_prices.RData containing 
# an xts series called prices, with the daily closing 
# Prices of the S&P500 stock index constituents.  

library(rutils)
load("/Users/jerzy/Develop/lecture_slides/data/sp500_prices.RData")


# Subset (select) from prices only the data after the 
# year 2000, and copy it over prices.
prices <- prices["2000/"]
# Copy over NA prices using the function zoo::na.locf().
prices <- zoo::na.locf(prices, na.rm=FALSE)
prices <- zoo::na.locf(prices, fromLast=TRUE)
# Create a vector of dates called dates, equal to the 
# time index of prices.
dates <- zoo::index(prices)
# Normalize the columns of prices, so that the first 
# row for all columns is equal to 1.
# The columns of prices will then represent the growth 
# of one dollar invested in that stock.
# You can use the functions lapply(), as.numeric(), cbind(), 
# and rutils::do_call().
prices <- lapply(prices, function(x) x/as.numeric(x[1]))
prices <- rutils::do_call(cbind, prices)
class(prices)
dim(prices)
sum(prices[1, ])
round(head(prices[, 1:6]), 3)
round(tail(prices[, 1:6]), 3)
# Calculate a vector equal to the dollar-weighted 
# Prices of the index components, i.e. the average of 
# the rows of prices, and call it indeks.
# You can use the functions NCOL() and rowSums(). 

ncols <- NCOL(prices)
indeks <- rowSums(prices)/ncols

# You should get the following output:
tail(indeks)
# [1] 12.27228 12.33409 12.33381 11.98787 12.11134 11.87442


# 2. (30pts) Select twenty equally dollar-weighted, 
# random sub-portfolios from the columns of prices,
# with each sub-portfolio being the average of five
# randomly selected columns (stocks) of prices.
# Bind the sub-portfolio prices into a single xts 
# time series called sub_portfolios.
# You can use the function sample.int() with "replace=FALSE". 
# You can also use the functions sapply(), xts::xts(), 
# rowSums(), paste0(), and colnames(). 
# You can use the vector of dates called dates.

n_portf <- 20
nums <- 5
set.seed(1121)
sub_portfolios <- sapply(1:n_portf, function(x) {
  prices <- prices[, sample.int(n=ncols, size=nums, replace=FALSE)]
  rowSums(prices)/nums
})  # end sapply

sub_portfolios <- xts::xts(sub_portfolios, order.by=dates)
colnames(sub_portfolios) <- paste0("portf", 1:n_portf)

# You should get output similar to the following:
# 
round(head(sub_portfolios[, 1:4]), 3)
#            portf1 portf2 portf3 portf4
# 2000-01-03  1.000  1.000  1.000  1.000
# 2000-01-04  0.977  0.975  0.962  0.973
# 2000-01-05  0.967  0.992  0.979  0.988
# 2000-01-06  0.950  1.001  0.981  1.008
# 2000-01-07  0.966  1.008  0.985  1.035
# 2000-01-10  0.980  1.010  0.980  1.043

round(tail(sub_portfolios[, 1:4]), 3)
#            portf1 portf2 portf3 portf4
# 2020-06-19 30.928 11.654 36.575  8.667
# 2020-06-22 31.553 11.691 37.173  8.662
# 2020-06-23 31.262 11.606 37.022  8.660
# 2020-06-24 30.275 11.409 37.289  8.415
# 2020-06-25 30.897 11.511 37.242  8.567
# 2020-06-26 29.834 11.228 36.912  8.570


# Plot the sub_portfolios from worst to best (based 
# on final price) using a color ramp from red to blue.
# 
# Create a color ramp, using functions colorRampPalette() 
# and order(). 

colors <- colorRampPalette(c("red", "blue"))(n_portf)
colors <- colors[order(order(sub_portfolios[NROW(sub_portfolios), ]))]

# Create a plot of the sub_portfolios with the custom 
# color ramp, using either function zoo::plot.zoo(), 
# Or functions chart_theme() and chart_Series(). 

# Plot using chart_theme() and chart_Series()
x11(width=6, height=5)
zoo::plot.zoo(sub_portfolios, plot.type="single", 
              col=colors, xlab="", ylab="",
              main="Random S&P500 Stock Sub-portfolios (normalized)")

# Or plot using quantmod::chart_Series()
plot_theme <- chart_theme()
plot_theme$col$line.col <- colors
quantmod::chart_Series(sub_portfolios, theme=plot_theme, 
                       name="Random S&P500 Stock Sub-portfolios (normalized)")



# Your plot should be similar to sp500_sub_portfolios.png


# Calculate an xts series called above_index, with the 
# percentage of sub-portfolios whose prices at the end 
# of each year are above the index price indeks.
# You cannot perform any loops.
# You can use the functions xts::endpoints(), rowSums(), 
# chart_theme(), and xts(). 

# You can calculate the end of year end points as follows:
endp <- xts::endpoints(dates, on="years")

# endp are the row numbers for the end of year dates:
dates[endp]

endp <- xts::endpoints(dates, on="years")
above_index <- (sub_portfolios[endp, ] > indeks[endp])
above_index <- rowSums(above_index)/n_portf
above_index <- xts::xts(above_index, order.by=dates[endp])
colnames(above_index) <- "percentage"

# You should get output similar to the following:
above_index
#             percentage
# 2000-12-29       0.35
# 2001-12-31       0.40
# 2002-12-31       0.35
# 2003-12-31       0.25
# 2004-12-31       0.35
# 2005-12-30       0.25
# 2006-12-29       0.25
# 2007-12-31       0.25
# 2008-12-31       0.30
# 2009-12-31       0.25
# 2010-12-31       0.30
# 2011-12-30       0.30
# 2012-12-31       0.30
# 2013-12-31       0.35
# 2014-12-31       0.30
# 2015-12-31       0.30
# 2016-12-30       0.30
# 2017-12-29       0.30
# 2018-12-31       0.40
# 2019-12-31       0.40
# 2020-06-26       0.40

# Create a plot of above_index using function 
# zoo::plot.zoo(). 

zoo::plot.zoo(above_index, col="blue", lwd=2, xlab="", ylab="",
              main="Percentage of Random Sub-portfolios 
              Above the Index")

# Your plot should be similar to sp500_sub_portfolios_above.png



      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Asset Allocation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Asset allocation means dividing an investment portfolio among different asset classes, such as large company stocks, small company stocks, international stocks, bonds, commodities, cash, etc.
      \vskip1ex
      The goal of asset allocation is to diversify the sources of returns and to reduce risk, depending on the investor's risk tolerance, investment goals, and investment time horizon.
      \vskip1ex
      For example, an investor who needs to fund college for her children might put some of her investments into government bonds that mature when her children will need to pay for college.
      \vskip1ex
      1,600 years ago \href{http://finance.yahoo.com/news/naive-diversification-vs-optimization-163550886.html}{rabbi Isaac bar Aha} proposed a simple heuristic method (rule of thumb) for asset allocation: "put a third in land, a third in merchandise, and a third in cash".
      <<echo=TRUE,eval=FALSE>>=
library(PortfolioAnalytics)
# Use ETF returns from package rutils
library(rutils)
portf_names <- c("VTI", "IEF", "DBC", "XLF",
        "VNQ", "XLP", "XLV", "XLU", "XLB", "XLE")
# Initial portfolio to equal weights
portf_init <- rep(1/NROW(portf_names),
                  NROW(portf_names))
# named vector
names(portf_init) <- portf_names
# Create portfolio object
portf_init <- portfolio.spec(
  assets=portf_init)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PortfolioAnalytics)
# Add constraints
portf_maxSR <- add.constraint(
  portfolio=portf_init,  # Initial portfolio
  type="weightsum",  # Constraint sum weights
  min_sum=0.9, max_sum=1.1)
# Add constraints
portf_maxSR <- add.constraint(
  portfolio=portf_maxSR,
  type="long_only")  # box constraint min=0, max=1
# Add objectives
portf_maxSR <- add.objective(
  portfolio=portf_maxSR,
  type="return",  # Maximize mean return
  name="mean")
# Add objectives
portf_maxSR <- add.objective(
  portfolio=portf_maxSR,
  type="risk",  # Minimize StdDev
  name="StdDev")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Portfolio Construction}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Portfolio construction means determining the amounts to be invested different assets, such as specific stocks, bonds, commodities, etc.
      \vskip1ex
      Portfolio optimization is one approach to portfolio construction.
      \vskip1ex
      Heuristic Methods for Portfolio Construction
      \vskip1ex
      \href{https://www.london.edu/faculty-and-research/faculty/profiles/d/demiguel-v}{Victor DeMiguel} and others have demonstrated that optimized portfolios perform poorly out-of-sample, and that simple heuristic methods can perform better than portfolio optimization.
      \vskip1ex
      <<echo=TRUE,eval=FALSE>>=
library(PortfolioAnalytics)
# Use ETF returns from package rutils
library(rutils)
portf_names <- c("VTI", "IEF", "DBC", "XLF",
        "VNQ", "XLP", "XLV", "XLU", "XLB", "XLE")
# Initial portfolio to equal weights
portf_init <- rep(1/NROW(portf_names),
                  NROW(portf_names))
# named vector
names(portf_init) <- portf_names
# Create portfolio object
portf_init <- portfolio.spec(
  assets=portf_init)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PortfolioAnalytics)
# Add constraints
portf_maxSR <- add.constraint(
  portfolio=portf_init,  # Initial portfolio
  type="weightsum",  # Constraint sum weights
  min_sum=0.9, max_sum=1.1)
# Add constraints
portf_maxSR <- add.constraint(
  portfolio=portf_maxSR,
  type="long_only")  # box constraint min=0, max=1
# Add objectives
portf_maxSR <- add.objective(
  portfolio=portf_maxSR,
  type="return",  # Maximize mean return
  name="mean")
# Add objectives
portf_maxSR <- add.objective(
  portfolio=portf_maxSR,
  type="risk",  # Minimize StdDev
  name="StdDev")
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Portfolio Efficient Frontier}


%%%%%%%%%%%%%%%
\subsection{Vector and Matrix Calculus}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
    \begin{columns}[T]
    \column{0.5\textwidth}
      Let $\mathbf{v}$ and $\mathbf{w}$ be vectors, with $\mathbf{v} = \left\{ v_i \right\}_{i=1}^{i=n}$, and let $\mathbbm{1}$ be the unit vector, with $\mathbbm{1} = \left\{ 1 \right\}_{i=1}^{i=n}$.
      \vskip1ex
      Then the inner product of $\mathbf{v}$ and $\mathbf{w}$ can be written as $\mathbf{v}^T \mathbf{w} = \mathbf{w}^T \mathbf{v} = {\sum_{i=1}^n {v_i w_i}}$.
      \vskip1ex
      We can then express the sum of the elements of $\mathbf{v}$ as the inner product: $\mathbf{v}^T \mathbbm{1} = \mathbbm{1}^T \mathbf{v} = {\sum_{i=1}^n v_i}$.
      \vskip1ex
      And the sum of squares of $\mathbf{v}$ as the inner product: $\mathbf{v}^T \mathbf{v} = {\sum_{i=1}^n v^2_i}$.
      \vskip1ex
      Let $\mathbb{A}$ be a matrix, with $\mathbb{A} = \left\{ A_{ij} \right\}_{{i,j}=1}^{{i,j}=n}$.
      \vskip1ex
      Then the inner product of matrix $\mathbb{A}$ with vectors $\mathbf{v}$ and $\mathbf{w}$ can be written as:
      \begin{displaymath}
        \mathbf{v}^T \mathbb{A} \, \mathbf{w} = \mathbf{w}^T \mathbb{A}^T \mathbf{v} = {\sum_{{i,j}=1}^n {A_{ij} v_i w_j}}
      \end{displaymath}
    \column{0.5\textwidth}
      The derivative of a scalar variable with respect to a vector variable is a vector, for example:
      \begin{align*}
        \frac{d (\mathbf{v}^T \mathbbm{1})}{d \mathbf{v}} = d_v[\mathbf{v}^T \mathbbm{1}] = d_v[\mathbbm{1}^T \mathbf{v}] = \mathbbm{1}^T\\
        d_v[\mathbf{v}^T \mathbf{w}] = d_v[\mathbf{w}^T \mathbf{v}] = \mathbf{w}^T\\
        d_v[\mathbf{v}^T \mathbb{A} \, \mathbf{w}] = \mathbf{w}^T \mathbb{A}^T\\
        d_v[\mathbf{v}^T \mathbb{A} \, \mathbf{v}] = \mathbf{v}^T \mathbb{A} + \mathbf{v}^T \mathbb{A}^T
      \end{align*}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Weight Constraints}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Portfolio optimization requires constraints on the portfolio weights to prevent excessive leverage (size of positions relative to capital).
      \vskip1ex
      Portfolio-level constraints limit the combined size of the weights.
      \vskip1ex
      For example, under \emph{linear} constraints the sum of the weights is equal to \texttt{1}: $\mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1$, so that the weights are constrained to a \emph{hyperplane}.
      \vskip1ex
      The disadvantage of \emph{linear} constraints is that they allow highly leveraged portfolios, with very large positive and negative weights.
      \vskip1ex
      Under \emph{quadratic} constraints the sum of the \emph{squared} weights is equal to \texttt{1}: $\mathbf{w}^T \mathbf{w} = {\sum_{i=1}^n w^2_i} = 1$, so that the weights are constrained to a \emph{hypersphere}.
      \vskip1ex
      Box constraints limit the individual weights, for example: $0 \leq w_i \leq 1$.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Linear constraint
weights <- weights/sum(weights)
# Quadratic constraint
weights <- weights/sqrt(sum(weights^2))
# Box constraints
weights[weights > 1] <- 1
weights[weights < 0] <- 0
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Maximum Return Portfolio Using Linear Programming}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The weights of the maximum return portfolio are obtained by maximizing the portfolio returns:
      \begin{displaymath}
        w_{max} = \operatorname*{arg\,max}_{w} [ \, \mathbf{r}^T \mathbf{w} \, ] = \operatorname*{arg\,max}_{w} [ \, \sum_{i=1}^n w_i r_i \, ]
      \end{displaymath}
      Where $\mathbf{r}$ is the vector of returns, and $\mathbf{w}$ is the vector of portfolio weights, constrained by:
      \begin{align*}
        \mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1\\
        0 \leq w_i \leq 1
      \end{align*}
      The weights of the maximum return portfolio can be calculated using linear programming (\emph{LP}), which is the optimization of linear objective functions subject to linear constraints.
      \vskip1ex
      The function \texttt{Rglpk\_solve\_LP()} from package \emph{Rglpk} solves linear programming problems by calling the \emph{GNU Linear Programming Kit} library.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(quantmod)
library(Rglpk)
# Vector of symbol names
symbolv <- c("VTI", "IEF", "DBC")
nweights <- NROW(symbolv)
# Calculate mean returns
returns <- rutils::etf_env$returns[, symbolv]
returns <- zoo::na.locf(returns, na.rm=FALSE)
returns <- na.omit(returns)
mean_rets <- colMeans(returns)
# Specify weight constraints
constr <- matrix(c(rep(1, nweights), 1, 1, 0),
                       nc=nweights, byrow=TRUE)
directs <- c("==", "<=")
rhs <- c(1, 0)
# Specify weight bounds (-1, 1) (default is c(0, Inf))
bounds <- list(lower=list(ind=1:nweights, val=rep(-1, nweights)),
               upper=list(ind=1:nweights, val=rep(1, nweights)))
# Perform optimization
optimd <- Rglpk::Rglpk_solve_LP(
  obj=mean_rets,
  mat=constr,
  dir=directs,
  rhs=rhs,
  bounds=bounds,
  max=TRUE)
unlist(optimd[1:2])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Minimum Variance} Portfolio Under \protect\emph{Linear} Constraints}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The portfolio variance is equal to: $\mathbf{w}^T \mathbb{C} \, \mathbf{w}$, where $\mathbb{C}$ is the covariance matrix of returns.
      \vskip1ex
      If the portfolio weights $\mathbf{w}$ are subject to \emph{linear} constraints: $\mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1$, then the weights that minimize the portfolio variance can be found by minimizing the \emph{Lagrangian}:
      \begin{displaymath}
        \mathcal{L} = \mathbf{w}^T \mathbb{C} \, \mathbf{w} - \, \lambda \, (\mathbf{w}^T \mathbbm{1} - 1)
      \end{displaymath}
      Where $\lambda$ is a \emph{Lagrange multiplier}.
      \vskip1ex
      The derivative of a scalar variable with respect to a vector variable is a vector, for example:
      \begin{align*}
        d_w[\mathbf{w}^T \mathbbm{1}] = d_w[\mathbbm{1}^T \mathbf{w}] = \mathbbm{1}^T\\
        d_w[\mathbf{w}^T \mathbf{r}] = d_w[\mathbf{r}^T \mathbf{w}] = \mathbf{r}^T\\
        d_w[\mathbf{w}^T \mathbb{C} \, \mathbf{w}] = \mathbf{w}^T \mathbb{C} + \mathbf{w}^T \mathbb{C}^T
      \end{align*}
      Where $\mathbbm{1}$ is the unit vector, and $\mathbf{w}^T \mathbbm{1} = \mathbbm{1}^T \mathbf{w} = \sum_{i=1}^n {x_i}$
    \column{0.5\textwidth}
      The derivative of the \emph{Lagrangian} $\mathcal{L}$ with respect to $\mathbf{w}$ is given by:
      \begin{displaymath}
        d_w \mathcal{L} = 2 \mathbf{w}^T \mathbb{C} - \lambda \mathbbm{1}^T
      \end{displaymath}
      By setting the derivative to zero we find $\mathbf{w}$ equal to:
      \begin{displaymath}
        \mathbf{w} = \frac{1}{2} \lambda \, \mathbb{C}^{-1} \mathbbm{1}
      \end{displaymath}
      By multiplying the above from the left by $\mathbbm{1}^T$, and using $\mathbf{w}^T \mathbbm{1} = 1$, we find $\lambda$ to be equal to:
      \begin{displaymath}
        \lambda = \frac{2}{\mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}}
      \end{displaymath}
      And finally the portfolio weights are then equal to:
      \begin{displaymath}
        \mathbf{w} = \frac{\mathbb{C}^{-1} \mathbbm{1}}{\mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}}
      \end{displaymath}
      If the portfolio weights are subject to \emph{quadratic} constraints: $\mathbf{w}^T \mathbf{w} = 1$ then the minimum variance weights are equal to the highest order \emph{principal component} (with the smallest eigenvalue) of the covariance matrix $\mathbb{C}$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Variance of the \protect\emph{Minimum Variance} Portfolio}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The weights of the \emph{minimum variance} portfolio under the constraint $\mathbf{w}^T \mathbbm{1} = 1$ can be calculated using the inverse of the covariance matrix:
      \begin{displaymath}
        \mathbf{w} = \frac{\mathbb{C}^{-1} \mathbbm{1}}{\mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}}
      \end{displaymath}
      The variance of the \emph{minimum variance} portfolio is equal to:
      \begin{displaymath}
        \sigma^2 = \frac{\mathbbm{1}^T \mathbb{C}^{-1} \mathbb{C} \, \mathbb{C}^{-1} \mathbbm{1}}{(\mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1})^2} = \frac{1}{\mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}}
      \end{displaymath}
      The function \texttt{solve()} solves systems of linear equations, and also inverts square matrices.
      \vskip1ex
      The \texttt{\%*\%} operator performs \emph{inner} (\emph{scalar}) multiplication of vectors and matrices.
      \vskip1ex
      \emph{Inner} multiplication multiplies the rows of one matrix with the columns of another matrix, so that each pair produces a single number:
      \vskip1ex
      The function \texttt{drop()} removes any dimensions of length \emph{one}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate covariance matrix of returns and its inverse
covmat <- cov(returns)
covinv <- solve(a=covmat)
unitv <- rep(1, NCOL(covmat))
# Minimum variance weights with constraint
# weights <- solve(a=covmat, b=unitv)
weights <- covinv %*% unitv
weights <- weights / drop(t(unitv) %*% weights)
# Minimum variance
t(weights) %*% covmat %*% weights
1/(t(unitv) %*% covinv %*% unitv)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Efficient Portfolios}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A portfolio which has the smallest variance, given a target return, is an \emph{efficient portfolio}.
      \vskip1ex
      The \emph{efficient portfolio} weights have two constraints: the sum of portfolio weights $\mathbf{w}$ is equal to \texttt{1}: $\mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1$, and the mean portfolio return is equal to the target return $r_t$: $\mathbf{w}^T \mathbf{r} = {\sum_{i=1}^n w_i r_i} = r_t$.
      \vskip1ex
      The weights that minimize the portfolio variance under these constraints can be found by minimizing the \emph{Lagrangian}:
      \begin{displaymath}
        \mathcal{L} = \mathbf{w}^T \mathbb{C} \, \mathbf{w} - \, \lambda1 \, (\mathbf{w}^T \mathbbm{1} - 1) - \, \lambda2 \, (\mathbf{w}^T \mathbf{r} - r_t)
      \end{displaymath}
      Where $\lambda1$ and $\lambda2$ are the \emph{Lagrange multipliers}.
      \vskip1ex
      The derivative of the \emph{Lagrangian} $\mathcal{L}$ with respect to $\mathbf{w}$ is given by:
      \begin{displaymath}
        d_w \mathcal{L} = 2 \mathbf{w}^T \mathbb{C} - \lambda1 \mathbbm{1}^T - \lambda2 \mathbf{r}^T
      \end{displaymath}
      By setting the derivative to zero we obtain the \emph{efficient portfolio} weights $\mathbf{w}$:
      \begin{displaymath}
        \mathbf{w} = \frac{1}{2} (\lambda1 \, \mathbb{C}^{-1} \mathbbm{1} + \lambda2 \, \mathbb{C}^{-1} \mathbf{r})
      \end{displaymath}
    \column{0.5\textwidth}
      By multiplying the above from the left first by $\mathbbm{1}^T$, and then by $\mathbf{r}^T$, we obtain a system of two equations for $\lambda1$ and $\lambda2$:
      \begin{align*}
        2 \mathbbm{1}^T \mathbf{w} = \lambda1 \, \mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1} + \lambda2 \, \mathbbm{1}^T \mathbb{C}^{-1} \mathbf{r} = 2\\
        2 \mathbf{r}^T \mathbf{w} = \lambda1 \, \mathbf{r}^T \mathbb{C}^{-1} \mathbbm{1} + \lambda2 \, \mathbf{r}^T \mathbb{C}^{-1} \mathbf{r} = 2 r_t
      \end{align*}
      The above can be written in matrix notation as:
      \begin{displaymath}
        \begin{bmatrix}
          \mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1} & \mathbbm{1}^T \mathbb{C}^{-1} \mathbf{r} \\
          \mathbf{r}^T \mathbb{C}^{-1} \mathbbm{1} & \mathbf{r}^T \mathbb{C}^{-1} \mathbf{r}
        \end{bmatrix}
        \begin{bmatrix}
          \lambda1 \\
          \lambda2
        \end{bmatrix} =
        \begin{bmatrix}
          2 \\
          2 r_t
        \end{bmatrix}
      \end{displaymath}
      Or:
      \begin{displaymath}
        \begin{bmatrix}
          a & b \\
          b & c
        \end{bmatrix}
        \begin{bmatrix}
          \lambda1 \\
          \lambda2
        \end{bmatrix} =
        \mathbb{F} \lambda =
        2 \begin{bmatrix}
          1 \\
          r_t
        \end{bmatrix} =
        2 u
      \end{displaymath}
      With $a = \mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}$, $b = \mathbbm{1}^T \mathbb{C}^{-1} \mathbf{r}$, $c = \mathbf{r}^T \mathbb{C}^{-1} \mathbf{r}$,
      $\lambda = \begin{bmatrix}
          \lambda1 \\
          \lambda2
        \end{bmatrix}$,
      $u = \begin{bmatrix}
          1 \\
          r_t
        \end{bmatrix}$,
        and
      $\mathbb{F} = u^T \mathbb{C}^{-1} u = \begin{bmatrix}
          a & b \\
          b & c
        \end{bmatrix}$.
      \vskip1ex
      The \emph{Lagrange multipliers} can be solved as:
      \begin{displaymath}
        \lambda = 2 \mathbb{F}^{-1} u
      \end{displaymath}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Efficient Portfolio} Weights}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{efficient portfolio} weights $\mathbf{w}$ can now be solved as:
      \begin{align*}
        \mathbf{w} = \frac{1}{2} (\lambda1 \, \mathbb{C}^{-1} \mathbbm{1} + \lambda2 \, \mathbb{C}^{-1} \mathbf{r}) = \\
        \frac{1}{2}
        {\begin{bmatrix}
          \mathbb{C}^{-1} \mathbbm{1} \\
          \mathbb{C}^{-1} \mathbf{r}
        \end{bmatrix}}^T
        \lambda =
        {\begin{bmatrix}
          \mathbb{C}^{-1} \mathbbm{1} \\
          \mathbb{C}^{-1} \mathbf{r}
        \end{bmatrix}}^T
        \mathbb{F}^{-1} \, u = \\
        \frac{1}{a c-b^2}
        {\begin{bmatrix}
          \mathbb{C}^{-1} \mathbbm{1} \\
          \mathbb{C}^{-1} \mathbf{r}
        \end{bmatrix}}^T
        \begin{bmatrix}
          c & -b \\
          -b & a
        \end{bmatrix}
        \begin{bmatrix}
          1 \\
          r_t
        \end{bmatrix} = \\
        \frac{(c - b r_t)  \, \mathbb{C}^{-1} \mathbbm{1} + (a r_t - b)  \, \mathbb{C}^{-1} \mathbf{r}}{a c-b^2}
      \end{align*}
      With $a = \mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}$, $b = \mathbbm{1}^T \mathbb{C}^{-1} \mathbf{r}$, $c = \mathbf{r}^T \mathbb{C}^{-1} \mathbf{r}$.
      \vskip1ex
      The above formula shows that a convex sum of two \emph{efficient portfolio} weights: $w = \alpha w1 + (1-\alpha) w2$ \\
      Are also the weights of an \emph{efficient portfolio}, with target return equal to: $r_t = \alpha r1 + (1-\alpha) r2$
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate vector of mean returns
mean_rets <- colMeans(returns)
# Specify the target return
targetr <- 1.5*mean(returns)
# Products of inverse with mean returns and unit vector
fmat <- matrix(c(
  t(unitv) %*% covinv %*% unitv,
  t(unitv) %*% covinv %*% mean_rets,
  t(mean_rets) %*% covinv %*% unitv,
  t(mean_rets) %*% covinv %*% mean_rets), nc=2)
# Solve for the Lagrange multipliers
lagm <- solve(a=fmat, b=c(2, 2*targetr))
# Calculate weights
weights <- drop(0.5*covinv %*% cbind(unitv, mean_rets) %*% lagm)
# Calculate constraints
all.equal(1, sum(weights))
all.equal(targetr, sum(mean_rets*weights))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Variance of the \protect\emph{Efficient Portfolios}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{efficient portfolio} variance is equal to:
      \begin{align*}
        \sigma^2 = \mathbf{w}^T \mathbb{C} \, \mathbf{w} = \frac{1}{4} \lambda^T \mathbb{F} \, \lambda = u^T \mathbb{F}^{-1} \, u =\\
        \frac{1}{a c-b^2}
        {\begin{bmatrix}
          1 \\
          r_t
        \end{bmatrix}}^T
        \begin{bmatrix}
          c & -b \\
          -b & a
        \end{bmatrix}
        \begin{bmatrix}
          1 \\
          r_t
        \end{bmatrix} =\\
        \frac{a r^2_t - 2b r_t + c}{a c-b^2}
      \end{align*}
      The above formula shows that the variance of the \emph{efficient portfolios} is a \emph{parabola} with respect to the target return $r_t$.
      \vskip1ex
      The vertex of the \emph{parabola} is at $r_t = \mathbbm{1}^T \mathbb{C}^{-1} \mathbf{r} / \mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}$ and $\sigma^2 = 1 / \mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1}$.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate portfolio return and standard deviation
retsp <- drop(returns %*% weights)
c(return=mean(retsp), sd=sd(retsp))
all.equal(mean(retsp), targetr)
# Calculate portfolio variance
uu <- c(1, targetr)
finv <- solve(fmat)
all.equal(var(retsp), drop(t(uu) %*% finv %*% uu))
# Calculate vertex of variance parabola
weights <- drop(covinv %*% unitv /
  drop(t(unitv) %*% covinv %*% unitv))
retsp <- drop(returns %*% weights)
retsv <- drop(t(unitv) %*% covinv %*% mean_rets /
  t(unitv) %*% covinv %*% unitv)
all.equal(mean(retsp), retsv)
varmin <- drop(1/t(unitv) %*% covinv %*% unitv)
all.equal(var(retsp), varmin)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Efficient Frontier}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{efficient frontier} is the plot of the \emph{efficient portfolio} standard deviations with respect to the target return $r_t$, which is a \emph{hyperbola}.
      <<echo=TRUE,eval=FALSE>>=
# Calculate efficient frontier
targets <- retsv*(1+seq(from=-1, to=1, by=0.1))
eff_front <- sapply(targets, function(targetr) {
  uu <- c(1, targetr)
  sqrt(drop(t(uu) %*% finv %*% uu))
})  # end sapply
# Plot efficient frontier
x11(width=6, height=5)
plot(x=eff_front, y=targets, t="l", col="blue", lwd=2,
     main="Efficient Frontier and Minimum Variance Portfolio",
     xlab="standard deviation", ylab="return")
points(x=sqrt(varmin), y=retsv, col="green", lwd=6)
text(x=sqrt(varmin), y=retsv, labels="minimum \nvariance",
     pos=4, cex=0.8)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Tangent Line} and the \protect\emph{Risk-free} Rate}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{tangent} line can be drawn at every point on the \protect\emph{efficient frontier}.
      \vskip1ex
      The slope $\beta$ of the \emph{tangent} line can be calculated by differentiating the variance $\sigma^2$ by the target return $r_t$:
      \begin{align*}
        \frac{d \sigma^2}{d r_t} = 2 \sigma \frac{d \sigma}{d r_t} = \frac{2 a r_t - 2 b}{a c-b^2} \\
        \frac{d \sigma}{d r_t} = \frac{a r_t - b}{\sigma \, (a c-b^2)} \\
        \beta = \frac{\sigma \, (a c-b^2)}{a r_t - b}
      \end{align*}
      The \emph{tangent} line connects the \emph{tangent} point on the \protect\emph{efficient frontier} with a \emph{risk-free} rate $r_f$.
    \column{0.5\textwidth}
      The \emph{risk-free} rate $r_f$ can be calculated as the intercept of the tangent line:
      \begin{align*}
        r_f = r_t - \sigma \, \beta = r_t - \frac{\sigma^2 \, (a c-b^2)}{a r_t - b} = \\
        r_t - \frac{a r^2_t - 2b r_t + c}{a c-b^2} \frac{a c-b^2}{a r_t - b} = \\
        r_t - \frac{a r^2_t - 2b r_t + c}{a r_t - b} = \frac{b r_t - c}{a r_t - b}
      \end{align*}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate portfolio standard deviation
stdev <- sqrt(drop(t(uu) %*% finv %*% uu))
# Calculate the slope of the tangent line
slopev <- (stdev*det(fmat))/(fmat[1, 1]*targetr-fmat[1, 2])
# Calculate the risk-free rate as intercept of the tangent line
riskf <- targetr - slopev*stdev
# Calculate the risk-free rate from target return
riskf <- (targetr*fmat[1, 2]-fmat[2, 2]) /
  (targetr*fmat[1, 1]-fmat[1, 2])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Tangent Line} on the \protect\emph{Efficient Frontier}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{efficient portfolios} are also called \emph{tangency portfolios}, since they are the tangent points on the \emph{efficient frontier}.
      \vskip1ex
      The \emph{tangency portfolio} is the \emph{market portfolio} corresponding to the given \emph{risk-free} rate.
      \vskip1ex
      The \emph{tangent line} at the \emph{market portfolio} is known as the \emph{Capital Market Line} (CML).
      <<echo=TRUE,eval=FALSE>>=
# Plot efficient frontier
plot(x=eff_front, y=targets, t="l", col="blue", lwd=2,
     xlim=c(0.0, max(eff_front)),
     main="Efficient Frontier and Tangency Portfolio",
     xlab="standard deviation", ylab="return")
# Plot minimum variance
points(x=sqrt(varmin), y=retsv, col="green", lwd=6)
text(x=sqrt(varmin), y=retsv, labels="minimum \nvariance",
     pos=4, cex=0.8)
# Plot tangent point
points(x=stdev, y=targetr, col="red", lwd=6)
text(x=stdev, y=targetr, labels="tangency\nportfolio", pos=2, cex=0.8)
# Plot risk-free point
points(x=0, y=riskf, col="red", lwd=6)
text(x=0, y=riskf, labels="risk-free", pos=4, cex=0.8)
# Plot tangent line
abline(a=riskf, b=slopev, lwd=2, col="green")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_tangent2.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Maximum \protect\emph{Sharpe} Portfolio Weights}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Sharpe} ratio is defined as the ratio of excess returns divided by the portfolio standard deviation:
      \begin{displaymath}
        SR = \frac{\mathbf{w}^T \mu}{\sigma}
      \end{displaymath}
      Where $\mu = \mathbf{r} - r_f$ is the vector of excess returns (in excess of the risk-free rate $r_f$), $\mathbf{w}$ is the vector of portfolio weights, and $\sigma = \sqrt{\mathbf{w}^T \mathbb{C} \, \mathbf{w}}$, where $\mathbb{C}$ is the covariance matrix of returns.
      \vskip1ex
      We can calculate the maximum \emph{Sharpe} portfolio weights by setting the derivative of the \emph{Sharpe} ratio with respect to the weights, to zero:
      \begin{displaymath}
        d_w {SR} = \frac{1}{\sigma} (\mu^T - \frac{(\mathbf{w}^T \mu) (\mathbf{w}^T \mathbb{C})}{\sigma^2}) = 0
      \end{displaymath}
      We then get:
      \begin{displaymath}
        (\mathbf{w}^T \mathbb{C} \, \mathbf{w}) \, \mu = (\mathbf{w}^T \mu) \, \mathbb{C} \mathbf{w}
      \end{displaymath}
      We can multiply the above equation by $\mathbb{C}^{-1}$ to get:
      \begin{displaymath}
        \mathbf{w} = \frac{\mathbf{w}^T \mathbb{C} \, \mathbf{w}}{\mathbf{w}^T \mu} \, \mathbb{C}^{-1} \mu
      \end{displaymath}
    \column{0.5\textwidth}
      We can finally rescale the weights so that they satisfy the constraint $\mathbf{w}^T \mathbbm{1} = 1$:
      \begin{displaymath}
        \mathbf{w} = \frac{\mathbb{C}^{-1} \mu}{\mathbbm{1}^T \mathbb{C}^{-1} \mu}
      \end{displaymath}
      These are the weights of the maximum \emph{Sharpe} portfolio, with the vector of excess returns equal to $\mu$, and the covariance matrix equal to $\mathbb{C}$.
      \vskip1ex
      The maximum \emph{Sharpe} portfolio is an \emph{efficient portfolio}, and so its mean return is equal to some target return $r_t$: $\mathbf{w}^T \mathbf{r} = {\sum_{i=1}^n w_i r_i} = r_t$.
      \vskip1ex
      The mean portfolio return can be written as:
      \begin{align*}
        \mathbf{r}^T \mathbf{w} = \frac{\mathbf{r}^T \mathbb{C}^{-1} \mu}{\mathbbm{1}^T \mathbb{C}^{-1} \mu} =
        \frac{\mathbf{r}^T \mathbb{C}^{-1} (\mathbf{r} - r_f)}{\mathbbm{1}^T \mathbb{C}^{-1} (\mathbf{r} - r_f)} = \\
        r_t = \frac{\mathbf{r}^T \mathbb{C}^{-1} \mathbbm{1} \, r_f - \mathbf{r}^T \mathbb{C}^{-1} \mathbf{r}}{\mathbbm{1}^T \mathbb{C}^{-1} \mathbbm{1} \, r_f - \mathbf{r}^T \mathbb{C}^{-1} \mathbbm{1}}
      \end{align*}
      The above formula calculates the target return $r_t$ from the risk-free rate $r_f$.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Returns and Variance of Maximum \protect\emph{Sharpe} Portfolio}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The weights of the maximum \emph{Sharpe} portfolio are equal to:
      \begin{displaymath}
        \mathbf{w} = \frac{\mathbb{C}^{-1} \mu}{\mathbbm{1}^T \mathbb{C}^{-1} \mu}
      \end{displaymath}
      Where $\mu$ is the vector of excess returns, and $\mathbb{C}$ is the covariance matrix.
      \vskip1ex
      The excess returns of the maximum \emph{Sharpe} portfolio are equal to:
      \begin{displaymath}
        R = \mathbf{w}^T \mu = \frac{\mu^T \mathbb{C}^{-1} \mu}{\mathbbm{1}^T \mathbb{C}^{-1} \mu}
      \end{displaymath}
      The variance of the maximum \emph{Sharpe} portfolio is equal to:
      \begin{displaymath}
        \sigma^2 = \frac{\mu^T \mathbb{C}^{-1} \mathbb{C} \, \mathbb{C}^{-1} \mu}{(\mathbbm{1}^T \mathbb{C}^{-1} \mu)^2} = \frac{\mu^T \mathbb{C}^{-1} \mu}{(\mathbbm{1}^T \mathbb{C}^{-1} \mu)^2}
      \end{displaymath}
      The \emph{Sharpe} ratio is equal to:
      \begin{displaymath}
        SR = \sqrt{\mu^T \mathbb{C}^{-1} \mu}
      \end{displaymath}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate excess returns
riskf <- 0.03/252
excess <- returns - riskf
# Calculate covariance and inverse matrix
covmat <- cov(returns)
unitv <- rep(1, NCOL(covmat))
covinv <- solve(a=covmat)
# Calculate mean excess returns
excess <- sapply(excess, mean)
# Weights of maximum Sharpe portfolio
# weights <- solve(a=covmat, b=returns)
weights <- covinv %*% excess
weights <- weights/drop(t(unitv) %*% weights)
# Sharpe ratios
sqrt(252)*sum(weights * excess) /
  sqrt(drop(weights %*% covmat %*% weights))
sapply(returns - riskf,
  function(x) sqrt(252)*mean(x)/sd(x))
weights_maxsharpe <- weights
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Portfolios Under Zero Correlation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the correlations of returns are equal to zero, then the covariance matrix is diagonal:
      \begin{displaymath}
        \mathbb{C} = \begin{pmatrix}
          \sigma^21 & 0 & \cdots & 0 \\
          0 & \sigma^22 & \cdots & 0 \\
          \vdots  & \vdots  & \ddots & \vdots  \\
          0 & 0 & \cdots & \sigma^2_n
        \end{pmatrix}
      \end{displaymath}
      Where $\sigma^2_i$ is the variance of returns of asset \texttt{i}.
      \vskip1ex
      The inverse of $\mathbb{C}$ is then simply:
      \begin{displaymath}
        \mathbb{C}^{-1} = \begin{pmatrix}
          \sigma^{-2}1 & 0 & \cdots & 0 \\
          0 & \sigma^{-2}2 & \cdots & 0 \\
          \vdots  & \vdots  & \ddots & \vdots  \\
          0 & 0 & \cdots & \sigma^{-2}_n
        \end{pmatrix}
      \end{displaymath}
    \column{0.5\textwidth}
      The \emph{minimum variance} portfolio weights are proportional to the inverse of the individual variances:
      \begin{displaymath}
        w_i = \frac{1}{\sigma^2_i \sum_{i=1}^n \sigma^{-2}_i}
      \end{displaymath}
      The maximum \emph{Sharpe} portfolio weights are proportional to the ratio of excess returns divided by the individual variances:
      \begin{displaymath}
        w_i = \frac{\mu_i}{\sigma^2_i \sum_{i=1}^n \mu_i \sigma^{-2}_i}
      \end{displaymath}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Portfolio Optimization Using Principal Components}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      First apply Principal Component Analysis and then perform portfolio optimization using the principal components.
      \vskip1ex
      If the correlations of returns are equal to zero, then the covariance matrix is diagonal:
      \begin{displaymath}
        \mathbb{C} = \begin{pmatrix}
          \sigma^21 & 0 & \cdots & 0 \\
          0 & \sigma^22 & \cdots & 0 \\
          \vdots  & \vdots  & \ddots & \vdots  \\
          0 & 0 & \cdots & \sigma^2_n
        \end{pmatrix}
      \end{displaymath}
      Where $\sigma^2_i$ is the variance of returns of asset \texttt{i}.
      \vskip1ex
      The inverse of $\mathbb{C}$ is then simply:
      \begin{displaymath}
        \mathbb{C}^{-1} = \begin{pmatrix}
          \sigma^{-2}1 & 0 & \cdots & 0 \\
          0 & \sigma^{-2}2 & \cdots & 0 \\
          \vdots  & \vdots  & \ddots & \vdots  \\
          0 & 0 & \cdots & \sigma^{-2}_n
        \end{pmatrix}
      \end{displaymath}
    \column{0.5\textwidth}
      The \emph{minimum variance} portfolio weights are proportional to the inverse of the individual variances:
      \begin{displaymath}
        w_i = \frac{1}{\sigma^2_i \sum_{i=1}^n \sigma^{-2}_i}
      \end{displaymath}
      The maximum \emph{Sharpe} portfolio weights are proportional to the ratio of excess returns divided by the individual variances:
      \begin{displaymath}
        w_i = \frac{\mu_i}{\sigma^2_i \sum_{i=1}^n \mu_i \sigma^{-2}_i}
      \end{displaymath}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Maximum \protect\emph{Sharpe} and \protect\emph{Minimum Variance} Performance}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The maximum \emph{Sharpe} and \emph{Minimum Variance} portfolios are both \emph{efficient portfolios}, with the lowest risk (standard deviation) for the given level of return.
      <<echo=TRUE,eval=FALSE>>=
library(quantmod)
# Calculate minimum variance weights
weights <- covinv %*% unitv
weights_minvar <- weights/drop(t(unitv) %*% weights)
# Calculate optimal portfolio returns
optim_rets <- xts(
  x=cbind(exp(cumsum(returns %*% weights_maxsharpe)),
          exp(cumsum(returns %*% weights_minvar))),
  order.by=index(returns))
colnames(optim_rets) <- c("maxsharpe", "minvar")
# Plot optimal portfolio returns, with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "green")
x11(width=6, height=5)
chart_Series(optim_rets, theme=plot_theme,
  name="Maximum Sharpe and
  Minimum Variance portfolios")
legend("top", legend=colnames(optim_rets), cex=0.8,
       inset=0.1, bg="white", lty=1, lwd=6,
       col=plot_theme$col$line.col, bty="n")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/maxsharpe_minvar.png}\\
      The \emph{Capital Market Line} represents delevered and levered portfolios, consisting of the \emph{market portfolio} combined with the \emph{risk-free} rate.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Efficient Frontier} and \protect\emph{Capital Market Line}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The maximum \emph{Sharpe} portfolio weights depend on the value of the risk-free rate $r_f$,
      \begin{displaymath}
        \mathbf{w} = \frac{\mathbb{C}^{-1} (\mathbf{r} - r_f)}{\mathbbm{1}^T \mathbb{C}^{-1} (\mathbf{r} - r_f)}
      \end{displaymath}
      The \emph{Efficient Frontier} is the set of \emph{efficient portfolios}, that have the lowest risk (standard deviation) for the given level of return.
      \vskip1ex
      The maximum \emph{Sharpe} portfolios are \emph{efficient portfolios}, and they lie on the \emph{Efficient Frontier}, forming a tangent line from the risk-free rate to the \emph{Efficient Frontier}, known as the \emph{Capital Market Line} (CML).
      \vskip1ex
      The maximum \emph{Sharpe} portfolios are considered to be the \emph{market portfolios}, corresponding to different values of the risk-free rate $r_f$.
      \vskip1ex
      The maximum \emph{Sharpe} portfolios are also called \emph{tangency} portfolios, since they are the tangent point on the \emph{Efficient Frontier}.
      \vskip1ex
      The \emph{Capital Market Line} is the line drawn from the \emph{risk-free} rate to the \emph{market portfolio} on the \emph{Efficient Frontier}.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_market.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting \protect\emph{Efficient Frontier} and Maximum \protect\emph{Sharpe} Portfolios}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
x11(wid_th <- 6, hei_ght <- 6)
# Calculate minimum variance weights
weights <- covinv %*% unitv
weights <- weights / drop(t(unitv) %*% weights)
# Minimum standard deviation and return
stdev <- sqrt(252*drop(weights %*% covmat %*% weights))
min_ret <- 252*sum(weights * mean_rets)
# Calculate maximum Sharpe portfolios
riskf <- (min_ret * seq(-10, 10, by=0.1)^3)/252
eff_front <- sapply(riskf, function(riskf) {
  weights <- covinv %*% (mean_rets - riskf)
  weights <- weights/drop(t(unitv) %*% weights)
  # Portfolio return and standard deviation
  c(return=252*sum(weights * mean_rets),
    stddev=sqrt(252*drop(weights %*% covmat %*% weights)))
})  # end sapply
eff_front <- cbind(252*riskf, t(eff_front))
colnames(eff_front)[1] <- "risk-free"
eff_front <- eff_front[is.finite(eff_front[, "stddev"]), ]
eff_front <- eff_front[order(eff_front[, "return"]), ]
# Plot maximum Sharpe portfolios
plot(x=eff_front[, "stddev"],
     y=eff_front[, "return"], t="l",
     xlim=c(0.0*stdev, 3.0*stdev),
     ylim=c(0.0*min_ret, 2.0*min_ret),
     main="Efficient Frontier and Capital Market Line",
     xlab="standard deviation", ylab="return")
points(x=eff_front[, "stddev"], y=eff_front[, "return"],
       col="red", lwd=3)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_market.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting the \protect\emph{Capital Market Line}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot minimum variance portfolio
points(x=stdev, y=min_ret, col="green", lwd=6)
text(stdev, min_ret, labels="minimum \nvariance",
     pos=4, cex=0.8)
# Draw Capital Market Line
sortv <- sort(eff_front[, 1])
riskf <- sortv[findInterval(x=0.5*min_ret, vec=sortv)]
points(x=0, y=riskf, col="blue", lwd=6)
text(x=0, y=riskf, labels="risk-free",
     pos=4, cex=0.8)
indeks <- match(riskf, eff_front[, 1])
points(x=eff_front[indeks, "stddev"],
       y=eff_front[indeks, "return"],
       col="blue", lwd=6)
text(x=eff_front[indeks, "stddev"],
     y=eff_front[indeks, "return"],
     labels="market portfolio",
     pos=2, cex=0.8)
sharp_e <- (eff_front[indeks, "return"]-riskf)/
  eff_front[indeks, "stddev"]
abline(a=riskf, b=sharp_e, col="blue", lwd=2)
text(x=0.7*eff_front[indeks, "stddev"],
     y=0.7*eff_front[indeks, "return"]+0.01,
     labels="Capital Market Line", pos=2, cex=0.8,
     srt=45*atan(sharp_e*hei_ght/wid_th)/(0.25*pi))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_market.png}\\
      \vspace{-1em}
      The \emph{Capital Market Line} represents delevered and levered portfolios, consisting of the \emph{market portfolio} combined with the \emph{risk-free} rate.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Random Portfolios}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate random portfolios
n_portf <- 1000
ret_sd <- sapply(1:n_portf, function(indeks) {
  weights <- runif(nweights-1, min=-0.25, max=1.0)
  weights <- c(weights, 1-sum(weights))
  # Portfolio return and standard deviation
  c(return=252*sum(weights * mean_rets),
    stddev=sqrt(252*drop(weights %*% covmat %*% weights)))
})  # end sapply
# Plot scatterplot of random portfolios
x11(wid_th <- 6, hei_ght <- 6)
plot(x=ret_sd["stddev", ], y=ret_sd["return", ],
     main="Efficient Frontier and Random Portfolios",
     xlim=c(0.5*stdev, 0.8*max(ret_sd["stddev", ])),
     xlab="standard deviation", ylab="return")
# Plot maximum Sharpe portfolios
lines(x=eff_front[, "stddev"],
     y=eff_front[, "return"], lwd=2)
points(x=eff_front[, "stddev"], y=eff_front[, "return"],
       col="red", lwd=3)
# Plot minimum variance portfolio
points(x=stdev, y=min_ret, col="green", lwd=6)
text(stdev, min_ret, labels="minimum\nvariance",
     pos=2, cex=0.8)
# Plot market portfolio
points(x=eff_front[indeks, "stddev"],
       y=eff_front[indeks, "return"], col="green", lwd=6)
text(x=eff_front[indeks, "stddev"],
     y=eff_front[indeks, "return"],
     labels="market\nportfolio",
     pos=2, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_random.png}\\
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot individual assets
points(x=sqrt(252*diag(covmat)),
       y=252*mean_rets, col="blue", lwd=6)
text(x=sqrt(252*diag(covmat)), y=252*mean_rets,
     labels=names(mean_rets),
     col="blue", pos=1, cex=0.8)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Plotting Random Portfolios Without Using Covariance Matrix}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Vector of symbol names
symbolv <- c("VTI", "IEF", "DBC")
nweights <- NROW(symbolv)
# Calculate random portfolios
n_portf <- 1000
ret_sd <- sapply(1:n_portf, function(indeks) {
  weights <- runif(nweights, min=0, max=10)
  weights <- weights/sum(weights)
  retsp <- etf_env$returns[, symbolv] %*% weights
  100*c(ret=mean(retsp), sd=sd(retsp))
})  # end sapply
# Plot scatterplot of random portfolios
x11(width=6, height=5)
plot(x=ret_sd[2, ], y=ret_sd[1, ], xlim=c(0, max(ret_sd[2, ])),
     main="Random portfolios",
     ylim=c(min(0, min(ret_sd[1, ])), max(ret_sd[1, ])),
     xlab=rownames(ret_sd)[2], ylab=rownames(ret_sd)[1])
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_random.png}\\
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot individual assets
points(x=sqrt(252*diag(covmat)),
       y=252*mean_rets, col="blue", lwd=6)
text(x=sqrt(252*diag(covmat)), y=252*mean_rets,
     labels=names(mean_rets),
     col="blue", pos=1, cex=0.8)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Efficient Frontier for Two-asset Portfolios}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The covariance matrix for two assets is equal to:
      \begin{displaymath}
        \mathbb{C} = \begin{pmatrix}
          \sigma^21 & \sigma_{12} \\
          \sigma_{12} & \sigma^22
        \end{pmatrix}
      \end{displaymath}
      Where $\sigma_{12}$ is the covariance of returns between the two assets,
      The excess returns of a two-asset portfolio are equal to:
      \begin{displaymath}
        R = w \mu1 + (1 - w) \mu2
      \end{displaymath}
      Solving for the weight $\mathbf{w}$:
      \begin{displaymath}
        w = (R - \mu2) / (\mu1 - \mu2)
      \end{displaymath}
      \vskip1ex
      The variance of the maximum \emph{Sharpe} portfolio is equal to:
      \begin{displaymath}
        \sigma^2 = \frac{\mu^T \mathbb{C}^{-1} \mathbb{C} \, \mathbb{C}^{-1} \mu}{(\mathbbm{1}^T \mathbb{C}^{-1} \mu)^2} = \frac{\mu^T \mathbb{C}^{-1} \mu}{(\mathbbm{1}^T \mathbb{C}^{-1} \mu)^2}
      \end{displaymath}
    \column{0.5\textwidth}
      If the correlations of returns are equal to zero, then
      The \emph{minimum variance} portfolio weights are proportional to the inverse of the individual variances:
      \begin{displaymath}
        w_i = \frac{1}{\sigma^2_i \sum_{i=1}^n \sigma^{-2}_i}
      \end{displaymath}
      The maximum \emph{Sharpe} portfolio weights are proportional to the ratio of excess returns divided by the individual variances:
      \begin{displaymath}
        w_i = \frac{\mu_i}{\sigma^2_i \sum_{i=1}^n \mu_i \sigma^{-2}_i}
      \end{displaymath}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Efficient Frontier for Two-asset Portfolios}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<corr_two_assets,echo=TRUE,eval=FALSE>>=
riskf <- 0.03
returns <- c(asset1=0.05, asset2=0.06)
stdevs <- c(asset1=0.4, asset2=0.5)
cor_rel <- 0.6
covmat <- matrix(c(1, cor_rel, cor_rel, 1), nc=2)
covmat <- t(t(stdevs*covmat)*stdevs)
weights <- seq(from=-1, to=2, length.out=31)
weights <- cbind(weights, 1-weights)
retsp <- weights %*% returns
portf_sd <-
  sqrt(rowSums(weights * (weights %*% covmat)))
sharper <- (retsp-riskf)/portf_sd
indeks <- which.max(sharper)
sharpem <- max(sharper)
# Plot efficient frontier
x11(wid_th <- 6, hei_ght <- 5)
par(mar=c(3,3,2,1)+0.1, oma=c(0, 0, 0, 0), mgp=c(2, 1, 0))
plot(portf_sd, retsp, t="l",
 main=paste0("Efficient frontier and CML for two assets\ncorrelation = ", 100*cor_rel, "%"),
 xlab="standard deviation", ylab="return",
 lwd=2, col="orange",
 xlim=c(0, max(portf_sd)),
 ylim=c(0.02, max(retsp)))
# Add Market Portfolio (maximum Sharpe ratio portfolio)
points(portf_sd[indeks], retsp[indeks],
       col="blue", lwd=3)
text(x=portf_sd[indeks], y=retsp[indeks],
     labels=paste(c("market portfolio\n",
       structure(c(weights[indeks], 1-weights[indeks]),
               namesv=names(returns))), collapse=" "),
     pos=2, cex=0.8)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/cml_two_assets.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot individual assets
points(stdevs, returns, col="green", lwd=3)
text(stdevs, returns, labels=names(returns), pos=4, cex=0.8)
# Add point at risk-free rate and draw Capital Market Line
points(x=0, y=riskf, col="blue", lwd=3)
text(0, riskf, labels="risk-free\nrate", pos=4, cex=0.8)
abline(a=riskf, b=sharpem, lwd=2, col="blue")
range_s <- par("usr")
text(portf_sd[indeks]/2, (retsp[indeks]+riskf)/2,
     labels="Capital Market Line", cex=0.8, , pos=3,
     srt=45*atan(sharpem*(range_s[2]-range_s[1])/
                   (range_s[4]-range_s[3])*
                   hei_ght/wid_th)/(0.25*pi))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Efficient Frontier of Stock and Bond Portfolios}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:3)),eval=FALSE>>=
# Plot portfolios in x11() window
x11(wid_th <- 6, hei_ght <- 5)
par(oma=c(0, 0, 0, 0), mar=c(3,3,2,1)+0.1, mgp=c(2, 1, 0), cex.lab=1.0, cex.axis=1.0, cex.main=1.0, cex.sub=1.0)
# Vector of symbol names
symbolv <- c("VTI", "IEF")
# Matrix of portfolio weights
weights <- seq(from=-1, to=2, length.out=31)
weights <- cbind(weights, 1-weights)
# Calculate portfolio returns and volatilities
returns <- rutils::etf_env$returns[, symbolv]
ret_sd <- returns %*% t(weights)
ret_sd <- cbind(252*colMeans(ret_sd),
  sqrt(252)*matrixStats::colSds(ret_sd))
colnames(ret_sd) <- c("returns", "stddev")
riskf <- 0.06
ret_sd <- cbind(ret_sd,
  (ret_sd[, "returns"]-riskf)/ret_sd[, "stddev"])
colnames(ret_sd)[3] <- "Sharpe"
indeks <- which.max(ret_sd[, "Sharpe"])
sharpem <- ret_sd[indeks, "Sharpe"]
plot(x=ret_sd[, "stddev"], y=ret_sd[, "returns"],
     main="Stock and Bond portfolios", t="l",
     xlim=c(0, 0.7*max(ret_sd[, "stddev"])), ylim=c(0, max(ret_sd[, "returns"])),
     xlab="standard deviation", ylab="return")
# Add blue point for market portfolio
points(x=ret_sd[indeks, "stddev"], y=ret_sd[indeks, "returns"], col="blue", lwd=6)
text(x=ret_sd[indeks, "stddev"], y=ret_sd[indeks, "returns"],
     labels=paste(c("market portfolio\n", structure(c(weights[indeks, 1], weights[indeks, 2]), namesv=symbolv)), collapse=" "),
     pos=3, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_stocks_bonds.png}\\
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot individual assets
mean_rets <- 252*sapply(returns, mean)
stdevs <- sqrt(252)*sapply(returns, sd)
points(stdevs, mean_rets, col="green", lwd=6)
text(stdevs, mean_rets, labels=names(returns), pos=2, cex=0.8)
# Add point at risk-free rate and draw Capital Market Line
points(x=0, y=riskf, col="blue", lwd=6)
text(0, riskf, labels="risk-free", pos=4, cex=0.8)
abline(a=riskf, b=sharpem, col="blue", lwd=2)
range_s <- par("usr")
text(max(ret_sd[, "stddev"])/3, 0.75*max(ret_sd[, "returns"]),
     labels="Capital Market Line", cex=0.8, , pos=3,
     srt=45*atan(sharpem*(range_s[2]-range_s[1])/
                   (range_s[4]-range_s[3])*
                   hei_ght/wid_th)/(0.25*pi))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performance of Market Portfolio for Stocks and Bonds}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
# Plot portfolios in x11() window
x11(wid_th <- 6, hei_ght <- 5)
# Calculate cumulative returns of VTI and IEF
optim_rets <- lapply(returns,
  function(returns) exp(cumsum(returns)))
optim_rets <- rutils::do_call(cbind, optim_rets)
# Calculate market portfolio returns
optim_rets <- cbind(exp(cumsum(returns %*%
    c(weights[indeks], 1-weights[indeks]))),
  optim_rets)
colnames(optim_rets)[1] <- "market"
# Plot market portfolio with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue", "green")
chart_Series(optim_rets, theme=plot_theme,
             name="Market portfolio for stocks and bonds")
legend("top", legend=colnames(optim_rets),
       cex=0.8, inset=0.1, bg="white", lty=1,
       lwd=6, col=plot_theme$col$line.col, bty="n")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/market_stocks_bonds.png}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Portfolio Optimization}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk (\protect\emph{CVaR})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Conditional Value at Risk} (\emph{CVaR}) is equal to the average of the \emph{VaR} for confidence levels less than a given confidence level $\alpha$:
      \begin{displaymath}
        \mathrm{CVaR} = \frac{1}{\alpha} \int_{0}^\alpha \mathrm{VaR}(p) \, \mathrm{d}p
      \end{displaymath}
      The \emph{Conditional Value at Risk} is also called the Expected Shortfall (\emph{ES}), or the Expected Tail Loss (\emph{ETL}).
      \vskip1ex
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data, and returns a list with a vector of loss values and a vector of corresponding densities.
      <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=4)
par(mar=c(3, 2, 1, 0), oma=c(0, 0, 0, 0))
# VTI percentage returns
returns <- rutils::diff_it(log(quantmod::Cl(rutils::etf_env$VTI)))
confl <- 0.1
varisk <- quantile(returns, confl)
cvar <- mean(returns[returns < varisk])
# Or
sort_ed <- sort(as.numeric(returns))
indeks <- round(confl*NROW(returns))
varisk <- sort_ed[indeks]
cvar <- mean(sort_ed[1:indeks])
# Plot histogram of VTI returns
varm <- (-0.05)
histo_gram <- hist(returns, col="lightgrey",
  xlab="returns", breaks=100, xlim=c(varm, 0.01),
  ylab="frequency", freq=FALSE, main="VTI Returns Histogram")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_var.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot density of losses
densv <- density(returns, adjust=1.5)
lines(densv, lwd=3, col="blue")
# Add line for VaR
abline(v=varisk, col="red", lwd=3)
ymax <- max(densv$y)
text(x=varisk, y=2*ymax/3, labels="VaR", lwd=2, pos=2)
# Add shading for CVaR
rangev <- (densv$x < varisk) & (densv$x > varm)
polygon(
  c(varm, densv$x[rangev], varisk),
  c(0, densv$y[rangev], 0),
  col=rgb(1, 0, 0,0.5), border=NA)
text(x=1.5*varisk, y=ymax/7, labels="CVaR", lwd=2, pos=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CVaR} Portfolio Weights Using Linear Programming}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The weights of the minimum \emph{CVaR} portfolio can be calculated using linear programming (\emph{LP}), which is the optimization of linear objective functions subject to linear constraints,
      \begin{displaymath}
        w_{min} = \operatorname*{arg\,max}_{w} [ \, \sum_{i=1}^n w_i b_i \, ]
      \end{displaymath}
      Where $b_i$ is the negative objective vector, and $\mathbf{w}$ is the vector of returns weights, constrained by:
      \begin{align*}
        \mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1\\
        0 \leq w_i \leq 1
      \end{align*}
      The function \texttt{Rglpk\_solve\_LP()} from package \emph{Rglpk} solves linear programming problems by calling the \emph{GNU Linear Programming Kit} library.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(rutils)  # Load rutils
library(Rglpk)
# Vector of symbol names and returns
symbolv <- c("VTI", "IEF", "DBC")
nweights <- NROW(symbolv)
returns <- rutils::etf_env$returns[((NROW(returns)-6):NROW(returns)), symbolv]
mean_rets <- colMeans(returns)
confl <- 0.05
rmin <- 0 ; wmin <- 0 ; wmax <- 1
weightsum <- 1
ncols <- NCOL(returns) # number of assets
nrows <- NROW(returns) # number of rows
# Create objective vector
objvec <- c(numeric(ncols), rep(-1/(confl/nrows), nrows), -1)
# Specify weight constraints
constr <- rbind(
  cbind(rbind(1, mean_rets),
        matrix(data=0, nrow=2, ncol=(nrows+1))),
  cbind(coredata(returns), diag(nrows), 1))
rhs <- c(weightsum, rmin, rep(0, nrows))
directs <- c("==", ">=", rep(">=", nrows))
# Specify weight bounds
bounds <- list(lower=list(ind=1:ncols, val=rep(wmin, ncols)),
               upper=list(ind=1:ncols, val=rep(wmax, ncols)))
# Perform optimization
optimd <- Rglpk_solve_LP(obj=objvec, mat=constr, dir=directs, rhs=rhs, types=rep("C", NROW(objvec)), max=T, bounds=bounds)
optimd$solution
constr %*% optimd$solution
objvec %*% optimd$solution
as.numeric(optimd$solution[1:ncols])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Sharpe} Ratio Objective Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{optimize()} performs \emph{one-dimensional} optimization over a single independent variable.
      \vskip1ex
      \texttt{optimize()} searches for the minimum of the objective function with respect to its first argument, in the specified interval.
      \vspace{-1em}
        <<echo=(-(1:3)),eval=FALSE>>=
# Calculate daily percentage returns
symbolv <- c("VTI", "IEF", "DBC")
returns <- rutils::etf_env$returns[, symbolv]
# Create initial vector of portfolio weights
weights <- rep(1, NROW(symbolv))
names(weights) <- symbolv
# Objective equal to minus Sharpe ratio
object <- function(weights, returns) {
  retsp <- returns %*% weights
  if (sd(retsp) == 0)
    return(0)
  else
    return(-mean(retsp)/sd(retsp))
}  # end object
# Objective for equal weight portfolio
object(weights, returns=returns)
optimd <- unlist(optimize(
  f=function(weight)
    object(c(1, 1, weight), returns=returns),
  interval=c(-4, 1)))
# Vectorize objective function with respect to third weight
objvec <- function(weights) sapply(weights,
  function(weight) object(c(1, 1, weight),
    returns=returns))
# Or
objvec <- Vectorize(FUN=function(weight)
    object(c(1, 1, weight), returns=returns),
  vectorize.args="weight")  # end Vectorize
objvec(1)
objvec(1:3)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_obj_one_dim.png}
      \vspace{-1em}
        <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=5)
par(oma=c(1, 1, 1, 1), mgp=c(2, 1, 0), mar=c(3, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# Plot objective function with respect to third weight
curve(expr=objvec,
      type="l", xlim=c(-4.0, 1.0),
      xlab=paste("weight of", names(weights[3])),
      ylab="", lwd=2)
title(main="Objective Function", line=-1)  # Add title
points(x=optimd[1], y=optimd[2], col="green", lwd=6)
text(x=optimd[1], y=optimd[2],
     labels="minimum objective", pos=4, cex=0.8)

### below is simplified code for plotting objective function
# Create vector of DBC weights
weights <- seq(from=-4, to=1, by=0.1)
obj_val <- sapply(weights,
  function(weight) object(c(1, 1, weight)))
plot(x=weights, y=obj_val, t="l",
      xlab="weight of DBC", ylab="", lwd=2)
title(main="Objective Function", line=-1)  # Add title
points(x=optimd[1], y=optimd[2], col="green", lwd=6)
text(x=optimd[1], y=optimd[2],
     labels="minimum objective", pos=4, cex=0.8)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Perspective Plot of Portfolio Objective Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{persp()} plots a 3d perspective surface plot of a function specified over a grid of argument values.
      \vskip1ex
      The function \texttt{outer()} calculates the values of a function over a grid spanned by two variables, and returns a matrix of function values.
      \vskip1ex
      The package \emph{rgl} allows creating \emph{interactive} 3d scatterplots and surface plots including perspective plots, based on the \emph{OpenGL} framework.
      <<portf_persp,echo=TRUE,eval=FALSE,fig.width=10,fig.height=10,fig.show='hide'>>=
# Vectorize function with respect to all weights
objvec <- Vectorize(
  FUN=function(w1, w2, w3) object(c(w1, w2, w3)),
  vectorize.args=c("w2", "w3"))  # end Vectorize
# Calculate objective on 2-d (w2 x w3) parameter grid
w2 <- seq(-3, 7, length=50)
w3 <- seq(-5, 5, length=50)
grid_object <- outer(w2, w3, FUN=objvec, w1=1)
rownames(grid_object) <- round(w2, 2)
colnames(grid_object) <- round(w3, 2)
# Perspective plot of objective function
persp(w2, w3, -grid_object,
      theta=45, phi=30, shade=0.5,
      col=rainbow(50), border="green",
      main="objective function")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/portf_persp.png}
    \vspace{-3em}
      <<echo=TRUE,eval=FALSE,fig.width=10,fig.height=10>>=
# Interactive perspective plot of objective function
library(rgl)
rgl::persp3d(z=-grid_object, zlab="objective",
        col="green", main="objective function")
rgl::persp3d(
  x=function(w2, w3) {-objvec(w1=1, w2, w3)},
  xlim=c(-3, 7), ylim=c(-5, 5),
  col="green", axes=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Multi-dimensional Portfolio Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Vector of initial portfolio weights equal to 1
weights <- rep(1, nweights)
names(weights) <- symbolv
# Objective function equal to standard deviation of returns
object <- function(weights) {
  retsp <- returns %*% weights
  sd(retsp)/sum(weights)
}  # end object
# object() for equal weight portfolio
object(weights)
object(2*weights)
# Perform portfolio optimization
optimd <- optim(par=weights,
                fn=object,
                method="L-BFGS-B",
                upper=rep(10, nweights),
                lower=rep(-10, nweights))
# Rescale the optimal weights
weights <- optimd$par/sum(optimd$par)
# Minimum variance portfolio returns
optim_rets <- xts(x=returns %*% weights,
                  order.by=index(returns))
chart_Series(x=exp(cumsum(optim_rets)), name="minvar portfolio")
# Add green point for minimum variance portfolio
optim_sd <- 100*sd(optim_rets)
optim_ret <- 100*mean(optim_rets)
points(x=optim_sd, y=optim_ret, col="green", lwd=6)
text(x=optim_sd, y=optim_ret, labels="minvar", pos=2, cex=0.8)


# Objective function equal to minus Sharpe ratio
riskf <- 0.03
object <- function(weights) {
  retsp <- 100*etf_env$returns[, names(weights)] %*% weights / sum(weights)
  -mean(retsp-riskf)/sd(retsp)
}  # end object
# Perform portfolio optimization
optimd <- optim(par=weights,
                   fn=object,
                   method="L-BFGS-B",
                   upper=rep(10, nweights),
                   lower=rep(-10, nweights))
# Maximum Sharpe ratio portfolio returns
weights <- optimd$par/sum(optimd$par)
optim_rets <- xts(x=returns %*% weights,
                  order.by=index(returns))
chart_Series(x=exp(cumsum(optim_rets)), name="maxSR portfolio")
optim_sd <- 100*sd(optim_rets)
optim_ret <- 100*mean(optim_rets)
points(x=optim_sd, y=optim_ret,
       col="blue", lwd=3)
text(x=optim_sd, y=optim_ret,
     labels="maxSR", pos=2, cex=0.8)
sharpem <- (optim_ret-riskf)/optim_sd
# Plot individual assets
mean_rets <- 100*sapply(returns, mean)
stdevs <- 100*sapply(returns, sd)
points(stdevs, mean_rets, col="green", lwd=3)
text(stdevs, mean_rets, labels=names(mean_rets), pos=2, cex=0.8)
# Add point at risk-free rate and draw Capital Market Line
points(x=0, y=riskf)
text(0, riskf, labels="risk-free", pos=4, cex=0.8)
abline(a=riskf, b=sharpem, col="blue")
range_s <- par("usr")
text(optim_sd/3, (optim_ret+riskf)/2.5,
     labels="Capital Market Line", cex=0.8, , pos=3,
     srt=45*atan(sharpem*(range_s[2]-range_s[1])/
                   (range_s[4]-range_s[3])*
                   hei_ght/wid_th)/(0.25*pi))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/eff_front_random.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Multi-dimensional Portfolio Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functional \texttt{optim()} performs \emph{multi-dimensional} optimization.
      \vskip1ex
      The argument \texttt{par} are the initial parameter values.
      \vskip1ex
      The argument \texttt{fn} is the objective function to be minimized.
      \vskip1ex
      The argument of the objective function which is to be optimized, must be a vector argument.
      \vskip1ex
      \texttt{optim()} accepts additional parameters bound to the dots \texttt{"..."} argument, and passes them to the \texttt{fn} objective function.
      \vskip1ex
      The arguments \texttt{lower} and \texttt{upper} specify the search range for the variables of the objective function \texttt{fn}.
      \vskip1ex
      \texttt{method="L-BFGS-B"} specifies the quasi-Newton optimization method.
      \vskip1ex
      \texttt{optim()} returns a list containing the location of the minimum and the objective function value.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Optimization to find weights with maximum Sharpe ratio
optimd <- optim(par=weights,
                   fn=object,
                   returns=returns,
                   method="L-BFGS-B",
                   upper=c(1.1, 10, 10),
                   lower=c(0.9, -10, -10))
# Optimal parameters
optimd$par
optimd$par <- optimd$par/sum(optimd$par)
# Optimal Sharpe ratio
-object(optimd$par)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimized Portfolio Performance}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The optimized portfolio has both long and short positions, and outperforms its individual component assets.
      \vskip1ex
      \vspace{-1em}
      <<optim_portf_basic,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
x11(width=6, height=5)
par(oma=c(1, 1, 1, 0), mgp=c(2, 1, 0), mar=c(2, 1, 2, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# Plot in two vertical panels
layout(matrix(c(1,2), 2),
       widths=c(1,1), heights=c(1,3))
# barplot of optimal portfolio weights
barplot(optimd$par, col=c("red", "green", "blue"),
        main="Optimized portfolio weights")
# Calculate cumulative returns of VTI, IEF, DBC
cumrets <- lapply(returns,
  function(returns) exp(cumsum(returns)))
cumrets <- rutils::do_call(cbind, cumrets)
# Calculate optimal portfolio returns with VTI, IEF, DBC
optim_rets <- cbind(
  exp(cumsum(returns %*% optimd$par)),
  cumrets)
colnames(optim_rets)[1] <- "optim_rets"
# Plot optimal returns with VTI, IEF, DBC
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("black", "red", "green", "blue")
chart_Series(optim_rets, theme=plot_theme,
             name="Optimized portfolio performance")
legend("top", legend=colnames(optim_rets), cex=0.8,
       inset=0.1, bg="white", lty=1, lwd=6,
       col=plot_theme$col$line.col, bty="n")
# Or plot non-compounded (simple) cumulative returns
PerformanceAnalytics::chart.CumReturns(
  cbind(returns %*% optimd$par, returns),
  lwd=2, ylab="", legend.loc="topleft", main="")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/optim_portf.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Mean-Variance Portfolio Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The mean-variance objective function is designed to maximize portfolio returns and minimize their variance:
      \begin{displaymath}
        O(x) = \mathbf{w}^T \mathbb{C} \, \mathbf{w} - q \, \mathbf{w}^T \mathbf{r}
      \end{displaymath}
      Where $\mathbb{C}$ is the covariance matrix of returns, $\mathbf{r}$ is the vector of returns, $\mathbf{w}$ is the vector of  portfolio weights, and $q$ is the risk tolerance factor.
      \vskip1ex
      The mean-variance optimal portfolio is defined as
      \begin{displaymath}
        \theta_{MLE} = \operatorname*{arg\,max}_{\theta} {\mathcal{L}(\theta|x)}
        \mathbf{w}^T \mathbb{C} \, \mathbf{w}
      \end{displaymath}
      Where the sum of portfolio weights $\mathbf{w}$ is constrained to equal \texttt{1}: $\mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1$.
      \vskip1ex
      Legacy stuff below:\\
      A Linear Regression model with $p$ explanatory variables $\{x_j\}$, is defined by the formula:
      \begin{displaymath}
        z_i = \alpha + \sum_{j=1}^{k} {\beta_j x_{i,j}} + \varepsilon_i
      \end{displaymath}
      Or in vector notation:
      \begin{displaymath}
        z = \alpha + \beta x + \varepsilon
      \end{displaymath}
      The response variable $z$ and the $p$ explanatory variables $\{x_j\}$ each contain \texttt{n} observations.
      \vskip1ex
      The response variable $z$ is a vector of length \texttt{n}, and the explanatory variable \texttt{x} is a $(n,p)$-dimensional matrix.
      \vskip1ex
      $\alpha$ and $\beta$ are the unknown regression coefficients, with $\alpha$ a scalar and $\beta$ a vector of length $p$.
      \vskip1ex
      $\varepsilon_i$ are the residuals, assumed to be normally distributed, independent, and stationary, with $\varepsilon$ a vector of length $p$.
    \column{0.5\textwidth}
      The OLS estimate for $\alpha$ is given by:
      \begin{align*}
        \alpha = z^T \mathbbm{1} - \beta x^T \mathbbm{1}
      \end{align*}
      If the variables are de-meaned, then the OLS estimate for $\beta$ is given by equating the RSS derivative to zero:
      \begin{flalign*}
        & RSS_\beta = - 2 (z - \beta x)^T x = 0\\
        & x^T z - \beta x^T x = 0\\
        & \beta = (x^T x)^{-1} x^T z
      \end{flalign*}
      The matrix $x^T x$ is the covariance matrix of the matrix \texttt{x}.
      \vskip1ex
      The covariance matrix $x^T x$ is invertible if the columns of \texttt{x} are linearly independent.
      \vskip1ex
      The matrix $(x^T x)^{-1} x^T$ is known as the \emph{Moore-Penrose pseudo-inverse} of the matrix \texttt{x}.
      \vskip1ex
      In the special case when the inverse matrix $x^{-1}$ does exist, then the \emph{pseudo-inverse} matrix simplifies to the inverse: $(x^T x)^{-1} x^T = x^{-1} (x^T)^{-1} x^T = x^{-1}$
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{quadprog} for Quadratic Programming}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Quadratic programming (\emph{QP}) is the optimization of quadratic objective functions subject to linear constraints.
      \vskip1ex
      Let $O(x)$ be an objective function that is quadratic with respect to a vector variable \texttt{x}:
      \begin{displaymath}
        O(x) = \frac{1}{2} x^T \mathbb{Q} x - d^T x
      \end{displaymath}
      Where $\mathbb{Q}$ is a \emph{positive definite} matrix ($x^T \mathbb{Q} x > 0$), and $d$ is a vector.
      \vskip1ex
      An example of a \emph{positive definite} matrix is the covariance matrix of linearly independent variables.
      \vskip1ex
      Let the linear constraints on the variable \texttt{x} be specified as:
      \begin{displaymath}
        \mathbb{A} x \geq b
      \end{displaymath}
      Where $\mathbb{A}$ is a matrix, and $b$ is a vector.
      \vskip1ex
      The function \texttt{solve.QP()} from package \emph{quadprog} performs optimization of quadratic objective functions subject to linear constraints.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=(-(1:6)),eval=FALSE>>=
riskf <- 0.03
returns <- c(asset1=0.05, asset2=0.06)
stdevs <- c(asset1=0.4, asset2=0.5)
cor_rel <- 0.6
covmat <- matrix(c(1, cor_rel, cor_rel, 1), nc=2)
covmat <- t(t(stdevs*covmat)*stdevs)
library(quadprog)
# Minimum variance weights without constraints
optimd <- solve.QP(Dmat=2*covmat,
                    dvec=rep(0, 2),
                    Amat=matrix(0, nr=2, nc=1),
                    bvec=0)
# Minimum variance weights sum equal to 1
optimd <- solve.QP(Dmat=2*covmat,
                    dvec=rep(0, 2),
                    Amat=matrix(1, nr=2, nc=1),
                    bvec=1)
# Optimal value of objective function
t(optimd$solution) %*% covmat %*% optimd$solution
## Perform simple optimization for reference
# Objective function for simple optimization
object <- function(x) {
  x <- c(x, 1-x)
  t(x) %*% covmat %*% x
}  # end object
unlist(optimize(f=object, interval=c(-1, 2)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Using Package \protect\emph{quadprog}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The objective function is designed to minimize portfolio variance and maximize its returns:
      \begin{displaymath}
        O(x) = \mathbf{w}^T \mathbb{C} \, \mathbf{w} - \mathbf{w}^T \mathbf{r}
      \end{displaymath}
      Where $\mathbb{C}$ is the covariance matrix of returns, $\mathbf{r}$ is the vector of returns, and $\mathbf{w}$ is the vector of  portfolio weights.
      \vskip1ex
      The portfolio weights $\mathbf{w}$ are constrained as:
      \begin{align*}
        \mathbf{w}^T \mathbbm{1} = {\sum_{i=1}^n w_i} = 1\\
        0 \leq w_i \leq 1
      \end{align*}
      The function \texttt{solve.QP()} has the arguments:
      \vskip1ex
      \texttt{Dmat} and \texttt{dvec} are the matrix and vector defining the quadratic objective function.
      \vskip1ex
      \texttt{Amat} and \texttt{bvec} are the matrix and vector defining the constraints.
      \vskip1ex
      \texttt{meq} specifies the number of equality constraints
      (the first \texttt{meq} constraints are equalities, and the rest are inequalities).
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Calculate daily percentage returns
symbolv <- c("VTI", "IEF", "DBC")
returns <- rutils::etf_env$returns[, symbolv]
# Calculate the covariance matrix
covmat <- cov(returns)
# Minimum variance weights, with sum equal to 1
optimd <- quadprog::solve.QP(Dmat=2*covmat,
                    dvec=numeric(3),
                    Amat=matrix(1, nr=3, nc=1),
                    bvec=1)
# Minimum variance, maximum returns
optimd <- quadprog::solve.QP(Dmat=2*covmat,
                    dvec=apply(0.1*returns, 2, mean),
                    Amat=matrix(1, nr=3, nc=1),
                    bvec=1)
# Minimum variance positive weights, sum equal to 1
a_mat <- cbind(matrix(1, nr=3, nc=1),
               diag(3), -diag(3))
b_vec <- c(1, rep(0, 3), rep(-1, 3))
optimd <- quadprog::solve.QP(Dmat=2*covmat,
                    dvec=numeric(3),
                    Amat=a_mat,
                    bvec=b_vec,
                    meq=1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{DEoptim} for Global Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{DEoptim()} from package \emph{DEoptim} performs \emph{global} optimization using the \emph{Differential Evolution} algorithm.
      \vskip1ex
      \emph{Differential Evolution} is a genetic algorithm which evolves a population of solutions over several generations,\\
      \hskip1em\url{http://www1.icsi.berkeley.edu/~storn/code.html}
      \vskip1ex
      The first generation of solutions is selected randomly.
      \vskip1ex
      Each new generation is obtained by combining solutions from the previous generation,       \vskip1ex
      The best solutions are selected for creating the next generation.
      \vskip1ex
      The \emph{Differential Evolution} algorithm is well suited for very large multi-dimensional optimization problems, such as portfolio optimization.
      \vskip1ex
      \emph{Gradient} optimization methods are more efficient than \emph{Differential Evolution} for smooth objective functions with no local minima.
    \column{0.5\textwidth}
        <<echo=TRUE,eval=FALSE>>=
# Rastrigin function with vector argument for optimization
rastri_gin <- function(vectorv, pa_ram=25){
  sum(vectorv^2 - pa_ram*cos(vectorv))
}  # end rastri_gin
vectorv <- c(pi/6, pi/6)
rastri_gin(vectorv=vectorv)
library(DEoptim)
# Optimize rastri_gin using DEoptim
optimd <-  DEoptim(rastri_gin,
  upper=c(6, 6), lower=c(-6, -6),
  DEoptim.control(trace=FALSE, itermax=50))
# Optimal parameters and value
optimd$optim$bestmem
rastri_gin(optimd$optim$bestmem)
summary(optimd)
plot(optimd)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Using Package \protect\emph{Deoptim}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Differential Evolution} algorithm is well suited for very large multi-dimensional optimization problems, such as portfolio optimization.
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Calculate daily percentage returns
returns <- rutils::etf_env$returns[, symbolv]
# Objective equal to minus Sharpe ratio
object <- function(weights, returns) {
  retsp <- returns %*% weights
  if (sd(retsp) == 0)
    return(0)
  else
    return(-mean(retsp)/sd(retsp))
}  # end object
# Perform optimization using DEoptim
optimd <- DEoptim::DEoptim(fn=object,
  upper=rep(10, NCOL(returns)),
  lower=rep(-10, NCOL(returns)),
  returns=returns,
  control=list(trace=FALSE, itermax=100, parallelType=1))
weights <- optimd$optim$bestmem/sum(abs(optimd$optim$bestmem))
names(weights) <- colnames(returns)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Using \protect\emph{Shrinkage}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The technique of \emph{shrinkage} (\emph{regularization}) is designed to reduce the number of parameters in a model, for example in portfolio optimization.
      \vskip1ex
      The \emph{shrinkage} technique adds a penalty term to the objective function.
      \vskip1ex
      The \emph{elastic net} regularization is a combination of \emph{ridge} regularization and \emph{Lasso} regularization:
      \begin{align*}
        w_{max} = \operatorname*{arg\,max}_{w} [ \, \mathbf{w}^T \mathbf{r} - \\
        \lambda ( (1-\alpha) \sum_{i=1}^n w^2_i + \alpha \sum_{i=1}^n|w_i| ) \, ]
      \end{align*}
      The portfolio weights $\mathbf{w}$ are shrunk to zero as the parameters $\lambda$ and $\alpha$ increase.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Objective with shrinkage penalty
object <- function(weights, returns, lambdav, alpha) {
  retsp <- returns %*% weights
  if (sd(retsp) == 0)
    return(0)
  else {
    penal_ty <- lambdav*((1-alpha)*sum(weights^2) +
        alpha*sum(abs(weights)))
    return(-mean(retsp)/sd(retsp) + penal_ty)
  }
}  # end object
# Objective for equal weight portfolio
weights <- rep(1, NROW(symbolv))
names(weights) <- symbolv
lambdav <- 0.5 ; alpha <- 0.5
object(weights, returns=returns,
  lambdav=lambdav, alpha=alpha)
# Perform optimization using DEoptim
optimd <- DEoptim::DEoptim(fn=object,
  upper=rep(10, NCOL(returns)),
  lower=rep(-10, NCOL(returns)),
  returns=returns,
  lambdav=lambdav,
  alpha=alpha,
  control=list(trace=FALSE, itermax=100, parallelType=1))
weights <- optimd$optim$bestmem/sum(abs(optimd$optim$bestmem))
names(weights) <- colnames(returns)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Portfolio Optimization Packages in \texttt{R}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The following \texttt{R} packages provide functions for portfolio optimization:
      \begin{itemize}
        \item package \emph{PortfolioAnalytics}: relies on packages \emph{xts}, \emph{ROI}, and \emph{DEoptim},
        \item package \emph{parma}: relies on packages \emph{xts}, \emph{Rglpk}, and \emph{quadprog},
        \item package \emph{fPortfolio} from the \emph{Rmetrics} suite: relies on packages \emph{tseries}, \emph{Rglpk}, and \emph{quadprog},
      \end{itemize}
      These portfolio optimization packages call generic optimization functions written in compiled \texttt{C++}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1))>>=
load(file="/Users/jerzy/Develop/lecture_slides/data/zoo_data.RData")
stxts <- as.ts(zoo_stx)
class(stxts)
tail(stxts[, 1:4])
library(xts)
st_ox <- as.xts(zoo_stx)
class(st_ox)
tail(st_ox[, 1:4])
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Package \protect\emph{PortfolioAnalytics} for Portfolio Optimization}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{PortfolioAnalytics}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The package \emph{PortfolioAnalytics} contains functions and data sets for portfolio optimization.
      \vskip1ex
      The function \texttt{data()} loads external data or lists data sets in a package.
      \vskip1ex
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(PortfolioAnalytics)  # load package "PortfolioAnalytics"
# get documentation for package "PortfolioAnalytics"
packageDescription("PortfolioAnalytics")  # get short description

help(package="PortfolioAnalytics")  # load help page

data(package="PortfolioAnalytics")  # list all datasets in "PortfolioAnalytics"

ls("package:PortfolioAnalytics")  # list all objects in "PortfolioAnalytics"

detach("package:PortfolioAnalytics")  # remove PortfolioAnalytics from search path
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Definition}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Portfolios are defined by a named vector of asset weights, and portfolio constraints and objectives.
      \vskip1ex
      \texttt{portfolio.spec} creates a portfolio object that contains asset weights, constraints, and objectives.
      \vskip1ex
      \texttt{add.constraint} adds or updates constraints on of the portfolio object.
      \vskip1ex
      \texttt{add.objective} adds or updates risk/return objectives of the portfolio object.
      <<echo=TRUE,eval=FALSE>>=
library(PortfolioAnalytics)
# Use ETF returns from package rutils
library(rutils)
portf_names <- c("VTI", "IEF", "DBC", "XLF",
        "VNQ", "XLP", "XLV", "XLU", "XLB", "XLE")
# Initial portfolio to equal weights
portf_init <- rep(1/NROW(portf_names), NROW(portf_names))
# named vector
names(portf_init) <- portf_names
# Create portfolio object
portf_init <- portfolio.spec(assets=portf_init)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PortfolioAnalytics)
# Add constraints
portf_maxSR <- add.constraint(
  portfolio=portf_init,  # Initial portfolio
  type="weightsum",  # Constraint sum weights
  min_sum=0.9, max_sum=1.1)
# Add constraints
portf_maxSR <- add.constraint(
  portfolio=portf_maxSR,
  type="long_only")  # box constraint min=0, max=1
# Add objectives
portf_maxSR <- add.objective(
  portfolio=portf_maxSR,
  type="return",  # Maximize mean return
  name="mean")
# Add objectives
portf_maxSR <- add.objective(
  portfolio=portf_maxSR,
  type="risk",  # Minimize StdDev
  name="StdDev")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_SR_basic,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
library(PortfolioAnalytics)
# Perform optimization of weights
maxSR_DEOpt <- optimize.portfolio(
  R=etf_env$returns[, portf_names],  # Specify returns
  portfolio=portf_maxSR,  # Specify portfolio
  optimize_method="DEoptim", # Use DEoptim
  maxSR=TRUE,  # Maximize Sharpe
  trace=TRUE, traceDE=0)
# Plot optimization
chart.RiskReward(maxSR_DEOpt,
  risk.col="stddev",
  return.col="mean")
      @
    \vspace{-2em}
      <<echo=(-(1:3)),eval=FALSE,tidy=TRUE>>=
options(width=50)
library(PortfolioAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
maxSR_DEOpt$weights
maxSR_DEOpt$objective_measures$mean[1]
maxSR_DEOpt$objective_measures$StdDev[[1]]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_basic-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Scatterplot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_SR_scatter,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot optimization
chart.RiskReward(maxSR_DEOpt,
  risk.col="StdDev",
  return.col="mean")

# Plot risk/ret points in portfolio scatterplot
risk_ret_points <- function(rets=etf_env$returns,
        risk=c("sd", "ETL"), symbolv=c("VTI", "IEF")) {
  risk <- match.arg(risk)  # Match to arg list
  if (risk=="ETL") {
    stopifnot(
      "package:PerformanceAnalytics" %in% search() ||
      require("PerformanceAnalytics", quietly=TRUE))
  }  # end if
  risk <- match.fun(risk)  # Match to function
  risk_ret <- t(sapply(rets[, symbolv],
     function(xtes)
       c(ret=mean(xtes), risk=abs(risk(xtes)))))
  points(x=risk_ret[, "risk"], y=risk_ret[, "ret"],
         col="red", lwd=3)
  text(x=risk_ret[, "risk"], y=risk_ret[, "ret"],
       labels=rownames(risk_ret), col="red",
       lwd=2, pos=4)
}  # end risk_ret_points

risk_ret_points()
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_scatter-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimized Sharpe Portfolio}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_portf_SR_vis,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
library(PortfolioAnalytics)
plot_portf <- function(portfolio,
            rets_data=etf_env$returns) {
  weights <- portfolio$weights
  portf_names <- names(weights)
  # Calculate xts of portfolio
  portf_max <- xts(
    rets_data[, portf_names] %*% weights,
    order.by=index(rets_data))
  colnames(portf_max) <-
    deparse(substitute(portfolio))
  graph_params <- par(oma=c(1, 0, 1, 0),
    mgp=c(2, 1, 0), mar=c(2, 1, 2, 1),
    cex.lab=0.8, cex.axis=1.0,
    cex.main=0.8, cex.sub=0.5)
  layout(matrix(c(1,2), 2),
    widths=c(1,1), heights=c(1,3))
  barplot(weights, names.arg=portf_names,
          las=3, ylab="", xlab="Symbol", main="")
  title(main=paste("Loadings",
                colnames(portf_max)), line=-1)
  chart.CumReturns(
    cbind(portf_max, rets_data[, c("IEF", "VTI")]),
    lwd=2, ylab="", legend.loc="topleft", main="")
  title(main=paste0(colnames(portf_max),
                    ", IEF, VTI"), line=-1)
  par(graph_params)  # restore original parameters
  invisible(portf_max)
}  # end plot_portf
maxSR_DEOpt_xts <- plot_portf(portfolio=maxSR_DEOpt)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_portf_SR_vis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Leverage Constraints}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The leverage constraint applies to the sum of absolute weights.
      \vspace{-1em}
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PortfolioAnalytics)
# Add leverage constraint abs(weightsum)
portf_maxSRN <- add.constraint(
  portfolio=portf_init, type="leverage",
  min_sum=0.9, max_sum=1.1)
# Add box constraint long/short
portf_maxSRN <- add.constraint(
  portfolio=portf_maxSRN,
  type="box", min=-0.2, max=0.2)

# Add objectives
portf_maxSRN <- add.objective(
  portfolio=portf_maxSRN,
  type="return",  # Maximize mean return
  name="mean")
# Add objectives
portf_maxSRN <- add.objective(
  portfolio=portf_maxSRN,
  type="risk",  # Minimize StdDev
  name="StdDev")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Leverage Constraint Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_SR_leverage,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
library(PortfolioAnalytics)
# Perform optimization of weights
maxSRN_DEOpt <- optimize.portfolio(
  R=etf_env$returns[, portf_names],  # Specify returns
  portfolio=portf_maxSRN,  # Specify portfolio
  optimize_method="DEoptim", # Use DEoptim
  maxSR=TRUE,  # Maximize Sharpe
  trace=TRUE, traceDE=0)
# Plot optimization
chart.RiskReward(maxSRN_DEOpt,
  risk.col="StdDev",
  return.col="mean",
  xlim=c(
    maxSR_DEOpt$objective_measures$StdDev[[1]]-0.001,
    0.016))
  points(x=maxSR_DEOpt$objective_measures$StdDev[[1]],
         y=maxSR_DEOpt$objective_measures$mean[1],
         col="green", lwd=3)
  text(x=maxSR_DEOpt$objective_measures$StdDev[[1]],
         y=maxSR_DEOpt$objective_measures$mean[1],
       labels="maxSR", col="green",
       lwd=2, pos=4)
# Plot risk/ret points in portfolio scatterplot
risk_ret_points()
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_leverage-1}
    \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE,tidy=TRUE>>=
library(PortfolioAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
maxSRN_DEOpt$weights
maxSRN_DEOpt$objective_measures$mean[1]
maxSRN_DEOpt$objective_measures$StdDev[[1]]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimized Leverage Constraint Portfolio}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_portf_SRN_vis,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
library(PortfolioAnalytics)
maxSRN_DEOpt_xts <-
  plot_portf(portfolio=maxSRN_DEOpt)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_portf_SRN_vis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Sharpe Portfolios \texttt{CumReturns} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{chart.CumReturns()} plots the cumulative returns of a time series of returns.
      <<optim_SR_SRN_vis,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
chart.CumReturns(
  cbind(maxSR_DEOpt_xts, maxSRN_DEOpt_xts),
  lwd=2, ylab="",
  legend.loc="topleft", main="")
      @
    \vspace{-2em}
      <<echo=(-(1:3)),eval=FALSE>>=
options(width=50)
library(PerformanceAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
rbind(maxSR_DEOpt$weights, maxSRN_DEOpt$weights)
c(maxSR_DEOpt$objective_measures$mean,
maxSRN_DEOpt$objective_measures$mean)
c(maxSR_DEOpt$objective_measures$StdDev[[1]],
maxSRN_DEOpt$objective_measures$StdDev[[1]])
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_SRN_vis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{STARR Portfolio Constraints}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The objective constraint applies to risk or return.
      \vspace{-1em}
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PortfolioAnalytics)
# Add constraints
portf_maxSTARR <- add.constraint(
  portfolio=portf_init,  # Initial portfolio
  type="weightsum",  # Constraint sum weights
  min_sum=0.9, max_sum=1.1)
# Add constraints
portf_maxSTARR <- add.constraint(
  portfolio=portf_maxSTARR,
  type="long_only")  # box constraint min=0, max=1
# Add objectives
portf_maxSTARR <- add.objective(
  portfolio=portf_maxSTARR,
  type="return",  # Maximize mean return
  name="mean")
# Add objectives
portf_maxSTARR <- add.objective(
  portfolio=portf_maxSTARR,
  type="risk",  # Minimize Expected Shortfall
  name="ES")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{STARR Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_STARR,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
library(PortfolioAnalytics)
# Perform optimization of weights
maxSTARR_DEOpt <- optimize.portfolio(
  R=etf_env$returns[, portf_names],  # Specify returns
  portfolio=portf_maxSTARR,  # Specify portfolio
  optimize_method="DEoptim", # Use DEoptim
  maxSTARR=TRUE,  # Maximize STARR
  trace=TRUE, traceDE=0)

# Plot optimization
chart.RiskReward(maxSTARR_DEOpt,
  risk.col="ES",
  return.col="mean")
# Plot risk/ret points in portfolio scatterplot
risk_ret_points(risk="ETL")
      @
    \vspace{-2em}
      <<echo=(-(1:3)),eval=FALSE,tidy=TRUE>>=
options(width=50)
library(PortfolioAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
maxSTARR_DEOpt$weights
maxSTARR_DEOpt$objective_measures$mean[1]
maxSTARR_DEOpt$objective_measures$ES[[1]]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_STARR-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimized STARR Portfolio}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_STARR_vis,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
library(PortfolioAnalytics)
maxSTARR_DEOpt_xts <-
  plot_portf(portfolio=maxSTARR_DEOpt)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_STARR_vis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Sharpe STARR \texttt{CumReturns} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{chart.CumReturns()} plots the cumulative returns of a time series of returns.
      <<optim_SR_STARR_vis,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
chart.CumReturns(
  cbind(maxSR_DEOpt_xts, maxSTARR_DEOpt_xts),
  lwd=2, ylab="",
  legend.loc="topleft", main="")
      @
    \vspace{-2em}
      <<echo=(-(1:3)),eval=FALSE>>=
options(width=50)
library(PerformanceAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
rbind(maxSR_DEOpt$weights, maxSTARR_DEOpt$weights)
c(maxSR_DEOpt$objective_measures$mean,
maxSTARR_DEOpt$objective_measures$mean)
c(maxSR_DEOpt$objective_measures$StdDev[[1]],
maxSTARR_DEOpt$objective_measures$ES[[1]])
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_STARR_vis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Efficient Frontier and Capital Market Line}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Efficient Frontier} is the set of \emph{efficient portfolios}, that have the lowest risk (standard deviation) for the given level of return.
      \vskip1ex
      The Capital Market Line (CML) is the line drawn from the risk-free asset to the tangent point on the Efficient Frontier.
      \vskip1ex
      The tangent point on the \emph{Efficient Frontier} is the \emph{Market Portfolio}.
      <<optim_eff_front,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# Plot the efficient frontier
chart.EfficientFrontier(maxSR_DEOpt,
                match.col="StdDev",
                n.portfolios=15, type="l")
points(x=maxSRN_DEOpt$objective_measures$StdDev[[1]],
         y=maxSRN_DEOpt$objective_measures$mean[1],
         col="green", lwd=3)
text(x=maxSRN_DEOpt$objective_measures$StdDev[[1]],
         y=maxSRN_DEOpt$objective_measures$mean[1],
       labels="maxSRN", col="green",
       lwd=2, pos=4)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_eff_front-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{minES Portfolio Constraints}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The objective constraint applies to risk or return.
      \vspace{-1em}
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PortfolioAnalytics)
# Add constraints
portf_minES <- add.constraint(
  portfolio=portf_init,  # Initial portfolio
  type="weightsum",  # Constraint sum weights
  min_sum=0.9, max_sum=1.1)
# Add constraints
portf_minES <- add.constraint(
  portfolio=portf_minES,
  type="long_only")  # box constraint min=0, max=1
# Add objectives
portf_minES <- add.objective(
  portfolio=portf_minES,
  type="risk",  # Minimize ES
  name="ES")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{minES Optimization}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_minES,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
library(PortfolioAnalytics)
# Perform optimization of weights
minESROI <- optimize.portfolio(
  R=etf_env$returns[, portf_names],  # Specify returns
  portfolio=portf_minES,  # Specify portfolio
  optimize_method="ROI", # Use ROI
  trace=TRUE, traceDE=0)

# Plot optimization
chart.RiskReward(maxSTARR_DEOpt,
  risk.col="ES",
  return.col="mean")
  points(x=minESROI$objective_measures$ES[[1]],
         y=mean(minESROI_xts),
         col="green", lwd=3)
  text(x=minESROI$objective_measures$ES[[1]],
         y=mean(minESROI_xts),
       labels="minES", col="green",
       lwd=2, pos=4)
# Plot risk/ret points in portfolio scatterplot
risk_ret_points(risk="ETL")
      @
    \vspace{-2em}
      <<echo=(-(1:3)),eval=FALSE,tidy=TRUE>>=
options(width=50)
library(PortfolioAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
minESROI$weights
minESROI$objective_measures$ES[[1]]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_minES-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimized minES Portfolio}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_minES_vis,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
library(PortfolioAnalytics)
minESROI_xts <-
  plot_portf(portfolio=minESROI)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_minES_vis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Sharpe minES \texttt{CumReturns} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{chart.CumReturns()} plots the cumulative returns of a time series of returns.
      <<optim_SR_minES_vis,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
chart.CumReturns(
  cbind(maxSR_DEOpt_xts, minESROI_xts),
  lwd=2, ylab="",
  legend.loc="topleft", main="")
      @
    \vspace{-2em}
      <<echo=(-(1:3)),eval=FALSE>>=
options(width=50)
library(PerformanceAnalytics)
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
rbind(maxSR_DEOpt$weights, minESROI$weights)
c(maxSR_DEOpt$objective_measures$mean,
minESROI$objective_measures$mean)
c(maxSR_DEOpt$objective_measures$StdDev[[1]],
minESROI$objective_measures$ES[[1]])
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_minES_vis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Out-of-sample Portfolios}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_SR_1h,echo=(-(1:3)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
library(PortfolioAnalytics)
options(width=50)
# Perform optimization of weights
maxSR_DEOpt <- optimize.portfolio(
  R=etf_env$returns["/2011", portf_names],
  portfolio=portf_maxSR,  # Specify portfolio
  optimize_method="DEoptim", # Use DEoptim
  maxSR=TRUE,  # Maximize Sharpe
  trace=TRUE, traceDE=0)
weights1h <- maxSR_DEOpt$weights

# Plot optimization
maxSR_DEOpt_xts <-
  plot_portf(portfolio=maxSR_DEOpt)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_1h-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Out-of-sample Portfolios (cont.)}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<optim_SR_2h,echo=(-(1:3)),eval=FALSE,fig.width=7,fig.height=8,fig.show='hide'>>=
load(file="/Users/jerzy/Develop/lecture_slides/data/portf_optim.RData")
library(PortfolioAnalytics)
options(width=50)
# Perform optimization of weights
maxSR_DEOpt <- optimize.portfolio(
  R=etf_env$returns["2011/", portf_names],
  portfolio=portf_maxSR,  # Specify portfolio
  optimize_method="DEoptim", # Use DEoptim
  maxSR=TRUE,  # Maximize Sharpe
  trace=TRUE, traceDE=0)
weights2h <- maxSR_DEOpt$weights

# Plot optimization
maxSR_DEOpt_xts <-
  plot_portf(portfolio=maxSR_DEOpt)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_SR_2h-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Out-of-sample Portfolio Weights}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
options(width=50)
weights1h
weights2h
weights1h - weights2h
      @
    \vspace{-2em}
      <<optim_weights,echo=(-(1:2)),eval=FALSE,fig.height=5,fig.show='hide'>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # Set plot panels
barplot(weights1h,
        names.arg=names(weights1h),
        las=3, ylab="", xlab="",
        main="Portfolio Weights First Half")
barplot(weights2h,
        names.arg=names(weights2h),
        las=3, ylab="", xlab="",
        main="Portfolio Weights Second Half")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/optim_weights-1}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Credit Portfolio Models}


%%%%%%%%%%%%%%%
\subsection{Simulating Single-period Defaults}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Consider a portfolio of credit assets (bonds or loans) over a single period of time.
      \vskip1ex
      At the end of the period, some of the assets default, while the rest don't.
      \vskip1ex
      The default probabilities are equal to $p_i$.
      \vskip1ex
      Individual defaults can be simulated by comparing the probabilities $p_i$ with the uniform random numbers $u_i$.
      \vskip1ex
      Default occurs if $u_i$ is less than the default probability $p_i$:
      \begin{displaymath}
        u_i < p_i
      \end{displaymath}
      Simulations in \texttt{R} can be accelerated by pre-computing a vector of random numbers, instead of generatng them one at a time in a loop.
      \vskip1ex
      Vectors of random numbers allow using \emph{vectorized} functions, instead of inefficient (slow) \texttt{for()} loops.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate random default probabilities
set.seed(1121)
nassets <- 100
def_probs <- runif(nassets, max=0.2)
mean(def_probs)
# Simulate number of defaults
unifunc <- runif(nassets)
sum(unifunc < def_probs)
# Simulate average number of defaults using for() loop (inefficient way)
nsimu <- 1000
set.seed(1121)
de_faults <- numeric(nsimu)
for (i in 1:nsimu) {  # Perform loop
  unifunc <- runif(nassets)
  de_faults[i] <- sum(unifunc < def_probs)
}  # end for
# Calculate average number of defaults
mean(de_faults)
# Simulate using vectorized functions  (efficient way)
set.seed(1121)
unifunc <- matrix(runif(nsimu*nassets), ncol=nsimu)
de_faults <- colSums(unifunc < def_probs)
mean(de_faults)
# Plot the distribution of defaults
x11(width=6, height=5)
plot(density(de_faults), main="Distribution of Defaults", 
     xlab="number of defaults", ylab="frequqncy")
abline(v=mean(de_faults), lwd=3, col="red")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Asset Values and Default Thresholds}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Defaults can also be simulated using normally distributed variables $a_i$ called \emph{asset values}, instead of the uniformly distributed variables $u_i$.
      \vskip1ex
      The asset values $a_i$ are the \emph{quantiles} corresponding to the uniform variables $u_i$: $a_i = \Phi^{-1}(u_i)$ (where $\Phi()$ is the cumulative standard normal distribution).
      \vskip1ex
      Similarly, the default probabilities $p_i$ are also transformed into \emph{default thresholds} $t_i$, which are the \emph{quantiles}: $t_i = \Phi^{-1}(p_i)$.
      \vskip1ex
      Before, default occurred if $u_i$ was less than the default probability $p_i$: $u_i < p_i$.
      \vskip1ex
      Now, default occurs if the \emph{asset value} $a_i$ is less than the \emph{default threshold} $t_i$: $a_i < t_i$.
      \vskip1ex
      The asset values $a_i$ are mathematical variables which can be negative, so they are not actual company asset values.
      <<echo=TRUE,eval=FALSE>>=
# Calculate default thresholds and asset values
def_thresh <- qnorm(def_probs)
assets <- qnorm(unifunc)
# Simulate defaults
de_faults <- colSums(assets < def_thresh)
mean(de_faults)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_def_threshold.png}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot Standard Normal distribution
x11(width=6, height=5)
xlim <- 4; def_thresh <- qnorm(0.025)
curve(expr=dnorm(x), type="l", xlim=c(-xlim, xlim),
      xlab="asset value", ylab="", lwd=3,
      col="blue", main="Distribution of Asset Values")
abline(v=def_thresh, col="red", lwd=3)
text(x=def_thresh-0.1, y=0.15, labels="default threshold",
       lwd=2, srt=90, pos=3)
# Plot polygon area
xvar <- seq(-xlim, xlim, length=100)
y_var <- dnorm(xvar)
are_a <- ((xvar >= (-xlim)) & (xvar <= def_thresh))
polygon(c(xlim, xvar[are_a], def_thresh),
        c(-1, y_var[are_a], -1), col="red")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vasicek Model of Correlated Asset Values}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      So far, the asset values are independent from each other, but in reality default events are correlated.
      \vskip1ex
      The \emph{Vasicek} model introduces correlation between the asset values $a_i$.
      \vskip1ex
      Under the \emph{Vasicek} single factor model, the asset value $a_i$ is equal to the sum of a \emph{systematic} factor $s$, plus an \emph{idiosyncratic} factor $z_i$:
      \begin{displaymath}
        a_i = \sqrt{\rho} \, s + \sqrt{1-\rho} \, z_i
      \end{displaymath}
      Where $\rho$ is the correlation between asset values.
      \vskip1ex
      The variables $s$, $z_i$, and $a_i$ all follow the Standard Normal distribution $\phi(0, 1)$.
      \vskip1ex
      The \emph{Vasicek} model resembles the \emph{CAPM} model, with the asset value equal to the sum of a \emph{systematic} factor plus an \emph{idiosyncratic} factor.
      \vskip1ex
      The Bank for International Settlements (BIS) uses the \emph{Vasicek} model as part of its regulatory capital requirements for bank credit risk:\\
      \tiny{
\hskip1em\url{http://bis2information.org/content/Vasicek_model}\\
\hskip1em\url{https://www.bis.org/bcbs/basel3.htm}\\
\hskip1em\url{https://www.bis.org/bcbs/irbriskweight.pdf}
      }
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define correlation parameters
rho <- 0.2
rho_sqrt <- sqrt(rho) ; rho_sqrtm <- sqrt(1-rho)
nassets <- 5 ; nsimu <- 10000
# Calculate vector of systematic and idiosyncratic factors
sysv <- rnorm(nsimu)
idio_syncratic <- rnorm(nsimu*nassets)
# Simulate asset values using vectorized functions (efficient way)
assets <- rho_sqrt*sysv + rho_sqrtm*idio_syncratic
dim(assets) <- c(nsimu, nassets)
# Asset values are standard normally distributed
apply(assets, MARGIN=2, function(x) c(mean=mean(x), sd=sd(x)))
# Calculate correlations between asset values
cor(assets)
# Simulate asset values using for() loop (inefficient way)
# Allocate matrix of assets
assets <- matrix(nr=nsimu, nc=nassets)
# Simulate asset values using for() loop
for (i in 1:nsimu) {  # Perform loop
  assets[i, ] <- rho_sqrt*sysv[i] + rho_sqrtm*rnorm(nassets)
}  # end for
cor(assets)
# benchmark the speed of the two methods
library(microbenchmark)
summary(microbenchmark(
  for_loop={for (i in 1:nsimu) {
    rho_sqrt*sysv[i] + rho_sqrtm*rnorm(nassets)}},
  vector_ized={rho_sqrt*sysv + rho_sqrtm*rnorm(nsimu*nassets)},
  times=10))[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vasicek Model of Correlated Defaults}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Under the \emph{Vasicek} model, default occurs if the \emph{asset value} $a_i$ is less than the \emph{default threshold} $t_i$:
      \begin{align*}
        a_i = \sqrt{\rho} s + \sqrt{1-\rho} z_i \\
        a_i < t_i
      \end{align*}
      The \emph{systematic} factor $s$ may be considered to represent the state of the macro economy, with positive values representing an economic expansion, and negative values representing an economic recession.
      \vskip1ex
      When the value of the \emph{systematic} factor $s$ is positive, then the asset values will all tend to be bigger as well, which will produce fewer defaults.
      \vskip1ex
      But when the \emph{systematic} factor is negative, then the asset values will tend to be smaller, which will produce more defaults.
      \vskip1ex
      This way the \emph{Vasicek} model introduces a correlation among defaults.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate random default probabilities
nassets <- 5
def_probs <- runif(nassets, max=0.2)
mean(def_probs)
# Calculate default thresholds
def_thresh <- qnorm(def_probs)
# Calculate number of defaults using vectorized functions (efficient way)
# Calculate vector of number of defaults
rowMeans(t(assets) < def_thresh)
def_probs
# Calculate number of defaults using for() loop (inefficient way)
# allocate matrix of de_faults
de_faults <- matrix(nr=nsimu, nc=nassets)
# Simulate asset values using for() loop
for (i in 1:nsimu) {  # Perform loop
  de_faults[i, ] <- (assets[i, ] < def_thresh)
}  # end for
colSums(de_faults) / nsimu
def_probs
# Calculate correlations between defaults
cor(de_faults)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Asset Correlation and Default Correlation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Default correlation is defined as the correlation between the \texttt{Boolean} vectors of default events.
      \vskip1ex
      The \emph{Vasicek} model introduces correlation among default events, through the correlation of \emph{asset values}.
      \vskip1ex
      If \emph{asset values} have a positive correlation, then the defaults among credits are clustered together, and if one credit defaults then the other credits are more likely to default as well.
      \vskip1ex
      Empirical studies have found that the asset correlation $\rho$ can vary between \texttt{5\%} to \texttt{20\%}, depending on the default risk.
      \vskip1ex
      Credits with higher default risk tend to also have higher asset correlation, since they are more  sensitive to the economic conditions.
      \vskip1ex
      Default correlations are usually much lower than the corresponding asset correlations.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define default probabilities
nassets <- 2
def_prob <- 0.2
def_thresh <- qnorm(def_prob)
# Define correlation parameters
rho <- 0.2
rho_sqrt <- sqrt(rho) ; rho_sqrtm <- sqrt(1-rho)
# Calculate vector of systematic factors
nsimu <- 1000
sysv <- rnorm(nsimu)
# Simulate asset values using vectorized functions
assets <- rho_sqrt*sysv + rho_sqrtm*rnorm(nsimu*nassets)
dim(assets) <- c(nsimu, nassets)
# Calculate number of defaults using vectorized functions
de_faults <- t(t(assets) < def_thresh)
# Calculate correlations between defaults
cor(de_faults)
# Calculate average number of defaults and compare to def_prob
colSums(de_faults) / nsimu
def_prob
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Cumulative Defaults Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If all the default probabilities are the same $p_i=p$, then the default threshold is equal to $t=\Phi^{-1}(p)$, and the conditional default probability $p(s)$, given the systematic factor $s$, is equal to:
      \begin{displaymath}
        p(s) = \Phi(\frac{t - \sqrt{\rho} s}{\sqrt{1-\rho}})
      \end{displaymath}
      The cumulative probability $P(x)$ for the percentage \texttt{x} of portfolio defaults (the portfolio cumulative default distribution) is equal to:
      \begin{displaymath}
        P(x) = \Phi(\frac{{\sqrt{1-\rho}} \, \Phi^{-1}(x) - t}{\sqrt{\rho}})
      \end{displaymath}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define cumulative default probability function
def_cumdistr <- function(x, def_thresh=(-2), rho=0.2)
  pnorm((sqrt(1-rho)*qnorm(x) - def_thresh)/sqrt(rho))
def_cumdistr(x=0.2, def_thresh=qnorm(def_prob), rho=rho)
# Plot cumulative default probability function
def_prob <- 0.4; def_thresh <- qnorm(def_prob)
curve(expr=def_cumdistr(x, def_thresh=def_thresh, rho=0.05),
      xlim=c(0, 0.999), lwd=3,
      xlab="percent default", ylab="probability",
      col="green", main="Cumulative Default Probabilities")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_cum_def.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot default distribution with higher correlation
curve(expr=def_cumdistr(x, def_thresh=def_thresh, rho=0.2),
      xlim=c(0, 0.999), add=TRUE, lwd=3,
      col="blue", main="")
# Add legend
legend(x="topleft",
       legend=c("high correlation", "low correlation"),
       title=NULL, inset=0.05, cex=0.8, bg="white",
       bty="n", lwd=6, lty=1, col=c("blue", "green"))
# Add unconditional default probability
abline(v=def_prob, col="red", lwd=3)
text(x=def_prob, y=0.0,
       labels="default probability",
       lwd=2, srt=90, pos=4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Defaults Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The probability density $f(x)$ of portfolio defaults is equal to the derivative of the cumulative default distribution:
      \begin{multline*}
        \hspace{-1.7em}f(x) = \frac{\sqrt{1-\rho}}{\sqrt{\rho}} \exp(-\frac{1}{2 \rho} ({\sqrt{1-\rho}} \, \Phi^{-1}(x) - t)^2 + \\ \frac{1}{2} {\Phi^{-1}(x)^2)}
      \end{multline*}
      <<echo=TRUE,eval=FALSE>>=
# Define default probability density function
def_distr <- function(x, def_thresh=(-2), rho=0.2)
  sqrt((1-rho)/rho)*exp(-(sqrt(1-rho)*qnorm(x) -
  def_thresh)^2/(2*rho) + qnorm(x)^2/2)
# Define parameters
rho <- 0.2 ; rho_sqrt <- sqrt(rho) ; rho_sqrtm <- sqrt(1-rho)
def_prob <- 0.3; def_thresh <- qnorm(def_prob)
def_distr(0.03, def_thresh=def_thresh, rho=rho)
# Plot probability distribution of defaults
curve(expr=def_distr(x, def_thresh=def_thresh, rho=0.1),
      xlim=c(0, 1.0), lwd=3,
      xlab="percentage of defaults", ylab="density",
      col="green", main="Distribution of Defaults")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_distr_def.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot default distribution with higher correlation
curve(expr=def_distr(x, def_thresh=def_thresh, rho=0.3),
      xlab="default percentage", ylab="",
      add=TRUE, lwd=3, col="blue", main="")
# Add legend
legend(x="topright",
       legend=c("high correlation", "low correlation"),
       title=NULL, inset=0.05, cex=0.8, bg="white",
       bty="n", lwd=6, lty=1, col=c("blue", "green"))
# Add unconditional default probability
abline(v=def_prob, col="red", lwd=3)
text(x=def_prob, y=2,
       labels="default probability",
       lwd=2, srt=90, pos=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Defaults Under Extreme Correlations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the correlation $\rho$ is close to \emph{zero}, then the asset values $a_i$ are independent from each other, and defaults are also independent, so that the percentage of portfolio defaults is very close to the default probability $p$.
      \vskip1ex
      In that case, the probability density of portfolio defaults is very narrow and is centered on the default probability $p$.
      \vskip1ex
      If the correlation $\rho$ is close to \emph{one}, then the asset values $a_i$ are almost the same, and defaults occur at the same time, so that the percentage of portfolio defaults is either \emph{zero} or \emph{one}.
      \vskip1ex
      In that case, the probability density of portfolio defaults becomes \emph{bimodal}, with two peaks around  \emph{zero} and \emph{one}.
      <<echo=TRUE,eval=FALSE>>=
# Plot default distribution with low correlation
curve(expr=def_distr(x, def_thresh=def_thresh, rho=0.01),
      xlab="default percentage", ylab="", lwd=2,
      col="green", main="Distribution of Defaults")
# Plot default distribution with high correlation
curve(expr=def_distr(x, def_thresh=def_thresh, rho=0.99),
      xlab="percentage of defaults", ylab="density",
      add=TRUE, lwd=2, n=10001, col="blue", main="")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_high_corr.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Add legend
legend(x="top",
       legend=c("high correlation", "low correlation"),
       title=NULL, inset=0.1, cex=0.8, bg="white",
       bty="n", lwd=6, lty=1, col=c("blue", "green"))
# Add unconditional default probability
abline(v=0.1, col="red", lwd=2)
text(x=0.1, y=10, lwd=2, pos=4,
       labels="default probability")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Numerical Integration of Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{integrate()} performs numerical integration of a function of a single variable, i.e. it calculates a definite integral over an integration interval.
      \vskip1ex
      Additional parameters can be passed to the integrated function through the dots \texttt{"..."} argument of the function \texttt{integrate()}.
      \vskip1ex
      The function \texttt{integrate()} accepts the integration limits \texttt{-Inf} and \texttt{Inf} equal to minus and plus infinity.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Get help for integrate()
?integrate
# Calculate slowly converging integral
func <- function(x) {1/((x+1)*sqrt(x))}
integrate(func, lower=0, upper=10)
integrate(func, lower=0, upper=Inf)
# Integrate function with parameter lambdav
func <- function(x, lambdav=1) {
  exp(-x*lambdav)
}  # end func
integrate(func, lower=0, upper=Inf)
integrate(func, lower=0, upper=Inf, lambdav=2)
# Cumulative probability over normal distribution
pnorm(-2)
integrate(dnorm, low=2, up=Inf)
str(dnorm)
pnorm(-1)
integrate(dnorm, low=2, up=Inf, mean=1)
# Expected value over normal distribution
integrate(function(x) x*dnorm(x), low=2, up=Inf)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Loss Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The expected loss (\emph{EL}) of a credit portfolio is equal to the sum of default probabilities ($p_i$) multiplied by the loss given default (\emph{LGD}, also known as the \emph{loss severity} - equal to $1$ minus the \emph{recovery rate}):
      \begin{displaymath}
        EL = \sum_{i=1}^{n} p_i LGD_i
      \end{displaymath}
      If the \emph{LGD} amounts are all the same, then the \emph{portfolio loss distribution} can be obtained from the \emph{default distribution}, adjusted for the \emph{LGD}:
      \begin{multline*}
        \hspace{-1.7em}f(x) = \frac{\sqrt{1-\rho}}{LGD \sqrt{\rho}} \exp(-\frac{1}{2 \rho} ({\sqrt{1-\rho}} \Phi^{-1}(\frac{x}{LGD}) - t)^2 + \\ \frac{1}{2} {\Phi^{-1}(\frac{x}{LGD}))^2}
      \end{multline*}
      <<echo=TRUE,eval=FALSE>>=
# Vasicek model parameters
rho <- 0.1; lgd <- 0.4
def_prob <- 0.05; def_thresh <- qnorm(def_prob)
# Define Vasicek loss distribution function
loss_distr <- function(x, def_thresh=(-2), rho=0.2, lgd=0.4)
  sqrt((1-rho)/rho)*exp(-(sqrt(1-rho)*qnorm(x/lgd) - def_thresh)^2/(2*rho) + qnorm(x/lgd)^2/2)/lgd
integrate(loss_distr, low=0, up=lgd, def_thresh=(-2), rho=rho, lgd=lgd)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_loss_distr.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot probability distribution of losses
x11(width=6, height=5)
curve(expr=loss_distr(x, def_thresh=def_thresh, rho=rho),
      type="l", xlim=c(0, 0.06),
      xlab="loss percentage", ylab="density", lwd=3,
      col="blue", main="Portfolio Loss Density")
# Add line for expected loss
abline(v=lgd*def_prob, col="red", lwd=3)
text(x=lgd*def_prob-0.001, y=35, labels="expected loss", lwd=3, pos=4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Collateralized Debt Obligations (\protect\emph{CDOs})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Collateralized Debt Obligations (cash \emph{CDOs}) are securities (bonds) collateralized by other debt assets.
      \vskip1ex
      The \emph{CDO} assets can be debt instruments like bonds, loans, and mortgages.
      \vskip1ex
      The \emph{CDO} liabilities are \emph{CDO} tranches, which receive cashflows from the \emph{CDO} assets, and are exposed to their defaults.
      \vskip1ex
      \emph{CDO} tranches have an attachment point (subordination, i.e. the percentage of asset default losses at which the tranche starts absorbing those losses), and a detachment point when the tranche is wiped out (suffers \texttt{100\%} losses).
      \vskip1ex
      The \emph{equity tranche} is the most junior tranche, and is the first to absorb default losses.
      \vskip1ex
      The \emph{mezzanine tranches} are senior to the \emph{equity tranche} and absorb losses ony after the \emph{equity tranche} is wiped out.
      \vskip1ex
      The \emph{senior tranche} is the most senior tranche, and is the last to absorb losses.
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/CDO2.jpg}
      \vskip1ex
      \vskip1ex
      \includegraphics[width=0.45\paperwidth]{figure/CDO.jpg}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CDO} Tranche Losses}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Single-tranche (synthetic) \emph{CDOs} are credit default swaps which reference credit portfolios.
      \vskip1ex
      The expected loss \emph{EL} on a \emph{CDO} tranche is:
      \begin{displaymath}
        EL = \frac{1}{d - a} \int_{a}^{d} {(x-a) \, f(x) \, \mathrm{d}x} + \int_{d}^{LGD} {f(x) \, \mathrm{d}x}
      \end{displaymath}
      Where $f(x)$ is the density of portfolio losses, and \emph{a} and \emph{d} are the tranche attachment (subordination) and detachment points.
      \vskip1ex
      The difference $(d-a)$ is the tranche \emph{thickness}, so that $EL$ is the expected loss as a percentage of the tranche notional.
      \vskip1ex
      A single-tranche \emph{CDO} can be thought of as a short option spread on the asset defaults, struck at the attachment and detachment points.
      <<echo=TRUE,eval=FALSE>>=
# Define cumulative default probability function
cum_loss <- function(x, def_thresh=(-2), rho=0.2, lgd=0.4)
  pnorm((sqrt(1-rho)*qnorm(x/lgd) - def_thresh)/sqrt(rho))
# Define Vasicek loss distribution function
# (vectorized version with error handling for x)
loss_distr <- function(x, def_thresh=-2, rho=0.1, lgd=0.4) {
  q_norm <- ifelse(x/lgd < 0.999, qnorm(x/lgd), 3.1)
  sqrt((1-rho)/rho)*exp(-(sqrt(1-rho)*q_norm - def_thresh)^2/(2*rho) + q_norm^2/2)/lgd
}  # end loss_distr
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/cdo_tranche.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
def_prob <- 0.2; def_thresh <- qnorm(def_prob)
rho <- 0.1; lgd <- 0.4
at_tach <- 0.15; de_tach <- 0.2
# Expected tranche loss is sum of two terms
tranche_loss <-
  # Loss between at_tach and de_tach
  integrate(function(x, at_tach) (x-at_tach)*loss_distr(x,
      def_thresh=def_thresh, rho=rho, lgd=lgd),
      low=at_tach, up=de_tach, at_tach=at_tach)$value / (de_tach-at_tach) +
  # Loss in excess of de_tach
        (1-cum_loss(x=de_tach, def_thresh=def_thresh, rho=rho, lgd=lgd))
# Plot probability distribution of losses
curve(expr=loss_distr(x, def_thresh=def_thresh, rho=rho),
      type="l", xlim=c(0, 3*lgd*def_prob),
      xlab="loss percentage", ylab="density", lwd=3,
      col="orange", main="CDO Tranche Losses")
# Add line for expected loss
abline(v=lgd*def_prob, col="red", lwd=3)
text(x=lgd*def_prob-0.001, y=4, labels="expected loss",
       lwd=2, srt=90, pos=3)
# Add lines for attach and detach
abline(v=at_tach, col="blue", lwd=3)
text(x=at_tach-0.001, y=4, labels="attach",
       lwd=2, srt=90, pos=3)
abline(v=de_tach, col="green", lwd=3)
text(x=de_tach-0.001, y=4, labels="detach",
       lwd=2, srt=90, pos=3)
# Add shading for CDO tranche
vars <- seq(at_tach, de_tach, length=100)
densv <- sapply(vars, loss_distr,
  def_thresh=def_thresh, rho=rho)
# Draw shaded polygon
polygon(c(at_tach, vars, de_tach), density=20,
  c(-1, densv, -1), col="red", border=NA)
text(x=0.5*(at_tach+de_tach), y=0, labels="CDO tranche", cex=0.9, lwd=2, pos=3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Value at Risk}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Value at Risk (\emph{VaR}) measures extreme portfolio loss (but not the worst possible loss), defined as the \emph{quantile} of the loss distribution, corresponding to a given confidence level $\alpha$.
      \vskip1ex
      A loss exceeding the \emph{EL} is called the Unexpected Loss (\emph{UL}), and can be calculated from the \emph{portfolio loss distribution}.
      <<echo=TRUE,eval=FALSE>>=
# Add lines for unexpected loss
abline(v=0.04, col="blue", lwd=3)
arrows(x0=0.02, y0=35, x1=0.04, y1=35, code=3, lwd=3, cex=0.5)
text(x=0.03, y=36, labels="unexpected loss", lwd=2, pos=3)
# Add lines for VaR
abline(v=0.055, col="red", lwd=3)
arrows(x0=0.0, y0=25, x1=0.055, y1=25, code=3, lwd=3, cex=0.5)
text(x=0.03, y=26, labels="VaR", lwd=2, pos=3)
text(x=0.055-0.001, y=10, labels="VaR", lwd=2, srt=90, pos=3)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_distr_var.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Conditional Value at Risk} (\emph{CVaR}) is equal to the average of the \emph{VaR} for confidence levels less than a given confidence level $\alpha$:
      \begin{displaymath}
        \mathrm{CVaR} = \frac{1}{\alpha} \int_{0}^{\alpha} {\mathrm{VaR}(p) \, \mathrm{d}p} = \frac{1}{\alpha} \int_{\mathrm{VaR}}^{LGD} {x \, f(x) \, \mathrm{d}x}
      \end{displaymath}
      The \emph{Conditional Value at Risk} is also called the Expected Shortfall (\emph{ES}), or Expected Tail Loss (\emph{ETL}).
      <<echo=TRUE,eval=FALSE>>=
varisk <- 0.04; varm <- 4*lgd*def_prob
# Calculate CVaR
cvar <- integrate(function(x, ...) x*loss_distr(x, ...),
  low=varisk, up=lgd, def_thresh=def_thresh, rho=rho, lgd=lgd)$value
cvar <- cvar/integrate(loss_distr, low=varisk, up=lgd, def_thresh=def_thresh, rho=rho, lgd=lgd)$value
# Plot probability distribution of losses
curve(expr=loss_distr(x, def_thresh=def_thresh, rho=rho),
      type="l", xlim=c(0, 0.06),
      xlab="loss percentage", ylab="density", lwd=3,
      col="orange", main="Conditional Value at Risk")
# Add line for expected loss
abline(v=lgd*def_prob, col="red", lwd=3)
text(x=lgd*def_prob-0.001, y=10, labels="expected loss", lwd=2, srt=90, pos=3)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_distr_cvar.png}
      <<echo=TRUE,eval=FALSE>>=
# Add lines for VaR
abline(v=varisk, col="red", lwd=3)
text(x=varisk-0.001, y=10, labels="VaR",
       lwd=2, srt=90, pos=3)
# Add shading for CVaR
vars <- seq(varisk, varm, length=100)
densv <- sapply(vars, loss_distr,
  def_thresh=def_thresh, rho=rho)
# Draw shaded polygon
polygon(c(varisk, vars, varm), density=20,
  c(-1, densv, -1), col="red", border=NA)
text(x=varisk+0.005, y=0, labels="CVaR", lwd=2, pos=3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Value at Risk Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Value at Risk (\emph{VaR}) measures extreme portfolio loss (but not the worst possible loss), defined as the \emph{quantile} of the loss distribution, corresponding to a given confidence level $\alpha$.
      \vskip1ex
      The \emph{quantile} of the loss distribution (the \emph{VaR}), for a given a confidence level $\alpha$, is given by the inverse of the cumulative loss distribution:
      \begin{displaymath}
        VaR(\alpha) = LGD \cdot \Phi(\frac{{\sqrt{\rho}} \Phi^{-1}(\alpha) + t}{\sqrt{1-\rho}})
      \end{displaymath}
      <<echo=TRUE,eval=FALSE>>=
# VaR (quantile of the loss distribution)
var_func <- function(x, def_thresh=qnorm(0.1), rho=0.1, lgd=0.4)
  lgd*pnorm((sqrt(rho)*qnorm(x) + def_thresh)/sqrt(1-rho))
var_func(x=0.99, def_thresh=def_thresh, rho=rho, lgd=lgd)
# Plot VaR
curve(expr=var_func(x, def_thresh=def_thresh, rho=rho, lgd=lgd),
      type="l", xlim=c(0, 0.999), xlab="confidence level", ylab="VaR", lwd=3,
      col="orange", main="VaR versus Confidence Level")
# Add line for expected loss
abline(h=lgd*def_prob, col="red", lwd=3)
text(x=0.2, y=lgd*def_prob, labels="expected loss", lwd=2, pos=3)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_var.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Value at Risk and Confidence Levels}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The confidence levels of \emph{VaR} values can also be calculated by integrating over the tail of the loss density function.
      <<echo=TRUE,eval=FALSE>>=
# Integrate loss_distr() over full range
integrate(loss_distr, low=0.0, up=lgd,
          def_thresh=def_thresh, rho=rho, lgd=lgd)
# Calculate expected losses using loss_distr()
integrate(function(x, ...) x*loss_distr(x, ...),
          low=0.0, up=lgd,
          def_thresh=def_thresh, rho=rho, lgd=lgd)
# Calculate confidence levels corresponding to VaR values
vars <- seq(0.07, 0.12, 0.001)
levels <- sapply(vars, function(varisk, ...) {
  integrate(loss_distr, low=varisk, up=lgd, ...)
}, def_thresh=def_thresh, rho=rho, lgd=lgd)  # end sapply
levels <- cbind(as.numeric(t(levels)[, 1]), vars)
colnames(levels) <- c("levels", "VaRs")
# Calculate 95% confidence level VaR value
levels[match(TRUE, levels[, "levels"] < 0.05), "VaRs"]
plot(x=1-levels[, "levels"],
     y=levels[, "VaRs"], lwd=2,
     xlab="confidence level", ylab="VaRs",
     t="l", main="VaR Values and Confidence Levels")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_var_conf.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{CVaR} values can be calculated by integrating over the tail of the loss density function.
      <<echo=TRUE,eval=FALSE>>=
# Calculate CVaR values
cvars <- sapply(vars, function(varisk, ...) {
  integrate(function(x, ...) x*loss_distr(x, ...),
            low=varisk, up=lgd, ...)
}, def_thresh=def_thresh, rho=rho, lgd=lgd)  # end sapply
levels <- cbind(levels, as.numeric(t(cvars)[, 1]))
colnames(levels)[3] <- "CVaRs"
# Divide CVaR by confidence level
levels[, "CVaRs"] <- levels[, "CVaRs"]/levels[, "levels"]
# Calculate 95% confidence level CVaR value
levels[match(TRUE,
  levels[, "levels"] < 0.05), "CVaRs"]
# Plot CVaRs
plot(x=1-levels[, "levels"],
     y=levels[, "CVaRs"],
     t="l", col="red", lwd=2,
     ylim=range(levels[, c("VaRs", "CVaRs")]),
     xlab="confidence level", ylab="CVaRs",
     main="CVaR Values and Confidence Levels")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_cvar_levels.png}
      <<echo=TRUE,eval=FALSE>>=
# Add VaRs
lines(x=1-levels[, "levels"], y=levels[, "VaRs"], lwd=2)
# Add legend
legend(x="topleft", legend=c("CVaRs", "VaRs"),
       title="default probability = 5%
correlation = 10%
loss given default = 40%",
       inset=0.1, cex=0.8, bg="white", bty="n",
       lwd=6, lty=1, col=c("red", "black"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Portfolio Losses Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the default probabilities $p_i$ are not all the same, then there's no formula for the \emph{portfolio loss distribution} under the Vasicek Model.
      \vskip1ex
      In that case the portfolio losses and \emph{VaR} must be simulated.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define model parameters
nassets <- 300; nsimu <- 1000; lgd <- 0.4
# Define correlation parameters
rho <- 0.2; rho_sqrt <- sqrt(rho); rho_sqrtm <- sqrt(1-rho)
# Calculate default probabilities and thresholds
set.seed(1121)
def_probs <- runif(nassets, max=0.2)
def_thresh <- qnorm(def_probs)
# Simulate losses under Vasicek model
sysv <- rnorm(nsimu)
assets <- matrix(rnorm(nsimu*nassets), ncol=nsimu)
assets <- t(rho_sqrt*sysv + t(rho_sqrtm*assets))
losses <- lgd*colSums(assets < def_thresh)/nassets
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{VaR} and \protect\emph{CVaR} Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{density()} calculates a kernel estimate of the probability density for a sample of data, and returns a list with a vector of loss values and a vector of corresponding densities.
      \vskip1ex
      <<echo=TRUE,eval=FALSE>>=
# Calculate VaR from confidence level
confl <- 0.95
varisk <- quantile(losses, confl)
# Calculate the CVaR as the mean losses in excess of VaR
cvar <- mean(losses[losses > varisk])
# Plot the density of portfolio losses
x11(width=6, height=5)
densv <- density(losses)
plot(densv, xlab="loss percentage", ylab="density", 
     lwd=3, col="blue", main="Portfolio Loss Distribution")
# Add vertical line for expected loss
exploss <- lgd*mean(def_probs)
abline(v=exploss, col="red", lwd=3)
xmax <- max(densv$x); ymax <- max(densv$y)
text(x=exploss, y=(6*ymax/7), labels="expected loss", 
     lwd=2, pos=4)
# Add vertical line for VaR
abline(v=varisk, col="red", lwd=3)
text(x=varisk, y=4*ymax/5, labels="VaR", lwd=2, pos=4)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_loss_distr_simu.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Draw shaded polygon for CVaR
indeks <- (densv$x > varisk)
xvar <- c(min(densv$x[indeks]), densv$x[indeks], max(densv$x))
polygon(xvar, c(-1, densv$y[indeks], -1), col="red", border=NA, density=10)
# Add text for CVaR
text(x=5*varisk/4, y=(ymax/7), labels="CVaR", lwd=2, pos=4)
# Add text with data
text(xmax, ymax, labels=paste0(
       "Expected Loss = ", format(100*exploss, digits=3), "%", "\n",
       "Loss severity = ", format(100*lgd, digits=3), "%", "\n",
       "Correlation = ", format(100*rho, digits=3), "%", "\n",
       "VaR = ", format(100*varisk, digits=3), "%", "\n",
       "CVaR = ", format(100*cvar, digits=3), "%"), 
     adj=c(1, 1), cex=0.8, lwd=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating \protect\emph{VaR} Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{VaR} can be calculated from the simulated portfolio losses using the function \texttt{quantile()}.
      \vskip1ex
      The function \texttt{quantile()} calculates the sample quantiles.  It uses interpolation to improve the accuracy.  Information about the different interpolation methods can be found by typing \texttt{?quantile}.
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_var_simu.png}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VaRs from confidence levels
levels <- seq(0.93, 0.99, 0.01)
vars <- quantile(losses, probs=levels)
plot(x=levels, y=vars, t="l", lwd=2,
     xlab="confidence level", ylab="VaRs",
     main="Simulated VaR and Confidence Levels")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating \protect\emph{CVaR} Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{CVaR} can be calculated from the frequency of tail losses in excess of the \emph{VaR}.
      \vskip1ex
      The function \texttt{table()} calculates the frequency distribution of categorical data.
      <<echo=TRUE,eval=FALSE>>=
# Calculate CVaRs
cvars <- sapply(vars, function(varisk) {
  mean(losses[losses >= varisk])
})  # end sapply
cvars <- cbind(cvars, vars)
# Alternative CVaR calculation using frequency table
# first calculate frequency table of losses
# tablev <- table(losses)/nsimu
# Calculate CVaRs from frequency table
# Cvars <- sapply(vars, function(varisk) {
#   tai_l <- tablev[names(tablev) > varisk]
#   tai_l %*% as.numeric(names(tai_l)) / sum(tai_l)
# })  # end sapply
# Plot CVaRs
plot(x=levels, y=cvars[, "cvars"],
     t="l", col="red", lwd=2,
     ylim=range(cvars),
     xlab="confidence level", ylab="CVaRs",
     main="Simulated CVaR and Confidence Levels")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_cvar_simu.png}
      <<echo=TRUE,eval=FALSE>>=
# Add VaRs
lines(x=levels, y=cvars[, "vars"], lwd=2)
# Add legend
legend(x="topleft", legend=c("CVaRs", "VaRs"), bty="n",
       title=NULL, inset=0.05, cex=0.8, bg="white",
       lwd=6, lty=1, col=c("red", "black"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Function for Simulating \protect\emph{VaR} Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      The function \texttt{calc\_var()} simulates default losses under the \emph{Vasicek} model, for a vector of confidence levels, and calculates a vector of \emph{VaR} and \emph{CVaR} values.
      <<echo=TRUE,eval=FALSE>>=
calcvar <- function(def_thresh, # Default thresholds
                     lgd=0.6, # loss given default
                     rho_sqrt, rho_sqrtm, # asset correlation
                     nsimu=1000, # number of simulations
                     levels=seq(0.93, 0.99, 0.01) # Confidence levels
                     ) {
  # Define model parameters
  nassets <- NROW(def_thresh)
  # Simulate losses under Vasicek model
  sysv <- rnorm(nsimu)
  assets <- matrix(rnorm(nsimu*nassets), ncol=nsimu)
  assets <- t(rho_sqrt*sysv + t(rho_sqrtm*assets))
  losses <- lgd*colSums(assets < def_thresh)/nassets
  # Calculate VaRs and CVaRs
  vars <- quantile(losses, probs=levels)
  cvars <- sapply(vars, function(varisk) {
    mean(losses[losses >= varisk])
  })  # end sapply
  names(vars) <- levels
  names(cvars) <- levels
  c(vars, cvars)
}  # end calcvar
      @
    \column{0.3\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of \protect\emph{VaR} Using Bootstrap Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The values of \emph{VaR} and \emph{CVaR} produced by the function \texttt{calc\_var()} are subject to uncertainty because they're calculated from a simulation.
      \vskip1ex
      We can calculate the standard errors of \emph{VaR} and \emph{CVaR} by running the function \texttt{calc\_var()} many times and repeating the simulation in a loop.
      \vskip1ex
      This bootstrap will only capture the uncertainty due to the finite number of trials in the simulation, but not due to the uncertainty of model parameters.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define model parameters
nassets <- 300; nsimu <- 1000; lgd <- 0.4
rho <- 0.2; rho_sqrt <- sqrt(rho); rho_sqrtm <- sqrt(1-rho)
# Calculate default probabilities and thresholds
set.seed(1121)
def_probs <- runif(nassets, max=0.2)
def_thresh <- qnorm(def_probs)
# Define number of bootstrap simulations
nboot <- 500
# Perform bootstrap of calcvar
set.seed(1121)
boot_data <- sapply(rep(lgd, nboot), calcvar,
  def_thresh=def_thresh,
  rho_sqrt=rho_sqrt, rho_sqrtm=rho_sqrtm,
  nsimu=nsimu, levels=levels)  # end sapply
boot_data <- t(boot_data)
# Calculate vectors of standard errors of VaR and CVaR from boot_data data
std_error_var <- apply(boot_data[, 1:7], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
std_error_cvar <- apply(boot_data[, 8:14], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
# Scale the standard errors of VaRs and CVaRs
std_error_var[2, ] <- std_error_var[2, ]/std_error_var[1, ]
std_error_cvar[2, ] <- std_error_cvar[2, ]/std_error_cvar[1, ]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of \protect\emph{VaR} at High Confidence Levels}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The standard errors of \emph{VaR} and \emph{CVaR} are inversely proportional to square root of the number of loss events in the simulation that exceed the \emph{VaR}.
      \vskip1ex
      So the greater the number of loss events, the smaller the standard errors, and vice versa.
      \vskip1ex
      But as the confidence level increases, the \emph{VaR} also increases, and the number of loss events decreases, causing larger standard errors.
      \vskip1ex
      So the as the confidence level increases, the standard errors of \emph{VaR} and \emph{CVaR} also increase.
      \vskip1ex
      The \emph{scaled} (relative) standard errors of \emph{VaR} and \emph{CVaR} also increase with the confidence level, making them much less reliable at very high confidence levels.
      \vskip1ex
      The standard error of \emph{CVaR} is even greater than that of \emph{VaR}.
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_cvar_stderror.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the standard errors of VaRs and CVaRs
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(0, 0, 0, 0), mgp=c(2, 1, 0))
plot(x=colnames(std_error_cvar), y=std_error_cvar[2, ], 
  t="l", col="red", lwd=2,
  ylim=range(c(std_error_var[2, ], std_error_cvar[2, ])),
  xlab="confidence level", ylab="standard error",
  main="Scaled standard errors of CVaR and VaR")
lines(x=colnames(std_error_var), y=std_error_var[2, ], lwd=2)
legend(x="topleft", legend=c("CVaRs", "VaRs"), bty="n",
       title=NULL, inset=0.05, cex=0.8, bg="white",
       lwd=6, lty=1, col=c("red", "black"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of \protect\emph{VaR} Using Parallel Bootstrap}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{scaled} standard errors of \emph{VaR} and \emph{CVaR} increase with the confidence level, making them much less reliable at very high confidence levels.
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # load package parallel
numcores <- detectCores() - 1  # number of cores
cluster <- makeCluster(numcores)  # Initialize compute cluster
# Perform bootstrap of calcvar for Windows
clusterSetRNGStream(cluster, 1121)
boot_data <- parLapply(cluster, rep(lgd, nboot),
  fun=calcvar, def_thresh=def_thresh,
  rho_sqrt=rho_sqrt, rho_sqrtm=rho_sqrtm,
  nsimu=nsimu, levels=levels)  # end parLapply
# Bootstrap under Mac-OSX or Linux
boot_data <- mclapply(rep(lgd, nboot),
  FUN=calcvar, def_thresh=def_thresh,
  rho_sqrt=rho_sqrt, rho_sqrtm=rho_sqrtm,
  nsimu=nsimu, levels=levels)  # end mclapply
boot_data <- rutils::do_call(rbind, boot_data)
stopCluster(cluster)  # Stop R processes over cluster
# Calculate vectors of standard errors of VaR and CVaR from boot_data data
std_error_var <- apply(boot_data[, 1:7], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
std_error_cvar <- apply(boot_data[, 8:14], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
# Scale the standard errors of VaRs and CVaRs
std_error_varscaled <- std_error_var[2, ]/std_error_var[1, ]
std_error_cvarscaled <- std_error_cvar[2, ]/std_error_cvar[1, ]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_cvar_stderror_parallel.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the standard errors of VaRs and CVaRs
x11(width=6, height=5)
plot(x=colnames(std_error_cvar),
  y=std_error_cvarscaled, t="l", col="red", lwd=2,
  ylim=range(c(std_error_varscaled, std_error_cvarscaled)),
  xlab="confidence level", ylab="standard error",
  main="Scaled standard errors of CVaR and VaR")
lines(x=colnames(std_error_var), y=std_error_varscaled, lwd=2)
legend(x="topleft", legend=c("CVaRs", "VaRs"), bty="n",
       title=NULL, inset=0.05, cex=0.8, bg="white",
       lwd=6, lty=1, col=c("red", "black"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vasicek Model With Uncertain Default Probabilities}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.7\textwidth}
      The previous bootstrap only captured the uncertainty due to the finite simulation trials, but not due to the uncertainty of model parameters, such as the default probabilities and correlations.
      \vskip1ex
      The below function \texttt{calc\_var()} can simulate the \emph{Vasicek} model with uncertain default probabilities.
      <<echo=TRUE,eval=FALSE>>=
calcvar <- function(def_probs, # Default probabilities
                     lgd=0.6, # loss given default
                     rho_sqrt, rho_sqrtm, # asset correlation
                     nsimu=1000, # number of simulations
                     levels=seq(0.93, 0.99, 0.01) # Confidence levels
                     ) {
  # Calculate random default thresholds
  def_thresh <- qnorm(runif(1, min=0.5, max=1.5)*def_probs)
  # Simulate losses under Vasicek model
  nassets <- NROW(def_probs)
  sysv <- rnorm(nsimu)
  assets <- matrix(rnorm(nsimu*nassets), ncol=nsimu)
  assets <- t(rho_sqrt*sysv + t(rho_sqrtm*assets))
  losses <- lgd*colSums(assets < def_thresh)/nassets
  # Calculate VaRs and CVaRs
  vars <- quantile(losses, probs=levels)
  cvars <- sapply(vars, function(varisk) {
    mean(losses[losses >= varisk])
  })  # end sapply
  names(vars) <- levels
  names(cvars) <- levels
  c(vars, cvars)
}  # end calcvar
      @
    \column{0.3\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors Due to Uncertain Default Probabilities}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The greatest contribution to the standard errors of \emph{VaR} and \emph{CVaR} is from the uncertainty of model parameters, such as the default probabilities, correlations, and loss severities.
      \vskip1ex
      For example, a \texttt{50\%} uncertainty in the default probabilities can produce a \texttt{20\%} uncertainty of the \emph{VaR}.
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # load package parallel
numcores <- detectCores() - 1  # number of cores
cluster <- makeCluster(numcores)  # Initialize compute cluster
# Perform bootstrap of calcvar for Windows
clusterSetRNGStream(cluster, 1121)
boot_data <- parLapply(cluster, rep(lgd, nboot),
  fun=calcvar, def_probs=def_probs,
  rho_sqrt=rho_sqrt, rho_sqrtm=rho_sqrtm,
  nsimu=nsimu, levels=levels)  # end parLapply
# Bootstrap under Mac-OSX or Linux
boot_data <- mclapply(rep(lgd, nboot),
  FUN=calcvar, def_probs=def_probs,
  rho_sqrt=rho_sqrt, rho_sqrtm=rho_sqrtm,
  nsimu=nsimu, levels=levels)  # end mclapply
boot_data <- rutils::do_call(rbind, boot_data)
stopCluster(cluster)  # Stop R processes over cluster
# Calculate vectors of standard errors of VaR and CVaR from boot_data data
std_error_var_param <- apply(boot_data[, 1:7], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
std_error_cvar_param <- apply(boot_data[, 8:14], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_var_stderror_default_uncertainty.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the standard errors of VaRs under uncertain default probabilities
x11(width=6, height=5)
plot(x=colnames(std_error_var),
  y=std_error_var[2, ], t="l", lwd=3,
  ylim=range(c(std_error_var[2, ], std_error_var_param[2, ])),
  xlab="confidence level", ylab="standard error",
  main="Standard Errors of VaR 
  with Uncertain Default Probabilities")
lines(x=colnames(std_error_var), y=std_error_var_param[2, ],
      col="red", lwd=3)
legend(x=0.95, y=0.02, bty="n",
       legend=c("VaR Fixed Def Probs", "VaR Random Def Probs"), 
       title=NULL, inset=0.05, cex=1.0, bg="white",
       lwd=6, lty=1, col=c("black", "red"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Relative Errors Due to Uncertain Default Probabilities}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{scaled} (relative) standard errors of \emph{VaR} and \emph{CVaR} under uncertain default probabilities decrease with higher confidence level, because the standard errors are less dependent on the confidence level and don't increase as fast as the \emph{VaR} does.
      <<echo=TRUE,eval=FALSE>>=
# Scale the standard errors of VaRs and CVaRs
std_error_varscaled <- std_error_var_param[2, ]/
  std_error_var_param[1, ]
std_error_cvarscaled <- std_error_cvar_param[2, ]/
  std_error_cvar_param[1, ]
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/vasicek_stderror_default_uncertainty.png}
      <<echo=TRUE,eval=FALSE>>=
# Plot the standard errors of VaRs and CVaRs
x11(width=6, height=5)
plot(x=colnames(std_error_cvar_param),
  y=std_error_cvarscaled, t="l", col="red", lwd=3,
  ylim=range(c(std_error_varscaled, std_error_cvarscaled)),
  xlab="confidence level", ylab="standard error",
  main="Relative Standard Errors of VaR and CVaR
  with Uncertain Default Probabilities")
lines(x=names(std_error_varscaled), y=std_error_varscaled, lwd=3)
legend(x="topright", legend=c("CVaR", "VaR"), bty="n",
       title=NULL, inset=0.05, cex=1.0, bg="white",
       lwd=6, lty=1, col=c("red", "black"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Model Risk of Credit Portfolio Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Credit portfolio models are subject to very significant \emph{model risk} due to the uncertainties of model parameters, such as the default probabilities, correlations, and loss severities.
      \vskip1ex
      Model risk is the risk of incorrect model predictions due to incorrect model specification, and due to incorrect model parameters.
      \vskip1ex
      Jon Danielsson at the London School of Economics (LSE) has studied the model risk of \emph{VaR} and \emph{CVaR} in:
\href{https://www.systemicrisk.ac.uk/publications/discussion-papers/why-risk-so-hard-measure}{Why Risk is So Hard to Measure}, and in 
\href{https://www.federalreserve.gov/econres/feds/model-risk-of-risk-models.htm}{Model Risk of Risk Models}.
      \vskip1ex
      Jon Danielsson has pointed out that there's not enough historical data to be able to accurately calculate the credit model parameters.
      \vskip1ex
      Jon Danielsson and Chen Zhou have demonstrated that accurately estimating \emph{CVaR} at \texttt{5\%} confidence 
\href{http://www.bloomberg.com/view/articles/2016-05-23/big-banks-risk-does-not-compute}{would require decades of price history}, something that simply doesn't exist for many assets.
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Simulating the Vasicek Model Using Importance Sampling}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The simulation estimates of \emph{VaR} and \emph{CVaR} have large standard errors because default events are rare, so the number of events which contribute to their estimates is therefore small.
      \vskip1ex
      The \emph{variance} of an estimate produced by simulation decreases with the number of events which contribute to the estimate: $\sigma^2 \propto \frac{1}{n}$.
      \vskip1ex
      \emph{Importance sampling} with probability tilting can be applied to reduce the standard errors of \emph{VaR} and \emph{CVaR}.
      \vskip1ex
      The exponential probability tilting can be applied to the \emph{systematic} factor $s$:
      \begin{displaymath}
        \Phi(s, \lambda) = \exp(s \lambda - \lambda^2/2) \cdot \Phi(s, \lambda = 0)
      \end{displaymath}
      Where $\lambda$ is the tilt parameter.
      \vskip1ex
      The simulation outputs are then multiplied by the weights to compensate for the probability tilting:
      \begin{displaymath}
        w_x = \exp(-x \lambda + \lambda^2/2)
      \end{displaymath}
    \column{0.5\textwidth}
      \vspace{-1em}
    % wippp
      <<echo=TRUE,eval=FALSE>>=
# Define model parameters
nassets <- 300; nsimu <- 1000; lgd <- 0.4
# Define correlation parameters
rho <- 0.2; rho_sqrt <- sqrt(rho); rho_sqrtm <- sqrt(1-rho)
# Calculate default probabilities and thresholds
set.seed(1121)
def_probs <- runif(nassets, max=0.2)
def_thresh <- qnorm(def_probs)
# Calculate vector of systematic factors
sysv <- rnorm(nsimu)
# Calculate vector of idiosyncratic factors
idio_syncratic <-
  matrix(rnorm(nsimu*nassets), ncol=nsimu)
# Simulate losses under Vasicek model
assets <-
  t(rho_sqrt*sysv + t(rho_sqrtm*idio_syncratic))
losses <-
  lgd*colSums(assets < def_thresh)/nassets
# Calculate VaRs
levels <- seq(0.93, 0.99, 0.01)
vars <- quantile(losses, probs=levels)

# Importance sampling losses
lambdav <- 3
assets <-
  t(rho_sqrt*sysv + t(rho_sqrtm*idio_syncratic))

cond_thresh <- outer(rho_sqrtm*def_thresh, -rho_sqrt*sysv, FUN="+")

cond_probs <- pnorm(cond_thresh)

tilt_probs <- lambdav*cond_probs/(1 + cond_probs*(lambdav - 1))

weights <- (1 + tilt_probs*(lambdav - 1))/lambdav

tilt_thresh <- qnorm(tilt_probs)

losses <-
  lgd*colSums(weights*(assets < tilt_thresh))/nassets

vars <- quantile(losses, probs=levels)


foo <- (unifunc < def_probs)

def_thresh <- qnorm(def_probs)





assets <- t(rho_sqrt*(sysv - lambdav) +
      t(rho_sqrtm*idio_syncratic))
losses <-
  lgd*colSums(assets < def_thresh)/nassets
# Calculate VaRs
vars <- quantile(losses, probs=levels)


assets <- t(rho_sqrt*(sysv - lambdav) +
      t(rho_sqrtm*idio_syncratic))
losses <-
  lgd*colSums(assets < def_thresh)/nassets
# Calculate VaRs
vars <- quantile(losses, probs=levels)



plot(x=levels, y=vars, t="l", lwd=2,
     xlab="confidence level", ylab="VaRs",
     main="Simulated VaR and Confidence Levels")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Standard Errors of \protect\emph{VaR} Using Bootstrap Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The values of \emph{VaR} and \emph{CVaR} produced by the function \texttt{calc\_var()} are subject to uncertainty because they're calculated from a simulation.
      \vskip1ex
      We can calculate the standard errors of \emph{VaR} and \emph{CVaR} by running the function \texttt{calc\_var()} many times and repeating the simulation in a loop.
      \vskip1ex
      This bootstrap will only capture the uncertainty due to the finite number of trials in the simulation, but not due to the uncertainty of model parameters.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define model parameters
nassets <- 300; nsimu <- 1000; lgd <- 0.4
rho <- 0.2; rho_sqrt <- sqrt(rho); rho_sqrtm <- sqrt(1-rho)
# Calculate default probabilities and thresholds
set.seed(1121)
def_probs <- runif(nassets, max=0.2)
def_thresh <- qnorm(def_probs)
# Define number of bootstrap simulations
nboot <- 500
# Perform bootstrap of calcvar
set.seed(1121)
boot_data <- sapply(rep(lgd, nboot),
  calcvar,
  def_thresh=def_thresh,
  rho_sqrt=rho_sqrt, rho_sqrtm=rho_sqrtm,
  nsimu=nsimu, levels=levels)  # end sapply
boot_data <- t(boot_data)
# Calculate vectors of standard errors of VaR and CVaR from boot_data data
std_error_var <- apply(boot_data[, 1:7], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
std_error_cvar <- apply(boot_data[, 8:14], MARGIN=2,
    function(x) c(mean=mean(x), sd=sd(x)))
# Scale the standard errors of VaRs and CVaRs
std_error_var[2, ] <- std_error_var[2, ]/std_error_var[1, ]
std_error_cvar[2, ] <- std_error_cvar[2, ]/std_error_cvar[1, ]
      @
  \end{columns}
\end{block}

\end{frame}


\end{document}
