library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='tiny', fig.width=4, fig.height=4)
options(width=80, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)

library(xtable)
gambl_e <- data.frame(win=c("p", "a", "1 + a"), lose=c("q = 1 - p", "-b", "1 - b"))
rownames(gambl_e) <- c("probability", "payout", "terminal wealth")
# print(xtable(gambl_e), comment=FALSE, size="tiny")
print(xtable(gambl_e), comment=FALSE)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Define logarithmic utility
utili_ty <- function(frac, p=0.3, a=20, b=1) {
  p*log(1+frac*a) + (1-p)*log(1-frac*b)
}  # end utili_ty
# Plot utility
curve(expr=utili_ty, xlim=c(0, 1),
ylim=c(-0.5, 0.4), xlab="betting fraction",
ylab="utility", main="", lwd=2)
title(main="Logarithmic Utility", line=0.5)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Define and plot Kelly fraction
kelly_frac <- function(a, p=0.5, b=1) {
  p/b - (1-p)/a
}  # end kelly_frac
curve(expr=kelly_frac, xlim=c(0, 5),
ylim=c(-2, 1), xlab="betting odds",
ylab="kelly fraction", main="", lwd=2)
abline(h=0.5, lwd=2, col="red")
text(x=1.5, y=0.5, pos=3, cex=0.8, labels="max Kelly fraction=0.5")
title(main="Kelly fraction", line=-0.8)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Plot several Kelly curves
curve(expr=kelly_frac(x, b=1), xlim=c(0, 5),
ylim=c(-1, 1.5), xlab="betting odds",
ylab="kelly fraction", main="", lwd=2)
abline(h=0.5, lwd=2, col="red")
text(x=1.5, y=0.5, pos=3, cex=0.8, labels="b=1.0; max fraction=0.5")
curve(expr=kelly_frac(x, b=0.5), add=TRUE, main="", lwd=2)
abline(h=1.0, lwd=2, col="red")
text(x=1.5, y=1.0, pos=3, cex=0.8, labels="b=0.5; max fraction=1.0")
title(main="Kelly fraction", line=-0.8)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Wealth of multiperiod binary betting
weal_th <- function(f, a=0.8, b=0.1, n=1e3, i=150) {
  (1+f*a)^i * (1-f*b)^(n-i)
}  # end weal_th
curve(expr=weal_th, xlim=c(0, 1),
xlab="betting fraction",
ylab="wealth", main="", lwd=2)
title(main="Wealth of Multiperiod Betting", line=0.1)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
set.seed(1121)  # Reset random number generator
# Simulate asset prices
calc_prices <- function(x) cumprod(1 + rnorm(1e3, sd=0.01))
price_paths <- sapply(1:3, calc_prices)
plot(price_paths[, 1], type="l", lwd=3,
     main="Simulated Asset Prices",
     ylim=range(price_paths),
     lty="solid", xlab="time", ylab="price")
lines(price_paths[, 2], col="blue", lwd=3)
lines(price_paths[, 3], col="orange", lwd=3)
abline(h=0.5, col="red", lwd=3)
text(x=200, y=0.5, pos=3, labels="liquidation threshold")

library(rutils)
# Calculate the VTI returns
re_turns <- rutils::etf_env$re_turns$VTI
re_turns <- na.omit(re_turns)
c(mean=mean(re_turns), std=sd(re_turns))
range(re_turns)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Define vectorized logarithmic utility function
utili_ty <- function(kell_y, re_turns) {
  sapply(kell_y, function(x)
    sum(log(1 + x*re_turns)))
}  # end utili_ty
utili_ty(1, re_turns)
utili_ty(c(1, 4), re_turns)
# Plot the logarithmic utility
curve(expr=utili_ty(x, re_turns=re_turns),
xlim=c(0.1, 5), xlab="leverage", ylab="utility",
main="Utility of Asset Returns", lwd=2)

# Approximate Kelly leverage
mean(re_turns)/var(re_turns)
PerformanceAnalytics::KellyRatio(R=re_turns, method="full")
# Kelly leverage
unlist(optimize(
  f=function(x) -utili_ty(x, re_turns),
  interval=c(1, 4)))

# Calculate the VTI returns
re_turns <- rutils::etf_env$re_turns$VTI
re_turns <- na.omit(re_turns)
# Calculate wealth paths
kelly_ratio <- drop(mean(re_turns)/var(re_turns))
kelly_wealth <- cumprod(1 + kelly_ratio*re_turns)
hyper_kelly <- cumprod(1 + (kelly_ratio+2)*re_turns)
sub_kelly <- cumprod(1 + (kelly_ratio-2)*re_turns)
kelly_paths <- cbind(kelly_wealth, hyper_kelly, sub_kelly)
colnames(kelly_paths) <- c("kelly", "hyper-kelly", "sub-kelly")

# Plot wealth paths
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("black", "orange", "blue")
quantmod::chart_Series(kelly_paths, theme=plot_theme, name="Wealth Paths")
legend("topleft", legend=colnames(kelly_paths),
 inset=0.1, bg="white", lty=1, lwd=6,
 col=plot_theme$col$line.col, bty="n")

# bid_offer equal to 10 bps for liquid ETFs
bid_offer <- 0.001
# Calculate wealth paths
kelly_ratio <- drop(mean(re_turns)/var(re_turns))
weal_th <- cumprod(1 + kelly_ratio*re_turns)
wealth_trans <- cumprod(1 + kelly_ratio*re_turns -
  0.5*bid_offer*kelly_ratio*(kelly_ratio-1)*abs(re_turns))
# Calculate compounded wealth from returns
weal_th <- cbind(weal_th, wealth_trans)
colnames(weal_th) <- c("Kelly", "Including bid-offer")
# Plot compounded wealth
dygraphs::dygraph(weal_th, main="Kelly Strategy With Transaction Costs") %>%
  dyOptions(colors=c("green","blue"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Plot several Kelly curves
curve(expr=kelly_frac(x, b=1), xlim=c(0, 5),
ylim=c(-1, 1.5), xlab="betting odds",
ylab="kelly fraction", main="", lwd=2)
abline(h=0.5, lwd=2, col="red")
text(x=1.5, y=0.5, pos=3, cex=0.8, labels="b=1.0; max fraction=0.5")
curve(expr=kelly_frac(x, b=0.5), add=TRUE, main="", lwd=2)
abline(h=1.0, lwd=2, col="red")
text(x=1.5, y=1.0, pos=3, cex=0.8, labels="b=0.5; max fraction=1.0")
title(main="Kelly fraction", line=-0.8)

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Plot logarithmic utility function
curve(expr=log, lwd=3, col="blue", xlim=c(0.5, 5),
xlab="wealth", ylab="utility",
main="Logarithmic Utility")

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Define CRRA utility
cr_ra <- function(w, ra) {
  (w^(1-ra) - 1)/(1-ra)
}  # end cr_ra
# Plot utility functions
curve(expr=cr_ra(x, ra=0.7), xlim=c(0.5, 5), lwd=3,
xlab="wealth", ylab="utility", main="", col="blue")
curve(expr=log, add=TRUE, lwd=3)
curve(expr=cr_ra(x, ra=1.3), add=TRUE, lwd=3, col="red")
# Add title and legend
title(main="CRRA Utility", line=0.5)
legend(x="topleft", legend=c("risk seeking", "logarithmic", "risk averse"),
 title="Risk Aversion", inset=0.05, cex=0.8, bg="white",
 lwd=6, lty=1, bty="n", col=c("blue", "black", "red"))

# Open x11 for plotting
x11(width=5, height=4)
# Set plot parameters to reduce whitespace around plot
par(mar=c(4, 4, 2, 1), oma=c(0, 0, 0, 0))
# Define CRRA utility
cr_ra <- function(w, ra) {
  (w^(1-ra) - 1)/(1-ra)
}  # end cr_ra
# Plot utility functions
curve(expr=cr_ra(x, ra=0.7), xlim=c(0.5, 5), lwd=3,
xlab="wealth", ylab="utility", main="", col="blue")
curve(expr=log, add=TRUE, lwd=3)
curve(expr=cr_ra(x, ra=1.3), add=TRUE, lwd=3, col="red")
# Add title and legend
title(main="CRRA Utility", line=0.5)
legend(x="topleft", legend=c("risk seeking", "logarithmic", "risk averse"),
 title="Risk Aversion", inset=0.05, cex=0.8, bg="white",
 lwd=6, lty=1, bty="n", col=c("blue", "black", "red"))

# Calculate the VTI returns
re_turns <- rutils::etf_env$re_turns$VTI
re_turns <- na.omit(re_turns)
# Calculate wealth paths
kelly_ratio <- drop(mean(re_turns)/var(re_turns))
kelly_wealth <- cumprod(1 + kelly_ratio*re_turns)
hyper_kelly <- cumprod(1 + (kelly_ratio+2)*re_turns)
sub_kelly <- cumprod(1 + (kelly_ratio-2)*re_turns)
kelly_paths <- cbind(kelly_wealth, hyper_kelly, sub_kelly)
colnames(kelly_paths) <- c("kelly", "hyper-kelly", "sub-kelly")

# Plot wealth paths
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("black", "orange", "blue")
quantmod::chart_Series(kelly_paths, theme=plot_theme,
       name="Wealth Paths")
legend("topleft", legend=colnames(kelly_paths),
 inset=0.1, bg="white", lty=1, lwd=6,
 col=plot_theme$col$line.col, bty="n")

# Calculate the VTI returns
re_turns <- rutils::etf_env$re_turns$VTI
re_turns <- na.omit(re_turns)
# Calculate higher moments of VTI returns
c(mean=sum(re_turns),
  variance=sum(re_turns^2),
  mom3=sum(re_turns^3),
  mom4=sum(re_turns^4))/NROW(re_turns)
# Calculate higher moments of minutely SPY returns
re_turns <- HighFreq::SPY[, 4]
re_turns <- na.omit(re_turns)
re_turns <- HighFreq::diff_it(log(re_turns))
c(mean=sum(re_turns),
  variance=sum(re_turns^2),
  mom3=sum(re_turns^3),
  mom4=sum(re_turns^4))/NROW(re_turns)

re_turns <- na.omit(rutils::etf_env$re_turns[, c("VTI", "IEF")])
# Logarithmic utility of stock and bond portfolio
utili_ty <- function(w_s, w_b) {
  -sum(log(1 + w_s*re_turns$VTI + w_b*re_turns$IEF))
}  # end utili_ty
# Draw 3d surface plot of utility
library(rgl)  # Load rgl
w_s <- seq(from=3, to=8, by=0.2)
w_b <- seq(from=10, to=20, by=0.2)
utility_mat <- sapply(w_b, function(y) sapply(w_s,
  function(x) utili_ty(x, y)))
rgl::persp3d(w_s, w_b, utility_mat, col="green",
  xlab="stocks", ylab="bonds", zlab="utility")
rgl::rgl.snapshot("utility_surface.png")

# Approximate Kelly weights
weight_s <- sapply(re_turns,
function(x) mean(x)/var(x))
# Kelly weight for stocks
unlist(optimize(f=function(x)
  utili_ty(x, w_b=0), interval=c(1, 4)))
# Kelly weight for bonds
unlist(optimize(f=function(x)
  utili_ty(x, w_s=0), interval=c(1, 14)))
# Vectorized utility of stock and bond portfolio
utility_vec <- function(weight_s) {
  utili_ty(weight_s[1], weight_s[2])
}  # end utility_vec
# Optimize with respect to vector argument
op_tim <- optim(fn=utility_vec, par=c(3, 10),
          method="L-BFGS-B",
          upper=c(8, 20),
          lower=c(2, 5))
# Exact Kelly weights
op_tim$par

# Approximate Kelly weights
p_rets <- (re_turns %*% weight_s)
drop(mean(p_rets)/var(p_rets))*weight_s
# Exact Kelly weights
op_tim$par

# Quarter-Kelly sub-optimal weights
weight_s <- op_tim$par/4
# Plot Kelly optimal portfolio
re_turns <- cbind(re_turns,
  weight_s[1]*re_turns$VTI +
    weight_s[2]*re_turns$IEF)
colnames(re_turns)[3] <- "Kelly_sub_optimal"
# Calculate compounded wealth from returns
weal_th <- cumprod(1 + re_turns)
# Plot compounded wealth
dygraphs::dygraph(weal_th, main="Stock and Bond Portfolio") %>%
  dyOptions(colors=c("green","blue","green")) %>%
  dySeries("Kelly_sub_optimal", color="red", strokeWidth=2) %>%
  dyLegend(show="always", width=500)

re_turns <- na.omit(rutils::etf_env$re_turns[, c("VTI", "IEF")])
# Calculate rolling returns and variance
look_back <- 200
var_rolling <- roll::roll_var(re_turns, width=look_back)
weight_s <- roll::roll_sum(re_turns, width=look_back)/look_back
weight_s <- weight_s/var_rolling
weight_s[1, ] <- 1/NCOL(weight_s)
weight_s <- zoo::na.locf(weight_s)
sum(is.na(weight_s))
range(weight_s)

# Plot the weight_s
x11(width=6, height=5)
par(mar=c(4, 4, 3, 1), oma=c(0, 0, 0, 0))
plot(density(re_turns$IEF), t="l", lwd=3, col="red",
     xlab="weights", ylab="density",
     ylim=c(0, max(density(re_turns$VTI)$y)),
     main="Kelly Weight Distributions")
lines(density(re_turns$VTI), t="l", col="blue", lwd=3)
legend("topright", legend=c("VTI", "IEF"),
 inset=0.1, bg="white", lty=1, lwd=6,
 col=c("blue", "red"), bty="n")

# Scale and lag the Kelly weights
weight_s <- lapply(weight_s,
  function(x) 10*x/sum(abs(range(x))))
weight_s <- do.call(cbind, weight_s)
weight_s <- rutils::lag_it(weight_s)
# Calculate the compounded Kelly wealth and VTI
weal_th <- cbind(cumprod(1 + weight_s$VTI*re_turns$VTI),
           cumprod(1 + re_turns$VTI))
colnames(weal_th) <- c("Kelly Strategy", "VTI")
dygraphs::dygraph(weal_th, main="VTI Strategy Using Rolling Kelly Weight") %>%
  dyAxis("y", label="Kelly Strategy", independentTicks=TRUE) %>%
  dyAxis("y2", label="VTI", independentTicks=TRUE) %>%
  dySeries(name="Kelly Strategy", axis="y", label="Kelly Strategy", strokeWidth=1, col="red") %>%
  dySeries(name="VTI", axis="y2", label="VTI", strokeWidth=1, col="blue")

# bid_offer equal to 10 bps for liquid ETFs
bid_offer <- 0.001
# Calculate the compounded Kelly wealth and margin
weal_th <- cumprod(1 + weight_s$VTI*re_turns$VTI)
mar_gin <- (re_turns$VTI - 1)*weal_th + 1
# Calculate the transaction costs
cost_s <- bid_offer*drop(rutils::diff_it(mar_gin))/2
wealth_diff <- drop(rutils::diff_it(weal_th))
costs_rel <- ifelse(wealth_diff>0, cost_s/wealth_diff, 0)
range(costs_rel)
hist(costs_rel, breaks=10000, xlim=c(-0.02, 0.02))
# Scale and lag the transaction costs
cost_s <- rutils::lag_it(abs(cost_s)/weal_th)
# Recalculate the compounded Kelly wealth
wealth_trans <- cumprod(1 + re_turns$VTI*re_turns$VTI - cost_s)
# Plot compounded wealth
weal_th <- cbind(weal_th, wealth_trans)
colnames(weal_th) <- c("Kelly", "Including bid-offer")
dygraphs::dygraph(weal_th, main="Kelly Strategy With Transaction Costs") %>%
  dyOptions(colors=c("green","blue"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Calculate compounded wealth from returns
weal_th <- cumprod(1 + rowSums(weight_s*re_turns))
weal_th <- xts::xts(weal_th, index(re_turns))
quantmod::chart_Series(weal_th, name="Rolling Kelly Strategy For VTI and IEF")
# Calculate the compounded Kelly wealth and VTI
weal_th <- cbind(weal_th,
  cumprod(1 + 0.6*re_turns$IEF + 0.4*re_turns$VTI))
colnames(weal_th) <- c("Kelly Strategy", "VTI plus IEF")
dygraphs::dygraph(weal_th, main="Rolling Kelly Strategy For VTI and IEF") %>%
  dyAxis("y", label="Kelly Strategy", independentTicks=TRUE) %>%
  dyAxis("y2", label="VTI plus IEF", independentTicks=TRUE) %>%
  dySeries(name="Kelly Strategy", axis="y", label="Kelly Strategy", strokeWidth=1, col="red") %>%
  dySeries(name="VTI plus IEF", axis="y2", label="VTI plus IEF", strokeWidth=1, col="blue")

# Test if IEF can time VTI
re_turns <- na.omit(rutils::etf_env$re_turns[, c("IEF", "VTI")])
vt_i <- re_turns$VTI
de_sign <- cbind(re_turns, 0.5*(vt_i+abs(vt_i)), vt_i^2)
colnames(de_sign)[3:4] <- c("merton", "treynor")
# Merton-Henriksson test
mod_el <- lm(IEF ~ VTI + merton, data=de_sign); summary(mod_el)
# Treynor-Mazuy test
mod_el <- lm(IEF ~ VTI + treynor, data=de_sign); summary(mod_el)
# Plot residual scatterplot
x11(width=6, height=5)
residual_s <- (de_sign$IEF - mod_el$coefficients[2]*de_sign$VTI)
plot.default(x=de_sign$VTI, y=residual_s, xlab="VTI", ylab="IEF")
title(main="Treynor-Mazuy Market Timing Test\n for IEF vs VTI", line=0.5)
# Plot fitted (predicted) response values
fit_ted <- (mod_el$coefficients["(Intercept)"] +
  mod_el$coefficients["treynor"]*vt_i^2)
points.default(x=de_sign$VTI, y=fit_ted, pch=16, col="red")
text(x=0.05, y=0.03, paste("Treynor test t-value =", round(summary(mod_el)$coefficients["treynor", "t value"], 2)))

library(xtable)
gambl_e <- data.frame(win=c("p", "a"), lose=c("q = 1 - p", "-b"))
rownames(gambl_e) <- c("probability", "payout")
# print(xtable(gambl_e), comment=FALSE, size="tiny")
print(xtable(gambl_e), comment=FALSE)

library(rutils)
# Extract ETF prices from rutils::etf_env$price_s
price_s <- rutils::etf_env$price_s
price_s <- zoo::na.locf(price_s, na.rm=FALSE)
price_s <- zoo::na.locf(price_s, fromLast=TRUE)
# Calculate simple dollar returns
rets_dollar <- rutils::diff_it(price_s)
# Or
# rets_dollar <- lapply(price_s, rutils::diff_it)
# rets_dollar <- rutils::do_call(cbind, rets_dollar)
# Calculate log returns
rets_log <- rutils::diff_it(log(price_s))
# Calculate percentage returns
rets_percent <- rets_dollar/
  rutils::lag_it(price_s, lagg=1, pad_zeros=FALSE)

# Calculate prices from simple dollar returns
rets_dollar[1, ] <- price_s[1, ]
new_prices <- cumsum(rets_dollar)
all.equal(new_prices, price_s)
# Compound the percentage returns
new_prices <- cumprod(1+ rets_percent)
new_prices <- lapply(1:NCOL(new_prices), function (i)
    init_prices[i]*new_prices[, i])
new_prices <- rutils::do_call(cbind, new_prices)
all.equal(new_prices, price_s)
# Sum the percentage returns
new_prices <- cumsum(rets_percent)
methods(cumsum)
new_prices <- lapply(1:NCOL(new_prices), function (i)
    new_prices[, i] + log(init_prices[i]))
new_prices <- rutils::do_call(cbind, new_prices)
# Only approximately equal
all.equal(new_prices, log(price_s))
# Plot log VTI prices
dygraphs::dygraph(log(quantmod::Cl(rutils::etf_env$VTI)),
  main="Logarithm of VTI Prices") %>%
  dyOptions(colors="blue", strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Calculate percentage VTI returns
price_s <- rutils::etf_env$price_s$VTI
price_s <- na.omit(price_s)
re_turns <- rutils::diff_it(price_s)/
  rutils::lag_it(price_s, lagg=1, pad_zeros=FALSE)

# Funding rate per day
f_rate <- 0.01/252
# Margin account
mar_gin <- cumsum(re_turns)
# Cumulative funding costs
f_costs <- cumsum(f_rate*mar_gin)
# Add funding costs to margin account
mar_gin <- (mar_gin + f_costs)
# dygraph plot of margin and funding costs
da_ta <- cbind(mar_gin, f_costs)
col_names <- c("Margin", "Cumulative Funding")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="VTI Margin Funding Costs") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="blue") %>%
  dySeries(name=col_names[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=500)

# bid_offer equal to 10 bps for liquid ETFs
bid_offer <- 0.001
# Cumulative transaction costs
cost_s <- bid_offer*cumsum(abs(re_turns))/2
# Subtract transaction costs from margin account
mar_gin <- cumsum(re_turns)
mar_gin <- (mar_gin - cost_s)
# dygraph plot of margin and transaction costs
da_ta <- cbind(mar_gin, cost_s)
col_names <- c("Margin", "Cumulative Transaction Costs")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="VTI Transaction Costs") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="blue") %>%
  dySeries(name=col_names[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=500)

# Calculate VTI and IEF dollar returns
price_s <- rutils::etf_env$price_s[, c("VTI", "IEF")]
price_s <- na.omit(price_s)
date_s <- index(price_s)
rets_dollar <- rutils::diff_it(price_s)
# Calculate VTI and IEF percentage returns
rets_percent <- rets_dollar/
  rutils::lag_it(price_s, lagg=1, pad_zeros=FALSE)

# Wealth of fixed shares (without rebalancing)
weight_s <- c(0.5, 0.5)
rets_dollar[1, ] <- price_s[1, ]
wealth_fixed_shares <- cumsum(rets_dollar %*% weight_s)
# Wealth of fixed dollars (with rebalancing)
wealth_fixed_dollars <- cumsum(rets_percent %*% weight_s)
# Plot log wealth
weal_th <- cbind(wealth_fixed_dollars, log(wealth_fixed_shares))
weal_th <- xts::xts(weal_th, index(price_s))
colnames(weal_th) <- c("Fixed dollars", "Fixed shares (log)")
col_names <- colnames(weal_th)
dygraphs::dygraph(weal_th, main="Wealth of Weighted Portfolios") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="red", strokeWidth=2) %>%
  dySeries(name=col_names[2], axis="y2", col="blue", strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Margin account for fixed dollars (with rebalancing)
mar_gin <- cumsum(rets_percent %*% weight_s)
# Cumulative transaction costs
cost_s <- bid_offer*cumsum(abs(rets_percent) %*% weight_s)/2
# Subtract transaction costs from margin account
mar_gin <- (mar_gin - cost_s)
# dygraph plot of margin and transaction costs
da_ta <- cbind(mar_gin, cost_s)
da_ta <- xts::xts(da_ta, index(price_s))
col_names <- c("Margin", "Cumulative Transaction Costs")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="Fixed Dollar Portfolio Transaction Costs") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="blue") %>%
  dySeries(name=col_names[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=500)

# Wealth of fixed shares (without rebalancing)
wealth_fixed_shares <- cumsum(rets_dollar %*% weight_s)
# Calculate weighted percentage returns
rets_weighted <- rets_percent %*% weight_s
# Wealth of fixed ratio of dollar amounts (with rebalancing)
wealth_fixed_ratio <- cumprod(1 + rets_weighted)
wealth_fixed_ratio <- wealth_fixed_shares[1]*wealth_fixed_ratio
# Plot log wealth
weal_th <- log(cbind(wealth_fixed_shares, wealth_fixed_ratio))
weal_th <- xts::xts(weal_th, index(price_s))
colnames(weal_th) <- c("Fixed Shares", "Fixed Ratio")
dygraphs::dygraph(weal_th, main="Log Wealth of Fixed Dollar Ratios") %>%
  dyOptions(colors=c("blue","red"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Returns in excess of weighted returns
ex_cess <- lapply(rets_percent, function(x) (rets_weighted - x))
ex_cess <- do.call(cbind, ex_cess)
sum(ex_cess %*% weight_s)
# Calculate weighted sum of absolute excess returns
ex_cess <- abs(ex_cess) %*% weight_s
# Total dollar amount of stocks that need to be traded
ex_cess <- ex_cess*rutils::lag_it(wealth_fixed_ratio)
# Cumulative transaction costs
cost_s <- bid_offer*cumsum(ex_cess)/2
# Subtract transaction costs from wealth
wealth_fixed_ratio <- (wealth_fixed_ratio - cost_s)

# dygraph plot of wealth and transaction costs
da_ta <- cbind(wealth_fixed_ratio, cost_s)
da_ta <- xts::xts(da_ta, index(price_s))
col_names <- c("Wealth", "Cumulative Transaction Costs")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="Transaction Costs With Fixed Dollar Ratios") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="blue") %>%
  dySeries(name=col_names[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=500)

library(rutils)  # Load package rutils
# Create name corresponding to "^GSPC" symbol
setSymbolLookup(
  SP500=list(name="^GSPC", src="yahoo"))
getSymbolLookup()
# view and clear options
options("getSymbols.sources")
options(getSymbols.sources=NULL)
# Download S&P500 prices into etf_env
quantmod::getSymbols("SP500", env=etf_env,
    adjust=TRUE, auto.assign=TRUE, from="1990-01-01")
quantmod::chart_Series(x=etf_env$SP500["2016/"],
       TA="add_Vo()",
       name="S&P500 index")

# Calculate stock and bond returns
re_turns <- na.omit(rutils::etf_env$re_turns[, c("VTI", "IEF")])
weight_s <- c(0.4, 0.6)
re_turns <- cbind(re_turns, re_turns %*% weight_s)
colnames(re_turns)[3] <- "Combined"
# Wealth of fixed ratio of dollar amounts
weal_th <- cumprod(1 + re_turns)
# Plot cumulative wealth
dygraphs::dygraph(log(weal_th), main="Stock and Bond Portfolio") %>%
  dyOptions(colors=c("blue","green","blue","red")) %>%
  dySeries("Combined", color="red", strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Calculate correlations
cor(re_turns)
# Calculate Sharpe ratios
sqrt(252)*sapply(re_turns, function(x) mean(x)/sd(x))
# Calculate standard deviations
sapply(re_turns, sd)
# Calculate standardized returns
re_turns <- lapply(re_turns, function(x) (x - mean(x))/sd(x))
re_turns <- do.call(cbind, re_turns)
sapply(re_turns, sd)
# Calculate skewness and kurtosis
sapply(re_turns, function(x) {
  c(skew=mean(x^3), kurt=mean(x^4))
})  # end sapply
# Or
t(sapply(c(skew=3, kurt=4), function(x)
  moments::moment(re_turns, order=x, central=TRUE)))

# Extract ETF returns
sym_bols <- c("VTI", "IEF", "DBC")
re_turns <- na.omit(rutils::etf_env$re_turns[, sym_bols])
# Calculate all-weather portfolio wealth
weights_aw <- c(0.30, 0.55, 0.15)
re_turns <- cbind(re_turns, re_turns %*% weights_aw)
colnames(re_turns)[4] <- "All Weather"

# Calculate cumulative wealth from returns
weal_th <- cumsum(re_turns)
# dygraph all-weather wealth
dygraphs::dygraph(weal_th, main="All-Weather Portfolio") %>%
  dyOptions(colors=c("blue", "green", "orange", "red")) %>%
  dySeries("All Weather", color="red", strokeWidth=2) %>%
  dyLegend(show="always", width=500)
# Plot all-weather wealth
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue", "green", "red")
quantmod::chart_Series(weal_th, theme=plot_theme, lwd=c(2, 2, 2, 4),
       name="All-Weather Portfolio")
legend("topleft", legend=colnames(weal_th),
  inset=0.1, bg="white", lty=1, lwd=6,
  col=plot_theme$col$line.col, bty="n")

library(rutils)  # Load package rutils
# Calculate ETF returns
re_turns <- na.omit(rutils::etf_env$re_turns[, c("IEF", "VTI")])
re_turns <- cbind(re_turns, 0.6*re_turns$IEF+0.4*re_turns$VTI)
colnames(re_turns)[3] <- "combined"
# Calculate correlations
cor(re_turns)
# Calculate Sharpe ratios
sqrt(252)*sapply(re_turns, function(x) mean(x)/sd(x))
# Calculate skewness and kurtosis
sapply(re_turns, sd)
# Calculate skewness and kurtosis
t(sapply(c(skew=3, kurt=4), function(x)
  moments::moment(re_turns, order=x, central=TRUE)))

# Calculate prices from returns
price_s <- lapply(re_turns, function(x) exp(cumsum(x)))
price_s <- do.call(cbind, price_s)
# Plot prices
dygraphs::dygraph(price_s, main="Stock and Bond Portfolio") %>%
  dyOptions(colors=c("green","blue","green")) %>%
  dySeries("combined", color="red", strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Calculate standardized simple dollar returns
rets_dollar_std <- lapply(rets_dollar, function(x) x/sd(x))
rets_dollar_std <- do.call(cbind, rets_dollar_std)
sapply(rets_dollar_std, sd)
# Wealth of fixed number of shares (without rebalancing)
weight_s <- c(0.5, 0.5)
wealth_fixed_shares <- cumsum(rets_dollar %*% weight_s)
# Calculate standardized percentage returns
rets_percent_std <- lapply(rets_percent, function(x) x/sd(x))
rets_percent_std <- do.call(cbind, rets_percent_std)
sapply(rets_percent_std, sd)
# Wealth of fixed dollar amount of shares (with rebalancing)
wealth_fixed_dollars <- cumsum(rets_percent_std %*% weight_s)
# Plot log wealth
weal_th <- cbind(wealth_fixed_dollars, log(wealth_fixed_shares))
# weal_th <- xts::xts(weal_th, index(price_s))
colnames(weal_th) <- c("With rebalancing", "Without rebalancing")
dygraphs::dygraph(weal_th, main="Wealth of Equal Dollar Amount of Shares") %>%
  dyOptions(colors=c("green","blue"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Calculate dollar and percentage returns for VTI and IEF.
price_s <- rutils::etf_env$price_s[, c("VTI", "IEF")]
price_s <- na.omit(price_s)
rets_dollar <- rutils::diff_it(price_s)
rets_percent <- rets_dollar/rutils::lag_it(price_s, lagg=1, pad_zeros=FALSE)
# Calculate wealth of fixed ratio of dollar amounts.
weight_s <- c(0.5, 0.5)
rets_weighted <- rets_percent %*% weight_s
wealth_fixed_ratio <- cumprod(1 + rets_weighted)
# Calculate rolling percentage volatility.
look_back <- 21
vo_l <- roll::roll_sd(rets_percent, width=look_back)
vo_l <- zoo::na.locf(vo_l, na.rm=FALSE)
vo_l <- zoo::na.locf(vo_l, fromLast=TRUE)
# Calculate the risk parity portfolio allocations.
allocation_s <- lapply(1:NCOL(price_s),
  function(x) weight_s[x]/vo_l[, x])
allocation_s <- do.call(cbind, allocation_s)
# Scale allocations to 1 dollar total.
allocation_s <- allocation_s/rowSums(allocation_s)
# Lag the allocations
allocation_s <- rutils::lag_it(allocation_s)
# Calculate wealth of risk parity.
rets_weighted <- rowSums(rets_percent*allocation_s)
wealth_risk_parity <- cumprod(1 + rets_weighted)

# Calculate the log wealths.
weal_th <- log(cbind(wealth_fixed_ratio, wealth_risk_parity))
weal_th <- xts::xts(weal_th, index(price_s))
colnames(weal_th) <- c("Fixed Ratio", "Risk Parity")
# Calculate the Sharpe ratios.
sqrt(252)*sapply(rutils::diff_it(weal_th), function (x) mean(x)/sd(x))
# Plot a dygraph of the log wealths.
dygraphs::dygraph(weal_th, main="Log Wealth of Risk Parity vs Fixed Dollar Ratios") %>%
  dyOptions(colors=c("blue","red"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Test risk parity market timing of VTI using Treynor-Mazuy test
re_turns <- rutils::diff_it(weal_th)
vt_i <- rets_percent$VTI
de_sign <- cbind(re_turns, vt_i, vt_i^2)
de_sign <- na.omit(de_sign)
colnames(de_sign)[1:2] <- c("fixed","risk_parity")
colnames(de_sign)[4] <- "treynor"
mod_el <- lm(risk_parity ~ VTI + treynor, data=de_sign)
summary(mod_el)
# Plot residual scatterplot
residual_s <- (de_sign$risk_parity -
  mod_el$coefficients[2]*de_sign$VTI)
residual_s <- mod_el$residuals
x11(width=6, height=5)
plot.default(x=de_sign$VTI, y=residual_s, xlab="VTI", ylab="residuals")
title(main="Treynor-Mazuy Market Timing Test\n for Risk Parity vs VTI", line=0.5)
# Plot fitted (predicted) response values
fit_ted <- (mod_el$coefficients["(Intercept)"] +
  mod_el$coefficients["treynor"]*vt_i^2)
points.default(x=de_sign$VTI, y=fit_ted, pch=16, col="red")
text(x=0.05, y=0.025, paste("Risk Parity t-value =", round(summary(mod_el)$coefficients["treynor", "t value"], 2)))

# Test for fixed ratio market timing of VTI using Treynor-Mazuy test
mod_el <- lm(fixed ~ VTI + treynor, data=de_sign)
summary(mod_el)
# Plot fitted (predicted) response values
fit_ted <- (mod_el$coefficients["(Intercept)"] +
  mod_el$coefficients["treynor"]*vt_i^2)
points.default(x=de_sign$VTI, y=fit_ted, pch=16, col="blue")
text(x=0.05, y=0.02, paste("Fixed Ratio t-value =", round(summary(mod_el)$coefficients["treynor", "t value"], 2)))

# Returns in excess of weighted returns
ex_cess <- lapply(rets_percent, function(x) (rets_weighted - x))
ex_cess <- do.call(cbind, ex_cess)
sum(ex_cess %*% weight_s)
# Calculate weighted sum of absolute excess returns
ex_cess <- abs(ex_cess) %*% weight_s
# Total dollar amount of stocks that need to be traded
ex_cess <- ex_cess*rutils::lag_it(wealth_fixed_ratio)
# Cumulative transaction costs
cost_s <- bid_offer*cumsum(ex_cess)/2
# Subtract transaction costs from wealth
wealth_fixed_ratio <- (wealth_fixed_ratio - cost_s)

# dygraph plot of wealth and transaction costs
da_ta <- cbind(wealth_fixed_ratio, cost_s)
da_ta <- xts::xts(da_ta, index(price_s))
col_names <- c("Wealth", "Cumulative Transaction Costs")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="Transaction Costs With Fixed Dollar Ratios") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="blue") %>%
  dySeries(name=col_names[2], axis="y2", col="red", strokeWidth=3) %>%
  dyLegend(show="always", width=500)

# Calculate positions
re_turns <- na.omit(rutils::etf_env$re_turns$VTI)
position_s <- rep(NA_integer_, NROW(re_turns))
date_s <- index(re_turns)
date_s <- format(date_s, "%m-%d")
position_s[date_s == "05-01"] <- 0
position_s[date_s == "05-03"] <- 0
position_s[date_s == "11-01"] <- 1
position_s[date_s == "11-03"] <- 1
# Carry forward and backward non-NA position_s
position_s <- zoo::na.locf(position_s, na.rm=FALSE)
position_s <- zoo::na.locf(position_s, fromLast=TRUE)
# Calculate strategy returns
sell_inmay <- position_s*re_turns
weal_th <- cbind(cumsum(re_turns),
           cumsum(sell_inmay))
colnames(weal_th) <- c("vti", "sell_in_may")

# Plot Sell in May strategy
dygraphs::dygraph(weal_th, main="Sell in May Strategy") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)
# OR: Open x11 for plotting
x11(width=6, height=5)
par(mar=c(4, 4, 3, 1), oma=c(0, 0, 0, 0))
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("blue", "red")
quantmod::chart_Series(weal_th, theme=plot_theme,
       name="Sell in May Strategy")
legend("topleft", legend=colnames(weal_th),
  inset=0.1, bg="white", lty=1, lwd=6,
  col=plot_theme$col$line.col, bty="n")

# Test if Sell in May strategy can time VTI
vt_i <- re_turns$VTI
re_turns <- cbind(re_turns, 0.5*(vt_i+abs(vt_i)), vt_i^2)
colnames(re_turns)[2:3] <- c("merton", "treynor")
# Merton-Henriksson test
mod_el <- lm(sell_inmay ~ VTI + merton, data=re_turns); summary(mod_el)
# Treynor-Mazuy test
mod_el <- lm(sell_inmay ~ VTI + treynor, data=re_turns); summary(mod_el)
# Plot residual scatterplot
x11(width=6, height=5)
residual_s <- mod_el$residuals
plot.default(x=vt_i, y=residual_s, xlab="VTI", ylab="residuals")
title(main="Treynor-Mazuy Market Timing Test\n for Sell in May vs VTI", line=0.5)
# Plot fitted (predicted) response values
fit_ted <- (mod_el$coefficients["(Intercept)"] +
  mod_el$coefficients["treynor"]*vt_i^2)
points.default(x=vt_i, y=fit_ted, pch=16, col="red")
text(x=0.05, y=0.05, paste("Treynor test t-value =", round(summary(mod_el)$coefficients["treynor", "t value"], 2)))

# Calculate the log of OHLC VTI prices
oh_lc <- log(rutils::etf_env$VTI)
op_en <- quantmod::Op(oh_lc)
hi_gh <- quantmod::Hi(oh_lc)
lo_w <- quantmod::Lo(oh_lc)
clos_e <- quantmod::Cl(oh_lc)
# Calculate the close-to-close log returns, the intraday
# open-to-close returns and the overnight close-to-open returns.
close_close <- rutils::diff_it(clos_e)
colnames(close_close) <- "close_close"
open_close <- (clos_e - op_en)
colnames(open_close) <- "open_close"
close_open <- (op_en - rutils::lag_it(clos_e, lagg=1, pad_zeros=FALSE))
colnames(close_open) <- "close_open"

# Plot log wealth
weal_th <- cumsum(cbind(close_close, close_open, open_close))
dygraphs::dygraph(weal_th,
  main="Wealth of Close-to-Close, Close-to-Open, and Open-to-Close Strategies") %>%
  dySeries(name="close_close", label="Close-to-Close (static)", strokeWidth=2, col="blue") %>%
  dySeries(name="close_open", label="Close-to-Open (overnight)", strokeWidth=2, col="red") %>%
  dySeries(name="open_close", label="Open-to-Close (daytime)", strokeWidth=2, col="green") %>%
  dyLegend(width=600)

# Calculate a vector of daily VTI log returns
re_turns <- na.omit(rutils::etf_env$re_turns$VTI)
date_s <- index(re_turns)
re_turns <- as.numeric(re_turns)
n_rows <- NROW(re_turns)
# Define predictor matrix for forecasting
order_max <- 5
predic_tor <- sapply(1:order_max, rutils::lag_it, in_put=re_turns)
predic_tor <- cbind(rep(1, n_rows), predic_tor)
colnames(predic_tor) <- paste0("pred_", 1:NCOL(predic_tor))
res_ponse <- re_turns
# Calculate forecasts as function of the AR order
forecast_s <- lapply(2:NCOL(predic_tor), function(or_der) {
  # Calculate fitted coefficients
  in_verse <- MASS::ginv(predic_tor[, 1:or_der])
  coeff_fit <- drop(in_verse %*% res_ponse)
  # Calculate in-sample forecasts of re_turns
  drop(predic_tor[, 1:or_der] %*% coeff_fit)
})  # end lapply
names(forecast_s) <- paste0("p=", 2:NCOL(predic_tor))

# Calculate mean squared errors
ms_e <- sapply(forecast_s, function(x) {
  c(mse=mean((re_turns - x)^2), cor=cor(re_turns, x))
})  # end sapply
ms_e <- t(ms_e)
rownames(ms_e) <- names(forecast_s)
# Plot forecasting MSE
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(0, 0, 0, 0), mgp=c(2, 1, 0))
plot(x=2:NCOL(predic_tor), y=ms_e[, 1],
  xlab="AR(p) order", ylab="MSE", type="l", lwd=2,
  main="MSE of In-sample AR(p) Forecasting Model for VTI")

in_sample <- 1:(n_rows %/% 2)
out_sample <- (n_rows %/% 2 + 1):n_rows
# Calculate forecasts as function of the AR order
forecast_s <- lapply(2:NCOL(predic_tor), function(or_der) {
  # Calculate fitted coefficients
  in_verse <- MASS::ginv(predic_tor[in_sample, 1:or_der])
  coeff_fit <- drop(in_verse %*% res_ponse[in_sample])
  # Calculate out-of-sample forecasts of re_turns
  drop(predic_tor[out_sample, 1:or_der] %*% coeff_fit)
})  # end lapply
names(forecast_s) <- paste0("p=", 2:NCOL(predic_tor))

# Calculate mean squared errors
ms_e <- sapply(forecast_s, function(x) {
  c(mse=mean((re_turns[out_sample] - x)^2), cor=cor(re_turns[out_sample], x))
})  # end sapply
ms_e <- t(ms_e)
rownames(ms_e) <- names(forecast_s)
# Plot forecasting MSE
plot(x=2:NCOL(predic_tor), y=ms_e[, 1],
  xlab="AR(p) order", ylab="MSE", type="l", lwd=2,
  main="MSE of Out-of-sample AR(p) Forecasting Model for VTI")

# Calculate out-of-sample PnLs
pnl_s <- sapply(forecast_s, function(x) {
  cumsum(sign(x)*re_turns[out_sample])
})  # end sapply
colnames(pnl_s) <- names(forecast_s)
pnl_s <- xts::xts(pnl_s, date_s[out_sample])

# Plot dygraph of out-of-sample PnLs
color_s <- colorRampPalette(c("red", "blue"))(NCOL(pnl_s[, 1:4]))
col_names <- colnames(pnl_s[, 1:4])
dygraphs::dygraph(pnl_s[, 1:4],
  main="Autoregressive Strategies Performance With Different Order Parameters") %>%
  dyOptions(colors=color_s, strokeWidth=2) %>%
  dyLegend(width=500)

# Define predictor as a rolling sum
n_agg <- 5
predic_tor <- rutils::roll_sum(re_turns, look_back=n_agg)
# Shift the res_ponse forward out-of-sample
res_ponse <- rutils::lag_it(predic_tor, lagg=(-n_agg))
# Define predictor matrix for forecasting
predic_tor <- sapply(1+n_agg*(0:order_max), rutils::lag_it,
               in_put=predic_tor)
predic_tor <- cbind(rep(1, n_rows), predic_tor)
# Calculate forecasts as function of the AR order
forecast_s <- lapply(2:NCOL(predic_tor), function(or_der) {
  in_verse <- MASS::ginv(predic_tor[in_sample, 1:or_der])
  coeff_fit <- drop(in_verse %*% res_ponse[in_sample])
  drop(predic_tor[out_sample, 1:or_der] %*% coeff_fit)
})  # end lapply
names(forecast_s) <- paste0("p=", 2:NCOL(predic_tor))

# Calculate out-of-sample PnLs
pnl_s <- sapply(forecast_s, function(x) {
  cumsum(sign(x)*re_turns[out_sample])
})  # end sapply
colnames(pnl_s) <- names(forecast_s)
pnl_s <- xts::xts(pnl_s, date_s[out_sample])
# Plot dygraph of out-of-sample PnLs
dygraphs::dygraph(pnl_s[, 1:4],
  main="Autoregressive Strategies Performance Using Rolling Average Predictor") %>%
  dyOptions(colors=color_s, strokeWidth=2) %>%
  dyLegend(width=500)

# Calculate out-of-sample PnLs
pnl_s <- sapply(forecast_s, function(x) {
  x <- rutils::roll_sum(x, look_back=n_agg)
  cumsum(sign(x)*re_turns[out_sample])
})  # end sapply
colnames(pnl_s) <- names(forecast_s)
pnl_s <- xts::xts(pnl_s, date_s[out_sample])

# Plot dygraph of out-of-sample PnLs
dygraphs::dygraph(pnl_s[, 1:4],
  main="Autoregressive Strategies Performance Using Rolling Average Forecasts") %>%
  dyOptions(colors=color_s, strokeWidth=2) %>%
  dyLegend(width=500)

library(rutils)
# Calculate a vector of daily VTI log returns
price_s <- log(quantmod::Cl(rutils::etf_env$VTI))
re_turns <- rutils::diff_it(price_s)
re_turns <- as.numeric(re_turns)
n_rows <- NROW(re_turns)
# Define predictor matrix for forecasting
order_max <- 5
de_sign <- sapply(1:order_max, rutils::lag_it, in_put=re_turns)
colnames(de_sign) <- paste0("pred_", 1:NCOL(de_sign))
# Add response equal to re_turns
de_sign <- cbind(re_turns, de_sign)
colnames(de_sign)[1] <- "response"
# Specify length of look-back interval
look_back <- 100
# Invert the predictor matrix
rang_e <- (n_rows-look_back):(n_rows-1)
design_inv <- MASS::ginv(de_sign[rang_e, -1])
# Calculate fitted coefficients
coeff_fit <- drop(design_inv %*% de_sign[rang_e, 1])
# Calculate forecast of re_turns for n_rows
drop(de_sign[n_rows, -1] %*% coeff_fit)
# Compare with actual value
de_sign[n_rows, 1]

# Calculate a vector of daily VTI log returns
re_turns <- na.omit(rutils::etf_env$re_turns$VTI)
date_s <- index(re_turns)
re_turns <- as.numeric(re_turns)
n_rows <- NROW(re_turns)
# Define predictor as a rolling sum
n_agg <- 5
predic_tor <- rutils::roll_sum(re_turns, look_back=n_agg)
# Shift the res_ponse forward out-of-sample
res_ponse <- rutils::lag_it(predic_tor, lagg=(-n_agg))
# Define predictor matrix for forecasting
order_max <- 5
predic_tor <- sapply(1+n_agg*(0:order_max), rutils::lag_it,
               in_put=predic_tor)
predic_tor <- cbind(rep(1, n_rows), predic_tor)
# Define de_sign matrix
de_sign <- cbind(res_ponse, predic_tor)
# Perform rolling forecasting
look_back <- 100
forecast_s <- sapply((look_back+1):n_rows, function(end_p) {
  # Define rolling look-back range
  start_p <- max(1, end_p-look_back)
  # Or expanding look-back range
  # start_p <- 1
  rang_e <- start_p:(end_p-1)
  # Invert the predictor matrix
  design_inv <- MASS::ginv(de_sign[rang_e, -1])
  # Calculate fitted coefficients
  coeff_fit <- drop(design_inv %*% de_sign[rang_e, 1])
  # Calculate forecast
  drop(de_sign[end_p, -1] %*% coeff_fit)
})  # end sapply
# Add warmup period
forecast_s <- c(rep(0, look_back), forecast_s)

# Mean squared error
mean((re_turns - forecast_s)^2)
# Correlation
cor(forecast_s, re_turns)
# Plot forecasting series with legend
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(0, 0, 0, 0))
plot(forecast_s[(n_rows-look_back):n_rows], col="red",
     xlab="", ylab="", type="l", lwd=2,
     main="Rolling Forecasting Using AR Model")
lines(re_turns[(n_rows-look_back):n_rows], col="blue", lwd=2)
legend(x="top", legend=c("re_turns", "forecasts"),
 col=c("blue", "red"), lty=1, lwd=6,
 cex=0.9, bg="white", bty="n")

# Define backtesting function
sim_forecasts <- function(res_ponse, predic_tor=res_ponse, n_agg=5,
                or_der=5, look_back=100) {
  n_rows <- NROW(res_ponse)
  # Define predictor as a rolling sum
  predic_tor <- rutils::roll_sum(res_ponse, look_back=n_agg)
  # Shift the res_ponse forward out-of-sample
  res_ponse <- rutils::lag_it(predic_tor, lagg=(-n_agg))
  # Define predictor matrix for forecasting
  predic_tor <- sapply(1+n_agg*(0:or_der), rutils::lag_it,
                 in_put=predic_tor)
  predic_tor <- cbind(rep(1, n_rows), predic_tor)
  # Define de_sign matrix
  de_sign <- cbind(res_ponse, predic_tor)
  # Perform rolling forecasting
  forecast_s <- sapply((look_back+1):n_rows, function(end_p) {
    # Define rolling look-back range
    start_p <- max(1, end_p-look_back)
    # Or expanding look-back range
    # start_p <- 1
    rang_e <- start_p:(end_p-1)
    # Invert the predictor matrix
    design_inv <- MASS::ginv(de_sign[rang_e, -1])
    # Calculate fitted coefficients
    coeff_fit <- drop(design_inv %*% de_sign[rang_e, 1])
    # Calculate forecast
    drop(de_sign[end_p, -1] %*% coeff_fit)
  })  # end sapply
  # Add warmup period
  forecast_s <- c(rep(0, look_back), forecast_s)
  rutils::roll_sum(forecast_s, look_back=n_agg)
}  # end sim_forecasts
# Simulate the rolling autoregressive forecasts
forecast_s <- sim_forecasts(re_turns, or_der=5, look_back=100)
c(mse=mean((re_turns - forecast_s)^2), cor=cor(re_turns, forecast_s))

look_backs <- seq(20, 600, 40)
library(parallel)  # Load package parallel
# Calculate number of available cores
n_cores <- detectCores() - 1
# Initialize compute cluster under Windows
clus_ter <- makeCluster(n_cores)
# clusterExport(clus_ter, c("star_t", "bar_rier"))
# Perform parallel loop under Windows
forecast_s <- parLapply(clus_ter, look_backs, sim_forecasts, res_ponse=re_turns,
                  predic_tor=re_turns, n_agg=5, or_der=5)
# Perform parallel bootstrap under Mac-OSX or Linux
forecast_s <- mclapply(look_backs, sim_forecasts, res_ponse=re_turns,
  predic_tor=re_turns, n_agg=5, or_der=5, mc.cores=n_cores)

# Calculate mean squared errors
ms_e <- sapply(forecast_s, function(x) {
  c(mse=mean((re_turns - x)^2), cor=cor(re_turns, x))
})  # end sapply
ms_e <- t(ms_e)
rownames(ms_e) <- look_backs
# Select optimal look_back interval
look_back <- look_backs[which.min(ms_e[, 1])]
# Plot forecasting MSE
plot(x=look_backs, y=ms_e[, 1],
  xlab="look-back", ylab="MSE", type="l", lwd=2,
  main="MSE of AR Forecasting Model As Function of Look-back")

order_s <- 2:6
library(parallel)  # Load package parallel
# Calculate number of available cores
n_cores <- detectCores() - 1
# Initialize compute cluster under Windows
clus_ter <- makeCluster(n_cores)
# clusterExport(clus_ter, c("star_t", "bar_rier"))
# Perform parallel loop under Windows
forecast_s <- parLapply(clus_ter, order_s, sim_forecasts, res_ponse=re_turns,
                  predic_tor=re_turns, n_agg=5, look_back=look_back)
stopCluster(clus_ter)  # Stop R processes over cluster under Windows
# Perform parallel bootstrap under Mac-OSX or Linux
forecast_s <- mclapply(order_s, sim_forecasts, res_ponse=re_turns,
  predic_tor=re_turns, n_agg=5, look_back=look_back, mc.cores=n_cores)
stopCluster(clus_ter)  # Stop R processes over cluster under Windows

# Calculate mean squared errors
ms_e <- sapply(forecast_s, function(x) {
  c(mse=mean((re_turns - x)^2), cor=cor(re_turns, x))
})  # end sapply
ms_e <- t(ms_e)
rownames(ms_e) <- order_s
# Select optimal order parameter
or_der <- order_s[which.min(ms_e[, 1])]
# Plot forecasting MSE
plot(x=order_s, y=ms_e[, 1],
  xlab="or_der", ylab="MSE", type="l", lwd=2,
  main="MSE of Forecasting Model As Function of AR Order")

# Simulate the rolling autoregressive forecasts
forecast_s <- sim_forecasts(re_turns, or_der=or_der, look_back=look_back)
# Calculate strategy PnLs
pnl_s <- sign(forecast_s)*re_turns
pnl_s <- cbind(re_turns, pnl_s, (re_turns+pnl_s)/2)
colnames(pnl_s) <- c("VTI", "AR_Strategy", "Combined")
cor(pnl_s)
# Annualized Sharpe ratios of VTI and AR strategy
sqrt(252)*apply(pnl_s, 2, function (x) mean(x)/sd(x))
pnl_s <- xts::xts(pnl_s, date_s)
pnl_s <- cumsum(pnl_s)

# Plot the cumulative strategy PnLs
dygraphs::dygraph(pnl_s, main="Rolling Autoregressive Strategy") %>%
  dyOptions(colors=c("blue","red","green"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Calculate PnLs for or_der=5
forecast_s <- sim_forecasts(re_turns, or_der=5, look_back=look_back)
pnls_5 <- cumsum(sign(forecast_s)*re_turns)
# Calculate PnLs for or_der=3
forecast_s <- sim_forecasts(re_turns, or_der=3, look_back=look_back)
pnls_3 <- cumsum(sign(forecast_s)*re_turns)

# Plot the cumulative strategy returns
da_ta <- cbind(pnls_5, pnls_3)
da_ta <- xts::xts(da_ta, date_s)
col_names <- c("AR(5)_Strategy", "AR(3)_Strategy")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="Autoregressive Strategies for Different Order Parameters") %>%
  dySeries(name=col_names[1], label=col_names[1], col="blue", strokeWidth=2) %>%
  dySeries(name=col_names[2], label=col_names[2], col="red", strokeWidth=2) %>%
  dyLegend(width=500)

# Calculate PnLs for rolling look-back
forecast_s <- sim_forecasts(re_turns, or_der=3, look_back=look_back, is_rolling=TRUE)
pnls_rolling <- cumsum(sign(forecast_s)*re_turns)
# Calculate PnLs for expanding look-back
forecast_s <- sim_forecasts(re_turns, or_der=3, look_back=look_back, is_rolling=FALSE)
pnls_expanding <- cumsum(sign(forecast_s)*re_turns)

# Plot the cumulative strategy returns
da_ta <- cbind(pnls_rolling, pnls_expanding)
da_ta <- xts::xts(da_ta, date_s)
col_names <- c("AR(3)_Rolling", "AR(3)_Expanding")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="Autoregressive Strategies for Expanding Look-back Interval") %>%
  dySeries(name=col_names[1], label=col_names[1], col="blue", strokeWidth=2) %>%
  dySeries(name=col_names[2], label=col_names[2], col="red", strokeWidth=2) %>%
  dyLegend(width=500)

# Cap the re_turns
cut_off <- 0.03
capp_ed <- ifelse(re_turns > cut_off, cut_off, re_turns)
capp_ed <- ifelse(capp_ed < (-cut_off), -cut_off, capp_ed)
# Calculate PnLs for re_turns
forecast_s <- sim_forecasts(re_turns, or_der=3, look_back=look_back, is_rolling=FALSE)
pnl_s <- cumsum(sign(forecast_s)*re_turns)
# Calculate PnLs for capped re_turns
forecast_s <- sim_forecasts(capp_ed, or_der=3, look_back=look_back, is_rolling=FALSE)
pnls_capped <- cumsum(sign(forecast_s)*re_turns)

# Plot the cumulative strategy returns
da_ta <- cbind(pnl_s, pnls_capped)
da_ta <- xts::xts(da_ta, date_s)
col_names <- c("AR(3)_Rolling", "AR(3)_Expanding")
col_names <- c("AR_Strategy", "AR_Strategy_Capped")
colnames(da_ta) <- col_names
dygraphs::dygraph(da_ta, main="Improved Autoregressive Strategies") %>%
  dySeries(name=col_names[1], label=col_names[1], col="blue", strokeWidth=2) %>%
  dySeries(name=col_names[2], label=col_names[2], col="red", strokeWidth=2) %>%
  dyLegend(width=500)

# Get close prices and calculate close-to-close returns
# price_s <- quantmod::Cl(rutils::etf_env$VTI)
price_s <- quantmod::Cl(HighFreq::SPY)
colnames(price_s) <- rutils::get_name(colnames(price_s))
re_turns <- TTR::ROC(price_s)
re_turns[1] <- 0
# Calculate the RSI indicator
r_si <- TTR::RSI(price_s, 2)
# Calculate the long (up) and short (dn) signals
sig_up <- ifelse(r_si < 10, 1, 0)
sig_dn <- ifelse(r_si > 90, -1, 0)
# Lag signals by one period
sig_up <- rutils::lag_it(sig_up, 1)
sig_dn <- rutils::lag_it(sig_dn, 1)
# Replace NA signals with zero position
sig_up[is.na(sig_up)] <- 0
sig_dn[is.na(sig_dn)] <- 0
# Combine up and down signals into one
sig_nals <- sig_up + sig_dn
# Calculate cumulative returns
eq_up <- exp(cumsum(sig_up*re_turns))
eq_dn <- exp(cumsum(-1*sig_dn*re_turns))
eq_all <- exp(cumsum(sig_nals*re_turns))

# Plot daily cumulative returns in panels
end_p <- endpoints(re_turns, on="days")
plot.zoo(cbind(eq_all, eq_up, eq_dn)[end_p], lwd=c(2, 2, 2),
  ylab=c("Total","Long","Short"), col=c("red","green","blue"),
  main=paste("RSI(2) strategy for", colnames(price_s), "from",
       format(start(re_turns), "%B %Y"), "to",
       format(end(re_turns), "%B %Y")))

# Define length for weights and decay parameter
wid_th <- 352
lamb_da <- 0.01
# Calculate EWMA prices
weight_s <- exp(-lamb_da*1:wid_th)
weight_s <- weight_s/sum(weight_s)
ew_ma <- .Call(stats:::C_cfilter, clos_e,
  filter=weight_s, sides=1, circular=FALSE)
ew_ma[1:(wid_th-1)] <- ew_ma[wid_th]
ew_ma <- cbind(clos_e, ew_ma)
colnames(ew_ma) <- c("VTI", "VTI EWMA")

# Plot EWMA prices with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue")
quantmod::chart_Series(ew_ma["2007/2010"], theme=plot_theme,
       name="EWMA prices")
legend("bottomleft", legend=colnames(ew_ma),
 inset=0.1, bg="white", lty=1, lwd=6,
 col=plot_theme$col$line.col, bty="n")

# Determine trade dates right after EWMA has crossed prices
in_dic <- sign(clos_e - ew_ma[, 2])
trade_dates <- (rutils::diff_it(in_dic) != 0)
trade_dates <- which(trade_dates) + 1
trade_dates <- trade_dates[trade_dates < n_rows]
# Calculate positions, either: -1, 0, or 1
position_s <- rep(NA_integer_, n_rows)
position_s[1] <- 0
position_s[trade_dates] <- in_dic[trade_dates-1]
position_s <- zoo::na.locf(position_s, na.rm=FALSE)
position_s <- xts::xts(position_s, order.by=index(oh_lc))

# Plot EWMA prices with position shading
quantmod::chart_Series(ew_ma["2007/2010"], theme=plot_theme,
       name="EWMA prices")
add_TA(position_s > 0, on=-1,
 col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
 col="lightgrey", border="lightgrey")
legend("bottomleft", legend=colnames(ew_ma),
 inset=0.1, bg="white", lty=1, lwd=6,
 col=plot_theme$col$line.col, bty="n")

# Calculate daily profits and losses
# Calculate pnl for days without trade
pnl_s <- rutils::diff_it(clos_e)*position_s
# Calculate realized pnl for days with trade
close_lag <- rutils::lag_it(clos_e)
pos_lagged <- rutils::lag_it(position_s)
pnl_s[trade_dates] <- pos_lagged[trade_dates]*
  (op_en[trade_dates] - close_lag[trade_dates])
# Calculate unrealized pnl for days with trade
pnl_s[trade_dates] <- pnl_s[trade_dates] +
  position_s[trade_dates]*
  (clos_e[trade_dates] - op_en[trade_dates])
# Annualized Sharpe ratio of EWMA strategy
sqrt(252)*sum(pnl_s)/sd(pnl_s)/NROW(pnl_s)
# Cumulative pnls
cum_pnls <- star_t + cumsum(pnl_s)
cum_pnls <- cbind(clos_e, cum_pnls)
colnames(cum_pnls) <- c("VTI", "EWMA PnL")

# Plot EWMA PnL with position shading
quantmod::chart_Series(cum_pnls, theme=plot_theme,
       name="Performance of EWMA Strategy")
add_TA(position_s > 0, on=-1,
 col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
 col="lightgrey", border="lightgrey")
legend("top", legend=colnames(cum_pnls),
 inset=0.05, bg="white", lty=1, lwd=6,
 col=plot_theme$col$line.col, bty="n")

# bid_offer equal to 10 bps for liquid ETFs
bid_offer <- 0.001
# Calculate transaction costs
cost_s <- 0.5*bid_offer*abs(pos_lagged - position_s)*clos_e
# pnl_s <- (pnl_s - cost_s)
# Plot strategy with transaction costs
cum_pnls <- star_t + cumsum(pnl_s)
cum_pnls <- cbind(cum_pnls, cum_pnls - cumsum(cost_s))
colnames(cum_pnls) <- c(sym_bol, "costs")
dygraphs::dygraph(cum_pnls, main=paste(sym_bol, "EWMA Strategy With Transaction Costs")) %>%
  dySeries(name="costs", label="Strategy With Transaction Costs", strokeWidth=2, col="green") %>%
  dySeries(name=sym_bol, label="EWMA Strategy", strokeWidth=2, col="blue")

simu_ewma <- function(oh_lc, lamb_da=0.01, wid_th=351, bid_offer=0.001, tre_nd=1) {
  n_rows <- NROW(oh_lc)
  # Calculate EWMA prices
  weight_s <- exp(-lamb_da*1:wid_th)
  weight_s <- weight_s/sum(weight_s)
  clos_e <- quantmod::Cl(oh_lc)
  ew_ma <- .Call(stats:::C_cfilter, clos_e, filter=weight_s, sides=1, circular=FALSE)
  ew_ma[1:(wid_th-1)] <- ew_ma[wid_th]
  # Determine trade dates right after EWMA has crossed prices
  in_dic <- tre_nd*sign(clos_e - ew_ma)
  trade_dates <- (rutils::diff_it(in_dic) != 0)
  trade_dates <- which(trade_dates) + 1
  trade_dates <- trade_dates[trade_dates < n_rows]
  # Calculate positions, either: -1, 0, or 1
  position_s <- rep(NA_integer_, n_rows)
  position_s[1] <- 0
  position_s[trade_dates] <- in_dic[trade_dates-1]
  position_s <- zoo::na.locf(position_s, na.rm=FALSE)
  op_en <- quantmod::Op(oh_lc)
  close_lag <- rutils::lag_it(clos_e)
  pos_lagged <- rutils::lag_it(position_s)
  # Calculate daily profits and losses
  pnl_s <- rutils::diff_it(clos_e)*position_s
  pnl_s[trade_dates] <- pos_lagged[trade_dates]*
    (op_en[trade_dates] - close_lag[trade_dates])
  pnl_s[trade_dates] <- pnl_s[trade_dates] +
    position_s[trade_dates]*
    (clos_e[trade_dates] - op_en[trade_dates])
  # Calculate transaction costs
  cost_s <- 0.5*bid_offer*abs(pos_lagged - position_s)*clos_e
  pnl_s <- (pnl_s - cost_s)
  # Calculate strategy returns
  pnl_s <- cbind(position_s, pnl_s)
  colnames(pnl_s) <- c("positions", "pnls")
  pnl_s
}  # end simu_ewma

source("C:/Develop/lecture_slides/scripts/ewma_model.R")
lamb_das <- seq(from=1e-5, to=0.05, by=0.01)
# Perform lapply() loop over lamb_das
pnl_s <- lapply(lamb_das, function(lamb_da) {
  # Simulate EWMA strategy and calculate re_turns
  star_t + cumsum(simu_ewma(oh_lc=oh_lc,
    lamb_da=lamb_da, wid_th=wid_th)[, "pnls"])
})  # end lapply
pnl_s <- do.call(cbind, pnl_s)
colnames(pnl_s) <- paste0("lambda=", lamb_das)

# Plot EWMA strategies with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <-
  colorRampPalette(c("blue", "red"))(NCOL(pnl_s))
quantmod::chart_Series(pnl_s, theme=plot_theme,
  name="Cumulative Returns of EWMA Strategies")
legend("topleft", legend=colnames(pnl_s), inset=0.1,
  bg="white", cex=0.8, lwd=rep(6, NCOL(pnl_s)),
  col=plot_theme$col$line.col, bty="n")

# Initialize compute cluster under Windows
library(parallel)
clus_ter <- makeCluster(detectCores()-1)
clusterExport(clus_ter,
  varlist=c("oh_lc", "wid_th", "simu_ewma"))
# Perform parallel loop over lamb_das under Windows
pnl_s <- parLapply(clus_ter, lamb_das, function(lamb_da) {
  library(quantmod)
  # Simulate EWMA strategy and calculate re_turns
  star_t + cumsum(simu_ewma(oh_lc=oh_lc,
    lamb_da=lamb_da, wid_th=wid_th)[, "pnls"])
})  # end parLapply
# Perform parallel loop over lamb_das under Mac-OSX or Linux
re_turns <- mclapply(lamb_das, function(lamb_da) {
  library(quantmod)
  # Simulate EWMA strategy and calculate re_turns
  star_t + cumsum(simu_ewma(oh_lc=oh_lc,
    lamb_da=lamb_da, wid_th=wid_th)[, "pnls"])
})  # end mclapply
stopCluster(clus_ter)  # Stop R processes over cluster under Windows
pnl_s <- do.call(cbind, pnl_s)
colnames(pnl_s) <- paste0("lambda=", lamb_das)

sharpe_ratios <- sqrt(252)*sapply(pnl_s, function(x_ts) {
  # Calculate annualized Sharpe ratio of strategy returns
  x_ts <- rutils::diff_it(x_ts)
  sum(x_ts)/sd(x_ts)
})/NROW(pnl_s)  # end sapply
plot(x=lamb_das, y=sharpe_ratios, t="l",
     main="Performance of EWMA trend following strategies
     as function of the decay parameter lambda")
trend_returns <- rutils::diff_it(pnl_s)
trend_sharpe <- sharpe_ratios

# Simulate best performing strategy
ewma_trend <- simu_ewma(oh_lc=oh_lc,
  lamb_da=lamb_das[which.max(sharpe_ratios)],
  wid_th=wid_th)
position_s <- ewma_trend[, "positions"]
pnl_s <- star_t + cumsum(ewma_trend[, "pnls"])
pnl_s <- cbind(clos_e, pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA PnL")
# Plot EWMA PnL with position shading
plot_theme$col$line.col <- c("orange", "blue")
quantmod::chart_Series(pnl_s, theme=plot_theme,
       name="Performance of Trend Following EWMA Strategy")
add_TA(position_s > 0, on=-1,
 col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
 col="lightgrey", border="lightgrey")
legend("top", legend=colnames(pnl_s),
  inset=0.05, bg="white", lty=1, lwd=6,
  col=plot_theme$col$line.col, bty="n")

source("C:/Develop/lecture_slides/scripts/ewma_model.R")
lamb_das <- seq(0.05, 1.0, 0.05)
# Perform lapply() loop over lamb_das
pnl_s <- lapply(lamb_das, function(lamb_da) {
  # Backtest EWMA strategy and calculate re_turns
  star_t + cumsum(simu_ewma(
    oh_lc=oh_lc, lamb_da=lamb_da, wid_th=wid_th, tre_nd=(-1))[, "pnls"])
})  # end lapply
pnl_s <- do.call(cbind, pnl_s)
colnames(pnl_s) <- paste0("lambda=", lamb_das)
# Plot EWMA strategies with custom line colors
column_s <- seq(1, NCOL(pnl_s), by=4)
plot_theme <- chart_theme()
plot_theme$col$line.col <-
  colorRampPalette(c("blue", "red"))(NROW(column_s))
quantmod::chart_Series(pnl_s[, column_s],
  theme=plot_theme, name="Cumulative Returns of Mean Reverting EWMA Strategies")
legend("topleft", legend=colnames(pnl_s[, column_s]),
  inset=0.1, bg="white", cex=0.8, lwd=6,
  col=plot_theme$col$line.col, bty="n")

sharpe_ratios <- sqrt(252)*sapply(pnl_s, function(x_ts) {
  # Calculate annualized Sharpe ratio of strategy returns
  x_ts <- rutils::diff_it(x_ts)
  sum(x_ts)/sd(x_ts)
})/NROW(pnl_s)  # end sapply
plot(x=lamb_das, y=sharpe_ratios, t="l",
     main="Performance of EWMA mean reverting strategies
     as function of the decay parameter lambda")
revert_returns <- rutils::diff_it(pnl_s)
revert_sharpe <- sharpe_ratios

# Backtest best performing strategy
ewma_revert <- simu_ewma(oh_lc=oh_lc, bid_offer=0.0,
  lamb_da=lamb_das[which.max(sharpe_ratios)],
  wid_th=wid_th, tre_nd=(-1))
position_s <- ewma_revert[, "positions"]
pnl_s <- star_t + cumsum(ewma_revert[, "pnls"])
pnl_s <- cbind(clos_e, pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA PnL")

# Plot EWMA PnL with position shading
plot_theme$col$line.col <- c("orange", "blue")
quantmod::chart_Series(pnl_s, theme=plot_theme,
       name="Performance of Mean Reverting EWMA Strategy")
add_TA(position_s > 0, on=-1,
 col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
 col="lightgrey", border="lightgrey")
legend("top", legend=colnames(pnl_s),
  inset=0.05, bg="white", lty=1, lwd=6,
  col=plot_theme$col$line.col, bty="n")

# Calculate correlation between trend following and mean reverting strategies
trend_ing <- ewma_trend[, "pnls"]
colnames(trend_ing) <- "trend"
revert_ing <- ewma_revert[, "pnls"]
colnames(revert_ing) <- "revert"
close_rets <- rutils::diff_it(clos_e)
cor(cbind(trend_ing, revert_ing, close_rets))
# Calculate combined strategy
com_bined <- trend_ing + revert_ing
colnames(com_bined) <- "combined"
# Calculate annualized Sharpe ratio of strategy returns
re_turns <- cbind(close_rets, trend_ing, revert_ing, com_bined)
sqrt(252)*sapply(re_turns, function(x_ts)
  sum(x_ts)/sd(x_ts))/NROW(com_bined)
pnl_s <- lapply(re_turns, function(x_ts) {star_t + cumsum(x_ts)})
pnl_s <- do.call(cbind, pnl_s)
colnames(pnl_s) <- c("VTI", "trending", "reverting", "EWMA combined PnL")

plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue", "green", "magenta2")
quantmod::chart_Series(pnl_s, theme=plot_theme,
       name="Performance of Combined EWMA Strategies")
legend("topleft", legend=colnames(pnl_s),
 inset=0.05, bg="white", lty=1, lwd=6,
 col=plot_theme$col$line.col, bty="n")

weight_s <- c(trend_sharpe, revert_sharpe)
weight_s[weight_s<0] <- 0
weight_s <- weight_s/sum(weight_s)
re_turns <- cbind(trend_returns, revert_returns)
avg_returns <- re_turns %*% weight_s
avg_returns <- xts::xts(avg_returns, order.by=index(re_turns))
pnl_s <- (star_t + cumsum(avg_returns))
pnl_s <- cbind(clos_e, pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA PnL")
# Plot EWMA PnL without position shading
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue")
quantmod::chart_Series(pnl_s, theme=plot_theme,
  name="Performance of Ensemble EWMA Strategy")
legend("top", legend=colnames(pnl_s),
  inset=0.05, bg="white", lty=1, lwd=6,
  col=plot_theme$col$line.col, bty="n")

# Calculate log OHLC prices
sym_bol <- "VTI"
# oh_lc <- rutils::etf_env$VTI
oh_lc <- get(sym_bol, rutils::etf_env)
oh_lc[, 1:4] <- log(oh_lc[, 1:4])
n_rows <- NROW(oh_lc)
op_en <- quantmod::Op(oh_lc)
clos_e <- quantmod::Cl(oh_lc)
colnames(clos_e) <- sym_bol
vol_ume <- quantmod::Vo(oh_lc)
re_turns <- rutils::diff_it(clos_e)
cum_rets <- cumsum(re_turns)
# Define aggregation interval and calculate VWAP
look_back <- 200
v_wap <- rutils::roll_sum(x_ts=cum_rets*vol_ume, look_back=look_back)
volume_roll <- rutils::roll_sum(x_ts=vol_ume, look_back=look_back)
v_wap <- v_wap/volume_roll
v_wap[is.na(v_wap)] <- 0

# Plot VTI and VWAP using dygraphs
weal_th <- cbind(cum_rets, v_wap)
colnames(weal_th) <- c(sym_bol, "VWAP")
dygraphs::dygraph(weal_th, main="VTI and VWAP") %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=3)
# Plot VTI and VWAP using quantmod
x11(width=6, height=5)
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("blue", "red")
quantmod::chart_Series(x=cbind(clos_e, v_wap),
  name="VTI and VWAP", theme=plot_theme)
legend("top", legend=c("VTI", "VWAP"), lty=1, lwd=6, cex=0.9,
 bg="white", col=c("blue", "red"), bty="n")

# Calculate VWAP positions
position_s <- sign(vwap_fast - vwap_slow)
# Lag the positions to avoid data snooping
position_s <- rutils::lag_it(position_s)
# Calculate daily profits and losses of strategy
pnl_s <- re_turns*position_s
colnames(pnl_s) <- "Strategy"
cum_pnls <- cumsum(pnl_s)
weal_th <- cbind(cum_rets, cum_pnls, v_wap)
colnames(weal_th) <- c(sym_bol, "Strategy", "VWAP")
# Annualized Sharpe ratios of VTI and VWAP strategy
sharp_e <- sqrt(252)*sapply(cbind(re_turns, pnl_s), function (x) mean(x)/sd(x))
# Calculate index for background shading
in_dic <- (cum_rets > v_wap)
whi_ch <- which(rutils::diff_it(in_dic) != 0)
in_dic <- rbind(first(in_dic), in_dic[whi_ch, ], last(in_dic))
date_s <- index(in_dic)
in_dic <- ifelse(drop(coredata(in_dic)), "lightgreen", "antiquewhite")

# Create dygraph object without rendering it
dy_graph <- dygraphs::dygraph(weal_th, main=paste("VWAP Crossover Strategy, Sharpe", paste(paste(names(sharp_e), round(sharp_e, 3), sep="="), collapse=", "))) %>%
  dyOptions(colors=c("blue", "red", "purple"), strokeWidth=2)
# Add shading
for (i in 1:(NROW(in_dic)-1)) {
    dy_graph <- dy_graph %>%
dyShading(from=date_s[i], to=date_s[i+1], color=in_dic[i])
}  # end for
# Render the dygraph object
dy_graph
# Plot VTI and VWAP strategy using quantmod
quantmod::chart_Series(x=cbind(cum_rets, cum_pnls),
  name="VWAP Crossover Strategy for VTI", theme=plot_theme)
add_TA(position_s > 0, on=-1, col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1, col="lightgrey", border="lightgrey")
legend("top", legend=c(sym_bol, "VWAP strategy"), lty=1, lwd=6,
 cex=0.9, inset=0.1, bg="white", col=c("blue", "red"), bty="n")

# Calculate positions from lagged indicator
lagg <- 2
in_dic <- sign(cum_rets - v_wap)
indic_sum <- roll::roll_sum(in_dic, width=lagg)
indic_sum[1:lagg] <- 0
position_s <- rep(NA_integer_, NROW(clos_e))
position_s[1] <- 0
position_s <- ifelse(indic_sum == lagg, 1, position_s)
position_s <- ifelse(indic_sum == (-lagg), -1, position_s)
position_s <- zoo::na.locf(position_s, na.rm=FALSE)
# Lag the positions to trade in next period
position_s <- rutils::lag_it(position_s, lagg=1)
# Calculate PnLs of lagged strategy
pnl_s <- re_turns*position_s
colnames(pnl_s) <- "Strategy"

cum_pnls_lag <- cumsum(pnl_s)
weal_th <- cbind(cum_pnls, cum_pnls_lag)
colnames(weal_th) <- c("Strategy", "Strategy_lag")
# Annualized Sharpe ratios of VWAP strategies
sharp_e <- sqrt(252)*sapply(cbind(re_turns, pnl_s),
  function (x) mean(x)/sd(x))
# Plot both strategies
dygraphs::dygraph(weal_th, main=paste("VWAP Crossover Strategy, Sharpe", paste(paste(names(sharp_e), round(sharp_e, 3), sep="="), collapse=", "))) %>%
  dyOptions(colors=c("blue", "red"), strokeWidth=3)

# Calculate fast and slow VWAPs
vwap_fast <- TTR::VWAP(cum_rets, volume=vol_ume, n=20)
vwap_fast[1:20] <- 0
vwap_slow <- TTR::VWAP(cum_rets, volume=vol_ume, n=200)
vwap_slow[1:200] <- 0
# Calculate VWAP positions
position_s <- sign(vwap_fast - vwap_slow)
# Lag the positions to avoid data snooping
position_s <- rutils::lag_it(position_s)
# Calculate daily profits and losses of strategy
pnl_s <- re_turns*position_s
colnames(pnl_s) <- "Strategy"
cum_pnls <- cumsum(pnl_s)
weal_th <- cbind(cum_rets, cum_pnls, vwap_fast, vwap_slow)
colnames(weal_th) <- c(sym_bol, "Strategy", "VWAP_fast", "VWAP_slow")
# Annualized Sharpe ratios of VTI and VWAP strategy
sharp_e <- sqrt(252)*sapply(cbind(re_turns, pnl_s),
  function (x) mean(x)/sd(x))
# Calculate index for background shading
in_dic <- (vwap_fast > vwap_slow)
whi_ch <- which(rutils::diff_it(in_dic) != 0)
in_dic <- rbind(first(in_dic), in_dic[whi_ch, ], last(in_dic))
date_s <- index(in_dic)
in_dic <- ifelse(drop(coredata(in_dic)), "lightgreen", "antiquewhite")

# Create dygraph object without rendering it
dy_graph <- dygraphs::dygraph(weal_th, main=paste("VWAP Crossover Strategy, Sharpe", paste(paste(names(sharp_e), round(sharp_e, 3), sep="="), collapse=", "))) %>%
  dyOptions(colors=c("blue", "red", "purple", "lightpurple"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)
# Add shading
for (i in 1:(NROW(in_dic)-1)) {
    dy_graph <- dy_graph %>%
dyShading(from=date_s[i], to=date_s[i+1], color=in_dic[i])
}  # end for
# Render the dygraph object
dy_graph

# Calculate correlation of VWAP strategy with VTI
cor(pnl_s, re_turns)
# Combine VWAP strategy with VTI
weal_th <- cbind(re_turns, pnl_s, 0.5*(re_turns+pnl_s))
colnames(weal_th) <- c(sym_bol, "VWAP", "Combined")
sharp_e <- sqrt(252)*sapply(weal_th, function (x) mean(x)/sd(x))

# Plot dygraph of VWAP strategy combined with VTI
dygraphs::dygraph(cumsum(weal_th),
  main=paste("VWAP Crossover Strategy, Sharpe", paste(paste(names(sharp_e), round(sharp_e, 3), sep="="), collapse=", "))) %>%
  dyOptions(colors=c("blue", "purple", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

# Determine trade dates right after VWAP has crossed prices
trade_dates <- (rutils::diff_it(in_dic) != 0)
trade_dates <- which(trade_dates) + 1
trade_dates <- trade_dates[trade_dates < n_rows]
# Calculate positions, either: -1, 0, or 1
position_s <- rep(NA_integer_, n_rows)
position_s[1] <- 0
position_s[trade_dates] <- in_dic[trade_dates-1]
position_s <- zoo::na.locf(position_s, na.rm=FALSE)
position_s <- xts::xts(position_s, order.by=index(oh_lc))
pos_lagged <- rutils::lag_it(position_s)
# Calculate pnl for days without trade
pnl_s <- rutils::diff_it(clos_e)*position_s
# Calculate realized pnl for days with trade
close_lag <- rutils::lag_it(clos_e)
pnl_s[trade_dates] <- pos_lagged[trade_dates]*
  (op_en[trade_dates] - close_lag[trade_dates])
# Calculate unrealized pnl for days with trade
pnl_s[trade_dates] <- pnl_s[trade_dates] +
  position_s[trade_dates]*
  (clos_e[trade_dates] - op_en[trade_dates])
cum_pnls_open <- star_t + cumsum(pnl_s)
# Annualized Sharpe ratio of VWAP strategy
sqrt(252)*sum(pnl_s)/sd(pnl_s)/NROW(pnl_s)
# Annualized Sharpe ratio of VTI
sqrt(252)*sum(re_turns)/sd(re_turns)/NROW(pnl_s)

# Determine trade dates right after VWAP has crossed prices
trade_dates <- (rutils::diff_it(in_dic) != 0)
trade_dates <- which(trade_dates) + 1
trade_dates <- trade_dates[trade_dates < n_rows]
# Calculate positions, either: -1, 0, or 1
position_s <- rep(NA_integer_, n_rows)
position_s[1] <- 0
position_s[trade_dates] <- in_dic[trade_dates-1]
position_s <- zoo::na.locf(position_s, na.rm=FALSE)
position_s <- xts::xts(position_s, order.by=index(oh_lc))
pos_lagged <- rutils::lag_it(position_s)
# Calculate pnl for days without trade
pnl_s <- rutils::diff_it(clos_e)*position_s
# Calculate realized pnl for days with trade
close_lag <- rutils::lag_it(clos_e)
pnl_s[trade_dates] <- pos_lagged[trade_dates]*
  (op_en[trade_dates] - close_lag[trade_dates])
# Calculate unrealized pnl for days with trade
pnl_s[trade_dates] <- pnl_s[trade_dates] +
  position_s[trade_dates]*
  (clos_e[trade_dates] - op_en[trade_dates])
cum_pnls_open <- star_t + cumsum(pnl_s)
# Annualized Sharpe ratio of VWAP strategy
sqrt(252)*sum(pnl_s)/sd(pnl_s)/NROW(pnl_s)
# Annualized Sharpe ratio of VTI
sqrt(252)*sum(re_turns)/sd(re_turns)/NROW(pnl_s)

# Plot both strategies
weal_th <- cbind(cum_pnls_open, cum_pnls)
colnames(weal_th) <- c("strategy_open", "VWAP")
dygraphs::dygraph(weal_th, main=paste(sym_bol, "VWAP Strategy on Open")) %>%
  dySeries(name="strategy_open", label="Strategy on Open", strokeWidth=2, col="green") %>%
  dySeries(name="VWAP", label="VWAP", strokeWidth=2, col="blue")
# Plot VTI and VWAP strategy
quantmod::chart_Series(x=clos_e, name="VWAP Crossover Strategy for VTI Trade at Open Price", col="orange")
add_TA(cum_pnls, on=1, lwd=2, col="blue")
add_TA(position_s > 0, on=-1,
 col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
 col="lightgrey", border="lightgrey")
legend("top", legend=c(sym_bol, "VWAP strategy"),
 inset=0.1, bg="white", lty=1, lwd=6,
 col=c("orange", "blue"), bty="n")

# Extract ETF returns
sym_bols <- c("VTI", "IEF", "DBC")
re_turns <- rutils::etf_env$re_turns[, sym_bols]
# Select rows with IEF data
re_turns <- re_turns[index(rutils::etf_env$IEF)]
# Copy over NA values
re_turns[1, is.na(re_turns[1, ])] <- 0
re_turns <- zoo::na.locf(re_turns, na.rm=FALSE)

# library(rutils)  # Load package rutils
# Define time interval for end points
re_balance <- "weeks"
# Look-back interval is multiple of re_balance
look_back <- 41
# Create index of rebalancing period end points
end_p <- xts::endpoints(rutils::etf_env$re_turns,
                       on=re_balance)
# start_p are multi-period lag of end_p
n_rows <- NROW(end_p)
start_p <- c(rep_len(0, look_back-1),
  end_p[1:(n_rows - look_back + 1)])
# Create list of look-back intervals
look_backs <- lapply(2:n_rows,
    function(ep) {
start_p[ep]:end_p[ep]
  })  # end lapply

# library(rutils)  # Load package rutils
# Create vector of symbols for model
sym_bols <- c("VTI", "IEF", "DBC")

# Calculate risk&ret stats for some symbols, over a range of dates
# Perform lapply() loop over look_backs
risk_stats <- lapply(look_backs,
  function(look_back) {
    x_ts <-
rutils::etf_env$re_turns[look_back, sym_bols]
    t(sapply(x_ts,
function(col_umn)
  c(return=mean(col_umn), risk=mad(col_umn))
))  # end sapply
    })  # end lapply
# rbind list into single xts or matrix
# risk_stats <- do.call_rbind(risk_stats)
# head(risk_stats)
# Calculate non-overlapping returns in interval
re_turns <-sapply(2:n_rows,
    function(ep) {
    sapply(rutils::etf_env$re_turns[
(end_p[ep-1]+1):end_p[ep],
sym_bols], sum)
  })  # end sapply
re_turns <- t(re_turns)

# Define end of month end points
end_p <- rutils::calc_endpoints(re_turns, inter_val="months")
n_rows <- NROW(end_p)
# start points equal end points lagged by 12-month look-back interval
look_back <- 12
start_p <- c(rep_len(0, look_back-1),
  end_p[1:(n_rows - look_back + 1)])
# Calculate matrix of look-back intervals
look_backs <- cbind(start_p, end_p)
# Calculate matrix of look-forward intervals
look_fwds <- cbind(end_p + 1, rutils::lag_it(end_p, -1))
look_fwds[n_rows, 1] <- end_p[n_rows]
# Inspect the intervals
tail(cbind(look_backs, look_fwds))

# Define performance function as Sharpe ratio
perform_ance <- function(re_turns) sum(re_turns)/sd(re_turns)
# Calculate past performance over look-back intervals
pas_t <- apply(look_backs, 1, function(ep) {
  sapply(re_turns[ep[1]:ep[2]], perform_ance)
})  # end sapply
pas_t <- t(pas_t)
pas_t[is.na(pas_t)] <- 0
# Calculate future performance
fu_ture <- apply(look_fwds, 1, function(ep) {
  sapply(re_turns[ep[1]:ep[2]], sum)
})  # end sapply
fu_ture <- t(fu_ture)
fu_ture[is.na(fu_ture)] <- 0
# Weights proportional to past performance
weight_s <- pas_t
# weight_s[weight_s < 0] <- 0
# Scale weight_s so sum is equal to 1
# weight_s <- weight_s/rowSums(weight_s)
# Scale weight_s so sum of squares is equal to 1.
weight_s <- weight_s/sqrt(rowSums(weight_s^2))
# Set NA values to zero
weight_s[is.na(weight_s)] <- 0
sum(is.na(weight_s))

# Calculate backtest returns
pnl_s <- rowSums(weight_s*fu_ture)
pnl_s <- xts::xts(pnl_s, order.by=date_s)
colnames(pnl_s) <- "ewma momentum"
close_rets <- rutils::diff_it(clos_e[date_s])
cor(cbind(pnl_s, close_rets))
pnl_s <- star_t + cumsum(pnl_s)

# Plot the backtest
quantmod::chart_Series(x=clos_e[end_p[-n_rows]],
  name="backtest of EWMA strategies", col="orange")
add_TA(pnl_s, on=1, lwd=2, col="blue")
legend("top", legend=c("VTI", "EWMA"),
 inset=0.1, bg="white", lty=1, lwd=6,
 col=c("orange", "blue"), bty="n")
# shad_e <- xts::xts(index(pnl_s) < as.Date("2008-01-31"), order.by=index(pnl_s))
# add_TA(shad_e, on=-1, col="lightgrey", border="lightgrey")
# text(x=7, y=0, labels="warmup period")

# Calculate momentum profits and losses (returns)
pnl_s <- rowSums(weight_s*fu_ture)
# Lag the momentum returns and weights
# to correspond with end of future interval
pnl_s <- rutils::lag_it(pnl_s)
weight_s <- rutils::lag_it(weight_s)
# bid_offer equal to 10 bps for liquid ETFs
bid_offer <- 0.001
# Calculate transaction costs
weal_th <- cumsum(pnl_s)
cost_s <- 0.5*bid_offer*weal_th*rowSums(abs(rutils::diff_it(weight_s)))
weal_th <- cumsum(pnl_s - cost_s)
date_s <- index(re_turns[end_p])
weal_th <- xts::xts(weal_th, date_s)

# Define all-weather benchmark
weights_aw <- c(0.30, 0.55, 0.15)
ret_aw <- re_turns %*% weights_aw
wealth_aw <- cumsum(ret_aw)
wealth_aw <- xts::xts(wealth_aw[end_p], date_s)
# Plot the Momentum strategy and benchmark
da_ta <- cbind(weal_th, wealth_aw)
colnames(da_ta) <- c("Momentum Strategy", "Benchmark")
dygraphs::dygraph(da_ta, main="Momentum Strategy") %>%
  dyAxis("y", label="Benchmark", independentTicks=TRUE) %>%
  dyAxis("y2", label="Momentum Strategy", independentTicks=TRUE) %>%
  dySeries(name="Momentum Strategy", axis="y2", label="Momentum Strategy", strokeWidth=2, col="red") %>%
  dySeries(name="Benchmark", axis="y", label="Benchmark", strokeWidth=2, col="blue")

# Define backtest functional
backtest_momentum <- function(re_turns,
                perform_ance=function(re_turns) (sum(re_turns)/sd(re_turns)),
                look_back=12, re_balance="months", bid_offer=0.001,
                end_p=rutils::calc_endpoints(re_turns, inter_val=re_balance),
                with_weights=FALSE, ...) {
  stopifnot("package:rutils" %in% search() || require("rutils", quietly=TRUE))
  # Define look-back and look-forward intervals
  n_rows <- NROW(end_p)
  start_p <- c(rep_len(0, look_back-1), end_p[1:(n_rows-look_back+1)])
  # Calculate look-back intervals
  look_backs <- cbind(start_p, end_p)
  # Calculate look-forward intervals
  look_fwds <- cbind(end_p + 1, rutils::lag_it(end_p, -1))
  look_fwds[n_rows, 1] <- end_p[n_rows]
  # Calculate past performance over look-back intervals
  pas_t <- t(apply(look_backs, 1, function(ep) sapply(re_turns[ep[1]:ep[2]], perform_ance)))
  pas_t[is.na(pas_t)] <- 0
  # Calculate future performance
  fu_ture <- t(apply(look_fwds, 1, function(ep) sapply(re_turns[ep[1]:ep[2]], sum)))
  fu_ture[is.na(fu_ture)] <- 0
  # Scale weight_s so sum of squares is equal to 1
  weight_s <- pas_t
  weight_s <- weight_s/sqrt(rowSums(weight_s^2))
  weight_s[is.na(weight_s)] <- 0  # Set NA values to zero
  # Calculate momentum profits and losses
  pnl_s <- rowSums(weight_s*fu_ture)
  # Calculate transaction costs
  cost_s <- 0.5*bid_offer*cumprod(1 + pnl_s)*rowSums(abs(rutils::diff_it(weight_s)))
  pnl_s <- (pnl_s - cost_s)
  if (with_weights)
    rutils::lag_it(cbind(pnl_s, weight_s))
  else
    rutils::lag_it(pnl_s)
}  # end backtest_momentum

source("C:/Develop/lecture_slides/scripts/back_test.R")
look_backs <- seq(3, 15, by=1)
perform_ance <- function(re_turns) sum(re_turns)/sd(re_turns)
pro_files <- sapply(look_backs, function(look_back) {
  pnl_s <- backtest_momentum(re_turns=re_turns, end_p=end_p,
    look_back=look_back, perform_ance=perform_ance)
  last(cumsum(pnl_s))
})  # end sapply
x11(width=6, height=5)
plot(x=look_backs, y=pro_files, t="l",
  main="Strategy PnL as function of look_back",
  xlab="look_back (months)", ylab="pnl")

look_back <- look_backs[which.max(pro_files)]
pnl_s <- backtest_momentum(re_turns=re_turns,
  look_back=look_back, end_p=end_p,
  perform_ance=perform_ance, with_weights=TRUE)
tail(pnl_s)
ret_mom <- as.numeric(pnl_s[, 1])
weal_th <- cumsum(ret_mom)
da_ta <- cbind(weal_th, wealth_aw)
colnames(da_ta) <- c("Momentum Strategy", "All_weather")

# Plot the Momentum strategy and benchmark
dygraphs::dygraph(da_ta, main="Momentum Strategy") %>%
  dyAxis("y", label="All_weather", independentTicks=TRUE) %>%
  dyAxis("y2", label="Momentum Strategy", independentTicks=TRUE) %>%
  dySeries(name="Momentum Strategy", axis="y2", label="Momentum Strategy", strokeWidth=2, col="red") %>%
  dySeries(name="All_weather", axis="y", label="All_weather", strokeWidth=2, col="blue")
# Or
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue")
quantmod::chart_Series(da_ta, theme=plot_theme, lwd=2,
       name="Momentum PnL")
legend("topleft", legend=colnames(da_ta),
  inset=0.1, bg="white", lty=1, lwd=6,
  col=plot_theme$col$line.col, bty="n")

# Plot the momentum portfolio weights
weight_s <- pnl_s[, -1]
vt_i <- rutils::etf_env$price_s$VTI[date_s]
da_ta <- cbind(vt_i, weight_s)
da_ta <- na.omit(da_ta)
colnames(da_ta)[2:NCOL(pnl_s)] <- paste0(colnames(weight_s), "_weight")
zoo::plot.zoo(da_ta, xlab=NULL, main="Momentum Weights")

# Calculate ETF betas
betas_etf <- sapply(re_turns, function(x)
  cov(re_turns$VTI, x)/var(x))
# Betas equal weights times ETF betas
beta_s <- weight_s %*% betas_etf
beta_s <- xts::xts(beta_s, order.by=date_s)
colnames(beta_s) <- "momentum_beta"
da_ta <- cbind(beta_s, rutils::etf_env$VTI[date_s, 4])
zoo::plot.zoo(da_ta,
  oma = c(3, 1, 3, 0), mar = c(0, 4, 0, 1),
  main="betas & VTI", xlab="")

# Open x11 for plotting and set parameters to reduce whitespace around plot
x11(width=6, height=5)
par(mar=c(4, 4, 3, 1), oma=c(0, 0, 0, 0))
# Merton-Henriksson test
vt_i <- rutils::diff_it(vt_i)/rutils::lag_it(vt_i)
de_sign <- cbind(VTI=vt_i, 0.5*(vt_i+abs(vt_i)), vt_i^2)
colnames(de_sign)[2:3] <- c("merton", "treynor")
mod_el <- lm(ret_mom ~ VTI + merton, data=de_sign); summary(mod_el)
# Treynor-Mazuy test
mod_el <- lm(ret_mom ~ VTI + treynor, data=de_sign); summary(mod_el)
# Plot residual scatterplot
plot.default(x=vt_i, y=ret_mom, xlab="VTI", ylab="momentum")
title(main="Treynor-Mazuy market timing test\n for Momentum vs VTI", line=0.5)
# Plot fitted (predicted) response values
points.default(x=vt_i, y=mod_el$fitted.values, pch=16, col="red")
text(x=0.05, y=0.15, paste("Treynor test t-value =", round(summary(mod_el)$coefficients["treynor", "t value"], 2)))

# Standardize the returns
ret_mom_std <- (ret_mom-mean(ret_mom))/sd(ret_mom)
vt_i <- (vt_i-mean(vt_i))/sd(vt_i)
# Calculate skewness and kurtosis
apply(cbind(ret_mom_std, vt_i), 2, function(x)
  sapply(c(skew=3, kurt=4),
    function(e) sum(x^e)))/n_rows

# Plot histogram
hist(ret_mom_std, breaks=30,
  main="Momentum and VTI Return Distributions (standardized",
  xlim=c(-4, 4),
  xlab="", ylab="", freq=FALSE)
# Draw kernel density of histogram
lines(density(ret_mom_std), col='red', lwd=2)
lines(density(vt_i), col='blue', lwd=2)
# Add legend
legend("topright", inset=0.05, cex=0.8, title=NULL,
 leg=c("Momentum", "VTI"),
 lwd=6, bg="white", col=c("red", "blue"))

# Combine momentum strategy with all-weather
ret_aw <- rutils::diff_it(wealth_aw)/rutils::lag_it(wealth_aw)
ret_aw <- sd(ret_mom)*ret_aw/sd(ret_aw)
da_ta <- cbind(ret_mom, ret_aw, 0.5*(ret_mom + ret_aw))
colnames(da_ta) <- c("momentum", "all_weather", "combined")
# Calculate strategy annualized Sharpe ratios
apply(da_ta, MARGIN=2, function(x) {
  sqrt(12)*sum(x)/sd(x)/NROW(x)
})  # end apply
# Calculate strategy correlations
cor(da_ta)
# Calculate cumulative wealth
weal_th <- apply(da_ta, MARGIN=2,
  function(x) {cumsum(x)}
)  # end apply
weal_th <- xts::xts(weal_th, date_s)

# Plot ETF momentum strategy combined with All-Weather
dygraphs::dygraph(weal_th, main="ETF Momentum Strategy Combined with All-Weather") %>%
  dyOptions(colors=c("green", "blue", "red"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)
# Or
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("green", "blue", "red")
quantmod::chart_Series(da_ta, theme=plot_theme,
       name="ETF Momentum Strategy Combined with All-Weather")
legend("topleft", legend=colnames(da_ta),
  inset=0.1, bg="white", lty=1, lwd=6,
  col=plot_theme$col$line.col, bty="n")

# Calculate rolling variance
look_back <- 252
vari_ance <- roll::roll_var(re_turns, width=look_back)
vari_ance <- zoo::na.locf(vari_ance, na.rm=FALSE)
vari_ance[is.na(vari_ance)] <- 0
# Calculate rolling Sharpe
pas_t <- roll::roll_mean(re_turns, width=look_back)
weight_s <- pas_t/sqrt(vari_ance)
weight_s[vari_ance == 0] <- 0
weight_s[1:look_back, ] <- 1
weight_s <- weight_s/sqrt(rowSums(weight_s^2))
weight_s[is.na(weight_s)] <- 0
weight_s <- rutils::lag_it(weight_s)
sum(is.na(weight_s))
# Calculate momentum profits and losses
pnl_s <- rowMeans(weight_s*re_turns)

# Calculate transaction costs
bid_offer <- 0.001
cost_s <- 0.5*bid_offer*rowSums(abs(rutils::diff_it(weight_s)))
weal_th <- cumsum(pnl_s - cost_s)
weal_th <- xts::xts(weal_th, order.by=index(re_turns))
# Plot momentum and VTI
wealth_aw <- cumsum(re_turns %*% weights_aw)
da_ta <- cbind(wealth_aw, weal_th)
colnames(da_ta) <- c("all_weather", "momentum")
col_names <- colnames(da_ta)
dygraphs::dygraph(da_ta, main="Momentum vs All-Weather") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="blue") %>%
  dySeries(name=col_names[2], axis="y2", col="red")

# Define backtest functional for daily momentum strategy
# If tre_nd=(-1) then it backtests a mean reverting strategy
momentum_daily <- function(re_turns, look_back=252, bid_offer=0.001, tre_nd=1, ...) {
  stopifnot("package:quantmod" %in% search() || require("quantmod", quietly=TRUE))
  # Calculate rolling variance
  vari_ance <- roll::roll_var(re_turns, width=look_back)
  vari_ance <- zoo::na.locf(vari_ance, na.rm=FALSE)
  # vari_ance[is.na(vari_ance)] <- 0
  vari_ance[vari_ance <= 0] <- 1
  # Calculate rolling Sharpe
  pas_t <- roll::roll_mean(re_turns, width=look_back)
  pas_t[1:look_back, ] <- 1
  weight_s <- pas_t/sqrt(vari_ance)
  # weight_s[vari_ance == 0] <- 0
  weight_s[1:look_back, ] <- 1
  weight_s <- weight_s/sqrt(rowSums(weight_s^2))
  weight_s[is.na(weight_s)] <- 0
  weight_s <- rutils::lag_it(weight_s)
  # Calculate momentum profits and losses
  pnl_s <- tre_nd*rowMeans(weight_s*re_turns)
  # Calculate transaction costs
  cost_s <- 0.5*bid_offer*rowSums(abs(rutils::diff_it(weight_s)))
  cumsum(pnl_s - cost_s)
}  # end momentum_daily

# Backtest a daily ETF momentum strategy
source("C:/Develop/lecture_slides/scripts/back_test.R")
weal_th <- momentum_daily(look_back=252,
  re_turns=re_turns, bid_offer=bid_offer)
# Perform sapply loop over look_backs
look_backs <- seq(50, 300, by=50)
weal_th <- sapply(look_backs, momentum_daily,
  re_turns=re_turns, bid_offer=bid_offer)
colnames(weal_th) <- paste0("look_back=", look_backs)
weal_th <- xts::xts(weal_th, index(re_turns))
tail(weal_th)

# Plot EWMA strategies with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <-
  colorRampPalette(c("blue", "red"))(NCOL(weal_th))
quantmod::chart_Series(weal_th,
  theme=plot_theme, name="Cumulative Returns of Daily ETF Momentum Strategies")
legend("bottomleft", legend=colnames(weal_th),
  inset=0.02, bg="white", cex=0.7, lwd=rep(6, NCOL(re_turns)),
  col=plot_theme$col$line.col, bty="n")

# Load daily S&P500 percentage stock returns.
load("C:/Develop/lecture_slides/data/sp500_returns.RData")
# Backtest a daily S&P500 momentum strategy.
source("C:/Develop/lecture_slides/scripts/back_test.R")
# Perform sapply loop over look_backs
look_backs <- seq(50, 300, by=50)
weal_th <- sapply(look_backs, momentum_daily,
  re_turns=returns_100, bid_offer=0)
colnames(weal_th) <- paste0("look_back=", look_backs)
weal_th <- xts::xts(weal_th, index(re_turns))

# Plot daily S&P500 momentum strategies with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <-
  colorRampPalette(c("blue", "red"))(NCOL(weal_th))
quantmod::chart_Series(weal_th,
  theme=plot_theme, name="Cumulative Returns of S&P500 Momentum Strategies")
legend("bottomleft", legend=colnames(weal_th),
  inset=0.02, bg="white", cex=0.7, lwd=rep(6, NCOL(re_turns)),
  col=plot_theme$col$line.col, bty="n")

# Perform sapply loop over look_backs
look_backs <- seq(5, 50, by=5)
weal_th <- sapply(look_backs, momentum_daily,
  re_turns=returns_100, bid_offer=0, tre_nd=(-1))
colnames(weal_th) <- paste0("look_back=", look_backs)
weal_th <- xts::xts(weal_th, index(price_s))

# Plot EWMA strategies with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <-
  colorRampPalette(c("blue", "red"))(NCOL(weal_th))
quantmod::chart_Series(weal_th,
  theme=plot_theme, name="Cumulative Returns of S&P500 Mean Reverting Strategies")
legend("topleft", legend=colnames(weal_th),
  inset=0.05, bg="white", cex=0.7, lwd=rep(6, NCOL(re_turns)),
  col=plot_theme$col$line.col, bty="n")

library(rutils)
# Select all the ETF symbols except "VXX", "SVXY" and "MTUM"
sym_bols <- colnames(rutils::etf_env$re_turns)
sym_bols <- sym_bols[!(sym_bols %in% c("VXX", "SVXY", "MTUM"))]
# Extract columns of rutils::etf_env$re_turns and overwrite NA values
re_turns <- rutils::etf_env$re_turns[, sym_bols]
n_assets <- NCOL(re_turns)
# re_turns <- na.omit(re_turns)
re_turns[1, is.na(re_turns[1, ])] <- 0
re_turns <- zoo::na.locf(re_turns, na.rm=FALSE)
# Returns in excess of risk-free rate
risk_free <- 0.03/252
ex_cess <- (re_turns - risk_free)
# Maximum Sharpe weights in-sample interval
in_verse <- MASS::ginv(cov(re_turns["/2014"]))
weight_s <- in_verse %*% colMeans(ex_cess["/2014"])
weight_s <- drop(weight_s/sqrt(sum(weight_s^2)))
names(weight_s) <- colnames(re_turns)
# Plot portfolio weights
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(0, 0, 0, 0), mgp=c(2, 1, 0))
barplot(sort(weight_s), main="Maximum Sharpe Weights", cex.names=0.7)
# Calculate portfolio returns
rets_is <- re_turns["/2014"]
portf_is <- xts::xts(rets_is %*% weight_s, index(rets_is))
in_dex <- xts::xts(rowSums(rets_is)/sqrt(n_assets), index(rets_is))
portf_is <- portf_is*sd(in_dex)/sd(portf_is)
# Plot cumulative portfolio returns
weal_th <- cumsum(cbind(portf_is, in_dex))
colnames(weal_th) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(weal_th, main="In-sample Optimal Portfolio Returns") %>%
  dyOptions(colors=c("red","blue"), strokeWidth=2) %>%
  dyLegend(width=500)

# Out-of-sample portfolio returns
rets_os <- re_turns["2015/"]
portf_os <- xts::xts(rets_os %*% weight_s, index(rets_os))
in_dex <- xts::xts(rowSums(rets_os)/sqrt(n_assets), index(rets_os))
portf_os <- portf_os*sd(in_dex)/sd(portf_os)

# Plot cumulative portfolio returns
weal_th <- cumsum(cbind(portf_os, in_dex))
colnames(weal_th) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(weal_th, main="Out-of-sample Optimal Portfolio Returns") %>%
  dyOptions(colors=c("red","blue"), strokeWidth=2) %>%
  dyLegend(width=500)

load("C:/Develop/lecture_slides/data/sp500_returns.RData")
# Overwrite NA values in re_turns
re_turns <- re_turns["2000/"]
n_assets <- NCOL(re_turns)
re_turns[1, is.na(re_turns[1, ])] <- 0
re_turns <- zoo::na.locf(re_turns, na.rm=FALSE)
risk_free <- 0.03/252
ex_cess <- (re_turns - risk_free)
rets_is <- re_turns["/2010"]
rets_os <- re_turns["2011/"]
# Maximum Sharpe weights in-sample interval
cov_mat <- cov(rets_is)
in_verse <- MASS::ginv(cov_mat)
weight_s <- in_verse %*% colMeans(ex_cess["/2010"])
weight_s <- drop(weight_s/sqrt(sum(weight_s^2)))
names(weight_s) <- colnames(re_turns)
# Calculate portfolio returns
portf_is <- xts::xts(rets_is %*% weight_s, index(rets_is))
portf_os <- xts::xts(rets_os %*% weight_s, index(rets_os))
in_dex <- xts::xts(rowSums(re_turns)/sqrt(n_assets), index(re_turns))

# Plot cumulative portfolio returns
weal_th <- rbind(portf_is, portf_os)
weal_th <- weal_th*sd(in_dex)/sd(weal_th)
weal_th <- cumsum(cbind(weal_th, in_dex))
colnames(weal_th) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(weal_th, main="Out-of-sample Optimal Portfolio Returns for Stocks") %>%
  dyOptions(colors=c("red","blue"), strokeWidth=2) %>%
  dyEvent(index(last(rets_is[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)

# Create rectangular matrix with collinear columns
ran_dom <- matrix(rnorm(10*8), nc=10)
# Calculate covariance matrix
cov_mat <- cov(ran_dom)
# Calculate inverse of cov_mat - error
in_verse <- solve(cov_mat)
# Calculate regularized inverse of cov_mat
in_verse <- MASS::ginv(cov_mat)
# Verify inverse property of mat_rix
all.equal(cov_mat, cov_mat %*% in_verse %*% cov_mat)
# Perform eigen decomposition
ei_gen <- eigen(cov_mat)
eigen_vec <- ei_gen$vectors
eigen_val <- ei_gen$values
# Set tolerance for determining zero singular values
to_l <- sqrt(.Machine$double.eps)
# Calculate regularized inverse matrix
not_zero <- (eigen_val > (to_l * eigen_val[1]))
reg_inverse <- eigen_vec[, not_zero] %*%
  (t(eigen_vec[, not_zero]) / eigen_val[not_zero])
# Verify inverse property of mat_rix
all.equal(in_verse, reg_inverse)

# Calculate in-sample covariance matrix
cov_mat <- cov(rets_is)
ei_gen <- eigen(cov_mat)
eigen_vec <- ei_gen$vectors
eigen_val <- ei_gen$values
# Calculate regularized inverse of covariance matrix
max_eigen <- 21
in_verse <- eigen_vec[, 1:max_eigen] %*%
  (t(eigen_vec[, 1:max_eigen]) / ei_gen$values[1:max_eigen])

# Calculate portfolio weights
weight_s <- in_verse %*% colMeans(ex_cess["/2010"])
weight_s <- drop(weight_s/sqrt(sum(weight_s^2)))
names(weight_s) <- colnames(re_turns)
# Calculate portfolio returns
portf_is <- xts::xts(rets_is %*% weight_s, index(rets_is))
portf_os <- xts::xts(rets_os %*% weight_s, index(rets_os))
in_dex <- xts::xts(rowSums(re_turns)/sqrt(n_assets), index(re_turns))

# Plot cumulative portfolio returns
weal_th <- rbind(portf_is, portf_os)
weal_th <- weal_th*sd(in_dex)/sd(weal_th)
weal_th <- cumsum(cbind(weal_th, in_dex))
colnames(weal_th) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(weal_th, main="Regularized Out-of-sample Optimal Portfolio Returns for Stocks") %>%
  dyOptions(colors=c("red","blue"), strokeWidth=2) %>%
  dyEvent(index(last(rets_is[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)

# Shrink the in-sample returns to their mean
rets_mean <- colMeans(rets_is) - risk_free
al_pha <- 0.7
rets_mean <- (1 - al_pha)*rets_mean + al_pha*mean(rets_mean)

# Calculate portfolio weights
weight_s <- in_verse %*% rets_mean
weight_s <- drop(weight_s/sqrt(sum(weight_s^2)))
# Calculate portfolio returns
portf_is <- xts::xts(rets_is %*% weight_s, index(rets_is))
portf_os <- xts::xts(rets_os %*% weight_s, index(rets_os))
# Plot cumulative portfolio returns
weal_th <- rbind(portf_is, portf_os)
weal_th <- weal_th*sd(in_dex)/sd(weal_th)
weal_th <- cumsum(cbind(weal_th, in_dex))
colnames(weal_th) <- c("Optimal Portfolio", "Equal Weight Portfolio")
dygraphs::dygraph(weal_th, main="Out-of-sample Returns for Stocks With Regularization and Shrinkage") %>%
  dyOptions(colors=c("red","blue"), strokeWidth=2) %>%
  dyEvent(index(last(rets_is[, 1])), label="in-sample", strokePattern="solid", color="red") %>%
  dyLegend(width=500)

library(RcppArmadillo)
# Source Rcpp functions from file
Rcpp::sourceCpp("C:/Develop/lecture_slides/scripts/calc_weights.cpp")
# Create random matrix of returns
mat_rix <- matrix(rnorm(300), nc=5)
# Regularized inverse of covariance matrix
max_eigen <- 4
ei_gen <- eigen(cov(mat_rix))
cov_inv <- ei_gen$vectors[, 1:max_eigen] %*%
  (t(ei_gen$vectors[, 1:max_eigen]) / ei_gen$values[1:max_eigen])
# Regularized inverse using RcppArmadillo
cov_inv_arma <- calc_inv(mat_rix, max_eigen)
all.equal(cov_inv, cov_inv_arma)
# Microbenchmark RcppArmadillo code
library(microbenchmark)
summary(microbenchmark(
  pure_r={
    ei_gen <- eigen(cov(mat_rix))
    ei_gen$vectors[, 1:max_eigen] %*%
(t(ei_gen$vectors[, 1:max_eigen]) / ei_gen$values[1:max_eigen])
  },
  r_cpp=calc_inv(mat_rix, max_eigen),
  times=100))[, c(1, 4, 5)]  # end microbenchmark summary

# Calculate vector of monthly end points and start points
end_p <- rutils::calc_endpoints(re_turns, inter_val="months")
end_p <- end_p[end_p > 2*NCOL(re_turns)]
n_rows <- NROW(end_p)
look_back <- 24
start_p <- c(rep_len(0, look_back-1),
       end_p[1:(n_rows-look_back+1)])

# Perform loop over end points
rets_portf <- lapply(2:n_rows, function(i) {
    # Subset the ex_cess returns
    ex_cess <- ex_cess[start_p[i-1]:end_p[i-1], ]
    in_verse <- MASS::ginv(cov(ex_cess))
    # Calculate the maximum Sharpe ratio portfolio weights
    weight_s <- in_verse %*% colMeans(ex_cess)
    weight_s <- drop(weight_s/sqrt(sum(weight_s^2)))
    # Calculate the out-of-sample portfolio returns
    re_turns <- re_turns[(end_p[i-1]+1):end_p[i], ]
    xts::xts(re_turns %*% weight_s, index(re_turns))
})  # end lapply
rets_portf <- rutils::do_call(rbind, rets_portf)
# Plot cumulative strategy returns
in_dex <- xts::xts(rowSums(re_turns)/sqrt(n_assets), index(re_turns))
weal_th <- cumsum(na.omit(cbind(rets_portf, in_dex*sd(rets_portf)/sd(in_dex))))
colnames(weal_th) <- c("Rolling Portfolio Strategy", "Equal Weight Portfolio")
dygraphs::dygraph(weal_th, main="Rolling Portfolio Optimization Strategy") %>%
  dyOptions(colors=c("red","blue"), strokeWidth=2) %>%
  dyLegend(show="always", width=500)

load("C:/Develop/lecture_slides/data/sp500_returns.RData")
# Overwrite NA values in re_turns
returns_100[1, is.na(returns_100[1, ])] <- 0
returns_100 <- zoo::na.locf(returns_100, na.rm=FALSE)
n_cols <- NCOL(returns_100) ; date_s <- index(returns_100)
# Define monthly end points
end_p <- rutils::calc_endpoints(returns_100, inter_val="months")
end_p <- end_p[end_p > (n_cols+1)]
n_rows <- NROW(end_p) ; look_back <- 12
start_p <- c(rep_len(0, look_back-1), end_p[1:(n_rows-look_back+1)])
end_p <- (end_p - 1)
start_p <- (start_p - 1)
start_p[start_p < 0] <- 0
al_pha <- 0.7 ; max_eigen <- 21

# Perform backtest in Rcpp
pnl_s <- HighFreq::back_test(typ_e="max_sharpe",
  ex_cess=returns_100, re_turns=returns_100,
  start_p=start_p, end_p=end_p,
  al_pha=al_pha, max_eigen=max_eigen)
# Calculate returns on equal weight portfolio
in_dex <- xts::xts(rowMeans(returns_100), index(returns_100))
# Plot cumulative strategy returns
weal_th <- cbind(pnl_s, in_dex, (pnl_s+in_dex)/2)
weal_th <- cumsum(na.omit(weal_th))
col_names <- c("Strategy", "Index", "Average")
colnames(weal_th) <- col_names
dygraphs::dygraph(weal_th[end_p], main="Rolling S&P500 Portfolio Optimization Strategy") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="red", strokeWidth=1) %>%
  dySeries(name=col_names[2], axis="y2", col="blue", strokeWidth=1) %>%
  dySeries(name=col_names[3], axis="y2", col="green", strokeWidth=2)

# Perform backtest over alphas
alpha_s <- seq(from=0.01, to=0.91, by=0.1)
pnl_s <- lapply(alpha_s, function(al_pha) {
  HighFreq::back_test(typ_e="max_sharpe",
  ex_cess=returns_100, re_turns=returns_100,
  start_p=start_p, end_p=end_p,
  al_pha=al_pha, max_eigen=max_eigen)
})  # end lapply
pro_files <- sapply(pnl_s, sum)
plot(x=alpha_s, y=pro_files, t="l", main="Strategy PnL as Function of Shrinkage Intensity Alpha",
  xlab="Shrinkage Intensity Alpha", ylab="pnl")
al_pha <- alpha_s[which.max(pro_files)]
pnl_s <- pnl_s[[which.max(pro_files)]]
# Perform backtest over max_eigens
max_eigens <- seq(from=3, to=40, by=2)
pnl_s <- lapply(max_eigens, function(max_eigen) {
  HighFreq::back_test(typ_e="max_sharpe",
    ex_cess=returns_100, re_turns=returns_100,
    start_p=start_p, end_p=end_p,
    al_pha=al_pha, max_eigen=max_eigen)
})  # end lapply
pro_files <- sapply(pnl_s, sum)
plot(x=max_eigens, y=pro_files, t="l", main="Strategy PnL as Function of Max_eigen",
  xlab="Max_eigen", ylab="pnl")
max_eigen <- max_eigens[which.max(pro_files)]
pnl_s <- pnl_s[[which.max(pro_files)]]

# Plot cumulative strategy returns
weal_th <- cbind(pnl_s, in_dex, (pnl_s+in_dex)/2)
weal_th <- cumsum(na.omit(weal_th))
col_names <- c("Strategy", "Index", "Average")
colnames(weal_th) <- col_names
dygraphs::dygraph(weal_th[end_p], main="Optimal Rolling S&P500 Portfolio Strategy") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="red", strokeWidth=1) %>%
  dySeries(name=col_names[2], axis="y2", col="blue", strokeWidth=1) %>%
  dySeries(name=col_names[3], axis="y2", col="green", strokeWidth=2)

# Perform backtest over look-backs
look_backs <- seq(from=3, to=24, by=1)
pnl_s <- lapply(look_backs, function(look_back) {
  start_p <- c(rep_len(0, look_back-1), end_p[1:(n_rows-look_back+1)])
  start_p <- (start_p - 1)
  start_p[start_p < 0] <- 0
  HighFreq::back_test(typ_e="max_sharpe",
    ex_cess=returns_100, re_turns=returns_100,
    start_p=start_p, end_p=end_p,
    al_pha=al_pha, max_eigen=max_eigen)
})  # end lapply
pro_files <- sapply(pnl_s, sum)
plot(x=look_backs, y=pro_files, t="l", main="Strategy PnL as Function of Look-back Interval",
  xlab="Look-back Interval", ylab="pnl")
look_back <- look_backs[which.max(pro_files)]
pnl_s <- pnl_s[[which.max(pro_files)]]

# Plot cumulative strategy returns
weal_th <- cbind(pnl_s, in_dex, (pnl_s+in_dex)/2)
weal_th <- cumsum(na.omit(weal_th))
col_names <- c("Strategy", "Index", "Average")
colnames(weal_th) <- col_names
dygraphs::dygraph(weal_th[end_p], main="Optimal Rolling S&P500 Portfolio Strategy") %>%
  dyAxis("y", label=col_names[1], independentTicks=TRUE) %>%
  dyAxis("y2", label=col_names[2], independentTicks=TRUE) %>%
  dySeries(name=col_names[1], axis="y", col="red", strokeWidth=1) %>%
  dySeries(name=col_names[2], axis="y2", col="blue", strokeWidth=1) %>%
  dySeries(name=col_names[3], axis="y2", col="green", strokeWidth=2)
