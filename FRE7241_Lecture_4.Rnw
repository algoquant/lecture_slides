% FRE7241_Lecture_4

% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='tiny', fig.width=4, fig.height=4)
options(width=80, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{mathtools}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
% bbold package for unitary vector or matrix symbol
\usepackage{bbold}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
\usepackage{listings}
\usepackage{xcolor}
\definecolor{anti_flashwhite}{rgb}{0.95, 0.95, 0.96}
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE7241 Lecture\#4]{FRE7241 Algorithmic Portfolio Management}
\subtitle{Lecture\#4, Spring 2021}

\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{April 29, 2021}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle



%%%%%%%%%%%%%%%
\section{Calibrating Time Series Models}


%%%%%%%%%%%%%%%
\subsection{Fitting Time Series to Autoregressive Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An \emph{autoregressive} process \emph{AR(p)} for the time series of returns $r_i$:
      \begin{multline*}
        r_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p} + \xi_i = \\
        \sum_{j=1}^{p} {\varphi_j r_{i-j}} + \xi_i
      \end{multline*}
      Can be solved as a \emph{multivariate} linear regression, with the \emph{response} equal to $r_i$, and the columns of the \emph{design matrix} equal to the lags of $r_i$.
      \vskip1ex
      An intercept term can be added to the above formula by adding a unit column to the regression design matrix.
      \vskip1ex
      Adding the intercept term produces slightly different coefficients, depending on the mean of the returns.
      \vskip1ex
      The function \texttt{stats::ar.ols()} fits an \emph{AR(p)} model, but it produces slightly different coefficients than linear regression, because it uses a different calibration procedure.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Specify AR process parameters
n_rows <- 1e3
co_eff <- c(0.1, 0.39, 0.5); n_coeff <- NROW(co_eff)
set.seed(1121); in_nov <- rnorm(n_rows)
# ari_ma <- filter(x=in_nov, filter=co_eff, method="recursive")
# Simulate AR process using C_rfilter()
ari_ma <- .Call(stats:::C_rfilter, in_nov, co_eff, 
  double(n_rows + n_coeff))[-(1:n_coeff)]
# Fit AR model using ar.ols()
ar_fit <- ar.ols(ari_ma, order.max=n_coeff, aic=FALSE)
class(ar_fit)
is.list(ar_fit)
drop(ar_fit$ar)
# Define design matrix with intercept column
de_sign <- sapply(1:n_coeff, function(lagg) {
  rutils::lag_it(ari_ma, lagg=lagg)
})  # end sapply
de_sign <- cbind(rep(1, n_rows), de_sign)
# Fit AR model using regression
design_inv <- MASS::ginv(de_sign)
coeff_reg <- drop(design_inv %*% ari_ma)
all.equal(drop(ar_fit$ar), coeff_reg[-1], check.attributes=FALSE)
# Define design matrix without intercept column
de_sign <- sapply(1:n_coeff, function(lagg) {
  rutils::lag_it(ari_ma, lagg=lagg)
})  # end sapply
# Fit AR model using regression
design_inv <- MASS::ginv(de_sign)
coeff_reg <- drop(design_inv %*% ari_ma)
all.equal(drop(ar_fit$ar), coeff_reg, check.attributes=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Standard Errors of the \protect\emph{AR(p)} Coefficients}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{standard errors} of the fitted \emph{AR(p)} coefficients are proportional to the standard deviation of the fitted residuals.
      \vskip1ex
      Their \emph{t}-values are equal to the ratio of the fitted coefficients divided by their standard errors.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the regression residuals
fit_ted <- drop(de_sign %*% coeff_reg)
residual_s <- drop(ari_ma - fit_ted)
# Variance of residuals
var_resid <- sum(residual_s^2)/(n_rows - NROW(coeff_reg))
# Design matrix squared
design_2 <- crossprod(de_sign)
# Calculate covariance matrix of AR coefficients
co_var <- var_resid*MASS::ginv(design_2)
coeff_regd <- sqrt(diag(co_var))
# Calculate t-values of AR coefficients
coeff_tvals <- drop(coeff_reg)/coeff_regd
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Order Selection of \protect\emph{AR(p)} Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Order selection means determining the \emph{order parameter} $p$ of the \emph{AR(p)} model that best fits the time series.
      \vskip1ex
      The order parameter $p$ can be set equal to the number of significantly non-zero \emph{partial autocorrelations} of the time series.
      \vskip1ex
      The order parameter can also be determined by only selecting coefficients with statistically significant \emph{t}-values.
      \vskip1ex
      Fitting an \emph{AR(p)} model can be performed by first determining the order $p$, and then calculating the coefficients.
      \vskip1ex
      The function \texttt{stats::arima()} calibrates (fits) an \emph{ARIMA} model to a univariate time series.
      \vskip1ex
      The function \texttt{auto.arima()} from the package \emph{forecast} performs order selection, and calibrates an \emph{AR(p)} model to a univariate time series.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Fit AR(5) model into AR(3) process
de_sign <- sapply(1:5, function(lagg) {
  rutils::lag_it(ari_ma, lagg=lagg)
})  # end sapply
de_sign <- cbind(rep(1, n_rows), de_sign)
design_inv <- MASS::ginv(de_sign)
coeff_reg <- drop(design_inv %*% ari_ma)
# Calculate t-values of AR(5) coefficients
residual_s <- drop(ari_ma - drop(de_sign %*% coeff_reg))
var_resid <- sum(residual_s^2)/(n_rows - NROW(coeff_reg))
co_var <- var_resid*MASS::ginv(crossprod(de_sign))
coeff_regd <- sqrt(diag(co_var))
coeff_tvals <- drop(coeff_reg)/coeff_regd
# Fit AR(5) model using arima()
arima_fit <- arima(ari_ma, order=c(5, 0, 0), include.mean=FALSE)
arima_fit$coef
# Fit AR(5) model using auto.arima()
library(forecast)  # Load forecast
arima_fit <- forecast::auto.arima(ari_ma, max.p=5, max.q=0, max.d=0)
# Fit AR(5) model into VTI returns
re_turns <- drop(zoo::coredata(na.omit(rutils::etf_env$re_turns$VTI)))
de_sign <- sapply(1:5, function(lagg) {
  rutils::lag_it(re_turns, lagg=lagg)
})  # end sapply
de_sign <- cbind(rep(1, NROW(re_turns)), de_sign)
design_inv <- MASS::ginv(de_sign)
coeff_reg <- drop(design_inv %*% re_turns)
# Calculate t-values of AR(5) coefficients
residual_s <- drop(re_turns - drop(de_sign %*% coeff_reg))
var_resid <- sum(residual_s^2)/(n_rows - NROW(coeff_reg))
co_var <- var_resid*MASS::ginv(crossprod(de_sign))
coeff_regd <- sqrt(diag(co_var))
coeff_tvals <- drop(coeff_reg)/coeff_regd
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Yule-Walker Equations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      To lighten the notation we can assume that the time series $r_i$ has zero mean $\mathbb{E}[r_i] = 0$ and unit variance $\mathbb{E}[r_i^2] = 1$.  ($\mathbb{E}$ is the expectation operator.)
      \vskip1ex
      Then the \emph{autocorrelations} of $r_i$ are equal to: $\rho_k = \mathbb{E}[r_i r_{i-k}]$.
      \vskip1ex
      If we multiply the \emph{autoregressive} process \emph{AR(p)}: $r_i = \sum_{j=1}^{p} {\varphi_j r_{i-j}} + \xi_i$, by $r_{i-k}$ and take the expectations, then we obtain the Yule-Walker equations:
      \begin{displaymath}
        \begin{pmatrix}
          \rho_1 \\
          \rho_2 \\
          \rho_3 \\
          \vdots \\
          \rho_p
        \end{pmatrix} =
        \begin{pmatrix}
          1 & \rho_1 & \dots & \rho_{p-1} \\
          \rho_1 & 1 & \dots & \rho_{p-2} \\
          \rho_2 & \rho_1 & \dots & \rho_{p-3} \\
          \vdots & \vdots & \ddots & \vdots \\
          \rho_{p-1} & \rho_{p-2} & \dots & 1
        \end{pmatrix}
        \begin{pmatrix}
          \varphi_1 \\
          \varphi_2 \\
          \varphi_3 \\
          \vdots \\
          \varphi_p
        \end{pmatrix}
      \end{displaymath}
      The Yule-Walker equations relate the \emph{autocorrelation coefficients} $\rho_i$ with the coefficients of the \emph{AR(p)} process $\varphi_i$.
      \vskip1ex
      The Yule-Walker equations can be solved for the \emph{AR(p)} coefficients $\varphi_i$ using matrix inversion.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Compute autocorrelation coefficients
ac_f <- acf(ari_ma, lag=10, plot=FALSE)
ac_f <- drop(ac_f$acf)
acf1 <- ac_f[-NROW(ac_f)]
# Define Yule-Walker matrix
yule_walker <- sapply(2:9, function(lagg) {
  c(acf1[lagg:1], acf1[2:(NROW(acf1)-lagg+1)])
})  # end sapply
yule_walker <- cbind(acf1, yule_walker, rev(acf1))
# Generalized inverse of Yule-Walker matrix
yule_walker_inv <- MASS::ginv(yule_walker)
# Solve Yule-Walker equations
coeff_yw <- drop(yule_walker_inv %*% ac_f[-1])
round(coeff_yw, 5)
coeff_reg
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Forecasting Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An \emph{autoregressive} process \emph{AR(p)}:
      \begin{displaymath}
        r_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p} + \xi_i
      \end{displaymath}
      Can be simulated using the function \texttt{filter()} with the argument \texttt{method="recursive"}.
      \vskip1ex
      Filtering can be performed even faster by directly calling the compiled \texttt{C++} function \texttt{stats:::C\_rfilter()}.
      <<echo=TRUE,eval=FALSE>>=
n_rows <- 1e2
co_eff <- c(0.1, 0.39, 0.5); n_coeff <- NROW(co_eff)
set.seed(1121); in_nov <- rnorm(n_rows)
# Simulate AR process using filter()
ari_ma <- filter(x=in_nov, filter=co_eff, method="recursive")
ari_ma <- as.numeric(ari_ma)
# Simulate AR process using C_rfilter()
arima_fast <- .Call(stats:::C_rfilter, in_nov, co_eff, 
  double(n_rows + n_coeff))
all.equal(ari_ma, arima_fast[-(1:n_coeff)], 
  check.attributes=FALSE)
      @
      The one step ahead \emph{forecast} $f_i$ is equal to the \emph{convolution} of the time series $r_i$ with the \emph{AR(p)} coefficients:
      \begin{displaymath}
        f_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p}
      \end{displaymath}
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ar_forecast.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Forecast AR(3) process using loop in R
forecast_s <- numeric(NROW(ari_ma)+1)
forecast_s[1] <- 0
forecast_s[2] <- co_eff[1]*ari_ma[1]
forecast_s[3] <- co_eff[1]*ari_ma[2] + co_eff[2]*ari_ma[1]
for (it in 4:NROW(forecast_s)) {
  forecast_s[it] <- ari_ma[(it-1):(it-3)] %*% co_eff
}  # end for
# Plot with legend
x11(width=6, height=5)
par(mar=c(3, 3, 2, 1), oma=c(0, 0, 0, 0), mgp=c(2, 1, 0))
plot(ari_ma, main="Forecasting Using AR(3) Model",
  xlab="", ylab="", type="l")
lines(forecast_s, col="orange", lwd=3)
legend(x="topright", legend=c("series","forecasts"),
       col=c("black", "orange"), lty=1, lwd=6,
       cex=0.9, bg="white", bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Fast Forecasting of Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The one step ahead \emph{forecast} $f_i$ is equal to the \emph{convolution} of the time series $r_i$ with the \emph{AR(p)} coefficients:
      \begin{displaymath}
        f_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p}
      \end{displaymath}
      The above \emph{convolution} can be quickly calculated by using the function \texttt{filter()} with the argument \texttt{method="convolution"}.
      \vskip1ex
      The convolution can be calculated even faster by directly calling the compiled \texttt{C++} function \texttt{stats:::C\_cfilter()}.
      \vskip1ex
      The forecasts can also be calculated using the design matrix multiplied by the \emph{AR(p)} coefficients.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Forecast using filter()
filter_fast <- filter(x=ari_ma, sides=1,
  filter=co_eff, method="convolution")
filter_fast <- as.numeric(filter_fast)
# Compare excluding warmup period
all.equal(forecast_s[-(1:n_coeff)], filter_fast[-(1:(n_coeff-1))], 
          check.attributes=FALSE)
# Filter using C_cfilter() compiled C++ function directly
filter_fast <- .Call(stats:::C_cfilter, ari_ma, filter=co_eff, 
                     sides=1, circular=FALSE)
# Compare excluding warmup period
all.equal(forecast_s[-(1:n_coeff)], filter_fast[-(1:(n_coeff-1))], 
          check.attributes=FALSE)
# Define design matrix without intercept column
de_sign <- sapply(1:(n_coeff-1), function(lagg) {
  rutils::lag_it(ari_ma, lagg=lagg)
})  # end sapply
de_sign <- cbind(ari_ma, de_sign)
de_sign <- rbind(numeric(n_coeff), de_sign)
# Forecast using design matrix
filter_fast <- drop(de_sign %*% co_eff)
# Compare with loop in R
all.equal(forecast_s, filter_fast, check.attributes=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Forecasting Using \texttt{predict.Arima()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The forecasts of the \emph{AR(p)} process can also be calculated using the function \texttt{predict()}.
      \vskip1ex
      The function \texttt{predict()} is a \emph{generic function} for forecasting based on a given model.
      \vskip1ex
      The \emph{method} \texttt{predict.Arima()} is \emph{dispatched} by \texttt{R} for calculating predictions from \emph{ARIMA} models produced by the function \texttt{stats::arima()}.
      \vskip1ex
      The \emph{method} \texttt{predict.Arima()} returns a prediction object which is a \texttt{list} containing the predicted value and its standard error.
      \vskip1ex
      The function \texttt{stats::arima()} calibrates (fits) an \emph{ARIMA} model to a univariate time series, using the \emph{maximum likelihood} method (which may give slightly different coefficients than the linear regression model).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Fit ARIMA model using arima()
arima_fit <- arima(ari_ma, order=c(3,0,0), include.mean=FALSE)
arima_fit$coef
co_eff
# One-step-ahead forecast using predict.Arima()
pre_dict <- predict(arima_fit, n.ahead=1)
# Or directly call predict.Arima()
# pre_dict <- predict.Arima(arima_fit, n.ahead=1)
# Inspect the prediction object
class(pre_dict)
names(pre_dict)
class(pre_dict$pred)
unlist(pre_dict)
# One-step-ahead forecast using matrix algebra
fore_cast <- drop(ari_ma[n_rows:(n_rows-2)] %*% arima_fit$coef)
# Compare one-step-ahead forecasts
all.equal(pre_dict$pred[[1]], fore_cast)
# Get information about predict.Arima()
?stats:::predict.Arima
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Forecasting Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{forecasting residuals} $\varepsilon_i$ are equal to the differences between the actual values $r_i$ minus their \emph{forecasts} $f_i$: $\varepsilon_i = r_i - f_i$.
      \vskip1ex
      Accurate forecasting of an \emph{AR(p)} process requires knowing its coefficients.
      \vskip1ex
      If the coefficients of the \emph{AR(p)} process are known exactly, then its \emph{in-sample residuals} $\varepsilon_i$ are equal to its \emph{innovations} $\xi_i$: $\varepsilon_i = r_i - f_i = \xi_i$.
      \vskip1ex
      In reality, we don't know the \emph{AR(p)} coefficients, so they must be fitted to an empirical time series.
      \vskip1ex
      If the \emph{AR(p)} coefficients are fitted to an empirical time series, then its \emph{residuals} are \emph{not} equal to its \emph{innovations}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate the in-sample forecasting residuals
residual_s <- (ari_ma - forecast_s[-NROW(forecast_s)])
# Compare residuals with innovations
all.equal(in_nov, residual_s, check.attributes=FALSE)
plot(residual_s, t="l", lwd=3, xlab="", ylab="", 
     main="ARIMA Forecast Errors")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Backtesting Autoregressive Forecasting Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Backtesting} is the simulation of a model on historical data to test its forecasting accuracy.
      \vskip1ex
      The autoregressive forecasting model can be \emph{backtested} by calculating forecasts over a rolling look-back interval.
      \vskip1ex
      The coefficients of the \emph{AR(p)} process are fitted to past data, and then applied to calculating out-of-sample forecasts.
      \vskip1ex
      The \emph{meta-parameters} of the \emph{backtesting} procedure are the order of the \emph{AR(p)} forecasting model (\texttt{p = or\_der}) and the length of look-back interval (\texttt{look\_back}).
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Simulate AR process using C_rfilter()
n_rows <- 1e3
co_eff <- c(0.5, 0.0, 0.0); n_coeff <- NROW(co_eff)
set.seed(1121); in_nov <- rnorm(n_rows)
ari_ma <- .Call(stats:::C_rfilter, in_nov, co_eff, 
  double(n_rows + n_coeff))[-(1:n_coeff)]
# Define order of the AR(p) forecasting model
or_der <- 5
# Define design matrix for forecasting
de_sign <- sapply(1:or_der, function(lagg) {
  rutils::lag_it(ari_ma, lagg=lagg)
})  # end sapply
de_sign <- cbind(rep(1, n_rows), de_sign)
de_sign <- cbind(ari_ma, de_sign)
# Length of look-back interval
look_back <- 100
# Perform rolling forecasting
forecast_s <- sapply(look_back:(n_rows-1), function(now) {
  # Subset the design matrix
  star_t <- max(1, now-look_back+1)
  de_sign <- de_sign[star_t:now, ]
  n_rows <- NROW(de_sign)
  # Fit AR(p) coefficients
  design_inv <- MASS::ginv(de_sign[, -1])
  co_eff <- drop(design_inv %*% de_sign[, 1])
  # Calculate forecast
  # de_sign[now:(now-or_der), 1] %*% co_eff
  sum(de_sign[n_rows:(n_rows-or_der), 1]*co_eff)
})  # end sapply
# Add warmup period
forecast_s <- c(numeric(look_back), forecast_s)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Accuracy of the Autoregressive Forecasting Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The accuracy of a forecasting model can be measured using the \emph{mean squared error} and the \emph{correlation}.
      \vskip1ex
      The mean squared error (\emph{MSE}) of a forecasting model is the average of the squared forecasting residuals $\varepsilon_i$, equal to the differences between the actual values $r_i$ minus the \emph{forecasts} $f_i$: $\varepsilon_i = r_i - f_i$:
      \begin{displaymath}
        \operatorname{MSE} = \frac{1}{n} \sum_{i=1}^n (r_i - f_i)^2
      \end{displaymath}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Mean squared error
mean((ari_ma - forecast_s)^2)
# Correlation
cor(forecast_s, ari_ma)
# Plot forecasting series with legend
x11(width=6, height=5)
par(mar=c(3, 3, 2, 0), oma=c(0, 0, 0, 0), mgp=c(2, 1, 0))
plot(ari_ma[(n_rows-look_back):n_rows], xlab="", ylab="", type="l", lwd=2,
  main="Rolling Forecasting Using AR(5) Model")
lines(forecast_s[(n_rows-look_back):n_rows], col="orange", lwd=2)
legend(x="topright", legend=c("series","forecasts"),
       col=c("black", "orange"), lty=1, lwd=6,
       cex=0.9, bg="white", bty="n")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/ar_forecast_rolling.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Backtesting Function for the Forecasting Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{meta-parameters} of the \emph{backtesting} function are the order $p$ of the \emph{AR(p)} forecasting model ($p$) and the length of look-back interval (\texttt{look\_back}).
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define backtesting function
back_test <- function(ari_ma, or_der=2, look_back=11) {
  n_rows <- NROW(ari_ma)
  # Define design matrix for forecasting
  de_sign <- sapply(1:or_der, function(lagg) {
    rutils::lag_it(ari_ma, lagg=lagg)
  })  # end sapply
  de_sign <- cbind(rep(1, n_rows), de_sign)
  de_sign <- cbind(ari_ma, de_sign)
  # Perform rolling forecasting
  forecast_s <- sapply(look_back:(n_rows-1), function(now) {
    # Subset the design matrix
    star_t <- max(1, now-look_back+1)
    de_sign <- de_sign[star_t:now, ]
    n_rows <- NROW(de_sign)
    # Fit AR(p) coefficients
    design_inv <- MASS::ginv(de_sign[, -1])
    co_eff <- drop(design_inv %*% de_sign[, 1])
    # Calculate forecast
    # de_sign[now:(now-or_der), 1] %*% co_eff
    sum(de_sign[n_rows:(n_rows-or_der), 1]*co_eff)
  })  # end sapply
  # Add warmup period
  forecast_s <- c(numeric(look_back), forecast_s)
  c(mse=mean((ari_ma - forecast_s)^2), cor=cor(forecast_s, ari_ma))
}  # end back_test
# Apply the backtesting function
back_test(ari_ma, or_der=5, look_back=100)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Optimal Parameters of the Forecasting Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{backtesting} function can be used to find the optimal \emph{meta-parameters} of the autoregressive forecasting model.
      \vskip1ex
      The accuracy of the forecasting model depends on the order $p$ of the \emph{AR(p)} model and on the length of look-back interval (\texttt{look\_back}).
      \vskip1ex
      The two \emph{meta-parameters} can be chosen by minimizing the \emph{MSE} of the model forecasts in a \emph{backtest} simulation.
      <<echo=TRUE,eval=FALSE>>=
look_backs <- seq(20, 200, 20)
back_tests <- sapply(look_backs, back_test, 
              ari_ma=ari_ma, or_der=or_der)
back_tests <- t(back_tests)
rownames(back_tests) <- look_backs
# Plot forecasting series with legend
plot(x=look_backs, y=back_tests[, 1], 
  xlab="look-back", ylab="MSE", type="l", lwd=2,
  main="MSE of AR(5) Forecasting Model")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth]{figure/ar_forecast_mse.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Ornstein-Uhlenbeck Process}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In the \emph{Ornstein-Uhlenbeck} process, the returns $r_i$ are proportional to the difference between the equilibrium price $\mu$ minus the current price $p_i$:
      \begin{displaymath}
        r_i = p_i - p_{i-1} = \theta \, (\mu - p_{i-1}) + \sigma \, \xi_i
      \end{displaymath}
      Where the parameter $\theta$ is the strength of mean reversion, $\sigma$ is the volatility, and $\xi_i$ are random normal \emph{innovations} with zero mean and unit variance.
      \vskip1ex
      The \emph{Ornstein-Uhlenbeck} process for prices can be written as an \emph{AR(1)} process plus a drift:
      \begin{displaymath}
        p_i = \theta \, \mu + (1 - \theta ) \, p_{i-1} + \sigma \, \xi_i
      \end{displaymath}
      The \emph{Ornstein-Uhlenbeck} process cannot be simulated using the function \texttt{filter()} because of the drift term in its equation, and must be simulated using loops.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define Ornstein-Uhlenbeck parameters
eq_price <- 1.0; sigma_r <- 0.02
the_ta <- 0.01; n_rows <- 1000
drif_t <- the_ta*eq_price
theta_1 <- 1-the_ta
# Simulate Ornstein-Uhlenbeck process
in_nov <- sigma_r*rnorm(n_rows)
price_s <- numeric(n_rows)
price_s[1] <- in_nov[1]
for (i in 2:n_rows) {
  price_s[i] <- theta_1*price_s[i-1] + in_nov[i] + drif_t
}  # end for
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Solution of the Ornstein-Uhlenbeck Process}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Ornstein-Uhlenbeck} process in continuous time is:
      \begin{displaymath}
        \mathrm{d} p_t = \theta \, (\mu - p_t) \, \mathrm{d} t + \sigma \, \mathrm{d} W_t
      \end{displaymath}
      Where $W_t$ is a \emph{Wiener process}, with $\mathrm{d} W_t$ following the standard normal distribution $\phi(0, \sqrt{\mathrm{d}t})$.
      \vskip1ex
      The solution of the \emph{Ornstein-Uhlenbeck} process is given by:
      \begin{displaymath}
        p_t = p_0 e^{-\theta t} + \mu (1 - e^{-\theta t}) + \sigma \int_{0}^{t} {e^{\theta (s - t)} \mathrm{d} W_s}
      \end{displaymath}
      \vskip1ex
      The mean and variance are given by:\\
      $\mathbb{E}[p_t] = p_0 e^{-\theta t} + \mu (1 - e^{-\theta t}) \rightarrow \mu$ \\
      $\mathbb{E}[(p_t - \mathbb{E}[p_t])^2] = \frac{\sigma^2}{2 \theta} (1 - e^{-\theta t}) \rightarrow \frac{\sigma^2}{2 \theta}$
      \vskip1ex
      The \emph{Ornstein-Uhlenbeck} process is mean reverting to a non-zero equilibrium price $\mu$.
      \vskip1ex
      The \emph{Ornstein-Uhlenbeck} process needs a \emph{warmup period} before it reaches equilibrium.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ou_proc.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
plot(price_s, type="l",
     xlab="time", ylab="prices",
     main="Ornstein-Uhlenbeck Process")
legend("topright",
       title=paste(c(paste0("sigma_r = ", sigma_r),
                     paste0("eq_price = ", eq_price),
                     paste0("the_ta = ", the_ta)),
                   collapse="\n"),
       legend="", cex=0.8, inset=0.1, bg="white", bty="n")
abline(h=eq_price, col='red', lwd=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Ornstein-Uhlenbeck Process Returns Correlation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Under the \emph{Ornstein-Uhlenbeck} process, the returns are negatively correlated to the lagged prices.
      <<echo=TRUE,eval=FALSE>>=
re_turns <- rutils::diff_it(price_s)
lag_prices <- rutils::lag_it(price_s)
for_mula <- re_turns ~ lag_prices
l_m <- lm(for_mula)
summary(l_m)
# Plot regression
plot(for_mula, main="OU Returns Versus Lagged Prices")
abline(l_m, lwd=2, col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ou_scatter.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Calibrating the Ornstein-Uhlenbeck Parameters}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The volatility parameter of the Ornstein-Uhlenbeck process can be estimated directly from the standard deviation of the returns.
      \vskip1ex
      The $\theta$ and $\mu$ parameters can be estimated from the linear regression of the returns versus the lagged prices.
      \vskip1ex
      Calculating regression parameters directly from formulas has the advantage of much faster calculations.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate volatility parameter
c(volatility=sigma_r, estimate=sd(re_turns))
# Extract OU parameters from regression
co_eff <- summary(l_m)$coefficients
# Calculate regression alpha and beta directly
be_ta <- cov(re_turns, lag_prices)/var(lag_prices)
al_pha <- (mean(re_turns) - be_ta*mean(lag_prices))
cbind(direct=c(alpha=al_pha, beta=be_ta), lm=co_eff[, 1])
all.equal(c(alpha=al_pha, beta=be_ta), co_eff[, 1],
          check.attributes=FALSE)
# Calculate regression standard errors directly
beta_s <- c(alpha=al_pha, beta=be_ta)
fit_ted <- (al_pha + be_ta*lag_prices)
residual_s <- (re_turns - fit_ted)
prices_squared <- sum((lag_prices - mean(lag_prices))^2)
beta_sd <- sqrt(sum(residual_s^2)/prices_squared/(n_rows-2))
alpha_sd <- sqrt(sum(residual_s^2)/(n_rows-2)*(1/n_rows + mean(lag_prices)^2/prices_squared))
cbind(direct=c(alpha_sd=alpha_sd, beta_sd=beta_sd), lm=co_eff[, 2])
all.equal(c(alpha_sd=alpha_sd, beta_sd=beta_sd), co_eff[, 2],
          check.attributes=FALSE)
# Compare mean reversion parameter theta
c(theta=(-the_ta), round(co_eff[2, ], 3))
# Compare equilibrium price mu
c(eq_price=eq_price, estimate=-co_eff[1, 1]/co_eff[2, 1])
# Compare actual and estimated parameters
co_eff <- cbind(c(the_ta*eq_price, -the_ta), co_eff[, 1:2])
rownames(co_eff) <- c("drift", "theta")
colnames(co_eff)[1] <- "actual"
round(co_eff, 4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Schwartz Process}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Ornstein-Uhlenbeck} time series can have negative values, while prices are usually not negative.
      \vskip1ex
      The \emph{Schwartz} process is similar to the \emph{Ornstein-Uhlenbeck} process, but it avoids negative prices by using the percentage returns $\mathrm{d} \log{p}$ instead of the simple returns $\mathrm{d} p$:
      \begin{displaymath}
        r_i = \log{p_i} - \log{p_{i-1}} = \theta \, (\mu - p_{i-1}) + \sigma \, \xi_i
      \end{displaymath}
      Where the parameter $\theta$ is the strength of mean reversion, $\sigma$ is the volatility, and $\xi_i$ are random normal \emph{innovations} with zero mean and unit variance.
      <<echo=TRUE,eval=FALSE>>=
# Simulate Schwartz process
re_turns <- numeric(n_rows)
price_s <- numeric(n_rows)
price_s[1] <- eq_price
set.seed(1121)  # Reset random numbers
for (i in 2:n_rows) {
  re_turns[i] <- the_ta*(eq_price - price_s[i-1]) + sigma_r*rnorm(1)
  price_s[i] <- price_s[i-1] * exp(re_turns[i])
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ou_schwartz.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
plot(price_s, type="l", xlab="time", ylab="prices",
     main="Schwartz Process")
legend("topright",
       title=paste(c(paste0("sigma_r = ", sigma_r),
                     paste0("eq_price = ", eq_price),
                     paste0("the_ta = ", the_ta)),
                   collapse="\n"),
       legend="", cex=0.8, inset=0.12, bg="white", bty="n")
abline(h=eq_price, col='red', lwd=2)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\secname}
\vspace{-1em}
\begin{block}{Required}
  \begin{itemize}[]
    \item Study all the lecture slides in \emph{FRE7241\_Lecture\_4.pdf}, and run all the code in \emph{FRE7241\_Lecture\_4.R}
  \end{itemize}
\end{block}
\begin{block}{Recommended}
  \begin{itemize}[]
    \item Download from NYU Classes and read about momentum strategies:\\
    \emph{Moskowitz Time Series Momentum.pdf}\\
    \emph{Bouchaud Momentum Mean Reversion Equity Returns.pdf}\\
    \emph{Hurst Pedersen AQR Momentum Evidence.pdf}
  \end{itemize}
\end{block}

\end{frame}


\end{document}
