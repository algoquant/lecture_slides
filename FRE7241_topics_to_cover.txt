### FRE-7241 Algorithmic Portfolio Management
FRE-GY 7241

GA is Zhenyu (Lucy) Yin \href{zy944@nyu.edu}{zy944@nyu.edu}
Rogers Hall room 705

# potential GAs
Gaurav Sharma <gaurav.sharma@nyu.edu>
Xiang Li <xiang.l@nyu.edu>

# former GAs
Haoran Su hs3265@nyu.edu
Shu Ye shu.ye@nyu.edu
Jaimin Doshi jbd316@nyu.edu
Luping Liu	ll2525@nyu.edu
Dong Huang dh1716@nyu.edu

# Song Tang C++ courses
FRE-GY 6883 Financial Computing
FRE-GY 7831 Financial Analytics & Big Data

# Asha Matthei teaches FRE7801 Quantitative Trading Strategies at NYU Tandon
https://www.linkedin.com/in/ashapaulmatthei

# contribute to Quantitative Finance Collector by Biao Guo Assistant Professor, School of Finance, Renmin University, China
http://www.mathfinance.cn/

http://getprismatic.com/hedge-funds

# request for sample textbooks
I'm an adjunct at NYU Tandon, where I teach graduate courses in applications of R in Finance, and Algorithmic Portfolio Management Using R.  

# Some students have asked me if I would be willing to supervise their projects

# find out more about the Student Response System - for live in-class polling
http://engineering.nyu.edu/academics/support/fitl/srs

# Below is a link to Google Drive with my lecture files: 
https://drive.google.com/drive/u/0/folders/0Bxzva1I0t63vVGEtaXNIY1JMa00
The .pdf files contain the narration text, formulas, and R code. Most slides have narration and formulas on the left panel, and the corresponding R code on the right panel.
There are two types of .pdf files.  First, there are thematic files, containing slides on certain topics.  For example you can take a look at portfolio_construction.pdf.  Second, there are lecture files, containing slides for specific lectures.  I create .pdf lecture files by selecting slides from thematic files.  I created the .pdf files from .Rnw Sweave files using the knitr package.

I also provide .R files containing the code, so that students can execute the code as they listen to the lecture. The lecture materials also contain .RData files with sample data. 
I welcome your comments.

For FRE-7241 Algorithmic Portfolio Management I need a grader.  The GA's responsibilities will be grading and answering student questions during office hours.
Preference is for student who has already taken FRE-7241 or FRE-6871, or who has strong R programming skills.

###############

Beixi, please see my answers below.

1. How do people in Wall Street decide the fair price of an Option, do they calculate them using the BS model and implied volatility provided by VIX?

Market prices of vanilla options (calls and puts) are determined in the exchange markets by supply and demand, not by any models.  The market prices of vanilla options are input into volatility models to calibrate implied volatility surfaces and skews.  The prices of exotic options are calculated from the implied volatility surfaces and skews.  Exotic options are usually traded over-the-counter, and their actual traded prices are negotiated between the dealers (banks) and investors.

2. Does the VIX represent the expected future vol? Can it represent the future risk?

No, the VIX doesn't represent the expected future realized volatility.  The VIX index is calculated from the implied volatilities.  VIX futures are contracts on the future value of the VIX index.  Most research that I have read claims that the implied volatility is typically higher than the future realized volatility.  So there's a risk premium associated with volatility.

3.If I have a VIX data and use them to calculate option price under BS model, and then I construct a strategy which trade on these option with the option price I derived from VIX and BS model, in the end, if I use the garch model on my strategy return, I can also have a time series of historical vol of my strategy. Here is my question, I have VIX representing future vol and garch vol representing realized vol, how can I test that the VIX I use is a good or bad predictor of realized vol? Do you know any test that can test the accuracy of VIX? Since the only idea I have is just using the linear regression and see if the R square is large or not.

I don't understand the volatility strategy that you describe.  The VIX index is calculated as an average of many implied volatilities at different strikes, so there's no way to reliably calculate a single option price from the VIX index.  You can use a GARCH model to forecast the volatility of your strategy, but I don't see how that would be related to the VIX index.




###############
# Syllabus:

1.	Time series analysis and ARIMA models,
2.	Moment estimation: range OHLC estimators of volatility, skewness, kurtosis, and covariance, 
3.	GARCH models and volatility forecasting, 
4.	Models of stock returns: Pareto distribution, stochastic volatility, Heston model, 
5.	Tail risk measures: value-at-risk, conditional value-at-risk, 
6.	Logarithmic utility and risk-adjusted performance measures: Sharpe, Calmar, and Sortino ratios, 
7.	Capital Asset Pricing Model (CAPM): the market portfolio, the Security Market Line, 
8.	Beta-adjusted performance measures: Treynor ratio, Jensen's alpha, information coefficient, 
9.	Factor models: Principal Component Analysis, cross-sectional regressions, Fama-French model, Barra model, 
10.	Pricing anomalies: size, value, momentum, volatility, 
11.	Forecasting models for price returns, stock beta, and correlation, 
12.	Portfolio optimization: mean-variance efficient portfolios, efficient frontier, Capital Market Line, 
13.	Correlation matrix estimation: Cholesky decomposition, Factor Augmented Regression, 
14.	Constrained portfolio optimization: coefficient shrinkage, 
15.	Static asset allocation strategies: cap-weighted and equal-weighted stock indices, all weather portfolios, 
16.	Portfolio management strategies: risk parity, minimum correlation, minimum variance, maximum Sharpe, maximum CVaR, betting against beta, factor investing, smart beta asset allocation, 
17.	Active portfolio management strategies: tactical asset allocation, portfolio rebalancing, Constant Proportion Portfolio Insurance (CPPI), sector rotation, 
18.	Benchmarking portfolio management skill: performance attribution, random portfolios, random investment choices, 
19.	Dynamic investment and consumption strategies: Merton model, 
20.	Performing rolling aggregations and regressions, bias-variance tradeoff, 
21.	Intertemporal portfolio choice and out-of-sample performance of optimized portfolios, 
22.	Strategy backtesting and optimization: data snooping, cross-validation, model overfitting, parameter regularization, 

## extract R chunks into .R file

# loop to extract R chunks in: C:/Develop/render_scripts.R
# without loop:
library(knitr)
knitr::purl('C:/Develop/R/lecture_slides/data_structures.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/dates_time_series.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/expressions.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/functions.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/investment_strategies.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/numerical_analysis.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/packages.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/plotting.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/portfolio_construction.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/statistics.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/R_environment.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/risk_models.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/time_series_multivariate.Rnw', documentation=0)
purl('C:/Develop/R/lecture_slides/time_series_univariate.Rnw', documentation=0)



###############
### to-do list

what you will learn:
how to apply R to systematic investment strategies
how to use R to create your own systematic investment strategies
how to measure the performance of investment strategies and managers

what you will NOT learn:
what are the best systematic investment strategies
which strategies are recommended

what you will learn:
how difficult it is to create successful systematic investment strategies


topics:
different asset allocation functions (rules)
p-hacking increases with portfolio size: back-test will always find profitable strategy out of the many allocation functions rules
divide data in two: in-sample performance increases but out-of-sample performance decreases
simulating Brownian motion
optimization
regression
CAPM market timing

+ [ ] Explain trading rule heuristics: 
Avoid making binary decisions (buy/not buy), and instead make incremental decisions (buy a little/buy some more/buy even more/...)
Use many different models and rules in parallel, and allocate small amounts of risk to each.
Avoid fitting models with many parameters.
Use rank (order) or count statistics instead of parametric models (like linear regression).

+ [ ] Explain that proper position sizing is as important as having a profitable strategy with a high probability (odds) of winning
Provide an estimate of the statistical edge (odds of winners versus losers) of systematic strategies in practice: best strategies have odds of just a few percent above even odds.
Explain that you can go bankrupt even with a winning (skilled) strategy. 
Calculate the probability of going bankrupt as a function of the strategy odds of winners versus losers.

+ [ ] Adapt from: Matloff book Statistical Modeling.pdf
http://heather.cs.ucdavis.edu/~matloff/132/PLN/probstatbook/ProbStatBook.pdf

+ [ ] Adapt from: Matloff Regression Analysis.pdf

+ [ ] Adapt from: Matloff Regression Classification.pdf

+ [ ] Explain different ways of combining trending and reverting strategies: using simple sum or by biasing the reverting strategy, depending on the direction of the trending strategy

+ [ ] Add dygraphs annotations: vertical lines for technical indicators
http://dygraphs.com/options.html
https://github.com/danvk/dygraphs/issues/889
http://dygraphs.com/tests/hairlines.html
https://stackoverflow.com/questions/7353539/dygraph-vertical-line

+ [ ] Explain that given many signals from an ensemble of models, it's better to first calculate the positions and then to average the positions, instead of averaging the signals and calculating a single positions vector
Averaging the positions reduces the binary risk.

+ [ ] combine the data from files sp500.RData sp500_2017.RData sp500_recent.RData

+ [ ] Demonstrate that in a mean-reversion strategy, if the look-back is longer then the signal is more normal so the threshold should be lower
Calculate the moments of the signal as a function of the look-back.

+ [ ] Use strategy objective function which isn't sensitive to small number of winners 
Remove the largest winners from strategy returns before calculating the performance.
Define objective function equal to Sharpe divided by number of trades.

+ [ ] in risk_models.Rnw update all the slides from section:
Package PerformanceAnalytics for Risk and Return Analysis
Remove/replace dependencies on PerformanceAnalytics.

+ [ ] Study different asset allocation functions (rules)
Modify function back_test() so it accepts an asset allocation function ?
Create asset allocation function which takes a permutation of recent returns to calculate weights.
That way every permutation corresponds to a different strategy.
Demonstrate that there's always one asset allocation function that is profitable in a back-test.
Demonstrate that the profitability grows with the number of assets.

+ [ ] Analyze function efficient.portfolio() in Zivot Efficient Portfolios in R.pdf  

+ [ ] update and expand slide The Efficient Frontier and Capital Market Line in portfolio_construction ?
Zivot Efficient Portfolios in R.pdf

+ [ ] Explain that portfolio managers have two types of skill:
Portfolio selection (stock-picking) skill
Market timing skill
Market timing skill is the ability to adjust the portfolio market beta by correctly forecasting future market returns.
Market timing is the act of moving in and out of the market or switching between asset classes based on using predictive methods such as technical indicators or economic data. 

+ [ ] Create backtest of EWMA strategy for single asset
calculate standard error of optimal EWMA strategy parameters
calculate standard errors of optimal EWMA strategy parameters
Create strategy with two EWMAs, and demonstrate that it performs better in-sample, but worse out-of-sample
Create strategy with multiple EWMAs, and demonstrate that they performs better in-sample, but worse out-of-sample
Demonstrate that applying shrinkage to EWMA coefficients improves out-of-sample performance
Perform backtest to find optimal shrinkage parameter

Investment strategies for multiple assets.
Momentum strategy for S&P500 stock portfolio.
Portfolio optimization for multiple assets

+ [ ] introduce univariate regression
perform regression of future cumulative returns from past cumulative returns
demonstrate that regression works better over longer period of future cumulative returns
introduce multivariate regression 
introduce ARIMA as regression
rolling regression in RcppArmadillo 

+ [ ] Demonstrate that a model with more parameters has bigger parameter standard errors than one with fewer parameters, when both models are calibrated on the same data
Is this a manifestation of conservation of entropy: the information in the parameters cannot exceed the information in the data?
Is this a manifestation of the Cramer-Rao bound and Fisher information?
Demonstrate that calibrating a model with more parameters requires more data, to achieve the same parameter standard errors. 
Demonstrate that parameter shrinkage reduces the standard errors, but increases the model bias (bias-variance tradeoff).
DeMiguel Shrinkage Estimators Portfolio Optimization draft.pdf

+ [ ] Perform simulation to demonstrate that shrinkage reduces estimator variance and standard error, even though it increases its bias
Stein's paradox: Yung Shrinkage Estimators Stein's Paradox
beta shrinkage estimator
http://eranraviv.com/blog/a-shrinkage-estimator-for-beta/

+ [ ] Study effect of shrinkage term in the form sqrt(abs())

+ [ ] rework backtesting to use roll_agg() (slide #33 titled Functional for Aggregating Asset Returns) from the start - skip looping over look_backs list
First pre-calculate matrix of EWMA returns (called re_turns) for a vector of lambda decay parameters, using parallel computing.
Use slide Performance of EWMA Strategies.
Then apply roll_agg() to perform loop and calculate aggregations over endpoints.
Get rid of calc_sharpe() and look_backs list.
Apply to ETF returns rutils::env_etf$re_turns.

+ [ ] rework backtesting: in roll_agg() call FUN() and then perform a look_backs loop over the output of FUN(), instead of a look_backs loop over the oh_lc input of FUN(). 
Get rid of the agg_regate() function. 
roll_agg() should perform two loops: 
first, a loop over lamb_das, to run the model function with multiple lamb_da parameters, output is time series of returns, 
second, a look_backs loop over the time series of returns, output is matrix of performance statistics (Sharpe ratios), 
roll_agg() should accept the arguments: x_ts, look_backs, FUN, lamb_das, ...
further improvement: instead of performing sapply() loop over the time series of returns, perform vectorized operation.
roll_agg() should return an time series of performance statistics (Sharpe ratios).

+ [ ] Create backtesting: at each endpoint rebalance, run models over expanding window, select optimal lamb_da, don't loop over lamb_das 

+ [ ] vectorize simu_ewma() with respect to its lamb_da parameter ?

+ [ ] rewrite the Backtesting Framework using exclusively vectorized functions:
introduce improved out-of-sample data notation using period_s
is "periods" needed?
risk_ret_stats() should perform lapply() and return list
split and rename pnl_period()
etf_reg_stats is not defined anywhere in "investment_strategies"
	load it from "time_series_multivariate"


+ [ ] Deprecate slides in investment_strategies.Rnw
deprecate calc_sharpe() on slide Aggregation Function for EWMA Model
deprecate slide Performing Overlapping Aggregations
deprecate roll_agg() on slide Functional for Performing Overlapping Aggregations

+ [ ] move slides in investment_strategies.Rnw
Move slides from Backtesting Active Investment Strategies to Active Investment Strategies:
Performance of EWMA Strategies
Simulating EWMA Strategies Using Parallel Computing

+ [ ] rewrite simu_ewma() in Rcpp ?

+ [ ] Modify simu_ewma() to catch error when oh_lc is shorter than look_back
add warmup period?

+ [ ] Modify slide "Rolling Weighted Aggregations Using Package RcppRoll" in risk_models, and add function filter()

+ [ ] compare speed of filter() with RcppRoll::roll_mean()

+ [ ] replace: sapply(re_turns, mean) with colMeans(re_turns) and microbenchmark the two

+ [ ] Add slide to risk_models: describing in-sample and out-of-sample aggregations
after slide Performing Aggregations Over Overlapping Intervals

+ [ ] Add Rcpp slide for calculating weighted rolling sum in numerical_analysis.Rnw based on roll_wsum.R from HighFreq

+ [ ] Create Rcpp code example from chapter 15.1.2: Matloff book The Art of R Programming
Modify slide about EWMA Realized Variance Estimator.
Exponentially Weighted Volatility using RCPP
http://adv-r.had.co.nz/Rcpp.html
http://systematicinvestor.github.io/Exponentially-Weighted-Volatility-RCPP
use RcppEigen or RcppArmadillo?
http://dirk.eddelbuettel.com/code/rcpp.eigen.html
https://stackoverflow.com/questions/22110075/r-use-primitive-functions-like-max-sum-in-rcpp
https://stackoverflow.com/questions/27490659/rcppeigen-going-from-inline-to-a-cpp-function-in-a-package-and-map


+ [ ] Demonstrate that investing in the rolling optimal portfolio is a trend-following strategy  

+ [ ] Explain difference between cross-sectional momentum and time-series momentum (trend-following)
http://blog.alphaarchitect.com/2017/04/17/does-market-sentiment-help-explain-momentum/
trend-following is trading single asset using many predictors.
momentum is trading several assets by sorting them using many predictors.

+ [ ] Explain difference between trend-following and momentum strategies
create simple trend-following and momentum strategies
Lewellen: momentum is cross-sectional ranking, meaning winners outperform losers
Autocorrelation is longitudinal ranking, meaning past performance will continue
Is it possible to have zero autocorrelation, but non-zero momentum?

+ [ ] Explain why momentum strategy works, even when trend-following doesn't work
demonstrate that trend-following is very hard to trade, but cross-sectional momentum is easier, because it isolates effect of market beta
create model of several time series, where each time series is random, but differences between them are autocorrelated
There's no autocorrelation of returns, but there's autocorrelation of rank statistics.
study Lewellen: momentum is cross-sectional ranking, meaning winners outperform losers
Autocorrelation is longitudinal ranking, meaning past performance will continue
How is it possible to have zero autocorrelation, but non-zero momentum?

+ [ ] reproduce time series momentum smile
Moskowitz Time Series Momentum.pdf
Hurst Pedersen AQR Momentum Evidence.pdf

+ [ ] can a momentum strategy based on ranking work even if trend-following doesn't work?

+ [ ] Read Jonathan Kinlay articles on linkedin

+ [ ] Explain that strategies that have both positive returns and positive skewness are genuine market anomalies
Strategies with positive returns usually also have negative skewness, and they have the characteristics of short option strategies.

+ [ ] Create slides from homework ?
Calculate autocorrelations and partial autocorrelations by hand.

+ [ ] improve slides:
Stationary Processes and Their Characteristic Equations
Integrated and Unit-root Processes

+ [ ] Perform portfolio optimization by hand using matrix algebra, SVD, Cholesky
Use matrix pseudo-inverse of covariance if inverse doesn't exist ?
Pav Markowitz Portfolio Distribution.pdf
Pantaleo Portfolio Optimization Pseudoinverse Matrix.pdf
Lee Portfolio Optimization Pseudoinverse Matrix.pdf
Pollak Portfolio Optimization Pseudoinverse Matrix.pdf
http://www.win-vector.com/blog/2010/01/easy-portfolio-allocation/

+ [ ] Calculate confidence interval of Sharpe ratio using bootstrap
Demonstrate that the Sharpe ratio confidence intervals are so wide, that it's hard to distinguish between assets with large Sharpe ratios from those with small Sharpe ratios.
Demonstrate that a very long time series is needed in order determine if the Sharpe ratios of two assets are different from each other.
So ranking assets on their trailing Sharpe ratios makes little sense ?
Use SharpeR package by Steven Pav, and also bootstrap. 
Sharpe ratio as Hotelling's t-squared distribution.  
https://github.com/shabbychef  
Pav Sharpe Ratio Notes Hotelling Statistic.pdf  
SharpeR Vignette.pdf  

+ [ ] SharpeR and MarkowitzR packages by Steven Pav  
finding optimal portfolio in-sample is the same as finding optimal strategy in-sample - both are over-fit and require shrinkage  
Sharpe ratio as Hotelling's t-squared distribution  
https://github.com/shabbychef  
Pav Sharpe Ratio Notes Hotelling Statistic.pdf  
Pav Strategy Overfit.pdf  
SharpeR Vignette.pdf  
Pav Portfolio Optimization.pdf  
Pav Markowitz Portfolio Signal Noise Ratio.pdf  
Pav Markowitz Portfolio Optimization Distribution.pdf  
MarkowitzR Vignette.pdf  
MarkowitzR AsymptoticMarkowitz.pdf  
Britten-Jones Efficient Portfolio Parameter Uncertainty.pdf
Simaan Efficient Portfolio Parameter Uncertainty.pdf

+ [ ] Adapt from package fromo: Fast Robust Moments in R with Rcpp
https://github.com/shabbychef/fromo

+ [ ] Adapt from package andrewuhl/RollingWindow

+ [ ] Create asset price model equal to sum of trending component plus mean-reverting component
Calibrate model using maximum log-likelihood estimation similar to package egcm.
Study the out-of-sample model performance.

+ [ ] Adapt from Brian Reich lectures with R code for statistics, optimization, LASSO regression, SVD, PCA, Kalman filter, machine learning
http://www4.stat.ncsu.edu/~reich/BigData/code/

+ [ ] Adapt from Farrell: logistic regression, Vector Auto-Regression (VAR),
Farrell week10-slides.pdf

+ [ ] Adapt from: Top 10 Machine Learning Algorithms
https://www.kdnuggets.com/2017/10/top-10-machine-learning-algorithms-beginners.html

+ [ ] Adapt from WRDS classroom tools and syllabus topics  
https://wrds-web.wharton.upenn.edu/wrds/classroom/
https://wrds-web.wharton.upenn.edu/wrds/classroom/investments.cfm

+ [ ] Adapt from OTIS Wharton Online Trading & Investment Simulator
https://wrds-otis.wharton.upenn.edu/otis/

+ [ ] Create shiny with shaded dygraphs and toggle shading on and off  

+ [ ] get data from: 
https://www.alphavantage.co/

+ [ ] Adapt from: Simaam Efficient Portfolio Parameter Uncertainty.pdf
https://www.linkedin.com/pulse/2-dynamic-asset-allocation-sector-etfs-majeed-simaan/
https://www.linkedin.com/pulse/asset-allocation-sector-etfs-empirical-perspective-error-simaan/
http://homepages.rpi.edu/~simaam/R.html
https://quantstats.shinyapps.io/yahoo/
Simaam Dynamic Asset Allocation Sector ETF.R
Simaam Asset Allocation Sector ETF.R

+ [ ] Adapt from: Simaam Financial Time Series Using R.pdf
Simaam Financial Time Series Using R.R

+ [ ] replace calls to quantmod::getSymbols() with get_symbols() ?

+ [ ] Adapt portfolio optimization from: 
Trapletti finance.R
Ian Kaplan etf_opt.R

+ [ ] Adapt linear programming example from Saldanha Linear Programming.pdf

+ [ ] Adapt from: Bloch ebook Quantitative Portfolio Management.pdf

+ [ ] Adapt from: Simaan Efficient Portfolio Parameter Uncertainty.pdf

+ [ ] Adapt from: 
http://gekkoquant.com/2012/08/29/parameter-optimisation-backtesting-part1/
http://gekkoquant.com/2012/08/29/parameter-optimisation-backtesting-part-2/

+ [ ] Explain that the shape of the efficient frontier depends on the weight constraints
Plot efficient frontier with two different weight constraints (scaling): sum and sum of squares.

+ [ ] Demonstrate that the efficient frontier is close to a parabola for small standard deviations, and close to a straight line for large standard deviations  
Explain why for small standard deviations, the efficient portfolio returns are proportional to the square root of their standard deviations (for different risk free rates).
Explain why for large standard deviations, the efficient portfolio returns are proportional to their standard deviations (for different risk free rates).
hint: study the efficient portfolio weights and the portfolio leverage.

+ [ ] Demonstrate that any convex combination of efficient frontier portfolios is also an efficient frontier portfolio  
This is known as the portfolio separation theorem (two fund separation theorem).
https://en.wikipedia.org/wiki/Mutual_fund_separation_theorem
http://www.bearcave.com/finance/long_short_cvar.html
Any efficient portfolio can be expressed as a combination of two other efficient funds (efficient portfolios). 
The efficient frontier consists of convex combinations of any two efficient frontier portfolios.  
The variance of a frontier portfolio is equal to the variance of the minimum variance portfolio plus the square of its return minus the return of the minimum variance portfolio.  
Brunnermeier CAPM Model: slide #53 Deriving the Frontier
CAPM Asset Pricing.pdf
Merton Efficient Frontier Portfolio.pdf

+ [ ] Adapt CAPM, portfolio optimization, and bootstrapping efficient frontier from: C:\Research\R\Tutorials\Zivot\Econ 424 files:
bootstrapPortfoliosPowerpoint.pdf
bootstrapPortfolio.R
portfolio_noshorts.R
demonstrate that the standard error of the means is much bigger than that of the standard deviations.
demonstrate that the standard error of the means is of the same order as the means themselves.
demonstrate that the standard error of the standard deviations is one order less than the standard deviations themselves.

+ [ ] Create function similar to PerformanceAnalytics function create.Efficient.Frontier()

+ [ ] Create portfolio functions:  
Compute global minimum variance portfolio
Compute minimum variance portfolio with target return
Compute tangency portfolio
Compute and plot efficient frontier
Zivot portfolio.r from econ424 - using covariance matrices  
http://faculty.washington.edu/ezivot/econ424/portfolio.r  

+ [ ] Add resource: Schmidt High Performance R Computing.pdf

+ [ ] Explain the difference and consequences between using the correlations of simple returns versus correlations of percentage returns

+ [ ] Adapt from:
https://rviews.rstudio.com/2017/07/21/visualizing-portfolio-volatility/
https://rviews.rstudio.com/2017/07/18/introduction-to-rolling-volatility/
https://rviews.rstudio.com/2017/07/12/introduction-to-volatility/

+ [ ] Expectation Maximization algorithm
Zafeiriou Expectation Maximization Algorithm.pdf
http://gallery.rcpp.org/articles/EM-algorithm-example/

+ [ ] Add to recommended books: Efron book Computer Age Statistical Inference?
https://web.stanford.edu/~hastie/CASI/

+ [ ] get trial for Techila
https://console.cloud.google.com/launcher/details/techila-public/techila
http://www.techilatechnologies.com/help/techila-distributed-computing-engine/r-techila-distributed-computing-engine.html

+ [ ] Explore: 
https://www.portfoliovisualizer.com/
https://www.portfoliovisualizer.com/examples
https://www.portfoliovisualizer.com/rolling-optimization

+ [ ] Adapt from package parma Portfolio Optimization: parma Vignette.pdf

+ [ ] Always use expanding look-backs, otherwise model may not have enough data  

+ [ ] Adapt optimization code for models and portfolios from package NMOF
http://enricoschumann.net/NMOF.htm
http://enricoschumann.net/files/NMOFman.pdf
Schumann NMOF Financial Optimisation.pdf
NMOF Financial Optimisation.pdf
NMOF Vectorised Objective Functions.pdf
C:\Users\Jerzy\Documents\R\win-library\3.3\NMOF\book\C-PortfolioOptimization\R
C:\Users\Jerzy\Documents\R\win-library\3.3\NMOF\book\C-EconometricModels\R

+ [ ] Analyze package caret to see if it performs loops in R or in C++
https://github.com/topepo/caret

+ [ ] Adapt from book R for Data Science

+ [ ] Pkg fImport
yahooBriefing("AAPL")
yahooBriefing

+ [ ] Deprecate file: "quantmod examples.R" in C:\Develop\R\scripts
mostly already extracted, except for last example

+ [ ] what is this?
source(file="C:/Develop/R/scripts/vis_portf.R")

+ [ ] Topic: simulate Parrondo games

+ [ ] coursera R Data Science Specialization Certificate
https://www.coursera.org/specialization/jhudatascience/1?utm_medium=sem&utm_source=gg&utm_campaign=spn_dss

+ [ ] Read: Sornette Power Law Tail Risk.pdf

+ [x] Add SVXY ETF to the ETF Dataset

+ [x] Create new file called data_management.Rnw, with thematic slides
Move slides about downloading data from time_series_univariate.Rnw
Move slides about Data Input and Output from R_environment.Rnw

+ [x] Calculate the efficient frontier portfolios as a convex combination of any two efficient portfolios  
Select the market portfolio as one portfolio and a portfolio with the maximum expected return as the other portfolio. 
Alternatively, select the minimum variance portfolio as one portfolio and a portfolio with the maximum expected return as the other portfolio. 

+ [x] Explain the benefits of performing a back-test 
Performing a back-test allows finding the optimal trading model parameters.
But the back-test just redefines the problem of finding (tuning) the optimal trading model parameters, into the problem of finding the optimal back-test meta-model parameters.
But the advantage of using the back-test meta-model is that it reduces the number of parameters that need to be optimized.
But the benefit of a dynamic quant strategy is that is has fewer meta-parameters than the number of portfolio weights, and the performance is less critical on the exact knowledge of those meta-parameters.
There are two models in a back-test: the trading model and the back-test (the meta-model).
For example, a momentum trading model has the following parameters: the length of the look-back interval, the lambda decay, and the asset allocation function (rule). 
The back-test meta-model has the following parameters: the bid-offer spread, and the rebalancing frequency.
The parameters of the back-test meta-model are the meta-parameters.
In the case of EWMA, the model has only one parameter (the lambda), and the meta-model has two parameters (look-back interval and rebalancing period) and a rebalancing function (rule).

+ [x] Flip ETF momentum strategy to a mean-reverting model - doesn't produce positive returns

+ [x] Demonstrate that momentum strategy is able to time the market: the beta changes ahead of market moves
Market timing is the act of moving in and out of the market or switching between asset classes based on using predictive methods such as technical indicators or economic data. 
https://www.rdocumentation.org/packages/PerformanceAnalytics/versions/1.4.3541/topics/MarketTiming
Wermers Market Timing.pdf
Henriksson Market Timing.pdf

+ [x] Add transaction costs to simu_ewma()

+ [x] Add Alpha Vantage as main data provider in time_series_univariate.Rnw

+ [x] change to 252 business days, instead of 260

+ [x] Add files to NYU Classes:
Storn Differential Evolution.pdf
DEoptim.pdf
DEoptim Introduction.pdf
DEoptim Portfolio Optimization.pdf

+ [x] rename the look_back parameter used for calculating weight_s, to wid_th
To avoid confusing it with other aggregation look-back parameters

+ [x] change inner_prod=(t(re_turns) %*% re_turns) to cross_prod=crossprod(re_turns)

+ [x] Fix calls to filter(): use rev() to reverse the order of weight_s so that most recent observation have biggest weight

+ [x] change endpoints calculation: define look_backs as a list of numeric vectors
Calculate aggregations using lapply() loop over the look_backs, instead of sapply()

+ [x] change endpoints calculation to without the extra 0 at the beginning

+ [x] Create data and script directories
Move data files from C:\Develop\data to C:\Develop\R\lecture_slides\data
Move script files from C:\Develop\R\scripts to C:\Develop\R\lecture_slides\scripts

+ [x] replace "window" with "interval", and "win\_dow" with "inter\_val", and "win_dow" with "inter_val"

+ [x] Create scatterplot of random portfolios using inverse covariance matrix

+ [x] Explain that Capital Market Line represents levered and delevered portfolios  

+ [x] Derive minimum variance weights  
http://www.bearcave.com/finance/portfolio_equations/  

+ [x] rename the look-back window for rolling aggregations from win_dow to look_back.

+ [x] replace xts::.subset_xts() with brackets operator []

+ [x] replace function RcppRoll::roll_mean() with filter()

+ [x] move the section "Performing Aggregations Over Time Series" from time_series_multivariate to risk_models



###############
### topics to add

+ [ ] Explain order types: market, limit, split spread, 
Split spread orders are orders priced within the spread between the bid price and ask price. These orders yield significant price improvement when they fill, and may earn you exchange rebates for adding liquidity.
https://www.interactivebrokers.com/en/index.php?f=26685

+ [ ] Adapt from
https://github.com/PhilGuerra/autotrade

+ [ ] Calculate constant maturity VIX futures - calculate VIX futures term structure from CBOE settlment data.
https://quantstrattrader.wordpress.com/2017/04/27/creating-a-vix-futures-term-structure-in-r-from-official-cboe-settlement-data/

+ [ ] Add package IButils
https://github.com/enricoschumann/IButils
http://enricoschumann.net/R/packages/IButils/index.htm

+ [ ] Add packages qmao and twsInstrument

+ [ ] Adapt intraday momentum strategy
Gao Intraday Momentum Strategy.pdf
https://eranraviv.com/market-intraday-momentum/

+ [ ] Adapt xts Cheat Sheet
https://www.datacamp.com/community/blog/r-xts-cheat-sheet

+ [ ] Adapt from Avellaneda VIX.pdf

+ [ ] Create constant maturity futures prices.
Plot the futures curve over time.
Perform PCA.

+ [ ] Downloading data from Bloomberg: adapt from data_scripts.R

+ [ ] Downloading data from tiingo
https://www.tiingo.com/
http://blog.fosstrading.com/2018/04/goodbye-google-hello-tiingo.html

+ [ ] opening and closing file connections using file() and file.create()

+ [ ] Explain how to simulate limit orders
Explain why limit orders are better than market orders.

+ [ ] Adapt from
https://www.qplum.co/investing-library

+ [ ] Adapt from Kris Longmore Interactive Brokers Introduction to Algorithmic Trading:
https://www.interactivebrokers.com/en/index.php?f=25244&vid=17779
https://www.interactivebrokers.com/en/index.php?f=25244&vid=17799
https://www.interactivebrokers.com/en/index.php?f=25244&vid=17800
https://www.interactivebrokers.com/en/index.php?f=25244
adapted from
https://robotwealth.com/

+ [ ] Adapt Interactive Brokers API script from:
C:\Develop\R\IBrokers\Sherrington IBrokers scripts.pdf
C:\Develop\R\IBrokers\Yadav IBrokers scripts.pdf

+ [ ] Adapt from: 
https://www.datacamp.com/courses/model-a-quantitative-trading-strategy-in-r/

+ [ ] Adapt backtest code from package PMwR
http://enricoschumann.net/R/packages/PMwR/manual/PMwR.html
Schumann package Portfolio Management with R.pdf
Schumann package Portfolio Management with R.html
Schumann PMwR.R

+ [ ] Adapt from Dao Variance Trend Following Strategies.pdf
Demonstrate that long option strategies have positive return skew due to positive convexity with respect to the underlying returns.
Demonstrate that long option strategies provide positive returns if Hurst ratio (variance ratio) of the underlying returns is greater than 0.5.
Demonstrate that trend-following and momentum strategies also provide positive returns if Hurst ratio is greater than 0.5, similar to long option strategies.
Calculate the performance of a trend-following strategy as a function of the Hurst ratio.
Simulate returns with different Hurst ratios, and produce signature plots.
Explain that CTA's follow trend-following and momentum strategies, and that explains their positive return skew.
Explain that CTA's are similar to long option strategies, so they perform better in periods of high market volatility. 
("The performance of trend-following strategies can be ascribed to the difference between long- and short-term realized variance.")
Explain that hedge fund returns have negative convexity and skew, so they perform worse in periods of high market volatility. 
Demonstrate that trend-following EWMA strategy returns have more positive skew than underlying asset, and mean-reverting strategy returns have more negative skew.
Download hedge fund and CTA data from Barclayhedge and apply the Merton-Henriksson and reynor-Mazuy tests.
Martin Momentum Skew Returns.pdf
Dao Variance Trend Following Strategies.pdf

+ [ ] Add slide explaining difference between trend-following versus momentum strategies

+ [ ] Add slide about Barclayhedge Hedge Fund & CTA Research Library and its free data for indexes
https://www.barclayhedge.com/research/

+ [ ] Add slides with scripts for loading ETF time series from CSV files, adapt code from utility_scripts.R and data_scripts.R

+ [ ] Forecast the returns using volatility-adjusted momentum - just like Sharpe ranking  
Calculate volatility-adjusted momentum rankings by dividing the prior twelve month total return by the realized volatility over the same period and then ranking in the standard fashion.  
Clare Volatility Momentum Trend Following Asset Allocation.pdf  
Baltas Volatility Momentum Trend Following Asset Allocation.pdf  
Baltas Volatility Momentum Trend Following Asset Allocation slides.pdf  
Zakamulin Momentum Indicators Stock Forecasting.pdf  

+ [ ] Explain Momentum Reversal
Novy Momentum Reversal Momentum Strategy.pdf
Xiong Momentum Reversal Momentum Strategy.pdf

+ [ ] Demonstrate that stock returns display mean reversion in good times and they display momentum in bad times
Huang Stock Forecasting.pdf

+ [ ] Explain that a strategy that has autocorrelated returns can be improved by trading it, but it strongly depends on the transaction costs (?)
Autocorrelations of strategy returns indicate presence of additional market factors that strategy doesn't account for.
strategy returns autocorrelations factor

+ [ ] Demonstrate that adding hairy noise to mean-reverting data will create spurious profits
Show how to scrub data using Hampel (median) filter.

+ [ ] Demonstrate that the z-scores (t-values) of the residuals of time series regressions of prices are increasingly lepto-kurtic for longer time periods, because the residual volatility drops and is time-dependent

+ [ ] Adapt momentum strategy using GARCH
https://medium.com/auquan/long-short-equity-trading-strategy-daa41d00a036

+ [ ] Adapt technical indicator strategy using GARCH
https://medium.com/auquan/time-series-analysis-for-finance-arch-garch-models-822f87f1d755

+ [ ] Adapt from introduction to statistical learning:
http://www.rnfc.org/courses/isl/

+ [ ] Add heatmap to investment_strategies  
heatmap(pnl_s, Colv=NA, Rowv=NA, col=c("red", "blue"))

+ [ ] Add rank regression for robust beta estimation

+ [ ] Adapt technical indicator timing ability from: Lissandrin Testing Technical Indicator Forecasting.pdf

+ [ ] Adapt Backtest Overfitting Demonstration Tool (BODT) and the Tenure Maker Simulation Tool (TMST) from: 
Bailey Borwein Strategy Backtesting Overfitting Cross-validation.pdf

+ [ ] Create RcppArmadillo function for calculating rolling z-scores of the residuals of a rolling regressions of time series of prices, using Kalman filter
Choudhry GARCH Kalman Stock Beta Forecasting.pdf

+ [ ] Create RcppArmadillo function for calculating rolling z-scores of the residuals of rolling regressions of time series of prices
Add as a technical indicator the z-scores of residual of the rolling regressions of time series of prices.
Perform rolling regressions over trading time - using a time-dependent look-back interval, so that the look-back interval always spans the same traded volume. 
Inoue Rolling Regressions Time Series Bias Variance Tradeoff.pdf

+ [ ] Explain in detail single time series regression: the time series of prices against its time index 
Explain the difference between the residuals of the regression of the time series of prices, versus the scaled returns.

+ [ ] Explain risk-management of algorithmic (systematic) strategies
Expected volatility.
Stop-loss limits.

+ [ ] Explain the need to center and scale the technical indicators, but without data snooping, using rolling regressions over a look-back interval

+ [ ] Demonstrate that the daily OHLC skew: sk_ew <- ((hi_gh+lo_w) - (op_en+clo_se)) is highly correlated to the daily skew calculated directly from minutely data.

+ [ ] implement market timing strategy using interest rate curve as a contrarian indicator: go short when IR curve is bull steepening
https://www.bloomberg.com/news/articles/2018-04-19/top-recession-indicator-makes-a-lousy-sell-signal-for-stocks

+ [ ] Create study of OHLC technical indicators
Create matrix of 6 technical indicators formed by differencing the four columns of OHLC data. 
Calculate the correlation matrix of the indicators together with daily returns, to show that only 4 indicators are somewhat independent: re_turns, sk_ew, op_en-hi_gh, and clo_se-hi_gh.
Scale the indicators using a sigmoid (logistic) function, to reduce the effects of very large values.
Find the optimal scaling parameter.
Average the indicators over a rolling look-back interval, to improve their predictive power by reducing the effects of noise.
Demonstrate that the predictive power increases but only up to a point because of bias-variance tradeoff.
Find the optimal look-back interval.

+ [ ] Create example trading strategy for VTI, which uses static weights calculated from regressions over a design matrix
Create design matrix with many technical indicators in columns.
Demonstrate that taking averages over the past values of indicators improves their predictive power, but only up to a point: this is bias-variance tradeoff.
Demonstrate that the bias-variance tradeoff depends on the level of volatility.
Split data in two: in-sample and out-of-sample.
Perform regression of future returns over the design matrix in-sample, and calculate the weights. 
Demonstrate that performance is better if future returns are the average over many days in the future.
Apply the weights to the design matrix out-of-sample, lag the resulting signal, and trade VTI.
Explain that the regression is biased by the returns in periods of high volatility, so the out-of-sample performance is also good in periods of high volatility, but poor otherwise.
Subset the data to exclude periods of high volatility.
Apply shrinkage and dimensional regularization.

+ [ ] Create shiny app for exploring trading strategy for OHLC technical indicators
Create sliders for weights, scaling and smoothing (look-back).

+ [ ] Apply Linear Discriminant Analysis lda() to classify future returns as either positive or negative
https://rstudio-pubs-static.s3.amazonaws.com/35817_2552e05f1d4e4db8ba87b334101a43da.html
https://www.displayr.com/linear-discriminant-analysis-in-r-an-introduction
https://rpubs.com/Nolan/298913

+ [ ] Explain that the lower order principal components represent systematic risk factors, while the higher order PC's represent idiosyncratic risk (which tends to resemble random noise)
Express stock prices as weighted average of systematic risk factors plus idiosyncratic risk.
Demonstrate that the idiosyncratic risk resembles random noise, and can be traded using mean-reverting strategies.

+ [ ] Simulate a vector of returns from buying lottery tickets, and calculate its mean, standard deviation, skew, and kurtosis
Plot the histogram of returns.
Plot the moments as function of ticket price and payout probability.
Simulate random wealth paths for stocks and for lottery tickets, and plot the probability distributions of terminal wealth.
Explain that the return distribution for buying lottery tickets has positive skew but negative mean.  Vice versa for selling lottery tickets.
Explain that return distribution for stocks positive mean but negative skew, just like for selling lottery tickets.

+ [ ] Use slides for utility function and investor risk preferences for large odd moments and small even moments
Demonstrate that investors with a logarithmic utility desire positive and large odd moments, and small even moments.

+ [ ] Derive CAPM from utility 
Show that logarithmic utility implies max Sharpe.

+ [ ] Add utility function for constant relative risk aversion (CRRA)  
https://en.wikipedia.org/wiki/Isoelastic_utility

+ [ ] Futures contracts conventions
https://www.investopedia.com/university/how-to-trade-e-mini-futures-contracts/e-mini-specifications.asp
http://emini-watch.com/emini-trading/emini-futures/

+ [ ] Adapt from: 
CME Trading Treasury Futures.pdf
CME Trading Treasury Yield Curve.pdf

+ [ ] Explain the differences between different objective functions for measuring strategy performance 
Total return of strategy is too sensitive to a small number of winning trades.
Correlation between forecast and actual returns is less sensitive to small number of winning trades.
Maximize skill objective function equal to: market timing gamma coefficient (Merton-Henriksson test), alpha coefficient, or information ratio.

+ [ ] Explain Grinold's Fundamental Law of Active Management (FLAM)
Outperformance is achieved by a combination of skill and breadth (trading frequency).
Models that trade more frequently perform better because they diversify their risk of being wrong.
Hallerbach Market Timing Strategies.pdf
Grinold Synopsis Active Portfolio Management.pdf  

+ [ ] Use coin flip puzzle to demonstrate difficulty of testing manager skill
Demonstrate that it's impossible to confirm skill of strategy that trades infrequently.
C:\Develop\R\scripts\coin_flips.R

+ [ ] Portfolio optimization using Omega ratio  
Gilli Omega Portfolio Optimization.pdf
Shaw Portfolio Optimization CVaR Omega Utility.pdf
Keating Omega Performance Measure.pdf

+ [ ] Tail risk measures  
value-at-risk and conditional value-at-risk as function of skewness and kurtosis parameters  
show that value-at-risk is not subadditive  
subadditive risk measures, ETL (ES/ETL/CVaR), Omega, Hurst exponent,  
conditional value at risk (CVaR)  
VaR for generalized Pareto distribution  
!!! Maillard Cvar Cornish Fisher Portfolio.pdf  
http://www.capitalspectator.com/tail-risk-analysis-in-r-part-i/  
https://gist.github.com/jpicerno1/c3af6285713c76a5d124  

+ [ ] Dynamic factor models package dlm
http://lalas.github.io/quantitativeThoughts/r/2014/09/01/dlmTutorial.html
https://stats.stackexchange.com/questions/164992/how-to-specify-var-dynamics-of-factors-in-dynamic-factor-model-in-r
Lalas State Space Models Kalman Filter.html
Bai Dynamic Factor Model Estimation.pdf
Poncela Dynamic Factor Models Kalman Filter.pdf
Bai Large Dimensional Factor Analysis.pdf
Bai Forecasting Factor Models Targeted Predictors.pdf
Meng Rolling Beta Factor Model.pdf
Barigozzi Dynamic Factor Models.pdf
Stock Multifactor Forecasting.pdf
Harvey Bootstrap Factor Models.pdf

+ [ ] Apply Kalman filter state space model for calculating rolling betas
Explain that Kalman filter is a generalization of exponential smoothing.
Explain that Kalman filter adapts its smoothing strength depending on the level of volatility.
Apply Kalman filter without package dlm
http://www4.stat.ncsu.edu/~reich/BigData/code/kalman.html
http://www4.stat.ncsu.edu/~reich/BigData/code/kalman.R
C:\Research\Academic\Brian Reich\kalman.R
Apply Kalman filter using package dlm
http://lalas.github.io/quantitativeThoughts/r/2014/09/01/dlmTutorial.html
Regression with time-varying beta parameters
http://past.rinfinance.com/agenda/2012/workshop/Zivot+Yollin.pdf
https://sites.ualberta.ca/~sfossati/e509/files/slides/Lec4.pdf
http://bilgin.esme.org/BitsBytes/KalmanFilterforDummies.aspx  
http://intelligenttradingtech.blogspot.com/2010/05/kalman-filter-for-financial-time-series.html  
http://stats.stackexchange.com/questions/8055/how-to-use-dlm-with-kalman-filtering-for-forecasting  
http://stats.stackexchange.com/questions/16841/is-the-kalman-filter-actually-forecasting
https://magesblog.com/post/2015-01-06-kalman-filter-example-visualised-with-r/
http://www.magesblog.com/2015/01/extended-kalman-filter-example-in-r.html  
http://www.bearcave.com/finance/random_r_hacks/kalman_smooth.html
Arnold Kalman Filter Expectation Maximization.pdf  
Tusell Kalman Filtering in R.pdf  
Sorensen Kalman Filter.pdf  
Prado Kinetic Component Analysis Forecasting.pdf  

+ [ ] Create pairs strategy using Kalman filter for beta
Forecast the volatility using GARCH or EWMA, and apply the volatility forecasts to calculate Kalman gain.

+ [ ] Apply Kalman to GARCH
Ferreira GARCH Volatility Kalman.pdf

+ [ ] Apply Kalman to PCA
https://people.eecs.berkeley.edu/~jordan/courses/281A-fall04/lectures/lec-11-2.pdf

+ [ ] how a Kalman filter works
Kalman Explained.pdf
Kalman Explained Detail.pdf
Kalman Filter Simple.pdf
http://www.cl.cam.ac.uk/~rmf25/papers/Understanding%20the%20Basis%20of%20the%20Kalman%20Filter.pdf
http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/
http://www4.stat.ncsu.edu/~reich/BigData/code/kalman.html

+ [ ] implement Kalman filter in Rcpp using RcppArmadillo
RcppArmadillo intro.pdf
RcppArmadillo Eddelbuettel 2014.pdf
https://github.com/eddelbuettel/rcppkalman
http://dirk.eddelbuettel.com/code/rcpp.kalman.html

+ [ ] Apply Kalman filter state space model for calculating trend slope (past returns)
Demonstrate that Kalman filter is equivalent to exponential smoothing.
Demonstrate that Kalman filter achieves a better bias-variance tradeoff than linear regression?
Bruder Momentum Indicators Kalman Filter SVM.pdf  
ZivotYollin2012.pdf
Jingtao Filtering Momentum Strategy.html ?

+ [ ] write fast Kalman filter in RcppArmadillo, adapt from package FKF ? (very old)
https://github.com/cran/FKF

+ [ ] Create an MA strategy with the return forecast equal to the MA model: weighted moving average over the past p returns 
Calculate the MA coefficients as equal to the partial autocorrelations.
Calculate the partial autocorrelations using average future returns, instead of single-period returns.
Add to the MA model the past High-Low ranges. 
Calculate the partial autocorrelations using RcppArmadillo.

+ [ ] Demonstrate that it's possible to optimize the MA strategy in-sample, so that it produces profits in almost a straight line, but the profits immediately disappear out-of-sample, as if they were arbitraged away by investors 
Demonstrate that as p (the number of past MA returns) increases, the in-sample performance improves, but the out-of-sample performance deteriorates.
Demonstrate that in-sample, the MA strategy performs very well even on random data.
Introduce a constraint on the weights, so that the neighboring weights can't differ by more than say by dp. 
Demonstrate that the out-of-sample performance improves as dp decreases. 
Explain that this constraint is a form of regularization.
Calculate the MA weights over a rolling interval, and perform PCA on the weights.
Determine shape of the first three principal components: flat, tilt, butterfly.
Apply regularization to the MA weights by expressing them as a weighted sum of three principal components: flat, tilt, butterfly.
Demonstrate that the out-of-sample performance improves with stronger regularization (fewer principal components). 

+ [ ] Explain that models with more parameters are more fragile 

+ [ ] P-hacking: simulate curing cancer with jelly beans: false discovery rate, p-value hacking
Demonstrate that risk of p-hacking increases with number of trials (number of jelly bean colors).
Demonstrate that out-of-sample the cure doesn't work.
Calculate how big should be sample size to avoid p-hacking.
Ioannidis Why Most Published Research Findings Are False.pdf
Taleb P-Value Distribution.pdf

+ [ ] Explain risk of data mining (p-hacking, synonyms significance inflation, multiple testing), and false discovery rate  
Demonstrate that the effects of p-hacking can be reduced by not selecting the optimal parameters, but instead selecting a range of parameters around the optimal value.
https://en.wikipedia.org/wiki/Look-elsewhere_effect  
create example of data mining: create tech indicator with several parameters  
http://datagrid.lbl.gov/backtest/  
http://www.financial-math.org/software/  

+ [ ] controlling the false-discovery rate using Bonferroni method Sidak correction  
http://www.alexchinco.com/screening-using-false-discovery-rates/  
http://eranraviv.com/sample-data-snooping/  
http://eranraviv.com/modern-statistical-discoveries/  
Bailey Prado Deflated Sharpe Ratio Overfitting.pdf  
Bailey Prado Strategy Backtesting Overfitting Cross-validation.pdf  
Bailey Prado Strategy Backtesting Overfitting.pdf  
Harvey Backtesting Data Mining Bonferroni Adjustment.pdf  
Harvey Evaluating Trading Strategies.pdf  
White Strategy Backtesting Overfitting Data Mining Cross-validation Bootstrap.pdf  

+ [ ] optimize a strategy using a portfolio constraint so that it's 50% long beta 
The idea is that this constraint is equivalent to a portfolio of 50% quant strategy plus 50% long beta. 
Quant strategies are uncorrelated to market portfolio, so it's best to combine the two.

+ [ ] Adapt from OShaughnessy Factors from Scratch
http://osam.com/Commentary/factors-from-scratch

+ [ ] Adapt from Blitz factor investing tutorial
https://factorinvestingtutorial.wordpress.com/hello/

+ [ ] Factor model regularization: 
Fan Factor Model Regularization.pdf
Fan Covariance Regularization.pdf

+ [ ] Use Kelly rule to allocate between cash and stocks as the level of stock predictability (forecastability) changes
Create a function which measures the level of predictability based on volatility, correlation, Hurst, etc.

+ [ ] Calculate the Kelly formula when the probability of winning is uncertain  
Consider different distributions of the probability of winning.
Sinclair Kelly Confidence Intervals.pdf

+ [ ] Create backtesting study of time series data scrubbing using Hampel median filter  
explain Type I and Type II errors
Type I error is rejecting a true null hypothesis
power of test
http://dsp.stackexchange.com/questions/26552/what-is-a-hampel-filter-and-how-does-it-work
https://en.wikipedia.org/wiki/Median_filter
use code from "demo_HighFreq.R" and "hfreq_aggregation.R"
1. create xts of smooth or random prices with changing vol
2. add random jump noise to it
3. filtering define scrubbing function with two params: vol estimation window and noise threshold
apply filtering to remove jump noise by applying: filter function, caTools, TTR, highfrequency package, etc. (compare speed)
http://www.cookbook-r.com/Manipulating_data/Calculating_a_moving_average/
http://stackoverflow.com/questions/743812/calculating-moving-average-in-r
4. optimize filter parameters and create ROC curve
5. add jump noise with variable volatility
6. optimize filter parameters in-sample: study bias-variance tradeoff with regards to window length, Precision and Recall tradeoff
7. create rCharts and shiny visualizations
8. apply best in-sample filter parameters to out-of-sample data
second version:
create a csv file with time series data plus some bad text data 
read csv file and coerce to numeric
format the dates and times
find bad data and scrub it
create zoo and plot it

+ [ ] Explain Randomization Test: feed random data into the strategy, to verify if it produces positive returns
If a strategy produces positive returns on random data then it's a problem.

+ [ ] rebalance the momentum strategy using different frequencies: annual, quarterly, monthly, daily
Demonstrate that less frequent rebalancing of momentum strategy works better. 

+ [ ] Calculate the weights of the maximum alpha portfolio using matrix algebra
It's a linear programming problem that requires box constraints to limit leverage, and prevent excessive shorting of assets with small or negative alpha.
This solution if no negative weights: the asset with the highest alpha has weight equal to 1, and remaining assets have weights equal to zero.

+ [ ] solve linear and quadratic programming problems by hand in R and in Rcpp

+ [ ] introduce Safety first portfolio models
adapt from: Engels Portfolio Optimization.pdf

+ [ ] introduce Value at Risk portfolio optimization, adapt from: Engels Portfolio Optimization.pdf
Introduce Elliptical distributions.
Demonstrate that minimizing the variance is the same as minimizing the Value at Risk, when returns are elliptically distributed.
Define the optimal Telser portfolio as the portfolio that maximizes expected return subject to a shortfall constraint.

+ [ ] Adapt from Bailey Borwein Portfolio Optimization Overfitting.pdf

+ [ ] Add slide about best way to calculate rolling beta using zero intercept regression
https://stackoverflow.com/questions/7333203/linear-regression-with-a-known-fixed-intercept-in-r
Demonstrate that zero intercept beta has higher bias but lower variance (bias-variance tradeoff).
Calculate rolling zero intercept beta and demonstrate that it has lower realized variance.

+ [ ] Create bias-variance tradeoff graphs
Create bias-variance tradeoff example for multivariate regression: compare multivariate regression with multivariate regression constrained to a single beta coefficient.
Calculate total error as the sum of bias plus variance, using bootstrap simulation.
Demonstrate that constrained multivariate regression has bias but has lower total error.
Explain that the variance increases with the number of model parameters, so regularization involves reducing the number of model parameters.
Explain that models with more parameters will tend to overfit the noisy data, so their variance will increase because of that.
Aswani Regression Shrinkage Bias Variance Tradeoff.pdf
Scott Fortmann-Roe: out of sample prediction error
http://scott.fortmann-roe.com/docs/MeasuringError.html
Scott Fortmann-Roe: bias-variance tradeoff and knn clustering
http://scott.fortmann-roe.com/docs/BiasVariance.html
bias_variance_tradeoff.png
bias_variance_tradeoff2.png

+ [ ] Create shiny for pairs trading
Hoang Johansen Cointegration Statistical Arbitrage.pdf
https://htran.shinyapps.io/pairs_trading/

+ [ ] Explain difference between covariance matrix regularization versus shrinkage and the tradeoffs between the two
https://github.com/yanyachen/FinCovRegularization
https://github.com/arorar/covmat
https://github.com/rstats-gsoc/gsoc2015/wiki/Covariance-Matrix-Estimators
https://github.com/AEBilgrau/correlateR

+ [ ] Explain the difference between weight constraints: sum constraint versus sum-of-squares constraint
sum constraint allows for infinite leverage of long-short portfolio

+ [ ] Add R compiler: compiler::cmpfun()

+ [ ] Add unit root test in Rcpp
https://github.com/olmallet81/URT

+ [ ] Add slides for unit root tests and cointegration
http://quantdevel.com/public/html/testForCoint.html
ADF test for unit roots  
package urca  

+ [ ] Add unit root ADF tests packages tseries fUnitRoots
ADF and MacKinnon tests
http://fabian-kostadinov.github.io/2015/01/27/comparing-adf-test-functions-in-r/
http://denizstij.blogspot.com/2013/11/stationary-tests-of-time-series-within-r.html

+ [ ] introduce statarb
select warmup data and perform PCA to determine factors
perform rolling PCA and calculate factors and z-scores
sort on z-scores and go long and short
define trading rules: entry, exit, stop-loss

+ [ ] Adapt from: Pav Sharpe Ratio Course.pdf
http://www.gilgamath.com/bad-cis.html

+ [ ] Adapt from Pav: Distribution of Maximal Sharpe
http://www.sharperat.io/max-sharpe-one.html
http://www.quantresearch.info/Intro.htm

+ [ ] Adapt Damien Challet's drawdown estimator of the Signal to Noise Sharpe ratio
Challet Drawdown Sharpe Ratio.pdf
http://www.sharperat.io/improved-moment-estimator-snr.html
https://github.com/amirsani/pySharpeRratio

+ [ ] Perform PCA, select clustered sub-portfolios, and perform PCA on the sub-portfolios
study if second PC of sub-portfolios is mean-reverting, and if it's persistent out-of-sample.

+ [ ] Add slide with PCA percentage of variance explained to time_series_multivariate
calculate by hand
summary(reg_model)

+ [ ] Principal component analysis PCA adapt from: CFM Principal Component Market Factors.pdf

+ [ ] Fundamental factor models adapt from: Zivot Factor Models.pdf
C:\Research\R\Tutorials\Zivot\research\factorModels.R

+ [ ] stock clustering
https://github.com/gjanesch/Stock-Clustering

+ [ ] regularization James-Stein shrinkage of covariance matrices
https://rviews.rstudio.com/2017/08/22/stocks/
http://strimmerlab.org/software/corpcor/
https://github.com/cran/corpcor
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2748251/
https://en.wikipedia.org/wiki/James%E2%80%93Stein_estimator

+ [ ] Adapt from: covmat package for estimating convariance matrices using shrinkage and Random Matrix Theory
https://github.com/rstats-gsoc/gsoc2015/wiki/Covariance-Matrix-Estimators  
https://github.com/arorar/covmat

+ [ ] Adapt from: tawny package for regularizinging correlation matrices using random matrix theory and shrinkage estimation  
Rowe Random Matrix Shrinkage Covariance Estimation.pdf  
Gatheral Random Matrix Shrinkage Covariance Estimation.pdf  
Plerou Random Matrix Correlation Estimation.pdf  
Goldberg Random Matrix Shrinkage Covariance Estimation.pdf  

+ [ ] visualize correlation matrices in R
https://github.com/JamesMarquezDev/Jupyter-Notebooks-Statistic-Walk-Throughs-Using-R/blob/master/correlation_matrices_in_r.ipynb
http://jamesmarquezportfolio.com/correlation_matrices_in_r.html

+ [ ] Define stock skewness as ratio of downside beta divided by upside beta - use OHLC data
Sort stocks by their rolling skewness, and check if it has forecasting ability.

+ [ ] Add stop-loss to back-test

+ [ ] Add slide explaining, summarizing conclusions about quant trading strategies:
It's very hard for quant strategies to beat a static stock and bond portfolio.
It's very hard to identify, distinguish a good quant strategy from a bad one, especially if it trades infrequently.
Trend-following and mean-reverting quant strategies tend to be uncorrelated, so it's best to combine them.
Good quant trading strategies tend to be uncorrelated with stocks, so it's best to combine quant strategies with stocks.

+ [ ] Explain that rolling backtest makes sense only if standard errors of meta-parameters are less than the standard errors of model parameters (?)
In other words, rolling backtest reduces parameter uncertainty.
No, meta-parameter uncertainty is still large, but pnl is less sensitive to meta-parameter value, so it doesn't matter.

+ [ ] Explain that backtesting is picking best performing model or asset over time
How much data is needed to achieve a given confidence level that we're picking the actual best performing model?
read: Pav Strategy Overfit.pdf slide #6
Standard error of Sharpe ratio decreases as square root of time interval length: 
SE(SR)  SR / sqrt(T)
required sample size decreases as square of Sharpe ratio: 
n  ? / ?^2
where ? is proportional to type I and type II error rates (Lehr's rule)
how do these formulas change for non-Gaussian distributions?

+ [ ] Adapt scripts for testing manager skill
Use bullet points under Benchmarking portfolio management skill, in file Systematic Investment Strategies.md
C:\Develop\R\scripts\select_manager.R
Demonstrate that active managers are likely to underperform the index, unless they have extraordinary skill.
The best performing stocks drive the index performance, while most stocks in the index perform relatively badly. 
So randomly picking stocks from the index will result in portfolios which underperform the index.
Heaton Stock Index Selection Active Portfolio Management.pdf  
https://www.bloomberg.com/view/articles/2015-11-11/why-indexing-beats-stock-picking
https://www.bloomberg.com/news/articles/2017-04-09/lopsided-stocks-and-the-math-explaining-active-manager-futility
package PeerPerformance
https://github.com/ArdiaD/PeerPerformance

+ [ ] Add slide where data is split in half, with calibration in first half and out-of-sample performance in second half
Demonstrate that this performs better than rolling backtest

+ [ ] Add backtest slides to section Performing Aggregations Over Time Series in risk_models.pdf
perform backtest in parallel using the map/reduce (split-apply-combine) procedure 
expand the slide Simulating EWMA Strategies Using Parallel Computing in investment_strategies.pdf

+ [ ] Create slide with bullet points of backtesting: collect historical data (returns, etc.), aggregate data into performance statistics (Sharpe ratio, etc.), apply trading rule and form portfolio, test portfolio performance out-of-sample
adapt language from Arman Arkilic capstone project.md

+ [ ] Adapt backtest code from package cv.ts
http://moderntoolmaking.blogspot.com/2011/11/functional-and-parallel-time-series.html
http://moderntoolmaking.blogspot.com/2011/11/time-series-cross-validation-2.html
https://github.com/zachmayer/cv.ts
http://robjhyndman.com/researchtips/tscvexample
# foreach package for parallelized backtesting with foreach
http://blog.revolutionanalytics.com/2009/05/parallelized-backtesting-with-foreach.html
# backtesting with elastic net, LASSO, glmnet and caret
https://quantmacro.wordpress.com/2016/04/26/fitting-elastic-net-model-in-r/

+ [ ] A backtest can only reject a potential strategy, but it can't predict its future success
Historical data can never be long enough to capture all the possible Black Swan events that can occur in the future, so a backtest can't tell us if a strategy will fail miserably. 
But if a strategy has failed in a backtest, then it's very likely to fail again in the future.

+ [ ] Adapt from: Harvey Evaluating Trading Strategies.pdf
Harvey Backtesting Data Mining Bonferroni Adjustment SSRN.pdf

+ [ ] Demonstrate that in backtest, an ensemble of EWMA strategies out-performs any single EWMA strategy out-of-sample
make ensemble weights dependent on correlations, to avoid over-weighting similar strategies
use minimum correlation portfolio model

+ [ ] Calculate confidence interval of strategy parameters as function of length of data used for calibration and total number of trades
Show that confidence interval increases with total number of trades, so strategy which trades infrequently requires very long backtest which may exceed available data.
SharpeR Vignette.pdf
Lo Sharpe Ratio Statistics.pdf
http://robotwealth.com/optimal-data-windows-for-training-a-machine-learning-model-for-financial-prediction/

+ [ ] Explain backtest overfitting and the Triple Penance Rule
Prado Portfolio Allocation Trading Meta-Strategies.pdf

+ [ ] Futures price prediction using the order book data
http://blog.kahutrading.com/2012/03/futures-price-prediction-using-order.html

+ [ ] Add slide constrained portfolio optimization using penalty terms: sum of weights equal to 1
This is an objective function equal to the portfolio variance plus a penalty term for the weight constraint: sum(weight_s) == 1.
object_ive <- function(weight_s, re_turns) {
  var(re_turns %*% weight_s) + 
    (sum(weight_s) - 1)^2
}  # end object_ive
You can then perform portfolio optimization for minimum variance, with the weight constraint:
op_tim <- optim(par=rep(1.0, NCOL(re_turns)),
                fn=object_ive,
                method="L-BFGS-B",
                upper=rep(1, NCOL(re_turns)),
                lower=rep(-1, NCOL(re_turns)),
                re_turns=re_turns)
weight_s <- op_tim$par
var(re_turns %*% weight_s)

+ [ ] Add slide calculating minimum CVaR portfolio: historical
Explain how Rglpk::Rglpk_solve_LP() works in case of minimum CVaR portfolio:
The (unkown) weights are applied to the portfolio, plus additional weights are applied to the individual returns at each point in time.
Rglpk_solve_LP() tries to maximize the product of the obj vector parameter times the (unkown) weights.
Since the obj vector elements are negative, the weights are pushed towards zero.
At the same time the mat constraints require the weights to be larger, because some of the individual returns are negative.
So the only way to maximize the obj product is to make the individual returns less negative, but adjusting the portfolio weights.

+ [ ] Add slide CVaR portfolio optimization using linear programming optimization

+ [ ] Calculate standard error of stock beta as function of time series length and level of volatility
Perform same analysis for eigenvectors and eigenvalues.
Simulate returns or bootstrap historical returns, and calculate standard errors of betas, alphas and sharpe ratios.
Demonstrate that sampling at higher frequency doesnt reduce standard errors.
Calculate how many years of data are need to reduce standard errors to tolerable level.
Explain that stock betas are useless because they have huge standard errors.
Since beta depends on time, we are not able to measure beta.

+ [ ] rolling portfolio optimization with shrinkage

+ [ ] Add slide portfolio optimization with elastic net shrinkage  

+ [ ] constrained portfolio optimization shrinkage  
http://www.finance-r.com/s/efficient_frontier_fPortfolio/complete/  
http://www.finance-r.com/s/simple_portfolio_optimization_tseries/complete/  
http://www.portfolioprobe.com/2011/04/28/a-test-of-ledoit-wolf-versus-a-factor-model  
http://quant.stackexchange.com/questions/10101/portfolio-optimization-shrinkage-of-covariance-matrix-when-data-is-available  
https://systematicinvestor.wordpress.com/2011/11/11/resampling-and-shrinkage-solutions-to-instability-of-mean-variance-efficient-portfolios/  
https://systematicinvestor.wordpress.com/2013/10/29/updates-for-proportional-minimum-variance-and-adaptive-shrinkage-methods/  
http://quant.stackexchange.com/questions/1504/robust-portfolio-optimization-re-balancing-with-transaction-costs  
Golts Constrained Shrinkage Portfolio Optimization.pdf  
Demiguel Shrinkage Estimators Portfolio Optimization.pdf  
Ledoit Wolf Covariance Shrinkage Estimators Portfolio Optimization.pdf 

+ [ ] Adapt optimization techniques from:
Bolker Optimization Methods.pdf
Yollin Optimization.pdf
Boudt DEoptim Large Portfolio Optimization.pdf

+ [ ] Add slide portfolio optimization using package Deoptim: example of portfolio optimization
Ardia DEoptim Portfolio Optimization.pdf  
Boudt DEoptim Large Portfolio Optimization.pdf  
Boudt PortfolioAnalytics Portfolio Optimization CVaR Budgets.pdf
CRAN Task View Empirical Finance
http://cran.r-project.org/web/packages/DEoptim/vignettes/DEoptimPortfolioOptimization.pdf

+ [ ] Demonstrate how to fix singular correlation matrix
first generate singular correlation matrix
package corpcor

+ [ ] Adapt from: Bailey Prado Stop Loss Rules.pdf

+ [ ] Adapt from: 
https://www.linkedin.com/pulse/secret-investing-canada-kurtis-hemmerling/

+ [ ] Simulate GARCH model using random returns  
use rugarch function ugarchsim()
https://faculty.washington.edu/ezivot/econ589/econ589univariateGarch.r
econ589/econ589univariateGarch.r
Burns GARCH Modelling.pdf

+ [ ] GARCH volatility models adapt from:
http://quant.stackexchange.com/questions/27755/garch-volatility-modeling-squared-returns-and-convergence
Reider Volatility Stochastic Volatility Models.pdf
Reider GARCH Volatility Models.pdf

+ [ ] Calculate standard errors of GARCH volatility forecasts using bootstrap simulation

+ [ ] introduce GARCH models and volatility forecasting  
http://models.cliffordang.com/garch11.R
http://eranraviv.com/multivariate-volatility-forecast-evaluation/
simulate stocks as ARMA + GARCH model
show that it has time dependent volatility
fit stock returns into ARMA + GARCH model
calculate standard errors of GARCH model parameters and demonstrate that GARCH models require large amount of data to calibrate
Brownlees Engle Volatility Forecasting.pdf

+ [ ] ARIMA GARCH strategy  
Halls-Moore ARIMA GARCH Strategy.pdf  

+ [ ] Create EWMA and GARCH examples from package GARPFRM  

+ [ ] Rcpp examples for GARCH
http://systematicinvestor.github.io/Exponentially-Weighted-Volatility-RCPP
http://unstarched.net/r-examples/rmgarch/fast-ewma-filtering-of-time-vayring-correlations/

+ [ ] incorporate GARCH scripts
https://theaverageinvestor.wordpress.com/category/r/
http://www.quintuitive.com/category/research/armagarch/
http://www.quintuitive.com/

+ [ ] Demonstrate that log of OHLC range is Gaussian and has strong autocorrelation  
Kinlay GARCH Volatility Forecasting.pdf
Alizadeh Range OHLC GARCH Volatility Estimators.pdf
LeBaron Improved OHLC Range Volatility Estimators.pdf

+ [ ] Estimating GARCH parameters using packages rugarch and fGarch problems
https://ntguardian.wordpress.com/2017/11/02/problems-estimating-garch-parameters-r/

+ [ ] Add package rugarch  
http://unstarched.net/r-examples/rugarch/a-short-introduction-to-the-rugarch-package/

+ [ ] Add package tseries GARCH volatility models  

+ [ ] calibrate into simulated GARCH data and show how the standard error of parameter estimates depends on the number of data points

+ [ ] Perform backtest of GARCH model, and calibrate it using variance targeting  
use DEoptim
http://unstarched.net/2013/01/07/does-anything-not-beat-the-garch11/
rolling GARCH:
http://stackoverflow.com/questions/25732348/volatility-forecast-with-for-loop-for-garch-family-model
calibrating GARCH model requires a minimum of about 2,000 observations i.e. 10 years of daily data.  
if less than 1,000 observations are available, then better to just pick some reasonable parameter values.  
the intraday seasonality of volatility makes it harder to use intraday data to calibrate GARCH model  
http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/

+ [ ] Calculate PACF and fit GARCH for all the variance estimator methods  

+ [ ] Simulate time-varying volatility process
Models of stock returns: Pareto distribution, stochastic volatility, Heston model, 
https://github.com/daleroberts/heston
http://models.cliffordang.com/hestonSV.R

+ [ ] slide Simulating Stochastic Volatility

+ [ ] Create GARCH examples from package highfrequency  

+ [ ] Create Normal mixture model and show that it has fat tails,  
Student t-distribution distribution as model for stocks: power law decay, instead of exponential  
fit returns into Student t-distribution, Cauchy, and Pareto distribution  
explain Method of Moments
explain fitting return time series distribution using expectation-maximization algorithm
MASS::fitdistr
Show that the Pareto distribution has infinite variance but has finite MAD.  
show that Normal mixture model is similar to Student's t-distribution  
create distribution with large skew - Poisson  
Shalizi: pareto.R  
http://edge.org/response-detail/25401  
http://datascienceplus.com/modelling-dependence-with-copulas/  
http://stats.stackexchange.com/questions/52609/fitting-t-distribtution-to-financial-data  
# define heteroskedasticity as the variability of the variance
http://www.investopedia.com/terms/h/heteroskedasticity.asp
Heteroskedasticity, in statistics, is when the standard deviations of a variable, monitored over a specific amount of time, are nonconstant. 
Heteroskedasticity often arises in two forms: conditional and unconditional. 
Conditional heteroskedasticity identifies nonconstant volatility when future periods of high and low volatility cannot be identified. 
Unconditional heteroskedasticity is used when futures periods of high and low volatility can be identified.

+ [ ] Analytic solution of the Ornstein-Uhlenbeck OU process solve pde
Grabovsky Statistical Arbitrage Pairs Trading.pdf
Thierfelder Ornstein-Uhlenbeck Process.pdf

+ [ ] Fitting calibration maximum likelihood Ornstein-Uhlenbeck OU process
Berg Ornstein-Uhlenbeck Calibration.pdf
Smith Ornstein-Uhlenbeck Calibration.pdf
http://r.789695.n4.nabble.com/Ornstein-Uhlenbeck-td2991060.html
https://rpubs.com/snowdj/oualberta
https://renkun.me/2014/04/15/fit-an-ornstein-uhlenbeck-process-with-discrete-time-series-data/
multiply returns times lagged prices minus constant
relation of Ornstein-Uhlenbeck OU process to ARIMA

+ [ ] Demonstrate how to fit time series of returns into normal distribution model using maximum log-likelihood estimation 
Explain that maximum log-likelihood estimation of any model is a two-step procedure:
First perform regression to calculate residuals.
The residuals are a function of the model parameters obtained from regression. 
Second, fit the residuals into normal distribution 

+ [ ] Explain that individual prices are almost impossible to forecast, but prices of some portfolios may be possible to forecast.
Examples of portfolios possible to forecast: pairs, max Sharpe.
But then the problem is, do these remain stable out-of-sample?
Do pairs remain cointegrated?

+ [ ] Perform rolling regression with shrinkage

+ [ ] Demonstrate shrinkage and the bias-variance tradeoff applied to multiple regression  
Demonstrate that shrinkage is more powerful when the signal-to-noise is low.
Point out that there is no formula for the optimal amount of shrinkage that should be applied to obtain the lowest MSE, so cross-validation is neeeded to calculate the optimal shrinkage amount. 
http://eranraviv.com/shrinkage-in-statistics/

+ [ ] Adapt shrinkage LASSO regression, SVD, PCA using glmnet
http://www4.stat.ncsu.edu/~reich/BigData/code/lasso.html
https://quantmacro.wordpress.com/2016/04/26/fitting-elastic-net-model-in-r/
https://onlinecourses.science.psu.edu/stat857/node/137

+ [ ] Adapt SVD and PCA from:
https://poissonisfish.wordpress.com/2017/01/23/principal-component-analysis-in-r/
http://www4.stat.ncsu.edu/~reich/BigData/code/svd_v_eigen.html

+ [ ] lift LaTeX formulas:
https://web.stanford.edu/~hastie/glmnet/glmnet_beta.html

+ [ ] Adapt EWMA moving average indicators from: 
C:\Research\R\R-Finance 2016\Service Dual Moving Average Indicators Automated Trading.pdf
Sample R code from Christian Silva presentation "Moving averages strategies" at R/Finance 2013
http://rpubs.com/silvaac/6165

+ [ ] Create several EWMA time series (current price minus EWMA price) for several different decay factors
Perform regression of returns on the EWMA time series

+ [ ] Create study of time series forecasting using ARIMA or regression
Create synthetic time series using ARIMA.
Apply various forecasting techniques.
introduce confusion matrix and ROC curve.
Add spurious random predictors, and show that they decrease forecasting performance.
Discuss Model Variable selection: AIC, AIC, BIC.
Demonstrate that monthly returns have higher autocorrelation than daily returns.

+ [ ] regression of time series data ARIMA
Lundholm Introduction R Time Series
Regression and time series data
auto.arima() handles order selection and differencing 
(but only checks if errors are stationary).
Model Variable selection
AIC, AIC, BIC

+ [ ] Create correlation heatmap
http://blog.revolutionanalytics.com/2014/08/quantitative-finance-applications-in-r-8.html

+ [ ] Use outer() to create heatmap and to find optimal trading parameters
Use statarb_sharpe_ratio.R
Interpolate the heatmap using package raster.
Plot an interactive perspective plot of heatmap using package rgl.
sharpe_matrix_dense <- raster::raster(sharpe_matrix)
sharpe_matrix_dense <- raster::disaggregate(sharpe_matrix_dense, fact=c(5, 5), method="bilinear")
sharpe_matrix_dense <- raster::as.matrix(sharpe_matrix_dense)
rgl::persp3d(z=sharpe_matrix_dense, col="green", zlab="", main="sharpe_matrix")

+ [ ] Estimate Hurst exponent for an xts time series of prices using variance ratios  
use package pracma 
Demonstrate that if prices follow geometric Brownian motion then the Hurst exponent is equal to 1, 
If prices are mean-reverting then the Hurst exponent is less than 1, 
If prices are trending then the Hurst exponent is greater than 1, 
simulate prices for OU prices and calculate variance ratios for different values of mean-reversion parameter
plot Hurst exponent as function of mean-reversion parameter
# calculate Hurst exponent using variance ratios for non-xts
hurst_exp <- function(da_ta, l_ag=4) {
  len_gth <- length(da_ta)
  var(da_ta[-(1:l_ag)]-da_ta[-((len_gth-l_ag+1):len_gth)])/var(da_ta[-1]-da_ta[-len_gth])/l_ag
}  # end hurst_exp

+ [ ] Adapt from testing the Efficient Market Hypothesis
Lo-MacKinlay Variance Ratio Test
https://github.com/StuartGordonReid/emh

+ [ ] Adapt from Hurst exponent with Python code
https://robotwealth.com/demystifying-the-hurst-exponent-part-1/
https://robotwealth.com/demystifying-the-hurst-exponent-part-2/
Demonstrate that for short time frames, the Hurst is less than 0.5, so it's better to trade mean-reversion trading strategies. 
Demonstrate that for long time frames, the Hurst is greater than 0.5, so it's better to trade momentum or trend-following trading strategies. 

+ [ ] Create slides for mean reversion tests: ADF and Hurst
demonstrate that power of mean reversion tests is weak and it increases with length of time series
apply tests to short samples of time series data and demonstrate that sometimes they are mean reverting  
study Lo and MacKinlay variance ratio test in: 
Kinlaw Variance Ratio Correlation Term Structure.pdf  
packages vrtest and pracma  
https://github.com/cran/pracma/blob/master/R/hurst.R

+ [ ] Demonstrate that term structure of variance may be caused by autocorrelation
simulate an autocorrelated series and calculate its term structure of variance
plotly or shiny plot the variance ratio as function of autocorrelation
stochastic (unobservable) drift term may cause autocorrelation, even if returns are iid and lognormal
http://www.portfolioprobe.com/2011/11/08/the-mystery-of-volatility-estimates-from-daily-versus-monthly-returns/

+ [ ] Create slides for packages sde and yuima for Ornstein-Uhlenbeck ?
sde.sim()

+ [ ] Simulate Ornstein-Uhlenbeck OU process AR(1) model and trade it  
http://quant.stackexchange.com/questions/1260/r-code-for-ornstein-uhlenbeck-process
https://cran.r-project.org/web/packages/Sim.DiffProc/index.html
https://cran.r-project.org/web/packages/yuima/index.html
create scatterplot of returns versus lagged prices
create plot with multiple OU processes
forecast returns and demonstrate that forecasting is easier with stronger mean-reversion  
Bertram Statistical Arbitrage Trading Solutions.pdf

+ [ ] Expand slide Integrated and Unit-root Processes
explain unit root process
create slide for Augmented Dickey-Fuller ADF test
perform ADF test as function of length "n"
adf.test(cumsum(rnorm(n)))
show that p-val doesn't become big until "n" is big
ADF is weak test (doesn't reject false hypothesis)
compare with ADF test on DAX
create synthetic time series using ARIMA
simulate and plot ARIMA AR(1) processes with different coefficients
show how diverges if unit root
perform ADF test
http://robotwealth.com/exploring-mean-reversion-and-cointegration-with-zorro-and-r-part-1/  
http://robotwealth.com/exploring-mean-reversion-and-cointegration-part-2/  

+ [ ] cointegration package irlba  
apply Doorniks method using the SVD to solve the cointegration problem  
Lewis RFinance 2012 Cointegration SVD.pdf  
Doornik Cointegration Analysis SVD QR.pdf
explain error propagation in matrix inversion use example
C:\Research\R\R-Finance 2015\Lewis RFinance 2015 Cointegration SVD.html  
https://bwlewis.github.io/rfinance-2017/#/section
https://github.com/bwlewis/irlba

+ [ ] Demonstrate that given any two random price series, you can always find a coefficient that creates a cointegrated portfolio in-sample, but it falls apart out-of-sample

+ [ ] Adapt from Sebastian Fossati and Hauser - very good time series and cointegration with some R
Granger Causality
C:\Research\R\Tutorials\Fossati\e509\Lec8.R
C:\Research\R\Tutorials\Fossati\e509\Lab4.R
Hauser Cointegration Vector Error Correction Autoregressive Model.pdf
Investigate the price series of black and white pepper, PepperPrices from the R library(AER) wrt cointegration and calibrate the VECM model.

+ [ ] Add total least squares regression of stock pair
C:\Research\R\Tutorials\Georgakopoulos\rfortraders\Chapter_06

+ [ ] Add Johansen cointegration statistical arbitrage
https://github.com/VermeirJellen/AlgorithmicTrading-Cointegration

+ [ ] Add Stanford Lisa Borland course MSE448 Big Financial Data for Algorithmic Trading (in Python)
http://web.stanford.edu/class/msande448/

+ [ ] Create slides for Engle-Granger two-step cointegration procedure, Augmented Dickey Fuller ADF test
1. identify cointegrated pairs in a portfolio of assets - heatmap,
2. calculate standard error of cointegration factor, 
3. test persistence of cointegrated pairs out-of-sample,
4. identify cointegrated portfolios from cluster analysis,
5. apply ADF test to pairs and portfolios
use sources in: ## trading cointegration pairs trading statistical arbitrage
https://github.com/matthewclegg/egcm
https://github.com/mikeschmitt/pairs-trading
https://www.quantstart.com/articles/Cointegrated-Augmented-Dickey-Fuller-Test-for-Pairs-Trading-Evaluation-in-R
http://gekkoquant.com/2012/10/21/statistical-arbitrage-correlation-vs-cointegration/
http://gekkoquant.com/2012/12/17/statistical-arbitrage-testing-for-cointegration-augmented-dicky-fuller/
http://gekkoquant.com/2017/01/23/investigation-into-the-power-of-co-integration-mean-reversion-tests/
http://davegiles.blogspot.com/2011/04/testing-for-granger-causality.html  
http://davegiles.blogspot.com/2015/10/cointegration-granger-causality.html
http://davegiles.blogspot.com/2011/10/var-or-vecm-when-testing-for-granger.html
http://davegiles.blogspot.com/2016/05/forecasting-from-error-correction-model.html
http://denizstij.blogspot.com/2013/11/stationary-tests-of-time-series-within-r.html
http://denizstij.blogspot.com/2013/11/cointegration-tests-adf-and-johansen.html
https://quant.stackexchange.com/questions/34460/granger-causality-with-stocks-and-cds
https://quant.stackexchange.com/questions/15948/two-correlated-time-series-driver-and-follower/15950
https://quant.stackexchange.com/questions/14865/detecting-and-measuring-lead-lag-effect
https://en.wikipedia.org/wiki/Granger_causality

+ [ ] Adapt from package egcm for Engle-Granger two-step cointegration procedure
https://github.com/matthewclegg/egcm

+ [ ] unit root tests, cointegration, and VAR vector autoregressive models, spurious correlation example  
C:\Research\R\Tutorials\Zivot\Econ 584\Zivot Cointegration.pdf  
Zivot Cointegration Tests.pdf
Zivot VAR Vector Autoregressive Time Series Models.pdf
Phillips-Ouliaris test for cointegration  

+ [ ] Expand on spurious time series regression
http://r-datameister.blogspot.com/2013/12/spurious-regression-of-time-series.html
http://davegiles.blogspot.com/2012/05/more-about-spurious-regressions.html
https://eranraviv.com/spurious-regression-illustrated/
https://eranraviv.com/how-regression-statistics-mislead-experts/

+ [ ] Create slides explaining Johansen test
Demonstrate that unit root test power is poor, by simulating and testing almost stationary ARIMA process. 
The power and size of unit root tests are poor. 
The test's weak power means that they cannot distinguish between a unit root process and a fractionally integrated series with long memory (Baillie, 1996)
Johansen Cointegration.pdf
SVD subset selection: 
Lewis RFinance 2012 Cointegration SVD.pdf
Doornik Cointegration Analysis SVD QR.pdf
https://www.quantstart.com/articles/Johansen-Test-for-Cointegrating-Time-Series-Analysis-in-R
http://www.spiderfinancial.com/support/documentation/numxl/users-guide/statistical-testing/cointegration-test
https://quant.stackexchange.com/questions/8494/cointegrating-relationships-johansen-in-r
https://quant.stackexchange.com/questions/3526/how-to-interpret-results-of-johansen-test
https://quant.stackexchange.com/questions/2076/how-to-interpret-the-eigenmatrix-from-a-johansen-cointegration-test?
https://quant.stackexchange.com/questions/25212/johansen-cointegration-test-interpretation-in-r
http://quant.stackexchange.com/questions/18581/johansen-test-on-two-stocks-for-pairs-trading-yielding-annoying-results
http://r.789695.n4.nabble.com/Testing-for-cointegration-Johansen-vs-Dickey-Fuller-td926500.html

+ [ ] Determine the lead-lag relationships between asset returns from their correlations  
Find which one leads by applying VAR model and Granger causality test.
Study the effect of longer lookback intervals.
Wu Leader Lagged Correlation.pdf
vars Vignette.pdf
VAR Models.pdf
DeMiguel VAR Model Stock Selection Forecasting.pdf
Ni Bayesian VAR Model Estimation.pdf
Barigozzi Nets Lasso Network Estimation for Time Series.pdf

+ [ ] Vector Autoregressive VaR Models
Christian Brownlees VAR autoregressive model with LASSO shrinkage package nets
vars.pdf
https://github.com/ctbrownlees/R-Package-nets

+ [ ] Create slides for pairs trading  
1. trade pairs in-sample and out-of-sample,
2. demonstrate that using ensemble of cointegration factors produces higher Sharpe out-of-sample. 
use sources in: ## trading cointegration pairs trading statistical arbitrage
http://quantdevel.com/public/html/testForCoint.html
http://www.rfortraders.com/lecture-4-regression-and-pairs-trading/
http://gekkoquant.com/2013/01/21/statistical-arbitrage-trading-a-cointegrated-pair/
https://stackoverflow.com/questions/24051503/filter-xts-objects-by-common-dates
https://github.com/dankim93/Pairs-Trading-Project
C:\Research\R\Tutorials\Pairs-Trading-Project-master
https://github.com/Jackal08/QuantInsti-Final-Project-Statistical-Arbitrage
https://www.linkedin.com/pulse/statistical-arbitrage-strategy-r-jacques-joubert
https://github.com/justinlent/PairTradeR

+ [ ] Adapt pairs trading from package PairTrading (removed from CRAN)
http://mockquant.blogspot.com/2011/10/introduction-to-pairtrading-package.html

+ [ ] Adapt from packages partialCI and partialAR for partial cointegration procedure
https://github.com/matthewclegg/partialCI
https://github.com/matthewclegg/partialAR

+ [ ] Explain steps of statistical arbitrage
1. determine cointegrated portfolio either using Engle-Granger two-step cointegration procedure, or Johansen VAR and VECM models.
2. estimate time-varying portfolio weights using stochastic control.
3. determine optimal trading parameters and stop-loss.

+ [ ] Trade Hurst model
http://timelyportfolio.blogspot.com/2011/06/exploring-market-with-hurst.html
Qian Rashid Hurst Predictability.pdf

+ [ ] WRDS research database SAS sample queries
https://wrds-web.wharton.upenn.edu/wrds/research/applications/index.cfm

+ [ ] WRDS research database SAS query replicating the momentum strategies of Jegadeesh and Titman - momentum crashes
https://wrds-www.wharton.upenn.edu/pages/support/replicating-momentum-strategies-jegadeesh-and-titman-jf-1993/

+ [ ] Files sp500_ohlc_prices.Rdata and sp500_ohlc_prices_permno.csv contain the data frame sp500_ohlc_prices  
File sp500_1997.csv contains S&P500 index constituents from 1997. 
Map PERMNO to gvkey and vice versa in file sp500_1997.csv using CRSP_Compustat_merged.csv
Aggregate by PERMNO to find the TICKER symbols assigned to PERMNO.
Aggregate by PERMNO into an environment of OHLC time series with volumes and adjustment factors.

+ [ ] WRDS database overview CRSP, Compustat, tickers, identifiers, conventions, formats
Compustat uses GVKEY identifier.
CRSP uses PERMNO and PERMCO identifiers.
https://wrds-web.wharton.upenn.edu/wrds/research/applications/linking/CRSP_COMPUSTAT_merged/
http://www.ruidaiwrds.info/data/linking-crsp-and-compustat
https://wrds-web.wharton.upenn.edu/wrds/query_forms/navigation.cfm?navId=120
The CRSP/Compustat Merged Database (CCM) contains only Compustat data items, but can be searched by CRSP's PERMNO and PERMCO in addition to Compustat's GVKEY. 
Merging this data with the CRSP stock data requires an additional step.

+ [ ] linking CRSP and Compustat databases
http://www.ruidaiwrds.info/data/linking-crsp-and-compustat
https://libguides.princeton.edu/MatchFinancial

+ [ ] Add tidyquant by Matt Dancho
Integrates the quantitative analysis functionality of xts/zoo, quantmod ttr and performance analytics.
Designed for the data science workflow of the tidyverse.
https://github.com/mdancho84
https://www.linkedin.com/pulse/introduction-portfolio-returns-jonathan-regenstein/

+ [ ] Constant Proportion Portfolio Insurance (CPPI)

+ [ ] Add cheatsheet slide: coercing objects to and from time series: xts(), as.numeric(), zoo::coredata(), 

+ [ ] Add cheatsheet slide: how to explore and inspect objects: class(), dim(), attributes(), str(), summary()

+ [ ] Ross Bennett:
file:///C:/Research/R/Packages/PortfolioAnalytics%20Bennett/presentation.html
C:\Research\R\Packages\PortfolioAnalytics\R\optimize.portfolio.R
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r
http://comisef.wikidot.com/tutorial:tangencyportfolio
http://www.calculatinginvestor.com/2011/06/07/efficient-frontier-1/
http://www.calculatinginvestor.com/2011/06/14/efficient-frontier-part-2/

+ [ ] Guy Yollin package MPO for book "Modern Portfolio Optimization"
C:\Research\R\Packages\mpo\pkg\R
C:\Research\R\Packages\mpo\kirk\MVO\constraints_tutorial.pdf
C:\Research\R\Packages\mpo\kirk\MVO\efront.constrained.r
C:\Research\R\Packages\mpo\kirk\MVO\efrontplot.shiny.R

+ [ ] Add package ROI (R Optimization Infrastructure): interface to the Rglpk package and the quadprog package to solve linear and quadratic programming problems  
Solves convex optimization problems: maxmimize portfolio return subject leverage
ECON457 R lab 3 Optimization in R: ROI_lab03.Rmd ROI_lab03.nb
https://moderndata.plot.ly/portfolio-optimization-using-r-and-plotly/

+ [ ] Create estimator of slope (returns), equal to difference of prices over lookback interval, and study the bias-variance tradeoff  
Simulate prices as the sum of deterministic sine function plus stochastic normal noise.
The objective is to estimate the slope of the deterministic sine function.
Create estimator of the slope of prices equal to the difference of prices over lookback interval. 
Demonstrate that the estimator variance increases with shorter lookback interval.
Demonstrate that the estimator bias increases with longer lookback interval.
Calculate the lookback interval with optimal bias-variance tradeoff and best performance.
Demonstrate that the optimal lookback interval increases with higher noise level.

+ [ ] Create strategy with EWMA indicator equal to difference of two EWMAs: short lookback interval minus long lookback interval  
Demonstrate that indicator is related to slope of price curve, and plot both.
Calculate correlations between indicators with different EWMA parameters, and create heatmap of correlations over matrix of EWMA parameters, to demonstrate that correlations are very high.
Implement binary trading rule, with the position equal to the absolute value of the lagged EWMA indicator (flips to long when the short EWMA crosses over the long EWMA from below, and flips to short when the short EWMA crosses over the long EWMA from above).
Implement trading rule that trades continuously with position proportional to the EWMA indicator.
Create heatmap of EWMA strategy PnL over matrix of EWMA parameters.
Find optimal parameters in-sample.
Demonstrate that the indicator is autocorrelated, so it may be better to trade on the forecasts of the indicator, instead of the indicator itself.
Demonstrate that the forecasts of the indicator are equal to the indicator differences over a lag period, and are related to the price curvature (second derivative of prices).  Plot the indicator forecasts and the price curvature.
Demonstrate that the indicator forecasts have high variance, so it's better to use more biased forecasts with more lag.
Study the bias-variance tradeoff of the forecasts of the indicator as a function of the lag period.

+ [ ] Create simple EWMA strategy: trend-following and mean-reverting
Find optimal parameters in-sample.
Demonstrate that the Sharpe of returns optimized in-sample decrease with the length of time series.

+ [ ] Find optimal in-sample parameters over rolling windows, and demonstrate that optimal parameters have zero autocorrelation to each other.

+ [ ] Create EWMA strategy using average over whole range of parameters, and demonstrate that it outperforms out-of-sample any single EWMA strategy with parameters optimized in-sample.

+ [ ] Demonstrate that the EWMA volatility estimator is an example of shrinkage and bias-variance tradeoff  
Simulate Brownian motion with deterministic, time-dependent volatility, and estimate the volatility using different EWMA lambda parameters.
Calculate the MSE of the volatility estimator, and find the lambda parameter which minimizes the MSE.
Demonstrate that the optimal lambda parameter depends on the signal-to-noise ratio and the rate at which volatility changes.
http://eranraviv.com/shrinkage-in-statistics/

+ [ ] Demonstrate bias-variance tradeoff when estimating volatility using EWMA
create study of bias-variance tradeoff using volatility estimation example:  
http://scott.fortmann-roe.com/docs/BiasVariance.html  
create xts of random prices with changing time-dependent deterministic vol parameter,  
estimate volatility use look-back interval parameter,  
too short look-back interval increases variance,  
too long look-back interval increases bias,  
tune filter parameters in-sample: study bias-variance tradeoff,  
create rCharts and shiny visualizations  
plot MSE as function of lambda

+ [ ] Demonstrate that for zero correlations, the optimal portfolio coefficients are equal to the t-values (Sharpe ratios) of the assets.

+ [ ] Simulate Adaptive Asset Allocation strategy: momentum rank + min-variance optimization
Sharpe Adaptive Asset Allocation.pdf
Gestalt Adaptive Asset Allocation.pdf
https://quantstrattrader.wordpress.com/2016/03/01/a-book-review-of-resolve-asset-managements-adaptive-asset-allocation/
ReSolve Asset Management by michael philbrick, adam butler, and rodrigo gordillo
http://www.investresolve.com/
http://www.investresolve.com/robo/research/

+ [ ] Simulate momentum strategy based on P/E ratios  
Gray PE Ratio Momentum Stock Forecasting.pdf

+ [ ] Simulate momentum strategy Elastic Asset Allocation using package IKTrading
Keller (2014) Elastic Asset Allocation  
https://quantstrattrader.wordpress.com/2015/01/30/comparing-flexible-and-elastic-asset-allocation/  
+ [ ] Flexible Asset Allocation returns algorithm  
Keller Elastic Asset Allocation.pdf  

+ [ ] Study intraday seasonality  
Demonstrate intraday volume seasonality in hfreq data.
Calculate intraday seasonality of trading volumes in high frequency data.

+ [ ] Simulate binomial volatility pumping harvesting
demonstrate that long-term portfolio returns increase thanks to rebalancing
demonstrate that positive expected logarithmic growth rate can be achieved even when both assets individually have negative expected logarithmic growth rates.
Witte Trading Volatility Pumping Harvesting.pdf

+ [ ] Calculate skew as difference between bull-market and bear-market betas
Calculate the betas using OHLC prices.
Granger CAPM Beta Skew.pdf

+ [ ] Calculate bull-market and bear-market betas using only positive or negative returns: the difference between bearish minus bullish betas is equal to the convexity
Is this convexity a good indicator?
http://jonathankinlay.com/2017/05/beta-convexity/

+ [ ] measures of dispersion: demonstrate that ratio of STDEV over MAD is related to kurtosis  

+ [ ] Calculate the standard errors of VaR and CVaR  
demonstrate that the standard error increases with the confidence level, because the number of observations decreases
demonstrate that the standard error decreases as the size of the lookback window increases, because the number of observations increases
show that VaR has a huge standard error and is therefore useless
show that CVaR has a bigger standard error than VaR
CVaR has an even bigger standard error than VaR, and is therefore useless for very large number of risk factors estimated using short span of data. 
Jon Danielsson and Chen Zhou have demonstrated that to accurately estimate CVAR at 5% confidence would require decades of price history, something that simply doesn't exist for many assets.
Danielsson CVAR Estimation Standard Error.pdf
http://www.bloomberg.com/view/articles/2016-05-23/big-banks-risk-does-not-compute
# reproduce these plots
http://www.modelsandrisk.org/VaR-and-ES/

+ [ ] Create slides about creating R packages and rcpp packages

+ [ ] Create an R package from cpp code and compile it using Rcpp

+ [ ] Demonstrate that portfolio optimization is extremely sensitive to small changes in assumptions: plot efficient frontiers for slightly different returns
http://www.pionline.com/article/20031222/PRINT/312220715/markowitz-says-michaud-has-built-a-better-mousetrap
Portfolio optimizers amplify errors in expected returns.

+ [ ] Adapt robust portfolio optimization by incorporating estimation errors: 
Lai Robust Portfolio Optimization.pdf
study Lai's NPEB estimator (has great out-of-sample performance)
Ceria Robust Portfolio Optimization.pdf
Portfolio optimization with bootstrap and shrinkage.
Jin Robust Portfolio Optimization.pdf
Ban Robust Portfolio Optimization.pdf
DeMiguel Parameter Uncertainty Multiperiod Portfolio Optimization Transaction Costs.pdf
DeMiguel Shrinkage Portfolio Optimization.pdf
DeMiguel Shrinkage Estimators Portfolio Optimization.pdf
Becker Robust Portfolio Optimization.pdf
Michaud Portfolio Resampling.pdf

+ [ ] Michaud Resampled Efficiency Portfolio Optimization (patented)  
Resampled random portfolios performs better out-of-sample.
https://en.wikipedia.org/wiki/Resampled_efficient_frontier
https://newfrontieradvisors.com/Research/Articles/MichaudResampledEfficiency.html  
https://systematicinvestor.wordpress.com/2011/11/11/resampling-and-shrinkage-solutions-to-instability-of-mean-variance-efficient-portfolios/  
Michaud Portfolio Resampling.pdf

+ [ ] Demonstrate tha combining the 1/N portfolio with the Markowitz portfolio improves out-of-sample performance  
Adapt from: Tu Rolling Portfolio Optimization.pdf.
The 1/N rule outperforms Markowitz out-of-sample.
The MacKinlay and Pastor strategy also performs well out-of-sample.

+ [ ] Adapt from Pav code for Cochrane Asset Pricing  
https://github.com/shabbychef/coursera_ap2013  

+ [ ] Adapt trending Ornstein-Uhlenbeck, stochastic time series Feynman-Kac Theorem, Girsanov Theorem from:
Thierfelder Ornstein-Uhlenbeck Process.pdf

+ [ ] Adapt from: quantbros  
http://quantbros.com/category/tutorial/

+ [ ] Explain Optimism of the Training Error Rate
http://eranraviv.com/optimism-training-error-rate/
https://stats.stackexchange.com/questions/88912/optimism-bias-estimates-of-prediction-error

+ [ ] Explain Fama-MacBeth two-pass regressions to explain cross-sectional returns/values by factors  
Fama-MacBeth two-pass regressions to explain cross-sectional returns/values by factors  
Cochrane Asset Pricing.pdf  
Campbell Market Factors Stock Forecasting.pdf  
Harvey Bootstrap MacBeth Factor Models.pdf  
http://quant.stackexchange.com/questions/16855/how-to-test-the-5-factor-capm-of-fama-french-2014  
http://quant.stackexchange.com/questions/17125/please-give-a-step-by-step-explanation-on-how-to-build-a-factor-model
http://quant.stackexchange.com/questions/8697/r-fast-and-efficient-way-of-running-a-multivariate-regression-across-a-really
factorAnalytics fitTsfm_vignette.pdf

+ [ ] Create shiny dashboard with Fama-French model
https://www.linkedin.com/pulse/r-shiny-fama-french-jonathan-regenstein
https://www.interactivebrokers.com/en/index.php?f=25244&vid=18409

+ [ ] Explain Fama-French model, Barra model
http://quant.stackexchange.com/questions/16855/how-to-test-the-5-factor-capm-of-fama-french-2014  
http://quant.stackexchange.com/questions/17125/please-give-a-step-by-step-explanation-on-how-to-build-a-factor-model
http://quant.stackexchange.com/questions/8697/r-fast-and-efficient-way-of-running-a-multivariate-regression-across-a-really
factorAnalytics fitTsfm_vignette.pdf
analyze function fitFfm()  
Perform sorts on the "stock" data frame from factorAnalytics - file Stock.df.RData
stock is used by function fitFfm()

+ [ ] Add Cauchy distribution to plotting.Rnw or risk_models.Rnw  
https://rviews.rstudio.com/2017/02/15/some-notes-on-the-cauchy-distribution/

+ [ ] Pricing anomalies: size, value, momentum, volatility  

+ [ ] Estimate correlation matrix for synthetic, colinear time series: study how correlation matrix becomes singular as one column of time series becomes colinear with the others

+ [ ] Create slides for categorizing S&P500 constituents using equity sector data.
create cap-weighted sub-portfolios: plot their performance, calculate rolling betas, etc.
Calculate sector correlations and heatmaps.

+ [ ] Create random OHLC data and pass it through EWMA strategy to test for data snooping

+ [ ] Create rebalancing strategy for portfolio with two assets: stock index plus bond index  
http://www.capitalspectator.com/portfolio-analysis-in-r-a-6040-us-stockbond-portfolio/  
Create portfolio return scatterplot and show that it's negatively skewed, because rebalancing strategy is equivalent to selling put options  
Demonstrate that a strategy using asset rebalancing to maintain constant market value adds risk  
Granger Portfolio Rebalancing Momentum Trend Following.pdf  
Qian Asset Allocation Portfolio Rebalancing Alpha.pdf  
Qian Asset Allocation Portfolio Rebalancing.pdf  

+ [ ] Create EWMA mean-reverting strategy with large tail risk: demonstrate that it's like selling far out-of-money options, and that it has very high Sharpe, but that it infrequently blows up

+ [ ] Simulate stop loss trading rule, and demonstrate that it only works in trending markets, but loses money in mean-reverting markets

+ [ ] Create Bollinger bands mean-reversion strategy

+ [ ] Create interactive dygraphs or plotly by first pre-calculating model output time series and saving to file, and passing the data through plotting function

+ [ ] Create Rcpp function for range volatility estimator  
http://quant.stackexchange.com/questions/2589/how-to-calculate-historical-intraday-volatility/3264#3264

+ [ ] Create slides for Rcpp using Rcpp RFinance_2015.pdf, Rcpp Getting Started.pdf, and RcppExamples.pdf
http://gallery.rcpp.org/articles/first-steps-with-C++11/
http://adv-r.had.co.nz/Rcpp.html

+ [ ] Rcpp: adapt from Farnsworth Econometrics in R.pdf: Calling C functions from R

+ [ ] Rcpp: create simple Rcpp function with logistic map - adapt from LearningRcpp  
https://github.com/rossb34/LearningRcpp

+ [ ] Adapt parallel Rcpp C++ code from packages roll by Jason Foster and RcppMovStat
https://cran.r-project.org/web/packages/roll/index.html  
https://github.com/jjf234/roll
https://github.com/peleonard/RcppMovStat


+ [ ] Adapt Rcpp C++ code from package RcppRoll by Kevin Ushey  
Install the package RcppRoll as follows:
install.packages("RcppRoll")
https://cran.r-project.org/web/packages/RcppRoll/index.html
https://github.com/kevinushey/RcppRoll

+ [ ] Create Rcpp function to perform parallel bootstrap in C++  
http://www4.stat.ncsu.edu/~reich/BigData/code/boot.html
http://www.onthelambda.com/2014/06/27/squeezing-more-speed-from-r-for-nothing-rcpp-style/
https://blog.rstudio.org/2016/01/15/rcppparallel-getting-r-and-c-to-work-some-more-in-parallel/
https://rcppcore.github.io/RcppParallel/
https://github.com/RcppCore/RcppParallel
https://github.com/RcppCore/Rcpp
http://gallery.rcpp.org/articles/rcpp-sgd/

+ [ ] Create functions that call ML C++ libraries based on packages RcppShark and RcppMLPACK

+ [ ] Fit VTI returns into t-dist and Generalized Lambda Distribution (GLD) by using Method of Moments:
https://www.r-bloggers.com/quantitative-finance-applications-in-r-4-using-the-generalized-lambda-distribution-to-simulate-market-returns/
https://www.r-bloggers.com/the-generalized-lambda-distribution-and-gldex-package-fitting-financial-return-data/

+ [x] Add slide about VIX crash on February 5th 2018

+ [x] Introduce SVXY short VIX futures ETF

+ [x] Chain futures data

+ [x] Add package iBrokers to thematic slides file data_management.Rnw

+ [x] Add package data.table to thematic slides file data_management.Rnw

+ [x] Principal component regression PCR

+ [x] Explain how to create pairs and portfolios in Interactive Brokers
https://www.interactivebrokers.com/en/index.php?f=744

+ [x] Calculate coefficients of multiple linear regression using function solve()

+ [x] Add formula for slope of tangency portfolio using derivative of efficient frontier.
Compute tangency portfolio in two different ways: from derivative of efficient frontier, and from Sharpe portfolio weights.

+ [x] Calculate the efficient frontier under sum of weights constraint using matrix algebra in two steps:
Calculate the minimum variance portfolio
Calculate the minimum variance portfolio under the constraint that it has a fixed target return
Demonstrate that efficient frontier is a parabola in sigma-squared-mu space
Demonstrate that efficient frontier is a hyperbola in sigma-mu space

+ [x] Demonstrate that the PCA with the smallest eigenvalue is the minimum variance portfolio

+ [x] Demonstrate that GARCH model returns have excess kurtosis, and fit them into t-distribution

+ [x] Perform Principal Component Analysis PCA by hand using optimization
update time_series_multivariate.Rnw

+ [x] Simulate Ornstein-Uhlenbeck OU process using Rcpp

+ [x] Demonstrate that a combination of momentum and static buy-and-hold strategies produces a better Sharpe ratio than the individual strategies alone

+ [x] Create slides for improved version of Performing Overlapping Aggregations in investment_strategies.Rnw

+ [x] Create shiny interactive plot of EWMA strategy 

+ [x] Demonstrate that returns of trend-following and mean-reverting strategies are negatively correlated
demonstrate that a combination of trend-following and mean-reverting strategies has better Sharpe ratio than the individual strategies

+ [ ] Create option examples from GARPFRM package  
demonstrate that call option returns have more positive skew than underlying asset
C:\Develop\R\fin_engine\vignettes
http://rossb34.github.io/GARPFRM_shiny/
optionSpec()
optionValue()
impliedVolatility()
computeGreeks()


# company identifiers symbols codes

CRSP codes
http://www.crsp.com/products/documentation/entity-keywords-and-usage
CRSP PERMNO, (permanent and unique 5-digit issue identification number assigned by CRSP) of an issue
CRSP PERMCO, (permanent and unique 5-digit company identification number assigned by CRSP) of an issue

SEC EDGAR codes
CIK (Central Index Key)  This is a publicly available number the SEC assigns to each filer. ...
CCC (CIK Confirmation Code)  A filer uses this code, in conjunction with a CIK number, in an EDGAR submission to verify its identity.

###

Sharadar discount
INPAV-100P-HWNT_SF0

###

+ [ ] specify sources of historical point-in-time fundamental data

+ [ ] scrape fundamental data from Yahoo or Google using getFinancials() from package quantmod
compare the fundamental data obtained from different sources
get stock statistics from Yahoo using XML, quantmod, plyr packages
http://allthingsr.blogspot.com/2012/10/pull-yahoo-finance-key-statistics.html
http://stackoverflow.com/questions/3693189/programmatic-api-for-downloading-historical-financial-statements

+ [ ] Download from Quandl RAYMOND financial ratios data for a list of companies
Fundamental data on Quandl is all premium.
harmonized database site:quant.stackexchange.com
https://www.quandl.com/data/RAYMOND-Raymond
https://www.quandl.com/data/RAYMOND-Raymond/documentation/documentation
http://quant.stackexchange.com/questions/17315/where-can-i-get-historical-fundamental-data-for-multiple-companies-in-a-single-c
http://quant.stackexchange.com/questions/22339/data-exported-from-capital-iq-factset-bloomberg-compustat

+ [ ] Add package TAQMNGR for processing high frequency data after it's downloaded from WRDS
# TAQMNGR processes raw data from WRDS (Wharton Research Data Service)
http://cran.r-project.org/web/packages/TAQMNGR/

+ [ ] quandl S&P500 index constituents
https://gist.github.com/ttmmghmm/28e88fbf4c20a15cbfb3

+ [ ] Adapt from Hugen WRDS Value Strategies.pdf

+ [ ] Download from WRDS S&P500 Stock index constituents and prices  
https://wrds-web.wharton.upenn.edu/wrds/query_forms/navigation.cfm?navId=84
https://faq.library.upenn.edu/business/faq/45457
https://lippincottlibrary.wordpress.com/2014/09/24/a-few-wrds-about-the-sp-500/
https://asklib.library.hbs.edu/friendly.php?slug=faq/47512

+ [ ] Download company fundamental data from WRDS
https://wrds-web.wharton.upenn.edu/wrds/query_forms/navigation.cfm?navId=84
https://wrds-web.wharton.upenn.edu/wrds/demo/demoform_compustat.cfm
https://wrds-web.wharton.upenn.edu/wrds/ds/comp/fundafinstat/index.cfm

+ [ ] recreate CRSPpanel.txt fundamental financial data for 265 S&P500 stocks  
trellis plots  
nice barchart, dotplot, bwplot, and data munging  

+ [ ] Download fundamental financial ratios data using quantmod
# Google query:
r quantmod fundamental data

+ [ ] Download U.S. stock fundamental data from simfin, based on reports submitted to EDGAR SEC
https://simfin.com/

+ [ ] Create slide for Dow Jones Industrial Average DJIA stock index

# S&P 500 index data
https://github.com/datasets
https://github.com/datasets/s-and-p-500
# List of companies in the S&P 500 index together with associated financials
https://github.com/datasets/s-and-p-500-companies

http://data.okfn.org/data/core/s-and-p-500-companies

https://github.com/alexchinco/CRSP-Data-Summary-Statistics-by-Industry-

+ [ ] WRDS and R using package DBI
https://wrds-web.wharton.upenn.edu/wrds/support/Accessing%20and%20Manipulating%20the%20Data/_007R%20Programming/_001Using%20R%20with%20WRDS.cfm
https://wrds-web.wharton.upenn.edu/wrds/support/Accessing%20and%20Manipulating%20the%20Data/_001Access%20Methods.cfm

+ [ ] WRDS dataset list
https://wrds-web.wharton.upenn.edu/wrds/tools/variable.cfm
# example SAS queries for TAQ
https://wrds-web.wharton.upenn.edu/wrds/support/Data/_003Sample%20Programs/TAQ/index.cfm

+ [x] Create shiny for two EWMA strategy, with performance in output

+ [x] Add slide for shiny plots

+ [x] Create shiny for EWMA model and assign it as homework

+ [x] Simulate geometric Brownian motion

+ [ ] slides for package h5 for hdf5 files

+ [ ] slides with script to load and analyze hdf5 file train.h5 with kaggle data

+ [ ] Black-Litterman model
http://www.blacklitterman.org/
https://systematicinvestor.wordpress.com/2011/11/16/black-litterman-model/
https://cran.r-project.org/web/packages/BLCOP/

+ [ ] Neural network trading example package nnet
adapt from: C:/Develop/R/scripts/Torgo_stock_trading.R  
http://www.dcc.fc.up.pt/~ltorgo/DataMiningWithR/code3.html

+ [ ] Create XIV VXX ZIV strategies
http://www.wikinvest.com/index/Volatility_Index_(VIX)

+ [ ] MUD statistical arbitrage trading strategy: sell the quantile of stocks that are up the most, and buy the quantile that are down the most  

+ [ ] Add to time_series_multivariate  
show that CAPM holds by construction when the market portfolio is chosen to be the efficient frontier (maximum Sharpe) portfolio.  
CAPM model is another way of saying that the market portfolio is the maximum Sharpe portfolio and lies on the efficient frontier. 
Can Security Market Line (SML) be derived from Capital Market Line (CML)?  
Yes, because if we choose the most efficient portfolio (maximum Sharpe) as the reference (market) portfolio for CAPM, then the idiosyncratic asset returns will have a cumulative sum equal to zero.  
When the market portfolio is chosen to be the maximum Sharpe portfolio, then the sums of idiosyncratic returns are zero, and all assets lie exactly on the Security Market Line (SML). 
When individual asset returns are regressed on the efficient (maximum Sharpe) portfolio returns, then their idiosyncratic residuals are uncorrelated to the efficient portfolio returns, because if they weren't then a more efficient portfolio could be constructed using those residuals.  
But the idiosyncratic returns can be correlated with each other.  
individual asset variance is the sume of beta squared times market variance plus idiosyncratic variance

+ [ ] Add to section Portfolio Optimization
two-asset portfolio
portfolio constraints: box and leverage
\subsection{Portfolio Leverage Constraint Optimization}
efficient frontier
portfolio return objectives
https://datashenanigan.wordpress.com/2016/05/24/a-gentle-introduction-to-finance-using-r-efficient-frontier-and-capm-part-1/

+ [ ] Fix slide Random Portfolios in portfolio_construction: don't scale by 100 and include risk-free rate  

+ [ ] Kyle Balkissoon overnight effect R/Finance presentation - lame
C:\Research\R\R-Finance 2016\KyleBalkissoon.pdf

+ [ ] Kyle Balkissoon: Portfolio Optimization - only PortfolioAnalytics
http://kkb.io/2016/10/26/portfolio-optimization/

+ [ ] Fix lecture slides prepared with older version of package factorAnalytics  

+ [ ] Demonstrate that an ensemble of VWAP strategies outperforms any single VWAP strategy
an ensemble of VWAP strategies is a combination of VWAP strategies with all possible window parameters.

+ [ ] Jensen alpha examples of how alpha can be generated: either by timing the market and by selecting optimal portfolio ex-post (through hindsight)  
calculate Jensen alpha for SPX (for example) and demonstrate that it's close to zero  
calculate Jensen alpha for timed SPX: buy SPX at lows and sell at highs  
calculate Jensen alpha for ex-post portfolio: optimize portfolio in-sample to obtain highest alpha  

+ [ ] Add risk-free rate to PortfolioAnalytics code  

+ [ ] Simulate volatility targeting strategy  
https://seekingalpha.com/article/3280795-a-random-beat-down-of-wall-street

+ [ ] Add stylized facts of asset return distributions
statistical empirical properties of asset returns
fat tails
time dependent volatility
autocorrelation of volatility
assymetric volatility: higher when prices drop
volume and correlation increase with volatility
Cont Empirical Stylized Facts Asset Returns.pdf
Cont Volatility Clustering AgentBased Models.pdf

+ [ ] Create risk parity strategy
First day of every month, sell all portfolio holdings at market. Same day, buy 50 random stocks from the S&P500 constituents. Weight positions by inverse volatility, i.e. simple vola parity sizing. Always be fully invested.
http://www.followingthetrend.com/2015/06/a-random-ass-kicking-of-wall-street/
# risk parity by Bridgewater Associates
https://www.linkedin.com/pulse/our-thoughts-risk-parity-all-weather-ray-dalio
# review of risk parity
http://unstarched.net/2013/12/17/a-review-of-risk-parity/ 

+ [ ] implement minimum variance, risk parity, HRP, and maximum diversification portfolios, and backtest their performance
Choueifaty Maximum Diversification Portfolios.pdf
Choueifaty Maximum Diversification Portfolios JPM.pdf
Clarke Maximum Diversification Portfolios.pdf
Qplum Maximum Diversification Portfolios.pdf
Lohre Maximum Diversification Risk Parity.pdf
Meucci Diversification Optimization.pdf
Damschroder Maximum Diversification Portfolios
https://quant.stackexchange.com/questions/7905/how-to-implement-maximum-diversification-in-r

+ [ ] introduce Hierarchical Risk Parity (HRP), the Gerber Statistic, and the Critical Line Algorithm (CLA)  
http://gallery.rcpp.org/articles/hierarchical-risk-parity/
https://github.com/RcppCore/rcpp-gallery/blob/gh-pages/src/2016-05-27-HRP.Rmd
http://nextlevelanalytics.github.io/2016/05/30/Gerber_Statistic_and_Hierarchical_Risk_Parity/

+ [ ] Explain that (taken from Prado Portfolio Optimization Hierarchical Risk Parity slides.pdf):
The condition number of a covariance matrix is the ratio between its highest and smallest (in moduli) eigenvalues.
The more correlated the assets, the higher the condition number, and the more unstable is the inverse matrix.
Demonstrate the above using synthetic data - create a shiny app.

+ [ ] Merton model: simulate dynamic investment and consumption strategies  
stochastic control theory 
Merton Dynamic Consumption and Portfolio Choice  
simulate Merton consumption wealth model  
Guasoni Merton Optimal Consumption Utility Shortfall Aversion.pdf  
An Merton Utility Asset Allocation.pdf  
https://en.wikipedia.org/wiki/Intertemporal_portfolio_choice  
https://en.wikipedia.org/wiki/Merton%27s_portfolio_problem  

+ [ ] TTR rolling regression: analyze rollSFM(), and create script with its code, and create example of using rollSFM()
rollSFM()

+ [x] Performing rolling aggregations
TTR rolling aggregations:
runSD()
runMedian()
runMAD()
explain, summarize, and benchmark rolling functions over margins:
package stats: runmed()
package zoo: rollmean()
package TTR: runMAD()
package caTools: runmad()

+ [ ] Study tenor (maturity) dependence of mean, variance, skewness, and kurtosis
show that skewness and kurtosis decay with time

+ [ ] Calculate tail shape of return frequency distribution and demonstrate power law

+ [ ] High-Frequency Financial Data Analysis
C:\Research\R\Tutorials\Guy Yollin Presentations
HF Tick Data Analysis.pdf
HFDA.pdf

+ [ ] Create Risk Measures (VaR and ES) examples from package GARPFRM  

+ [ ] Provide examples showing when forecasting and VaR models fail due to human-induced events: CHF currency, corporate events (mergers, takeovers, defaults)

+ [ ] Provide example showing when VaR isn't additive (coherent), show that ES is coherent  

+ [ ] generating random OHLC time series  

+ [ ] implement plotting of xts OHLC time series using candleChart()
http://www.quantmod.com/examples/charting/

+ [ ] Add example forecasting stock returns using Smarket data from package ISLR James book Statistical Learning in R.pdf

+ [ ] Create MUD strategy for S&P500 stocks, and show how performance dropped over time  

+ [ ] incorporate simple scripts for Tactical Asset Allocation System by Mebane Faber
http://petewerner.blogspot.com/2012/04/mebane-faber-tactical-asset-allocation.html
https://github.com/petewerner/misc/blob/master/gtaa-script.R

+ [ ] Create CAPM examples from GARPFRM package  
C:\Develop\R\fin_engine\vignettes
efficient frontiers
http://rossb34.github.io/GARPFRM_shiny/

+ [ ] bootstrapping time series of prices and OHLC time series in parallel  

The no drift assumption is a good approximation when the dimensionless parameter vT/s is small

+ [ ] Demonstrate that aggregating to longer periods (tenor, time scale) makes the distribution of returns more Gaussian and reduces skew and kurtosis
The distributions of returns are increasingly fat-tailed as data frequency increases (smaller interval sizes) and are hence distinctly unstable.
use function to_period() as follows:
aggregate to longer periods
calculate returns, variance, skew, kurtosis, Sharpe
plot distribution of returns
calculate returns using hfreq prices over non-overlapping periods of varying length (tenor)
calculate at different time agg horizons:
	returns, variance, skew, kurtosis, Sharpe
calculate and study the tenor dependence (term structure) of:
mean, variance, skewness, and kurtosis
show that skewness and kurtosis decay with longer tenor
show that mean returns grow like t, 
variance grows like sqrt(t), 
skewness decays like 1/sqrt(t), 
kurtosis decays like 1/t, 
https://quantivity.wordpress.com/2012/10/23/volume-clock-gaps-and-goog/

+ [ ] Demonstrate that using trading time makes the distribution of returns more Gaussian and reduces skew and kurtosis
Easley Volume Clock Trading Paradigm.pdf

+ [ ] Package ROCR for Visualizing the Performance of Scoring Classifiers

+ [ ] nonlinear time series BDS test
fNonlinear.pdf
tseries.pdf

+ [ ] Create plotly portfolo optimization slides
http://moderndata.plot.ly/portfolio-optimization-using-r-and-plotly/

+ [ ] Add plotly OHLC chart examples - create account
https://plot.ly/r/
https://plot.ly/javascript/candlestick-charts/
http://moderndata.plot.ly/interactive-r-visualizations-with-d3-ggplot2-rstudio/
http://moderndata.plot.ly/r-python-matlab-dashboards-graphs-with-d3-js-webgl/
http://moderndata.plot.ly/interactive-r-visualizations-with-d3-ggplot2-rstudio/
https://plot.ly/quandl/?code=GOOG/AMEX_LVOL

+ [x] Add slide for markdown and knitr documents containing interactive charts
Use blog web pages.

+ [x] Explain, summarize, and benchmark rolling functions over endpoints:
rollapply
apply.rolling
period.apply
period.sum

+ [x] Demonstrate that squared returns are autocorrelated, but squared ranges are not autocorrelated  

+ [x] robust measures of centrality, dispersion, and skewness MAD

+ [x] OHLC variance estimators  

+ [x] Explain why range variance estimators have bias and they underestimate variance

+ [x] Explain the effect of aggregation frequency and observation (measurement) units on the time scaling of variance  

+ [x] Create dygraphs slides for time series

+ [ ] Create dygraphs slides for OHLC time series
https://github.com/danielkrizian/rChartsDygraphs
https://github.com/danvk/dygraphs/pull/538
http://dygraphs.com/tests/plotters.html

+ [ ] Create plotly slides for OHLC time series
http://moderndata.plot.ly/candlestick-charts-using-plotly-and-quantmod/

+ [ ] convert all lectures from Sweave LaTeX to knitr R Markdown ?  what about two-column layout?
http://jeromyanglim.blogspot.com/2012/06/how-to-convert-sweave-latex-to-knitr-r.html
http://stackoverflow.com/questions/20934148/sweave-to-r-markdown-file-conversion-code-or-converters-available
http://pandoc.org/

+ [ ] Create online interactive documents using .Rmd files on RPubs  

+ [x] Create package fin_engine, a clone of GARPFRM package  

+ [ ] using hfreq return data, estimate daily data: mean return, variance, skewness and kurtosis
show that daily returns are not autocorrelated, 
show that daily variance is autocorrelated, 
maybe also skewness and kurtosis
fit ARIMA into daily data
fit GARCH model using hfreq data

+ [ ] Adapt code from package deSolve DLL models  

+ [ ] Ryan Haffen trelliscope, tessera

+ [ ] incorporate ideas from and contribute to Matt Brigida Teaching Resources with R/Shiny
https://github.com/Matt-Brigida

+ [ ] Akaike and Bayesian information criteria AIC BIC

+ [ ] Use following data:  
data(package="factorAnalytics")  
C:\Research\R\Packages\factorAnalytics\extdata  
data(package="GARPFRM")  
data(package="mpo")  

+ [ ] QMJ Quality Minus Junk Factor
http://timelyportfolio.blogspot.com/2014/04/all-factors-more-looks.html
qmj package
https://github.com/anttsou/qmj

+ [ ] Supervised Principal Components PCA regression package superpc  
http://statweb.stanford.edu/~tibs/superpc/
http://statweb.stanford.edu/~tibs/superpc/tutorial

+ [ ] Principal component regression PCR and Supervised Principal Components
http://www.milanor.net/blog/performing-principal-components-regression-pcr-in-r/
write full PCR code, then compare with package roll  
create synthetic data and show that PCR outperforms ordinary regression when noise is high  
show that using all the PCAs is equivalent to ordinary regression
https://en.wikipedia.org/wiki/Principal_component_regression

+ [ ] Principal Component PCA clusters example - adapt
https://plot.ly/r/github-getting-started-for-data-scientists/

+ [ ] Perform k-means clustering by hand and compare to Principal Component Analysis PCA
https://predictivealpha.wordpress.com/tag/random-portfolios/

+ [ ] Higher Moments Factor Models  
Boudt Asset Allocation Utility Higher Moments Factor Models.pdf
Boudt Asset Allocation Higher Moments Factor Models.pdf

+ [ ] Modify Security Market Line?  

+ [ ] Random portfolios  
https://seekingalpha.com/article/3967318-trade-like-chimp-unleash-inner-primate
https://predictivealpha.wordpress.com/tag/random-portfolios/
draw scatterplot of random portfolios, model on:
https://quantstrattrader.wordpress.com/2015/09/10/monte-carlo-in-asset-allocation-tests/  
http://www.portfolioprobe.com/2012/02/27/realized-efficient-frontiers/
Novomestky package: rportfolios  
Random portfolios with constraints: random_portfolios from PortfolioAnalytics  
Stein Random Portfolios Fund Analysis.pdf  
Resampling Methods Bootstrap Cross Validation Random Portfolios  
http://quantbros.com/parallelized-simple-random-constrained-portfolio-generation/
TechilaEfficientFrontier.R
http://www.capitalspectator.com/skewed-by-randomness-testing-arbitrary-rebalancing-dates/  
http://www.capitalspectator.com/using-random-portfolios-to-test-asset-allocation-strategies/  
https://gist.github.com/jpicerno1/fbc2e589023be56dde42  
https://gist.github.com/jpicerno1/af88861bcbbb80687cfb  
http://www.burns-stat.com/documents/tutorials/the-statistical-bootstrap-and-other-resampling-methods-2/  

+ [ ] Add Capital Market Line  
plot efficient frontier plus capital market line
http://zoonek.free.fr/blosxom/R/2012-06-01_Optimization.html  
https://gist.github.com/jpicerno1/565be39ca4226ecd004c  
http://www.capitalspectator.com/efficient-frontier-portfolios-impractical-but-still-useful/  
http://moderndata.plot.ly/portfolio-optimization-using-r-and-plotly/
Portfolio optimization: mean-variance efficient portfolios, efficient frontier, Capital Market Line, in portfolio_construction.Rnw

+ [ ] Portfolio optimization with different objective functions - VaR, CVaR,  
Ian Kaplan (UofWash) minimum variance and tangency portfolios, CVaR portfolio optimization, ETF portfolios, Wharton Research Data Service (WRDS) data set and Factor Model Factors  
http://www.bearcave.com/finance/  
using fPortfolio package:  
http://www.bearcave.com/finance/portfolio_equations/  
Shaw Portfolio Optimization CVaR Omega Utility.pdf  
Yollin Optimization.pdf
# uses function portfolio.optim from package tseries
Yollin Portfolio Optimization.pdf

+ [ ] Add package tseries portfolio.optim() for calculating mean-variance efficient portfolios  

+ [ ] Portfolio optimization using optim  
can mean variance portfolio optimization be converted to min variance optimization ?  
different objective functions,  
constraints

+ [ ] Portfolio rebalancing  
C:\Research\R\Packages\PortfolioAnalytics Bennett
C:\Research\R\Packages\PortfolioAnalytics Bennett Random Portfolios Swarm Optimization.pdf
C:\Research\R\Packages\PortfolioAnalytics Bennett\moment_estimation_notes.txt
PortfolioAnalytics Bennett Random Portfolios Swarm Optimization.pdf  
C:\Research\R\Packages\PortfolioAnalytics Bennett  
https://github.com/rossb34/PortfolioAnalyticsPresentation2015  
analyze PortfolioAnalytics function optimize.portfolio.rebalancing()

+ [ ] Zivot bootstrap portfolios - bootstrap mean, sd, weights  
C:\Research\R\Tutorials\Zivot\Econ 424\bootstrapPortfoliosPowerpoint.pdf  
C:\Research\R\Tutorials\Zivot\Econ 424\bootstrapPortfolio.R  

+ [ ] Adapt from C:\Research\R\Packages\PortfolioAnalytics\demo\demo_efficient_frontier

+ [x] mean-variance portfolio optimization using quadratic programming package quadprog
http://www.wdiam.com/2012/06/10/mean-variance-portfolio-optimization-with-r-and-quadratic-programming/
http://blog.ryanwalker.us/2014/01/solving-quadratic-progams-with-rs.html
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r
https://quant.stackexchange.com/questions/31743/dmat-argument-in-solve-qp-r-function-cov-or-2cov

+ [ ] Guy Yollin functions effFrontier() and maxSharpe() call the function portfolio.optim() from package tseries  
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r/  
C:\Research\R\Tutorials\Guy Yollin Presentations  
Levy Alpha Sharpe Portfolio Optimization.pdf  

+ [ ] introduce the Critical Line Algorithm (CLA)  
http://rnfc.org/2015/06/05/Markowitz/
function CCLA()  
Bailey Prado Critical Line Algorithm Portfolio Selection  

+ [ ] introduce the Gerber Statistic  
http://nextlevelanalytics.github.io/2016/05/26/Gerber/

+ [ ] Portfolio Optimization using the Gerber Statistic  
Gerber Statistic Portfolio Optimization.pdf

+ [ ] Adapt description of Ultra High-Frequency Data(UHFD) and exchanges from: Brownlees High Frequency Data Management.pdf

+ [ ] using hfreq prices, calculate beta
calculate separate betas using intraday returns and using overnight returns
calculate separate betas using open-to-close returns and using close-to-open overnight returns
test CAPM
Bollerslev High Frequency Market Factors CAPM Model.pdf

+ [ ] Add slides to section High Frequency and Intraday Time Series Data in risk_models.Rnw
use HighFreq package slides from 2015 presentations RFinance_2015.Rnw and EARL_Boston_2015.Rnw
Running volatility estimation using OHLC data - compare to closing vol
estimate variance of volatility estimator
Volume-Weighted Average Price Indicator
Running regression estimation using OHLC data - compare to closing regression

+ [ ] Develop range OHLC estimators for skewness and kurtosis

+ [ ] introduce seasonal and trend decomposition  
https://anomaly.io/seasonal-trend-decomposition-in-r

+ [ ] Study Hawkes process as model for asset returns with decaying skewness and kurtosis  

+ [ ] Kelly criterion
KellyRatio.R
create charts of random time series of wealth with different expected pv and growth rates
create charts of random time series of ruin
create terminal wealth charts
as function of betting fraction
as function of probability
as function of odds

+ [ ] Kelly in R:
simulate binary betting strategy using "for" loops and/or "apply"
then also simulate using vector functions
which betting fraction maximizes expected terminal wealth? - step-wise
which betting fraction maximizes expected growth rate? - Kelly
calculate SR of binary betting strategy
which betting fraction maximizes SR?

+ [ ] Kelly in R:
calculate utility as function of betting fraction, from empirical time series of returns, 
compare with Kelly from variance alone
include skew and kurtosis

+ [ ] Kelly for negative betting fraction (shorting)
Kelly for betting fraction greater than 1 (leverage)

+ [ ] Kelly proofs:
find optimal betting fraction, assuming you know the future number of wins and losses
find max expected log of wins and losses
extend Kelly formula to higher moments

+ [ ] Shlok Datye: Kelly Criterion and Optimal-f
http://shlok.is/thesis
Shlok Kelly Optimal-f Criteria.pdf
# Kelly Criterion and Optimal-f
https://alphaism.wordpress.com/2012/04/13/testing-kelly-criterion-and-optimal-f-in-r/
Vince Kelly Optimal-f Criteria.pdf

+ [ ] replace "look_back" and "win_dow" with "inter_val" - deprecated

+ [x] change start_points in time_series_univariate: make it consistent with HighFreq::roll_apply(): win_dow is the size of the lookback window, equal to the number of data points used for applying the aggregation function (including the current point)  
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))]
instead of:
start_points <-  end_points[c(rep_len(1, win_dow), 1:(len_gth-win_dow))] + 1

+ [x] review Optimal Mean Reversion Trading: mostly math from his papers  
Redemption Code:	F3P8XXBB7SKVXFZNX6KP
https://bookshelf.vitalsource.com/#/books/9789814725934/cfi/6/2!/4/2/2@0:66.1

+ [x] convert all code from nrow() and ncol() to NROW() and NCOL()  

+ [x] update ETF list and etf_data.Rdata

+ [x] hw/test: eapply over hypothesis tests 

+ [x] Create package rutils: Utility Functions for Financial Data Management and Modeling

+ [x] Downloading S&P500 stock price data with R
https://grollchristian.wordpress.com/2013/08/07/sp500-stock-price-data/

+ [x] Stock index constituents and meta-data  
https://www.quandl.com/blog/useful-lists

+ [x] Download data for all S&P500 stocks from Quandl
Quandl API Key:	pUJi9Mv3V9CD3Js5s7Rx
https://www.quandl.com/blog/quandl-launches-intraday-data-2

+ [x] update HighFreq package

+ [ ] Demonstrate that positive correlation doesn't translate into similar long-term returns
develop the contrived hypothetical example in: Kinlaw Variance Ratio Correlation Term Structure.pdf  
demonstrate that the term structure of correlation decreases with tenor  
show that correlation depends on time scale, and decreases with shorter time scale  
on short time scales correlation is very small  
on intermediate time scales correlation is greater  
on long time scales correlation is lower  
study Lo and MacKinlay variance ratio test in: 

# lame
http://stackoverflow.com/questions/25340257/how-to-import-fundamentals-for-stocks-by-using-quandl-package
# GICS Sectors data spreadsheet download
http://stackoverflow.com/questions/11339993/getting-stocks-by-industry-via-yahoo-finance
http://www.reddit.com/r/investing/comments/1f6kjt/anyone_know_where_i_can_find_a_data_set_of/
https://www.quantopian.com/posts/creating-an-algorithm-that-uses-fundamental-data
https://www.quantopian.com/posts/using-the-fetcher-with-quandl

# Stock market historical data
http://opendata.stackexchange.com/questions/4116/stock-market-historical-data

# download hfreq data from Quandl
# get Quandl trial license and download VIX S&P futures data ? use WRDS instead

# create lecture slides for:
https://ropensci.org/
https://plot.ly



###############
### homework topics existing best

# ask students to fix code that has been corrupted with a bug - take large chunks of good code and corrupt it with a bug
For example:
Download from Interactive Brokers daily historical data for expired VIX futures, starting with the July 2017 contract, through August 2018.
Load VIX time series data from csv files into an environment.
Chain together VIX futures prices in a loop.

# Summary: Coerce the time indices of all the xts series 
# in an environment, from class POSIXct to class Date.

# Summary: Calculate efficient portfolios with the 
# lowest variance given a fixed target return.

# Summary: Create a function which simulates an ARIMA process in Rcpp.

# Summary: Create a function which calculates the rolling 
# variance of an xts series over a look-back interval using Rcpp.

# Summary: Create a function which calculates the rolling 
# weighted sum of an xts series over a look-back interval,
# using RcppArmadillo.

# Calculate the maximum Sharpe ratio portfolio weights

# Summary: Simulate a rolling portfolio optimization strategy 
# using the regularized inverse of the covariance matrix.

# Summary: Perform a rolling portfolio optimization 
# over annual intervals, calculate optimized portfolio 

# Summary: Calculate the standard errors of the Yang-Zhang 
# and the close-to-close variance estimators using bootstrap 
# simulation.

# Summary: Create an Rcpp function which simulates 
# the GARCH model using Rcpp.

# Calculate the CVaR minimum portfolio weights using 
# linear programming and function Rglpk::Rglpk_solve_LP().

# Summary: Create a function which simulates an EWMA 

# Summary: Calculate the number of trades in an 
# EWMA strategy, and plot the number of trades as 
# a function of the lambda decay parameter.

# Simulate a long-short trading strategy based on two VWAPs
number of trades
winners losers
success rate
fix data snooping

# Summary: Fit t-distributions with different degrees of freedom 

# Calculate autocorrelations and partial autocorrelations by hand.

# Summary: Identify bad data in a time series using 
# a Hampel median filter.  Optimize the filter parameters 

# Summary: Perform interval aggregations on an OHLC time 
# series, to obtain an OHLC series with lower periodicity, 
# similar to function to.period() from package xts, or 
# function to_period() from package rutils.

# Summary: Calculate the total yearly trading volumes 
# of SPY, and plot it with custom axis.

# Summary: Calculate the maximum drawdown of a time series.

# Summary: Calculate the eigenvectors and eigenvalues

# Summary: Calculate performance of random sub-portfolios
# of S&P500 constituent stocks.

# Summary: Combine data for the S&P500 constituents,
# and stitch the newer data to the older data.

## backtesting models

# Summary: Perform multiple back-tests of momentum strategies 

# Optimize the weights and find the maximum Sharpe 
# for a portfolio with and without the VWAP strategy. 

# Summary: calculate a matrix of the best performing ETFs
# in each year.  Create a scatterplot of alphas for the
# years 2008 and 2009.



###############
### homework and test ideas

+ [ ] Calculate VIX futures term structure for several dates, and perform PCA
https://quantstrattrader.wordpress.com/2017/04/27/creating-a-vix-futures-term-structure-in-r-from-official-cboe-settlement-data/

+ [ ] Simulate an investment strategy which ramps up its notional based on the trailing performance of a portfolio manager.  
Imagine a portfolio manager with no skill, whose returns are binary, with a 50% probability of earning one dollar, and a 50% probability of losing one dollar.
Imagine an investor who follows a conservative strategy of increasing (doubling) his invested capital after each positive return.  
The investor withdraws all his capital after after a single loss.
Demonstrate that the investor returns have negative skew, because small gains are always followedd by a large loss.

+ [ ] Write and read time series from csv files, directly using write.table() and read.table(), instead of write.zoo() and read.zoo()

+ [ ] Create function roll_count() using RcppArmadillo which reproduces roll_countr() 
roll_count() should count the number of consecutive TRUE elements, and reset to zero after every FALSE element.
Create a contrarian strategy using roll_count(): the number of consecutive close_low or close_high.
Scale the count threshold levels depending on the level of volatility.

+ [ ] Load ETF time series from XLS files, with badly formatted dates: first save data down to CSV files, and adapt code from utility_scripts.R

+ [x] Load VIX time series data from csv files into an environment

+ [x] Chain together VIX futures prices in a loop

+ [x] Load VIX time series data from csv files into an environment

+ [x] Download from Interactive Brokers daily historical data for expired VIX futures, starting with the July 2017 contract, through August 2018.

+ [ ] Create a rolling Hampel filter using RcppArmadillo

+ [ ] Create a function which simulates an ARIMA process in Rcpp

+ [ ] Create a function which calculates the rolling variance of an xts series over a look-back interval using Rcpp 

+ [ ] Create a function which calculates the rolling weighted sum of an xts series over a look-back interval using RcppArmadillo

+ [ ] Calculate the maximum Sharpe and the minimum variance portfolio weights from the regularized inverse of the covariance matrix, in R and in RcppArmadillo
calculate the maximum Sharpe ratio portfolio weights - adapt sharpe_weights()

+ [ ] Create shiny app for Ornstein-Uhlenbeck process
simulate multiple OU, to demonstrate how the paths change as the strength of mean reversion is increased

+ [ ] Perform rolling minimum variance strategy for S&P500 portfolio

+ [ ] Demonstrate that for the log-normal distribution, the standard error of the higher moments increases relative to their value (higher moments are increasingly noisy)
Perform bootstrap in parallel to estimate the standard errors.
Therefore higher moments are not well suited for forecasting.

+ [ ] Demonstrate that performing PCA on unscaled variables produces very large loadings for variables with high variance, and creates over-dependence of principal components on variables with high variance
https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/

+ [ ] Modify function back_test():
return list with performance stats: Sharpe, number of trades, trading volume ?
compare speed when weights aren't returned

+ [ ] Perform loop in parallel to run back_test() over vector of look-back intervals and calculate matrix of performance stats: Sharpe, number of trades, trading volume

+ [ ] Simulate multiple momentum strategies for S&P500, with different wid_th parameters to calculate past returns, but use the same rolling variance
create shiny Rmd file

+ [ ] Demonstrate that maximum Sharpe portfolio weights obtained from inverse matrix are equal to weights obtained from optimization using quadprog::solve.QP() or optim()

+ [ ] For S&P500 portfolio, find using quadprog: minimum variance, maximum returns, with weights between -1 and 1, sum equal to 1

+ [ ] Create acf function that calculates acf for vector of lags in sapply() loop, and plots the acf plot

+ [ ] Calculate EWMA variance using Rcpp based on slide for calculating weighted rolling sum in numerical_analysis.Rnw

+ [ ] Calculate EWMA variance using filter() and sapply()
microbenchmark with roll::roll_var()

+ [ ] Calculate volatility, skew, and kurtosis over non-overlapping intervals
create scatterplot of skew or kurtosis as function of volatility
show that in periods of high volatility the kurtosis is lower

+ [ ] Download some data using getSymbols() using a limited time range, and save in Rmd and CSV files
Then download more data using getSymbols(), read the data from the files, and combine the two using rbind in a loop and mget().

+ [ ] Calculate the standard errors of the standard deviation and MAD estimators for VTI, using parallel bootstrap
already in lecture notes?

+ [ ] Calculate the standard errors of all the different TTR variance estimators using parallel bootstrap
meth_ods <- c("close", "garman.klass", "rogers.satchell", "gk.yz", "yang.zhang")
boot_strap <- sapply(1:100, function(x) {
# create random OHLC
  oh_lc <- HighFreq::random_ohlc()
# calculate variance estimates
  sapply(meth_ods, function(meth_od) {
    sqrt((6.5*60)*mean(na.omit(TTR::volatility(oh_lc, N=1, calc=meth_od))^2))
  })  # end sapply
})  # end sapply

+ [ ] Read the giant data frame in the file sp500_ohlc_prices_permno.csv
sp500_ohlc_prices <- read.csv("C:/Develop/data/WRDS/sp500_ohlc_prices_permno.csv", header=TRUE, stringsAsFactors=FALSE)
save(sp500_ohlc_prices, file="C:/Develop/data/WRDS/sp500_ohlc_prices.Rdata")
Perform the map/reduce (split-apply-combine) procedure to convert the data frame into multiple xts series, in an environment.
Save the xts series into individual csv files in a directory.

+ [ ] Define end points over equally spaced business days (rows of data), with a stub interval at the and end and at the beginning

+ [ ] Define end points over equally spaced calendar days, with a given start date and end date (different from the start and end of the data), with a stub interval at the and end and at the beginning

+ [ ] Perform backtest of strategy which rebalances at every point (without endpoints), using only vectorized functions

+ [ ] Perform backtest of strategy which chooses best and worst performing ETFs based on their Sharpe ratios 
scale weights so that strategy volatility is constant

+ [ ] Read csv file with S&P500 constituents and calculate pivot tables by GICS Sector and GICS Sub Industry
sp500_Yahoo 04-02-16.csv

+ [ ] Calculate the probability of obtaining 80 heads in 100 tosses for a biased coin with 60% heads and 40% tails  
Use binomial function, and also use approximation using normal function.

+ [ ] Brownian bridge puzzle: given a deck of 52 cards, every time you randomly choose a red card you're account increases by $1, but if you choose a black card you're account decreases by -$1
At any point you can choose to continue playing, or to stop and keep your net wins.
The optimal strategy is to stop playing if the current net wins are greater than the expected value of wins from continuing to play.
Calculate the expected value of the optimal strategy, assuming you start with zero in your account.
This puzzle is a free boundary problem related to Brownian bridges:
http://puzzles.nigelcoldwell.co.uk/fourteen.htm
https://math.stackexchange.com/questions/380571/a-boundary-crossing-result-for-discrete-brownian-bridge
https://math.stackexchange.com/questions/638846/running-maximum-for-geometric-brownian-motion
https://math.stackexchange.com/questions/515162/brownian-bridge-distribution-sup-a-leq-u-leq-b-fracw0u-sqrtu1
Law of the iterated logarithm
https://en.wikipedia.org/wiki/Law_of_the_iterated_logarithm
# Solution code using recursive function in R:
stra_tegy <- function(cash, positive, negative) {
  # cat(paste("args=", cash, positive, negative, "\n"))
  pro_b <- positive/(positive + negative)
  if (positive==0)
    max(cash, 0)
  else if (negative==0)
    max(cash + positive, 0)
  else
    max(cash, 
        pro_b*stra_tegy(cash+1, positive-1, negative) + 
          (1-pro_b)*stra_tegy(cash-1, positive, negative-1))
}  #end stra_tegy
stra_tegy(0, 3, 3)
stra_tegy(0, 5, 5)
# Solution code using loops in R:
n_pos <- 26
stra_tegy <- outer(n_pos:0, n_pos:0, function(positive, negative) 
  (negative - positive))
stra_tegy[, n_pos+1] <- 0
stra_tegy[n_pos+1, ] <- n_pos:0
prob_s <- outer(n_pos:0, n_pos:0, function(positive, negative) 
  positive/(positive + negative))
prob_s[, n_pos+1] <- 0
for (i in n_pos:1) {
  for (j in n_pos:1) 
    stra_tegy[i, j] <- max(stra_tegy[i, j], 
                           prob_s[i, j]*stra_tegy[i+1, j] + (1-prob_s[i, j])*stra_tegy[i, j+1])
  for (j in n_pos:1) 
    stra_tegy[j, i] <- max(stra_tegy[j, i], 
                           prob_s[j, i]*stra_tegy[j+1, i] + (1-prob_s[j, i])*stra_tegy[j, i+1])
}  # end for
stra_tegy[1, 1]

+ [ ] Calculate the frequency distribution of the maximum value of a Brownian bridge process
http://risklatte.com/Articles/QuantitativeFinance/QF176.php
Brownian bridge process can describe the price of a risk-free bond as it approaches maturity.
https://quant.stackexchange.com/questions/10960/usage-of-brownian-bridge
https://quant.stackexchange.com/questions/31036/brownian-bridge-density-and-risk-neutral-density-for-derivative-pricing
https://quant.stackexchange.com/questions/10960/usage-of-brownian-bridge

+ [ ] Create plot of Market portfolio weights as a function of the risk free rate  
Create plot of the returns and standard deviation of the Market portfolio as a function of the risk free rate.
Demonstrate that the Market portfolio depends on the risk free rate: higher risk free rate forces higher standard deviation.
Demonstrate that for larger risk-free rates, the market portfolio is more highly levered, with a smaller weight for bonds  

+ [ ] update: create plot with multiple Capital Market Lines (CML) and Market Portfolios

+ [ ] Calculate and plot the efficient frontier using the quadprog package
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r

+ [ ] Create shiny app for efficient frontier, with inputs for risk_free, correlation, and individual asset returns  

+ [ ] Create estimator of price curvature (second derivative), and repeat all the tasks for the estimator of slope (returns)
Demonstrate that the noise level has an even greater effect.

+ [ ] Demonstrate that long-term returns are dominated by the tails of the return distribution:
calculate wealth of S&P 500 Index if investor avoids the 10 worst trading days, or misses best trading days.

+ [ ] Calculate the number of years of data needed to select the best manager, with 95% confidence, as function of excess Sharpe ratio
adapt from select_manager.R and select_manager.Rmd
plot with plotly

+ [ ] Provide trading strategy code with data snooping, and ask students to fix it

+ [ ] Add transaction costs to simu_ewma()

+ [ ] Create random OHLC data and pass it through EWMA strategy to test for data snooping

+ [x] Simulate rolling portfolio optimization strategy using regularized inverse 
Calculate the corresponding maximum Sharpe and the minimum variance portfolio weights, in R and in RcppArmadillo.
Create a shiny app in an R file.

+ [x] combine data for the S&P500 constituents, and stitch the newer data to the older data

+ [x] Calculate the standard errors of the Yang-Zhang and the close-to-close variance estimators using bootstrap simulation
Demonstrate that the Yang-Zhang estimator has much smaller standard error than the standard close-to-close variance estimator.
Calculate the standard errors of both variance estimators by bootstrapping minutely SPY prices.

+ [x] Simulate many ARIMAs with increasing coefficients to 1, and calculate a vector of ADF statistics - already in lecture notes

+ [x] Use filter() to simulate an ARIMA and its integrated series - already in lecture notes

+ [x] rework in RcppArmadillo the code on slide titled Eigenvalues of the Covariance Matrix

+ [x] Simulate Ornstein-Uhlenbeck process using Rcpp
solution is rcpp_ou.cpp

+ [x] Calculate the time series of the index price from the components from the S&P index data in file sp500.RData
select ten equal dollar-weighted random sub-portfolios from the S&P index data in file sp500.RData
for the end of each year, calculate the percentage of sub-portfolios that underperform the index average

+ [x] Simulate GARCH model using Rcpp, for a grid of alpha and beta parameters
Calculate kurtosis and plot heatmap of kurtosis.
Find alpha and beta parameters that produce biggest kurtosis.
Calculate Jarque-Bera test statistic, and the p-value.
Plot heatmap of Jarque-Bera test statistic.

+ [x] Simulate GARCH model using Rcpp

+ [x] Fit t-distributions with different degrees of freedom to VTI returns
Also fit other distributions, like normal or cauchy distributions.
Calculate the Kolmogorov-Smirnov and Chi-squared test statistics for the fitted distributions and find which fits best.
Find which value of degree of freedom provides best fit, based on goodness of fit tests.

+ [x] Calculate list of dates with extreme returns either above +3% or below -3% for all EuStockMarkets columns
Remove extreme returns from DAX returns, and calculate the cumulative DAX returns.
Coerce DAX EuStockMarkets into xts and plot it using dygraphs.

+ [x] Calculate backtest performance as function of meta-parameters: look-back interval
optimize meta-parameters

+ [x] Create functional which performs backtest 
arguments: time series of past_rets and fwd_rets, 
output: time series of backtest returns

+ [x] Create functional which performs look-back and look-forward aggregations using single lapply() loop
arguments: agg_fun=sum, re_turns, end_points?, look_back, re_balance,
output: time series of past_rets and fwd_rets

+ [x] Calculate time series of model returns using parallel parLapply()

+ [ ] Calculate correlation matrix of returns from ensemble of EWMA strategies

+ [ ] Create data frame with latest fundamental data for S&P500 companies from usfundamentals data

+ [ ] Create time series of fundamental data for MSFT from usfundamentals data

+ [ ] Create time series of S&P500 stock fundamental data since 2011, using data files from Linelane
C:\Develop\data\usfundamentals

+ [ ] Create R Markdown document containing dygraphs and plotly plots

+ [ ] Perform non-overlapping aggregations using roll_agg(): volume, volatility, regress - already assigned ?

+ [x] Download U.S. stock fundamental data from Linelane, based on reports submitted to EDGAR SEC
http://usfundamentals.com/
https://www.reddit.com/user/usfundamentals
C:\Develop\data\usfundamentals
https://www.reddit.com/r/investing/comments/4qxjr6/ive_processed_1tb_of_secs_data_to_extract/

+ [ ] load BRK-B, BF-B, and a few other stocks into existing environment object, without reloading stocks already the environment
provide students with existing environment object

+ [ ] Calculate cap-weighted sub-portfolios for industry, size, and quality sub-portfolios for the S&P500 stocks
calculate monthly performance tables and rank the industries
determine if the rankings are persistent (autocorrelated) or not

+ [ ] Create cap-weighted, price-weighted, and equal-market-value-weighted portfolios
rebalance weekly the equal-market-value-weighted portfolio
calculate the PnL from the rebalancings

+ [ ] rebalance monthly two-asset portfolio to maintain: equal market value weights, equal risk weights  
make sure to rebalance on the last workday of every month  

+ [ ] subtract two lagged columns of OHLC time series by using as.vector()
jump_s[which_periods] <- as.vector(oh_lc[which_periods, 1]) - as.vector(oh_lc[which_periods-1, 4])

+ [ ] recreate function remove_jumps() to remove overnight close-to-open jumps from OHLC  

+ [ ] Find the minimum volatility portfolio, loop over volatility and find maximum return portfolios (that's efficient frontier), and plot the efficient frontier  

+ [ ] what is CAPM alpha of VWAP strategy?
where is VWAP strategy on CAPM scatterplot?
draw the Efficient Frontier
Is it possible to combine SPY with VWAP strategy to achieve higher Sharpe than either of them alone?

+ [x] Create functional which performs overlapping aggregations using lapply()
roll the function simu_ewma() over overlapping windows, and collect statistics
find optimal parameters and apply them out-of-sample

+ [x] Create shiny for simu_ewma() trading an Ornstein-Uhlenbeck process

+ [x] Trade an Ornstein-Uhlenbeck process using simu_ewma()

+ [x] loop over correlations in two-asset portfolio, find maximum Sharpe, and plot efficient frontiers in different colors  

+ [x] Calculate number of trades in EWMA strategy as function of lambda decay parameter, and create shiny

+ [x] Create function for trading strategy with two EWMA, and plot prices with two EWMA plus shading

+ [x] Create shiny for two EWMA strategy, with two sliders and also input for window size

+ [x] Perform aggregations over OHLC to reproduce function to_period() from package rutils  

+ [x] Calculate volatility estimates using all the different "calc" methods in function volatility() from package TTR  

+ [x] Calculate daily close-to-open volatility and open-to-close volatility

+ [ ] recursively rbind() a list of objects, such as xts time series - reproduce do_call_rbind()

+ [x] convert the date and time to different time zones  

+ [x] Create a vector of dates that are the last workdays of every month  

+ [ ] Calculate standard deviation, skewness, and kurtosis of SPY returns in each year using sapply loop  
plot histograms of returns in each year in panels

+ [ ] Calculate SPY moments in each month, in each year, 

+ [ ] benchmark runmed with runquantile and runMedian
benchmark TTR::runMAD() with caTools::runmad()

+ [ ] Calculate standard errors of variance estimators using bootstrap - parallel version

+ [ ] reproduce function melt() from package reshape2
http://stackoverflow.com/questions/3777174/plotting-two-variables-as-lines-using-ggplot2-on-the-same-graph
http://www.wekaleamstudios.co.uk/posts/melt/

+ [ ] Calculate rolling/sliding volatility
regress against volume
regress levels and changes in levels at different horizons
extract stats into vector
perform sapply over window size and agg horizons
select different market regimes

+ [ ] Explain Sharpe ratio as a t-statistic
simulate Sharpe ratios
create distribution of Sharpe ratios

+ [ ] Create function that performs hypothesis testing in a loop over parameters
create wrapper function for hypothesis testing functions

+ [x] Calculate data frame of hypothesis test statistics for returns data
sapply over sym_bols and extract:
Shapiro-Wilk Test of Normality
Jarque-Bera Test of Normality
sort by most/least normal
save to comma-delimited CSV file

+ [ ] Calculate data frame of perf stats for price data and
create data frame
save to comma-delimited CSV file
use table.Stats()
sd, MAD, skew, kurt, alpha, beta, max drawdown, 

+ [ ] Expand code from slide:
Downloading Time Series Data Using Package quantmod

+ [ ] Extract "Adjusted" and "Volume" columns
etf_series_ad <- do.call(merge, 
                  eapply(env_data, Ad)[sym_bols])

plot with quantmod
chartSeries(blah, theme=chartTheme("white"))
chart_Series(blah, name="SPY")


+ [ ] Reading and Writing data frame or xts Series With Date-time Index from txt and csv files


+ [ ] idea for homework:
modify get.hist.quote to download from any URL
add extra argument for URL, with default:
http://ichart.yahoo.com/table.csv


+ [ ] idea for homework:
provide list of tickers
tickers for Asset Allocation exercises
sym_bols <- c("VTI", "VEU", "IEF", "VNQ", "DBC", "XLY", "XLP", "XLE", "XLF", "XLV", "XLI", "XLB", "XLK", "XLU", "IWB", "IWD", "IWF", "IWM", "IWN", "IWO", "IWP", "IWR", "IWS", "IWV", "IWW", "IWZ")

? download descriptive data ticker (name, industry, sector, etc.)
? format data frame of descriptive data: columns and rows

read etf database file called "etf_list.csv" into data frame called "etf_list", using "read.csv"
subset etf_list to include only those ETF's in sym_bols, using "%in%" operator

create a data directory on your computer, and save all files to that directory 
remember the location of that data directory for future use
? save description data to CSV file


? using description data frame

download 10yrs of data for list of sym_bols, and call it "zoo_series"
Use get.hist.quote() and lapply() loop,
For each sym_bol download fields "AdjClose" and "Volume",
the zoo_series data lapply returned is a list - each list element is a zoo object,
assign names() attribute to zoo_series, equal to sym_bols vector - result should be named list,

flatten zoo_series into a single zoo object, using do.call() and merge(),
assign new names() to zoo_series, in the format "XLI.Close", "XLI.Volume", etc.
Use sapply() and paste(),



###############
## save data for future load

save(env_data, sym_bols, etf_series_ad, etf_rets, etf_list, ret_stats, etf_perf_stats, file='etf_data.Rdata')

save(
maxSR_DEOpt, maxSR_DEOpt_xts, maxSR_ROI, maxSRN_DEOpt, maxSRN_DEOpt_xts,
maxSTARR_DEOpt, maxSTARR_DEOpt_xts, maxSTARR_RP, minES_ROI, minES_ROI_xts,
plot_portf, portf_init, portf_maxSR, portf_maxSRN, portf_maxSTARR,
portf_minES, portf_names, risk_ret_points,
weights_1h, weights_2h,
period_stats, pnl_xts,
file="C:/Develop/data/portf_optim.Rdata")

###############
# end save data for future load



###

# Dupoyet High Frequency Self Organizing Critical Markets

# LeBaron Stock Momentum Volume.pdf
LeBaron Improved Range Volatility Estimators.pdf

# ETF Sector Rotation Strategy
http://www.etfscreen.com/sectorstrategy.php
http://systematicinvestor.wordpress.com/2011/12/06/multi-asset-backtest-rotational-trading-strategies/

# Ekholm Decomposition of Hussman Strategic Growth (HSGFX) - uses Fama/French factors
https://gist.github.com/timelyportfolio/9b962f7c391c492bfe35
# function
https://gist.githubusercontent.com/timelyportfolio/e5728c8c7fb45dbdb6e0/raw/e124379f19225fcdee18f30cb848da6fc6cae764/ekholm.R
http://timelyportfolio.blogspot.com/2014/10/selectionshare-timingshare-masterfully.html

# use of systematic investor part 1.r
http://timelyportfolio.blogspot.com/2012/02/simplified-example-of-systematic.html
https://gist.github.com/timelyportfolio/1793607


# Yahoo explains its data
https://help.yahoo.com/kb/finance/historical-prices-sln2311.html


########################
### emails announcements

# grading policies
The problem with applying such a fixed scale to translate numerical scores into letter grades is that it doesn't take into account the difficulty of the assignments, which may differ between courses.
In the case of this class (FRE7241), I have made it easier by providing test outlines several days in advance.  As a result most students received almost perfect scores, but you didn't.
In the first lecture, on the slide titled "Course Grading Policies" I explained that:
Very high numerical scores close to the maximum wont guarantee an A letter grade, since grading will also depend on the difficulty of the assignments.

# jobs
Marto Capital is looking for an intern to help in developing risk parity and alpha strategies.  The strategies can invest in interest rate futures, bonds, currencies, and commodities, and they depend on macroeconomic data such as inflation, GDP growth rates, etc.
The job requires knowledge of econometrics, financial markets, and R programming.

Please contact Michael Marco, Director of Research, at:
michael.marco@martocapital.com

##

Please change your default settings in Linkedin so that you receive alerts for new postings.

##

I also highly recommend that you first take FRE6871 R in Finance, which also contains very valuable material that can be applied to investing.  

Dear Students,
Welcome to FRE7241 Algorithmic Portfolio Management.  Please see attached the syllabus. 
I'm glad to see that so many students have registered for this course.  In this course you'll learn how to apply the R programming language to quantitative portfolio management, like volatility forecasting, the Capital Asset Pricing Model (CAPM), portfolio optimization, and active portfolio management strategies.  You'll also learn how to apply machine learning techniques, like model parameter regularization (shrinkage), strategy backtesting (cross-validation), and the bias-variance tradeoff. 
But I must warn you that many students find this course to be difficult.  The R language is considered to be very challenging, so this course requires strong programming skills and experience.  Students should therefore have extensive programming experience with the R language and other languages such as C++ or Python.  

The course FRE6871 R in Finance is designed as an introduction to R, and to important applications to finance, like building credit scoring models using logistic regression, and pricing options using Monte Carlo simulation.  FRE7241 Algorithmic Portfolio Management is designed as a followup course for teaching applications of R to portfolio management.  I recommend taking these courses either sequentially (first FRE6871 and then FRE7241) or concurrently.

Students with less programming experience are encouraged to first take FRE6871 R in Finance.  Students should also have knowledge of basic statistics (random variables, estimators, hypothesis testing, regression, etc.)

It may be helpful for you to prepare by taking some free online courses: 
http://tryr.codeschool.com/
https://www.datacamp.com/courses/free-introduction-to-r
https://www.datacamp.com/courses/intermediate-r
https://www.datacamp.com/introduction-to-statistics
https://www.datacamp.com/courses/statistical-inference-and-data-analysis

I uploaded the syllabus and other course materials to NYU Classes.

You may download the previous lecture slides from here:
https://drive.google.com/drive/u/1/folders/0Bxzva1I0t63vVGEtaXNIY1JMa00

Regards,  Jerzy Pawlowski
NYU Tandon, Finance and Risk Engineering

Dear Students,
Below is the link to the survey results for the FRE7241 course.  13 students answered so far, and the feedback is pretty positive.  But one area that still needs improvement are test instructions.

https://www.surveymonkey.com/results/SM-P76ZVKKJ/

## GA

Can you please send a message to all students via NYU Classes announcing that you will be the GA?
Also please ask students for the most convenient time for office hours, and then announce to them when you'll be holding office hours.
Please read the first lecture slides with instructions for grading and submission of assignments.


Dear Students,
I have open positions for GAs for the two courses I am currently teaching this semester:
FRE-6871 R in Finance
FRE-7241 Algorithmic Portfolio Management

The GA positions require strong programming experience in R.
The jobs are posted on CareerNet, so please apply through CareerNet.
You may also contact Jonnett R Romano (jonnett.romano@nyu.edu).
If you decide to apply for the GAs positions, then please send me your resume to my email.

Best Regards,  Jerzy Pawlowski



## Google drive

Dear Students,
I uploaded many lecture slides to Google drive:
https://drive.google.com/folderview?id=0Bxzva1I0t63vVGEtaXNIY1JMa00&usp=sharing

I encourage you to study them, and I welcome your questions via NYU Classes forums or in class.


## grading

Dear Students,
As stated in the FRE6871 syllabus: 
"The final course letter grade will be derived from the cumulative scores obtained for all the homeworks and tests."
However, there is no fixed formula for assigning a letter grade from the cumulative score.  Over half of students received letter grades of "A" or "A-", which I think is very generous.

## tests

Dear Students,
Please upload your test file to NYU Classes by 7:00 PM.

Dear Students,
Here are some suggestions that may help you on the tests.

Don't leave assignments unanswered because you won't get partial credit.  At least try to copy some lecture code that makes sense for the assignment.
First, search the lecture code for keywords and function names mentioned in the instructions.
Second, copy lecture code that makes sense for the assignment.
Third, modify that lecture code as best you can.
Fourth, ask for hints from me.

Dear Students,
There will be an in-class test this Tuesday, October 4th.
The test will start at 6:30 PM, and will last 60min until 7:30 PM.
I will upload the test file at 6:30 PM to NYU Classes.
The lecture will start at 6:00 PM, as usual.  
You must bring your laptops and be able to log into WiFi.

The test will be based on lecture notes, so please study the topics below.

In Part I you will be asked to perform the following:
Apply the function filter_prices() from test #3 over overlapping 12-month intervals in the past. 
Define end points at the end of each month using function endpoints() from package xts.
Calculate a time series of trailing 12-month optimal thresholds, and the associated true positive and false positive rates, using function sapply() and an anonymous function.
Calculate the trailing 12-month volatility, defined as the standard deviation of daily returns, using functions sapply() sd(), index(), xts(), and diff_xts() from package rutils.
Plot in multiple panels using the functions chart_Series() and add_TA().
Plot scatterplots using function plot(). 

In Part II you will be asked to perform the following:
Create a function which calculates the volume-weighted average price (VWAP) of an OHLC time series.
The function should return an xts series with a single column containing the VWAP of the adjusted close prices.
You can use functions Ad(), Vo() and roll_sum() (defined in the lecture slides).
You can also use functions paste0(), strsplit(), and colnames(), to change the column name.
You cannot use for() or sapply() loops of any kind.
Calculate the same VWAP using function VWAP() from package TTR. 
Find which elements are significantly different between the two results (absolute difference is greater than 0.01).
Benchmark the speed of of the two functions using function microbenchmark() from package microbenchmark.
Find the crossing points of VWAP with prices, and create plots with background shading, using functions chart_Series() and add_TA().


benchmark it to function VWAP()
# from package TTR, and create plots.


Performing hypothesis tests and extracting test statistics.
Plotting scatterplots of test statistics. 
Performing apply() and sapply() loops over vectors. 
Plotting xts series using chart_Series() from package quantmod. 
Passing arguments to functions through the dots "..." argument of sapply(). 
Sorting data frames on columns.
Saving data frames to comma-delimited CSV files.
Calculating Median Absolute Deviation over a rolling window.
Lagging and advancing time series.
Identifying bad data in a time series using a Hampel median filter.  
http://www.mathworks.com/help/signal/ref/hampel.html
http://dsp.stackexchange.com/questions/26552/what-is-a-hampel-filter-and-how-does-it-work
Identifying type I and type II errors in hypothesis tests. 
Plotting Receiver Operating Characteristic (ROC) curves. 
http://www.joyofdata.de/blog/illustrated-guide-to-roc-and-auc/
Optimizing filter parameters in-sample, and backtesting their performance out-of-sample. 


Formatting dates into months and years. 
Using anonymous functions with apply(). 
Performing apply() and eapply() loops over matrices, data frames, xts series, and environments. 
Extracting objects from environments using get(). 
Flattening lists using do.call() and rbind() or merge().
Calculating equally spaced end points over OHLC time series. 
Performing interval aggregations over OHLC time series.
Plotting with custom "x" axis using plot() and axis(). 

Coercing integers and strings to "POSIXct" date-time objects. 
Converting dates into days of the week. 
Using functions from package lubridate, 
Converting the date and time to different time zones.

Calculating downside deviations, and Sortino and Calmar ratios. 
Defining objective functions for portfolio optimization. 
Performing portfolio optimizations using optim(). 
Plotting scatterplots of random portfolios. 

Searching in strings for sub-strings using grep() and glob2rx(). 
Extracting columns from OHLC data. 
Extracting data from output of function table.Drawdowns(). 
Assigning objects to environments using assign(). 
Invisibly returning values using invisible(). 
Creating functions that produce side effects. 
Subsetting data frames using logical operators. 
Subsetting xts series to specified dates and endpoints. 
Extracting the time index from xts series. 
Converting dates into days of the week. 
Calculating percentage returns from prices. 
Coercing integers and strings to "POSIXct" date-time objects. 

You will need to use the following functions:
coredata(), unname(), shapiro.test(), jarque.bera.test(), sapply(), na.omit(), t(), plot(), text(), order(), write.csv(), TTR::runMedian(), TTR::runMAD(), rutils::lag_xts()

seq(), as.Date(), Sys.Date(), weekdays(), as.POSIXct(), Sys.timezone(), format(), Sys.setenv()

You will need to use the following functions:
format(), as.POSIXct(), names(), unique(), index(), coredata(), get(), sapply(), eapply(), is.xts(), xts(), unlist(), dim(), rbind(), merge(), do.call(), plot(), axis(), to_period() from package rutils, the %in% operator, and anonymous functions


You will need to use the following functions:
apply(), sapply(), SortinoRatio(), CalmarRatio(), optim(), xts(), chart_Series(), seq(), runif().

Ad(), Vo(), assign(), table.Drawdowns(), invisible(), grep(), and glob2rx()
grep(), glob2rx(), Cl(), 
sum(), is.na(), read.csv(), write.csv(), endpoints(), weekdays(), index(), tail(), log(), diff(), which(), which.max(), which.min().


###

Dear Students,
Please create your personal account on Stack Exchange:
http://stackexchange.com/

Please add Stack Overflow as one of your communities on Stack Exchange.


###

Dear Students,
If you're not able to install package rutils, then you can copy directly from the source code of rutils available on github:
https://github.com/algoquant/rutils/blob/master/R/rutils.R

Copy and paste the required rutils functions into your solution code, and call them directly:
diff_xts()
instead of: 
rutils::diff_xts()

You can download the source code of rutils into your local drive, by going into this page:
https://github.com/algoquant/rutils

And then click on the green button on the right that says "clone or download".
Github will download a zip file with a directory structure.  In the data directory there's a file called etf_data.RData.  
You can load etf_data.RData into R using load().


Dear Students,
Installing all the required R packages is mandatory.
But we won't be using the packages roll, rutils, and HighFreq in the next few weeks, so you have time to install them later.

If you have problems with installing packages then please send a request to the GA using NYU Classes and copy me.
Please provide the text or screenshots of error messages.
Specify your operating system, Windows or OSX, and version.
Did these commands produce any errors?
devtools::find_rtools()
devtools::has_devel()


Dear Students,
The first class of FRE7241 Algorithmic Portfolio Management will be tomorrow, Tuesday October 31st at 6:00 PM, in room RH211.
Before the class please install R and RStudio: 
http://cran.us.r-project.org
https://www.rstudio.com/products/rstudio/download/

Please download all the Resources files from NYU Classes.

If you already have a previous R installation, then upgrade R and RStudio to the newest versions.  It's better to install only the 64-bit version of R, without the 32-bit version.

Please install the following R packages: lubridate, microbenchmark, devtools, tseries, xts, ggplot2, dygraphs, plotly, shiny, htmltools, knitr, rmarkdown, Rcpp, RcppArmadillo, matrixStats, profvis, ISLR, PerformanceAnalytics, and PortfolioAnalytics.
You can install them from the "Tools" menu in RStudio, or using the R command:
install.packages(c("lubridate", "microbenchmark", "devtools", "tseries", "xts", "ggplot2", "dygraphs", "plotly", "shiny", "htmltools", "knitr", "rmarkdown", "Rcpp", "RcppArmadillo", "matrixStats", "profvis", "ISLR", "PerformanceAnalytics", "PortfolioAnalytics"))

Also install the packages TTR, quantmod, and roll from GitHub as follows:
devtools::install_github(repo="joshuaulrich/TTR")
devtools::install_github(repo="joshuaulrich/quantmod")

Next install the 64-bit version of Rtools for Windows:
https://cran.r-project.org/bin/windows/Rtools/Rtools33.exe

Or install 64-bit version of Xcode for Mac/OSX:
https://developer.apple.com/xcode/

Verify that Rtools is working properly by running these commands in R:
devtools::find_rtools()
devtools::has_devel()

Check the system PATH to ensure that the PATH contains the directories with Rtools and the gcc compiler.  If needed edit the PATH.
For example, I have the following paths:
C:\Rtools\bin
C:\Rtools\gcc-4.6.3\bin

Next install the packages rutils and HighFreq from GitHub as follows:
devtools::install_github(repo="algoquant/rutils", type="source")
devtools::install_github(repo="algoquant/HighFreq", type="source")

install the packages qmao and twsInstrument
https://r-forge.r-project.org/R/?group_id=1113
install.packages("qmao", repos="http://r-forge.r-project.org")
install.packages("twsInstrument", repos="http://r-forge.r-project.org")

Create pdf documentation
system("R CMD Rd2pdf C:/Users/Jerzy/Documents/R/win-library/3.4/qmao")
system("R CMD Rd2pdf C:/Users/Jerzy/Documents/R/win-library/3.4/twsInstrument")


Next install the package roll as follows:
devtools::install_github(repo="jjf234/roll", type="source")

I think the reason you're getting the error is that the standard compiler under Mac/OSX doesn't support the OpenMP feature for parallel computing.  But you can install a compiler extension that supports the OpenMP feature.  Many Mac/OSX users have struggled with installing compiler extensions for OpenMP, and there are quite a few articles with solutions.  I don't have a Mac, so the best I can do is provide you with the links to articles offering solutions.
You can read more about this issue and how to solve it here:
http://thecoatlessprofessor.com/programming/openmp-in-r-on-os-x/#after-3-4-0
http://thecoatlessprofessor.com/programming/openmp-in-r-on-os-x/#gui-clang4

If you still have problems, then try solutions from here (follow jounih instructions):
https://github.com/ppwwyyxx/OpenPano/issues/16
https://github.com/velocyto-team/velocyto.R/issues/2


Next install the package RQuantLib as follows:
install.packages("RQuantLib", type="source")

Please also install the following packages:
install.packages("DEoptim")
install.packages("Rglpk", type="source")
install.packages("glpkAPI", type="source")
devtools::install_github("cran/quadprog", type="source", INSTALL_opts = "--merge-multiarch")

Next install the package factorAnalytics as follows:
install.packages("factorAnalytics", type="source", repos="http://r-forge.r-project.org")

Also install the packages RcppRoll as follows:
install.packages("RcppRoll")

Installing package rgl on a Mac OSX may require installing XQuartz first.
Here are the links:
http://stackoverflow.com/questions/33634871/installing-rgl-package-in-r-mac-osx-el-captian-fixed
http://stackoverflow.com/questions/32747616/installing-accessing-rgl-package-in-mac-yosemite
or:
http://stackoverflow.com/questions/9878693/error-in-loading-rgl-package-with-mac-os-x

Please install the following packages:
dplyr
tidyr
latticeExtra
directlabels

install.packages(c("PortfolioAnalytics", "factorAnalytics", "PortfolioAttribution", "FinancialInstrument", "quantstrat", "blotter"), type="source", repos="http://r-forge.r-project.org")

install.packages("xtsExtra", repos='http://r-forge.r-project.org')

install.packages(c("lmtest", "lubridate", "quantmod", "TTR", "PerformanceAnalytics", "Quandl", "ROI", "ROI.plugin.quadprog", "ROI.plugin.glpk", "DEoptim", "NMOF"))


install.packages(c("dplyr", "ggvis", "shiny", "knitr", "rmarkdown", "nycflights13", "babynames", "forecast", "devtools"))

##

Zhuo,
Installing all the packages, including HighFreq, is a prerequisite for this course, and you can't finish this course without installing all the packages.  
Please send an email request for assistance via NYU Classes to the GA and copy me.  Please include a minimal working example.

Dear Students,
If you're having problems installing some R packages, then follow these steps:

Remove your R installation and reinstall only 64-bit R, without 32-bit R.
Reinstall Rtools and make sure it installs the gcc compiler.
Run sessionInfo() and make sure you have installed64-bit R and64-bit RTools.
Edit the system PATH to ensure that the PATH contains the directories with Rtools and the gcc compiler.
I have the following paths:
C:\Rtools\bin
C:\Rtools\gcc-4.6.3\bin

Under Windowz do this:
Go to "Control Panel -> System."
Click on the tab "Advanced" and then on "Environment Variables."
Highlight "Path" at the bottom and click "Edit".

You can read more here:
http://thecoatlessprofessor.com/programming/installing-rtools-for-compiled-code-via-rcpp/

## 

Friedrich,
If I understand correctly, you want 5 or 10 second OHLCV time series bar data for stocks.
Yes, my package HighFreq has the function save_scrub_agg() for scrubbing and aggregating TAQ time series into OHLCV time series.
The package vignettes: managing_time_series.html and HighFreq.pdf explain how to perform the aggregation.  They're both on github.

The function save_scrub_agg() assumes a certain format of the TAQ data.  You can find an example of that format in the SPY_TAQ dataset.
Run these commands:
ls("package:HighFreq")
tail(HighFreq::SPY_TAQ)

Have you looked at package highfrequency by Kris Boudt?  It also has scrubbing and aggregation functions, but I decided to write my own because I wasn't totally happy with the speed and features of package highfrequency.
http://cran.r-project.org/web/packages/highfrequency/index.html
https://github.com/jonathancornelissen/highfrequency
http://highfrequency.herokuapp.com/


Have you considered the CRSP database (part of WRDS) for downloading the TAQ data?
https://wrds-web.wharton.upenn.edu/wrds/

I have downloaded some data from there, but not TAQ.  I have used TAQ data from other friendly sources.


########################

Resources:

# ECON 424/AMATH 462:  Introduction to Computational Finance and Financial Econometrics
http://faculty.washington.edu/ezivot/econ424/econ424.htm
http://faculty.washington.edu/ezivot/econ424/424syllabus.htm
http://faculty.washington.edu/ezivot/econ424/424notes.htm
http://faculty.washington.edu/ezivot/econ424/R_hints.htm

# Jeff Ryan
quantmod Workshop.pdf

# quantmod and quantstrat
C:\Research\R\Tutorials\Guy Yollin Presentations
Efficient Indexes Factor Models.pdf
quantmod.pdf

# Vinod good cointegration
C:\Research\R\Tutorials\Vinod\Econometrics\exercises3.pdf

# Tsai Skewness Kurtosis Asset Allocation.pdf

# project ReturnAnalytics (packages  PortfolioAnalytics and PerformanceAnalytics)
C:\Research\R\Packages\PerformanceAnalytics\doc

Meucci Dynamic Allocation Strategies

# Alexios Ghalanos packages rugarch parma
http://unstarched.net/

Bailey Prado Portfolio Optimization Algorithm
Didenko Random Forest Ensemble Learning Portfolio Views
Fossati time series with some R:	C:\Research\R\Tutorials\Fossati\e509

# R examples in:
C:\Research\R\Packages\Quantstrat
http://r-forge.r-project.org/projects/returnanalytics/
http://blog.fosstrading.com/2014/03/intro-to-portfolioanalytics.html

# Steiner Alpha Misleading Performance Measure

# Why do we need a Risk Model
http://systematicinvestor.wordpress.com/2012/02/26/portfolio-optimization-why-do-we-need-a-risk-model/

# R Examples for the second edition
http://www.pfaffikus.de/springerex2.html



##############
### lecture topics

###
FRE7241_Lecture_1

Date and time objects
Time series objects: ts, zoo, xts
Environments in R
interactive plots: dygraphs, shiny
R markdown documents


###
FRE7241_Lecture_2

Modeling and Fitting Asset Returns
Standard Errors of Estimators Using Bootstrap Simulation
Performing rolling aggregations over time series

Performing rolling aggregations over time series using Rcpp

Time series modeling
Autocorrelation function
Time series regressions
Fitting calibrating ARIMA models
Forecasting ARIMA models
Augmented Dickey-Fuller ADF test
Simulating Ornstein-Uhlenbeck process using Rcpp


###
FRE7241_Lecture_3

GARCH models and volatility forecasting
Fitting calibrating Ornstein-Uhlenbeck process to data
Models of stock returns: Pareto distribution, stochastic volatility, Heston model, 



###
FRE7241_Lecture_4

GARCH models and volatility forecasting
Time series of asset prices
Time evolution of stock prices
Log-normal probability distribution
Simulating Random OHLC prices
Active Investment Strategies: EWMA strategies
package Rcpp
Linear Algebra
Regression


###
FRE7241_Lecture_5

Forecasting models for price returns, stock beta, and correlation, 
bias-variance tradeoff, 
Time series rolling regressions

Backtesting Active Investment Strategies

Plotting heatmaps
Out-of-sample strategy performance in two-period model
Model overfitting
Demonstrate that model with many parameters (EWMA, ARIMA) performs better in-sample, but worse out-of-sample
Demonstrate that one can always optimize parameters to fit random prices in-sample
Strategy backtesting (cross-validation)
Strategy optimization: data snooping
Parameter regularization (shrinkage)
Lasso and Elastic Net shrinkage
Optimization of the regularization (shrinkage) parameter using backtesting (cross-validation)

Package quantmod for quantitative financial modeling

cointegration 
pairs trading
Statistical Arbitrage
trading Ornstein-Uhlenbeck process

range OHLC estimators of volatility, skewness, kurtosis, and covariance, 
Fitting calibrating EWMA models

Package tseries for time series analysis
Downloading time series data
Logarithmic utility and risk-adjusted performance measures: Sharpe, Calmar, and Sortino ratios, 
Capital Asset Pricing Model (CAPM): the market portfolio, the Security Market Line, 
Beta-adjusted performance measures: Treynor ratio, Jensen's alpha, information coefficient, 
Factor models: Principal Component Analysis (PCA), cross-sectional regressions, Fama-French model, Barra model, 
Pricing anomalies: size, value, momentum, volatility, 


###
FRE7241_Lecture_6

Portfolio optimization: mean-variance efficient portfolios, efficient frontier, Capital Market Line, 
Correlation matrix estimation: Cholesky decomposition, Factor Augmented Regression, 
Simulating correlated time series using Cholesky matrx
Constrained portfolio optimization: coefficient shrinkage, 
Intertemporal portfolio choice and out-of-sample performance of optimized portfolios, 

Tail risk measures: value-at-risk, conditional value-at-risk, 

Loading data



###
FRE7241_Lecture_7

Static asset allocation strategies: cap-weighted and equal-weighted stock indices, all weather portfolios, 
Portfolio management strategies: risk parity, minimum correlation, minimum variance, maximum Sharpe, maximum CVaR, betting against beta, factor investing, smart beta asset allocation, 
Active portfolio management strategies: tactical asset allocation, portfolio rebalancing, Constant Proportion Portfolio Insurance (CPPI), sector rotation, 
Benchmarking portfolio management skill: performance attribution, random portfolios, random investment choices, 
Dynamic investment and consumption strategies: Merton model, 


##############
### order of topics

R packages

Date and Time Objects
Time Series Objects
Package tseries
Package quantmod

Performing Aggregations Over Time Series
in: investment_strategies.pdf
EWMA strategy heatmaps

simulating geometric Brownian Motion
simulating Ornstein-Uhlenbeck OU process
Regression

plotly
R Markdown documents
shiny apps

Optimization
Principal Component Analysis PCA

time series of investments: time series of returns, chart_Series plot
Cross-validation backtesting
Out-of-sample performance and strategy optimization
Model overfitting
Parameter regularization
Test for data snooping using random data
Optimize strategy that trades on random data to demonstrate that in-sample optimization is misleading
simulate ARIMA and trade it using shiny

parallel computing
parallel backtesting

high frequency data

Fit pairs data into Ornstein-Uhlenbeck OU process
Factor models
Risk-adjusted performance measures

Optimization techniques
Bolker Optimization Methods.pdf
Yollin Optimization.pdf
Boudt DEoptim Large Portfolio Optimization.pdf

In-sample strategy optimization

Bootstrap standard errors of strategy parameters
Strategy backtesting and optimization

Estimating rolling volatility, skewness, kurtosis

Portfolio optimization

downloading fundamental data
downloading data from WRDS

scrubbing high freq data


