### FRE-7241 Algorithmic Portfolio Management
FRE-GY 7241

GA is Zhenyu (Lucy) Yin \href{zy944@nyu.edu}{zy944@nyu.edu}
Rogers Hall room 705

# potential GAs
Gaurav Sharma <gaurav.sharma@nyu.edu>
Xiang Li <xiang.l@nyu.edu>

# former GAs
Haoran Su hs3265@nyu.edu
Shu Ye shu.ye@nyu.edu
Jaimin Doshi jbd316@nyu.edu
Luping Liu	ll2525@nyu.edu
Dong Huang dh1716@nyu.edu

# Song Tang C++ courses
FRE6883 Financial Computing
FRE7831 Financial Analytics & Big Data

# Igor Halperin course FRE9733 Machine Learning for Finance

# NYU links
https://www.nyu.edu/registrar/calendars/university-academic-calendar.html


## My comments:

Below are some interesting facts about the Markowitz portfolio optimization model.  At first it was opposed by some famous economists like Milton Friedman.  Then it was accepted and rewarded with a Nobel Prize.  But practitioners realized it doesn't work in practice out-of-sample, because inverting the covariance matrix amplifies the noise.  But now the machine learning techniques of regularization and shrinkage are able to reduce the noise amplification and portfolio optimization is being applied by many practitioners. 

http://falkenblog.blogspot.com/2010/09/was-friedman-right-on-markowitz.html
Harry Markowitz:
"When I defended my dissertation in the Economics Department of the University of Chicago, professor Milton Friedman argued that my portfolio theory was not economics, so they could not award me a PhD degree in economics."

https://en.wikipedia.org/wiki/Harry_Markowitz
Markowitz won the Nobel Prize in Economics in 1990 while a professor of finance at Baruch College of the City University of New York. 
The topic of Markowitz' PhD thesis was so novel that professor Milton Friedman argued his contribution was not economics.

Some criticisms of the Markowitz portfolio optimization model:
The Markowitz model often produces highly leveraged portfolios (with very large positive and negative weights), which are extremely sensitive to small changes in the returns of the assets and can therefore be extremely dangerous.  So leverage constraints are needed on the weights.

The Markowitz model is an "error maximization" algorithm (Scherer 2002): "It is an algorithm that uses the estimates of returns and covariances as inputs and treats them as if they were known with certainty."  The portfolio weights are very sensitive to small differences in the returns and covariances, which can be within the measurement error.  This instability of the model causes poor out-of-sample performance.

https://en.wikipedia.org/wiki/Modern_portfolio_theory#Criticisms
Financial economist and NYU Tandon professor Nassim Taleb has criticized the Markowitz model because it assumes that returns are Gaussian, writing:
"After the stock market crash (in 1987), they rewarded two theoreticians, Harry Markowitz and William Sharpe, who built beautifully Platonic models on a Gaussian base, contributing to what is called Modern Portfolio Theory.  The Nobel Committee could have tested the Sharpe and Markowitz models and found that they work like quack remedies sold on the Internet, but nobody in Stockholm seems to have thought about it."


## To-do

# contribute to Quantitative Finance Collector by Biao Guo Assistant Professor, School of Finance, Renmin University, China
http://www.mathfinance.cn/

http://getprismatic.com/hedge-funds

# request for sample textbooks
I'm an adjunct at NYU Tandon, where I teach graduate courses in applications of R in Finance, and Algorithmic Portfolio Management Using R.  

# Some students have asked me if I would be willing to supervise their projects

# find out more about the Student Response System - for live in-class polling
http://engineering.nyu.edu/academics/support/fitl/srs

# Below is a link to Google Drive with my lecture files: 
https://drive.google.com/drive/u/0/folders/0Bxzva1I0t63vVGEtaXNIY1JMa00
The .pdf files contain the narration text, formulas, and R code. Most slides have narration and formulas on the left panel, and the corresponding R code on the right panel.
There are two types of .pdf files.  First, there are thematic files, containing slides on certain topics.  For example, you can take a look at portfolio_construction.pdf.  Second, there are lecture files, containing slides for specific lectures.  I created the .pdf files from .Rnw Sweave files using the knitr package.  I created the .pdf lecture files by selecting slides from the thematic files.  
There are also .R files containing the code in the lecture slides so that students can execute the code as they listen to the lecture. The lecture materials also contain RData files with sample data. 

Most of my code is open-source and available on GitHub:
https://github.com/algoquant

I welcome your comments.


# IB data request

In the field ‘Purpose’:
-	What is the purpose of the class?
The course is called FRE-7241 Algorithmic Portfolio Management.
The purpose of the course is to teach students how to test and implement algorithmic trading strategies using the R language and C++.

-	What will the students be using the data for?
The data will be used for testing algorithmic trading strategies.

-	Will there be assignments, tests, exams, papers, etc.
Yes, the assignments will require programming algorithmic trading strategies using the R language and C++.
 
In the field ‘Who/Where’:
-	Are there any other professors or TAs that will have access to the data?
The only people who will have access to the data will be the students enrolled in the course, the TA, and myself.


###############

Beixi, please see my answers below.

1. How do people in Wall Street decide the fair price of an Option, do they calculate them using the BS model and implied volatility provided by VIX?

Market prices of vanilla options (calls and puts) are determined in the exchange markets by supply and demand, not by any models.  The market prices of vanilla options are input into volatility models to calibrate implied volatility surfaces and skews.  The prices of exotic options are calculated from the implied volatility surfaces and skews.  Exotic options are usually traded over-the-counter, and their actual traded prices are negotiated between the dealers (banks) and investors.

2. Does the VIX represent the expected future vol? Can it represent the future risk?

No, the VIX doesn't represent the expected future realized volatility.  The VIX index is calculated from the implied volatilities.  VIX futures are contracts on the future value of the VIX index.  Most research that I have read claims that the implied volatility is typically higher than the future realized volatility.  So there's a risk premium associated with volatility.

3.If I have a VIX data and use them to calculate option price under BS model, and then I construct a strategy which trade on these option with the option price I derived from VIX and BS model, in the end, if I use the garch model on my strategy return, I can also have a time series of historical vol of my strategy. Here is my question, I have VIX representing future vol and garch vol representing realized vol, how can I test that the VIX I use is a good or bad predictor of realized vol? Do you know any test that can test the accuracy of VIX? Since the only idea I have is just using the linear regression and see if the R square is large or not.

I don't understand the volatility strategy that you describe.  The VIX index is calculated as an average of many implied volatilities at different strikes, so there's no way to reliably calculate a single option price from the VIX index.  You can use a GARCH model to forecast the volatility of your strategy, but I don't see how that would be related to the VIX index.




###############
# Syllabus:

1.	Time series analysis and ARIMA models,
2.	Moment estimation: range OHLC estimators of volatility, skewness, kurtosis, and covariance, 
3.	GARCH models and volatility forecasting, 
4.	Models of stock returns: Pareto distribution, stochastic volatility, Heston model, 
5.	Tail risk measures: value-at-risk, conditional value-at-risk, 
6.	Logarithmic utility and risk-adjusted performance measures: Sharpe, Calmar, and Sortino ratios, 
7.	Capital Asset Pricing Model (CAPM): the market portfolio, the Security Market Line, 
8.	Beta-adjusted performance measures: Treynor ratio, Jensen's alpha, information coefficient, 
9.	Factor models: Principal Component Analysis, cross-sectional regressions, Fama-French model, Barra model, 
10.	Pricing anomalies: size, value, momentum, volatility, 
11.	Forecasting models for price returns, stock beta, and correlation, 
12.	Portfolio optimization: mean-variance efficient portfolios, efficient frontier, Capital Market Line, 
13.	Correlation matrix estimation: Cholesky decomposition, Factor Augmented Regression, 
14.	Constrained portfolio optimization: coefficient shrinkage, 
15.	Static asset allocation strategies: cap-weighted and equal-weighted stock indices, all weather portfolios, 
16.	Portfolio management strategies: risk parity, minimum correlation, minimum variance, maximum Sharpe, maximum CVaR, betting against beta, factor investing, smart beta asset allocation, 
17.	Active portfolio management strategies: tactical asset allocation, portfolio rebalancing, Constant Proportion Portfolio Insurance (CPPI), sector rotation, 
18.	Benchmarking portfolio management skill: performance attribution, random portfolios, random investment choices, 
19.	Dynamic investment and consumption strategies: Merton model, 
20.	Performing rolling aggregations and regressions, bias-variance tradeoff, 
21.	Intertemporal portfolio choice and out-of-sample performance of optimized portfolios, 
22.	Strategy backtesting and optimization: data snooping, cross-validation, model overfitting, parameter regularization, 

## extract R chunks into .R file

# loop to extract R chunks in: C:/Develop/render_scripts.R


###############
### Explore study

+ [ ] Open Source Hedge Fund Project
http://www.quantsportal.com/
http://www.quantsportal.com/open-source-hedge-fund/

+ [ ] How to Write a Great Quant Blog
https://www.quantstart.com/articles/How-to-Write-a-Great-Quant-Blog



###############
### To-do list

what you will learn:
how to apply R to systematic investment strategies
how to use R to create your own systematic investment strategies
how to measure the performance of investment strategies and managers

what you will NOT learn:
what are the best systematic investment strategies
which strategies are recommended

what you will learn:
how difficult it is to create successful systematic investment strategies

topics:
static stock-bond allocation works better than most active strategies
simple active asset allocation strategy: sell in may
simple active asset allocation strategy: rebalance between stocks and bonds, using logistic function
different asset allocation functions (rules)
p-hacking increases with portfolio size: backtest will always find profitable strategy out of the many allocation functions rules
divide data in two: in-sample performance increases but out-of-sample performance decreases
simulating Brownian motion
optimization
regression
CAPM market timing


+ [ ] Add S&P 500 index and constituents data from datahub
https://datahub.io/core/s-and-p-500-companies
https://datahub.io/core/s-and-p-500#data
https://github.com/datasets
https://github.com/datasets/s-and-p-500
https://github.com/datasets/s-and-p-500-companies
S&P 500 index data
https://github.com/datasets
https://github.com/datasets/s-and-p-500
List of companies in the S&P 500 index together with associated financials
https://github.com/datasets/s-and-p-500-companies

+ [ ] Create a buy signal from the "Recession Indicator"
https://eranraviv.com/create-recession-indicator-using-mixture-models/

+ [ ] Create intraday momentum strategy from: Gao Intraday Momentum Strategy.pdf
https://eranraviv.com/market-intraday-momentum/
If the return is positive in the first half hour of trading then go long just before the last half hour, and then unwind.  And vice versa.
Explain that the Gao paper states that the predictability of the last half-hour returns depends on the level of volatility, and the predictability is meaningful only for days with high volatility.  The higher the volatility, the greater the predictability.  But when the first half-hour volatility is low, then the predictability is minimal.

+ [ ] In time_series_multivariate.Rnw add slide for Security Market Line using S&P500 data
https://seekingalpha.com/article/4181903-low-beta-outperforms  
https://backland.typepad.com/investigations/2018/06/why-low-beta-outperforms.html  
Demonstrate that stock alpha and beta are negatively correlated using S&P500 data.
Explain that the CAPM model is just a tautology because it doesn't really specify any relationship between the individual stock beta and its returns.
The CAPM equation states that individual stock returns are the sum of systematic returns (equal to beta times the market returns) plus idiosyncratic returns (equal to alpha plus e):
R - Rf = a + ß(Rm - Rf) + e
Where Rm are the market returns, and Rf are the risk-free returns.
The CAPM equation doesn't specify any relationship between the stock beta and its alpha (and thus its returns), so stocks with larger betas can have a smaller alphas (and returns), and vice versa.
Explain that the relationship between the stock beta and its alpha can be biased by the trend in the market returns.  So it's better to de-trend the market returns and to adjust the individual stock returns accordingly.

+ [ ] Explain Cornish-Fisher VaR
Tail risk measures
Carles Cornish-Fisher Sharpe Ratio
Calculate value-at-risk and conditional value-at-risk as function of skewness and kurtosis parameters.
Demonstrate that value-at-risk is not subadditive.
subadditive risk measures, ETL (ES/ETL/CVaR), Omega, Hurst exponent,  
conditional value at risk (CVaR)  
VaR for generalized Pareto distribution  
!!! Maillard Cvar Cornish Fisher Portfolio.pdf
!!! Lamb Cornish-Fisher Expansion.pdf
Maillard Cornish-Fisher Sharpe Ratio.pdf
http://www.capitalspectator.com/tail-risk-analysis-in-r-part-i/  
https://gist.github.com/jpicerno1/c3af6285713c76a5d124  

+ [ ] Forecast portfolio returns from the quantiles of the portfolio return distribution 
For example, forecast from the difference of the median price.
Can the Edgeworth or the Cornish–Fisher expansions be used?

+ [ ] Create an ARIMA forecasting model using MAD correlation coefficients
Demonstrate that it has superior out-of-sample performance using a back-test.

+ [ ] Forecast expected returns using the median of past returns instead of the mean
Demonstrate that for negatively skewed returns the median is positively biased, but that it has a smaller standard error than the mean.
Explain the bias-variance tradeoff.
Demonstrate how to adjust the bias of the median using quantiles.  Can the Edgeworth or the Cornish–Fisher expansions be used?
https://en.wikipedia.org/wiki/Edgeworth_series
https://en.wikipedia.org/wiki/Cornish%E2%80%93Fisher_expansion

+ [ ] Demonstrate that the MAD scales with time as the square root of time, just like the standard deviation
Demonstrate that for fat-tailed processes, the MAD is more forecastable (autocorrelated?) than the standard deviation.
Create a process for MAD, similar to GARCH (fit GARCH?).

+ [ ] Calculate the MAD covariance - the covariance based on the median, analogous to the MAD Median Absolute Deviation
Calculate the covariance equal to the difference between the MAD of the sum, squared, minus the MAD of the difference, squared:
cov = (MAD(r1+r2)^2 - MAD(r1-r2)^2)/4
Calculate the correlation coefficient.
Calculate the standard error of the MAD covariance, and its t-value: adapt variance ratio test. 

+ [ ] Calculate the portfolio variance using the MAD covariance coefficients, as a quadratic form of the portfolio weights and the MAD covariance coefficients

+ [ ] Explain the Spearman and Kendall correlation coefficients
The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables.
Demonstrate that Kendall's tau and Spearman's rho are special cases of a general rank correlation coefficient.
https://en.wikipedia.org/wiki/Rank_correlation#General_correlation_coefficient

+ [ ] Explain difference between Kendall's tau and rank regression
https://en.wikipedia.org/wiki/Rank_correlation
https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient

+ [ ] Demonstrate that the MAD ratio is better than the variance ratio for identifying portfolios that are forecastable out-of-sample
Calculate the standard error of the MAD ratio, and its t-value: adapt variance ratio test. 

+ [ ] Calculate the PCA using the MAD covariance coefficients instead of the standard covariance coefficients

+ [ ] Introduce MAD ratio component analysis MRCA: the first component is the max MAD ratio portfolio, the second is the max MAD ratio portfolio orthogonal to the first one, etc.
Use the MAD ratio to calculate the most trending portfolio (the first component).
Calculate orthogonality using rank statistic (MAD covariance).
Similar to forecastable component analysis.
Introduce Hurst component analysis HCA in a similar way.
Prado Kinetic Component Analysis Forecasting.pdf  

+ [ ] Introduce MAD component analysis MCA: the first component is the max MAD portfolio, the second is the max MAD portfolio orthogonal to the first one, etc.
Calculate orthogonality using rank statistic (MAD covariance).
Similar to forecastable component analysis.
Introduce Hurst component analysis HCA in a similar way.
Prado Kinetic Component Analysis Forecasting.pdf  

+ [ ] Introduce Sharpe component analysis SCA: the first component is the max Sharpe portfolio, the second is the max Sharpe portfolio orthogonal to the first one, etc.
Introduce Hurst component analysis HCA in a similar way.
Prado Kinetic Component Analysis Forecasting.pdf  

+ [ ] Instead of optimizing portfolio for highest Sharpe, optimize for highest forecastability
Weghenkel Predictable Feature Analysis.pdf
Goerg Forecastable Component Analysis.pdf
Is highest forecastability the same as highest Hurst exponent?
Can Hurst exponent be forecast?
Create scatterplot of many portfolios: variance versus Hurst exponent. 
Use package ForeCA by Georg M. Goerg who is now at Google NYC
https://ai.google/research/people/GeorgGoerg
http://fastml.com/are-stocks-predictable/
http://stats.stackexchange.com/questions/126829/how-to-determine-forecastability-of-time-series
http://stats.stackexchange.com/questions/23007/assessing-forecastability-of-time-series?lq=1

+ [ ] Create VAR autoregressive model using forecastable components

+ [ ] Calculate orthogonality in PCA using rank statistic instead of sum of products: median of products instead of sum of products

+ [ ] Analyze file vectorizedOUsim.R from Andrew Papanicolaou about vectorized OU code

+ [ ] Analyze file Trend filter_presentation.html by Jingtao Chen

+ [ ] Adapt from Joshua Wiley book: 
C:\Research\Machine Learning\Wiley book Deep Learning.pdf
C:\Research\Machine Learning\Wiley Deep Learning code
https://github.com/JWiley
http://joshuawiley.com/

+ [ ] Adapt from: Allaire TensorFlow.html

+ [ ] Adapt time series forecasting using keras tensorflow
https://blogs.rstudio.com/tensorflow/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/

+ [ ] Adapt from: machine learning Eddelbuettel RcppMLPACK.pdf

+ [ ] Adapt from book by Pim Van Vliet and Jan de Koning: High Returns from Low Risk: A Remarkable Stock Market Paradox
http://falkenblog.blogspot.com/2017/01/robecos-pim-van-vliet-has-new-low-vol.html
https://www.robeco.com/en/insights/authors/pim-van-vliet.html
https://www.paradoxinvesting.com/
https://blogi.bossa.pl/2017/03/06/wysokie-ryzyko-daje-niskie-zyski/
data:	C:\Research\Academic\high_returns_low_risk.xlsx

+ [ ] Study machine learning capstone project by Haotian Cai 
Use Boltzmann machine for feature extraction.
C:\Research\Machine Learning\Haotian Cai machine learning capstone

+ [ ] Create animation of a backtest over a sliding interval
https://yihui.name/animation/example/cv-ani/

+ [ ] Create examples for Oanda API in Python
https://github.com/richierocks/oanda
https://developer.oanda.com/rest-live-v20/introduction/
https://github.com/yhilpisch/tpqoa

+ [ ] Explore quantconnect and learn Python
https://www.quantconnect.com/

+ [ ] Request for NYU library
Norman Matloff
Statistical Regression & Classification
Publisher: Chapman and Hall/CRC; 1 edition (August 3, 2017)
ISBN-10: 9781498710916
ISBN-13: 978-1498710916

+ [ ] Adapt stock forecasting from:
https://github.com/topics/stock-prediction?l=r
https://github.com/topics/stock-prediction
https://github.com/topics/stock-market-prediction
https://github.com/rvndbalaji/StockMarketPrediction
https://github.com/JamesPNacino/Stock-Predictor-Application
https://github.com/Krishnadhruv/Stock-Market-Analysis-with-R

+ [ ] Add taxonomy of investment strategies from: Beaudan Backtest Overfitting.pdf

+ [ ] Demonstrate that ratio of STDEV divided by MAD is related to kurtosis

+ [ ] Create an Rcpp back-testing functional which accepts a C++ forecasting function

+ [ ] Install MKL library
http://dirk.eddelbuettel.com/blog/code/r4/

+ [ ] Study Rcpp
https://thecoatlessprofessor.com/programming/unofficial-rcpp-api-documentation/

+ [ ] Introduce functors for Rcpp - call lapply() in Rcpp
http://gallery.rcpp.org/articles/rcppnt2-introduction/

+ [ ] Introduce RcppNT2
http://rcppcore.github.io/RcppNT2/
http://gallery.rcpp.org/articles/rcppnt2-introduction/
http://gallery.rcpp.org/articles/rcppnt2-sum/

+ [ ] Add to recommended texts:
Prado book
Davies Book of R.pdf
Matloff book Linear Models Machine Learning.pdf
Matloff book Programming on Parallel Machines.pdf
Matloff book Statistical Modeling.pdf

wippp

+ [x] Set up gcloud

+ [x] Install Debian

+ [ ] Explain setup for Google Cloud
Study DataCamp tutorial Google Cloud for Data Science: set up Google Compute Engine, install Anaconda and run Jupyter notebooks.
https://www.datacamp.com/community/tutorials/google-cloud-data-science

+ [ ] Explain Google Compute Engine and virtual machines
https://robotwealth.com/run-trading-algorithms-google-cloud-platform-6-easy-steps/
Google Compute Engine (GCE) provides virtual machines (VMs) that run on hardware located in Google’s global network of data centres (a VM is simply an emulation of a computer system that provides the functionality of a physical computer). You can essentially use a VM just like you would a normal computer, without actually owning the requisite hardware.

+ [ ] Install RStudio and shiny servers on cloud
https://www.rstudio.com/products/rstudio/download-server/
https://www.rstudio.com/products/shiny/download-server/
https://docs.rstudio.com/shiny-server/
http://conormclaughlin.net/2018/03/hosting-your-own-rstudio-and-shiny-servers-in-the-cloud/
https://stackoverflow.com/questions/36948162/installing-shiny-server-on-debian-vm
https://github.com/rstudio/shiny-server/wiki/Building-Shiny-Server-from-Source

+ [ ] Reproduce from Baitinger Risk Parity Higher Moments.pdf

+ [ ] Add to recommended books: Bradley Efron and Trevor Hastie book Computer Age Statistical Inference
https://web.stanford.edu/~hastie/CASI/

+ [ ] Add to recommended books: Kenneth Lange book Numerical Analysis for Statisticians

+ [ ] Adapt machine learning from:
C:\Research\Machine Learning\JPM Kolanovic Machine Learning Strategies.pdf
C:\Research\Machine Learning\Peterson machine_learning.html
C:\Research\Machine Learning\Machine Learning Shrinkage LASSO Bias Variance Tradeoff.pdf
C:\Research\Machine Learning\Ritter Machine Learning Trading.pdf
C:\Research\Machine Learning\Dixon High Frequency Trading Market Making Machine Learning 2017.pdf
C:\Research\Machine Learning\Spiegeleer Machine Learning Options Skew.pdf
C:\Research\Machine Learning\Parnes Performance Machine Learning Trading.pdf
C:\Research\Machine Learning\Liew Neural Network Stock Premium Forecasting.pdf

+ [ ] Adapt RcppArmadillo code from: https://thecoatlessprofessor.com/programming/common-operations-with-rcpparmadillo/

+ [ ] Add function roll_count() using RcppArmadillo which reproduces roll_countr() in scratch.R
roll_count() is in lm_arma.cpp
roll_count() should count the number of consecutive TRUE elements, and reset to zero after every FALSE element.
Create a contrarian strategy using roll_count(): the number of consecutive close_low or close_high.
Scale the count threshold levels depending on the level of volatility.

+ [ ] Demonstrate how to book iBrokers trades in different models
https://www.interactivebrokers.com/en/software/tws/usersguidebook/modelportfolios/createmodel.htm

+ [ ] Compare speed of filter() with RcppRoll::roll_mean()

+ [ ] Replace: sapply(re_turns, mean) with colMeans(re_turns) and microbenchmark the two

+ [ ] Add Rcpp slide for calculating weighted rolling sum in numerical_analysis.Rnw based on roll_wsum.R from HighFreq

+ [ ] Create Rcpp code example from chapter 15.1.2: Matloff book The Art of R Programming
Modify slide about EWMA Realized Variance Estimator.
Exponentially Weighted Volatility using RCPP
http://adv-r.had.co.nz/Rcpp.html
http://systematicinvestor.github.io/Exponentially-Weighted-Volatility-RCPP
use RcppEigen or RcppArmadillo?
http://dirk.eddelbuettel.com/code/rcpp.eigen.html
https://stackoverflow.com/questions/22110075/r-use-primitive-functions-like-max-sum-in-rcpp
https://stackoverflow.com/questions/27490659/rcppeigen-going-from-inline-to-a-cpp-function-in-a-package-and-map

+ [ ] Explain that the Garman-Klass range estimator underestimates volatility because it doesn't capture close-to-open jumps, but that for intraday data that effect is very small - it matters more for daily data where overnight jumps are large

+ [ ] Explain difference between Theil–Sen estimator and rank regression
https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator

+ [ ] Explain that a time series can be decomposed into a trending term plus a mean-reverting term
The trending term can be calculated using a low-pass filter, for example moving average or regression.
The trending term can be used as a technical indicator of trend.
The mean-reverting term can be used as a technical indicator of mean-reversion.

+ [ ] Explain that a market making strategy is an integral over the Brownian motion - is the PnL mean-reverting?

+ [ ] Introduce the Schwartz model - generalization of the Ornstein-Uhlenbeck process to log-normal prices
Kearns Market Making Mean Reversion Models.pdf

+ [ ] Adapt dygraphs plotting from:
https://stackoverflow.com/questions/17888989/how-to-skip-weekends-on-dygraps-x-axis

+ [ ] Adapt from LeBaron Stock Momentum Volume.pdf

+ [ ] Adapt from LeBaron Improved Range Volatility Estimators.pdf

+ [ ] Adapt from Avellaneda Papanicolaou VIX Volatility Trading Risk.pdf

+ [ ] Adapt from: Cai Stock Premium Forecasting Tests.pdf
Campbell Stock Premium Forecasting Tests.pdf
Martin SVIX Stock Premium Forecasting.pdf

+ [ ] Adapt from ETF Sector Rotation Strategy
http://www.etfscreen.com/sectorstrategy.php
http://systematicinvestor.wordpress.com/2011/12/06/multi-asset-backtest-rotational-trading-strategies/

+ [ ] Adapt from Ekholm Decomposition of Hussman Strategic Growth (HSGFX) - uses Fama/French factors
https://gist.github.com/timelyportfolio/9b962f7c391c492bfe35
https://gist.githubusercontent.com/timelyportfolio/e5728c8c7fb45dbdb6e0/raw/e124379f19225fcdee18f30cb848da6fc6cae764/ekholm.R
http://timelyportfolio.blogspot.com/2014/10/selectionshare-timingshare-masterfully.html

+ [ ] Read: Bates thesis Market Making Stochastic Control Algorithmic Trading.pdf
The inventory process is an Ornstein-Uhlenbeck process.

+ [ ] Convert cumulative returns to log returns, not compounded returns

+ [ ] Rework backtesting to use roll_agg() (slide #33 titled Functional for Aggregating Asset Returns) from the start - skip looping over look_backs list
First pre-calculate matrix of EWMA returns (called re_turns) for a vector of lambda decay parameters, using parallel computing.
Use slide Performance of EWMA Strategies.
Then apply roll_agg() to perform loop and calculate aggregations over endpoints.
Get rid of calc_sharpe() and look_backs list.
Apply to ETF returns rutils::etf_env$re_turns.

+ [ ] Rework backtesting: in roll_agg() call FUN() and then perform a look_backs loop over the output of FUN(), instead of a look_backs loop over the oh_lc input of FUN(). 
Get rid of the agg_regate() function. 
roll_agg() should perform two loops: 
first, a loop over lamb_das, to run the model function with multiple lamb_da parameters, output is time series of returns, 
second, a look_backs loop over the time series of returns, output is matrix of performance statistics (Sharpe ratios), 
roll_agg() should accept the arguments: x_ts, look_backs, FUN, lamb_das, ...
further improvement: instead of performing sapply() loop over the time series of returns, perform vectorized operation.
roll_agg() should return an time series of performance statistics (Sharpe ratios).

+ [ ] Create backtesting: at each endpoint rebalance, run models over expanding window, select optimal lamb_da, don't loop over lamb_das 

+ [ ] Vectorize simu_ewma() with respect to its lamb_da parameter ?

+ [ ] Rewrite the Backtesting Framework using exclusively vectorized functions:
introduce improved out-of-sample data notation using period_s
is "periods" needed?
risk_ret_stats() should perform lapply() and return list
split and rename pnl_period()
etf_reg_stats is not defined anywhere in "investment_strategies"
	load it from "time_series_multivariate"

+ [ ] Deprecate slides in investment_strategies.Rnw
deprecate calc_sharpe() on slide Aggregation Function for EWMA Model
deprecate slide Performing Overlapping Aggregations
deprecate roll_agg() on slide Functional for Performing Overlapping Aggregations

+ [ ] Rewrite simu_ewma() in Rcpp ?

+ [ ] Modify simu_ewma() to catch error when oh_lc is shorter than look_back
add warmup period?

+ [ ] Modify slide "Rolling Weighted Aggregations Using Package RcppRoll" in risk_models, and add function filter()

+ [ ] Demonstrate that mean-reverting (statistical arbitrage) strategies often benefit if trades are delayed, as opposed to trend-following strategies which require trading immediately
Explain that this is because mean-reverting strategies depend on cheap/rich signals (indicators) which may be premature.  For example, prices may drop further even if they are already cheap.  So waiting a little bit may allow buying at a lower price.

+ [ ] Demonstrate how to use iBrokers data playback replay feature
The script added to data_management.Rnw downloads the raw data, but doesn't replay the bar data properly.
https://offerm.wordpress.com/2015/05/21/market-data-recording-and-playback-with-ibrokers-and-r-2/

+ [ ] Optimize portfolio using trailing Sharpe ratios instead of trailing returns

+ [ ] Demonstrate that rank momentum (weights proportional to ranks) works better than momentum strategy (weights proportional to returns or Sharpe)

+ [ ] Demonstrate that the best rank momentum strategy is with positive uniform weights for the top quantile of assets and negative uniform weights for the bottom quantile (instead of proportional weights)

+ [ ] Create shiny app for rank momentum strategy

+ [ ] Forecast the returns using volatility-adjusted momentum - just like Sharpe ranking  
Calculate volatility-adjusted momentum rankings by dividing the prior twelve month total return by the realized volatility over the same period and then ranking in the standard fashion.  
Clare Volatility Momentum Trend Following Asset Allocation.pdf  
Baltas Volatility Momentum Trend Following Asset Allocation.pdf  
Baltas Volatility Momentum Trend Following Asset Allocation slides.pdf  
Zakamulin Momentum Indicators Stock Forecasting.pdf  

+ [ ] Simulate Adaptive Asset Allocation strategy: momentum rank + min-variance optimization
Sharpe Adaptive Asset Allocation.pdf
Gestalt Adaptive Asset Allocation.pdf
https://quantstrattrader.wordpress.com/2016/03/01/a-book-review-of-resolve-asset-managements-adaptive-asset-allocation/
ReSolve Asset Management by michael philbrick, adam butler, and rodrigo gordillo
http://www.investresolve.com/
http://www.investresolve.com/robo/research/

+ [ ] Estimate correlation using OHLC data  
Bannouh Range High Frequency Covariance Estimators.pdf
Rogers OHLC Range Covariance Estimators.pdf

+ [ ] Use Huge Stock Market Dataset: C:\Develop\data\Kaggle_stocks.zip
https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs

+ [ ] Explain how to create your own package: Pfaff Package Development in R.pdf  

+ [ ] Adapt from: Boudt Covariance Shrinkage.pdf

+ [ ] Adapt from: Feng Deep Learning Momentum.pdf

+ [ ] Adapt from: variance risk term premia
http://www.sr-sv.com/variance-term-premia/

+ [ ] Adapt from: Winton Stock Market Challenge
https://www.kaggle.com/c/the-winton-stock-market-challenge

+ [ ] Implement GARCH model using range volatility estimators
Demonstrate that the log of the OHLC range is Gaussian and has strong autocorrelation.
Kinlay GARCH Volatility Forecasting.pdf
Alizadeh Range OHLC GARCH Volatility Estimators.pdf
LeBaron Improved OHLC Range Volatility Estimators.pdf

+ [ ] Explain that strategies which have both positive returns and positive skewness are genuine market anomalies
Strategies with positive returns usually also have negative skewness, and they have the characteristics of short option strategies.
Demonstrate that contrarian (short volatility) strategies have negative skewness, but positive returns, because they earn a premium for selling options.
And vice versa, long option volatility strategies have positive skewness, but negative returns, because they pay a premium for buying options.
Demonstrate that momentum (long volatility) strategies have positive skewness, but may also have positive returns, and that they are genuine market anomalies.

+ [ ] Adapt from IB script TWS Kovalevsky.R

+ [ ] Adapt from: Chris Conlan book Automated Trading with R
https://chrisconlan.com/automated-trading-r-apressspringer/
https://github.com/Apress/automated-trading-with-r
C:/Research/R/Tutorials/Conlan_automated_trading_with_r

+ [ ] Convert backtest_ep() to percentage returns, similar to backtest_rolling()

+ [ ] Add slide explaining momentum strategies
Momentum strategies work best with a lookback interval of about 12 months or less.
The most recent month exhibits reversal, so it's often excluded.
Momentum is a genuine market anomaly, since its returns have positive skew and also positive return.
Momentum strategies crash after a sharp rebound in the underlying market.
Momentum strategies complement the underlying asset instead of replacing it: the optimal portfolio is a combination of a momentum strategy plus the underlying asset.

+ [ ] Add slides:
Taxonomy of quantitative investment (trading) models: trend-following, momentum, portfolio
Momentum and portfolio models are better but they face the problem of overfitting because they have many parameters (weights).
Criticisms of back-testing: 
Trading model parameters are unknown, so quantitative investment (trading) faces the problem of model parameter tuning: adjusting the model parameters, to optimize model performance.
Back-testing doesn't solve the problem of parameter tuning, because it just replaces the trading model parameters with meta-parameters (look-back length, shrinkage intensity).

+ [ ] In time_series_univariate, add slide for the standard errors of forecasts from autoregressive models
Calculate the rolling z-scores of forecasts.

+ [ ] Adapt QPAS from QUSMA:
http://qusma.com/software/qpas/
https://github.com/qusma
Install QPAS trading journal for Interactive Brokers
https://github.com/qusma/QPAS
Install QDMS
https://github.com/qusma/QDMS

+ [ ] Adapt Parallel Constrained Random Portfolio Generation from:
http://quantbros.com/parallelized-simple-random-constrained-portfolio-generation/
C:\Develop\R\scripts\TechilaEfficientFrontier.R

+ [ ] Adapt portfolio VAR and CVAR in R from:
http://quantbros.com/portfolio-single-stock-var-and-cvar-in-r/

+ [ ] In investment_strategies, split and expand the slides: 
Rolling Portfolio Optimization Strategy
and 
Rolling Portfolio Optimization Strategy for S&P500
List and explain function HighFreq::roll_portf()
Add plots and more detail about weight scaling
Explain weight scaling: 
Sum of weights equal to 1 produces highly leveraged portfolios.
Sum of squared weights equal to 1 produces highly under-leveraged portfolios.
Weights scaled to match the volatility of the equally weighted portfolio are best compromise.

+ [ ] In investment_strategies, add slide explaining difference between scaling of the weights by using sum of weights versus using sum of squared weights
Add the slide after the slide: Aggregations Over Look-back and Look-forward Intervals

+ [ ] In investment_strategies, explain/fix the scaling of weights in back_test_ep
What does this mean "Calculate portfolio weights equal to number of shares" ?
Why divide weight_s by end_prices?  Is this legacy from when re_turns were dollar returns not percentage returns?
weight_s <- back_aggs/rowSums(abs(back_aggs))/end_prices

+ [ ] In rolling portfolio optimization strategies, calibrate the correlation matrix on a longer look-back interval than the returns, and shrink it to block-diagonal form
This is effectively PCA with sub-portfolios.
Then no need to shrink returns because portfolio optimization will use average returns of sub-portfolios?

+ [ ] Introduce concept of dynamic/adaptive shrinkage (instead of static shrinkage): apply shrinkage dynamically, only enough to reduce the covariance singularity below threshold level.
The covariance singularity index is the ratio of the largest eigenvalue divided by the smallest eigenvalue.

+ [ ] Add a shiny app to:
https://github.com/mkearney/shinyapps_links

+ [ ] Explain difference between cross-sectional momentum and time-series momentum (trend-following)
http://blog.alphaarchitect.com/2017/04/17/does-market-sentiment-help-explain-momentum/
trend-following is trading single asset using many predictors.
momentum is trading several assets by sorting them using many predictors.

+ [ ] Explain difference between trend-following and momentum strategies
create simple trend-following and momentum strategies
Lewellen: momentum is cross-sectional ranking, meaning winners outperform losers
Autocorrelation is longitudinal ranking, meaning past performance will continue
Is it possible to have zero autocorrelation, but non-zero momentum?

+ [ ] Replace back-test with backtest?

+ [ ] Keller momentum strategy Elastic Asset Allocation using package IKTrading
Keller (2014) Elastic Asset Allocation  
Keller Elastic Asset Allocation.pdf
https://quantstrattrader.wordpress.com/2015/01/30/comparing-flexible-and-elastic-asset-allocation/  

+ [ ] Simulate Keller Asset Allocation strategies
Keller Momentum Protective Asset Allocation.pdf
Keller Momentum Markowitz Shrinkage Asset Allocation.pdf

+ [ ] Implement Varadi's PCA momentum
https://quantstrattrader.wordpress.com/2018/09/17/principal-component-momentum/
https://cssanalytics.wordpress.com/2018/07/23/2d-asset-allocation-using-pca-part-1/
https://cssanalytics.wordpress.com/2018/08/21/2d-asset-allocation-using-pca-part-2/

+ [ ] Explain Dual Momentum strategy
http://www.quantsportal.com/momentum-on-dual-momentum-portfolios/

+ [ ] Explain momentum reversal
Novy Momentum Reversal Momentum Strategy.pdf
Xiong Momentum Reversal Momentum Strategy.pdf
https://voxeu.org/article/momentum-trading-return-chasing-and-predictable-crashes

+ [ ] Adapt momentum strategy using GARCH
https://medium.com/auquan/long-short-equity-trading-strategy-daa41d00a036

+ [ ] Rebalance the momentum strategy using different frequencies: annual, quarterly, monthly, daily
Demonstrate that less frequent rebalancing of momentum strategy works better. 

+ [ ] Implement constrained critical line algorithm CCLA
https://quantstrattrader.wordpress.com/2015/06/05/momentum-markowitz-and-solving-rank-deficient-covariance-matrices-the-constrained-critical-line-algorithm/
https://epublications.bond.edu.au/ejsie/vol2/iss3/2/

+ [ ] Introduce the Critical Line Algorithm (CLA)  
http://rnfc.org/2015/06/05/Markowitz/
function CCLA()  
Bailey Prado Critical Line Algorithm Portfolio Selection  

+ [ ] Implement simple scripts for Tactical Asset Allocation System by Mebane Faber
http://petewerner.blogspot.com/2012/04/mebane-faber-tactical-asset-allocation.html
https://github.com/petewerner/misc/blob/master/gtaa-script.R

+ [ ] Tactical Asset Allocation simple script  
http://blog.fosstrading.com/2009/11/tactical-asset-allocation-using-blotter.html  
http://petewerner.blogspot.com/2012/04/mebane-faber-tactical-asset-allocation.html  
https://github.com/petewerner/misc/blob/master/gtaa-script.R  
+ [ ] Tactical Asset Allocation Faber  
http://unstarched.net/2013/06/18/the-fallacy-of-1n-and-static-weight-allocation/  

# Sign up to Allocate Smartly by Walter Jones ?
https://allocatesmartly.com/
https://www.valuewalk.com/2017/04/tactical-asset-allocation-us-6040-benchmark/
https://alphaarchitect.com/2017/04/27/tactical-asset-allocation-us-6040-benchmark/

+ [ ] Fit ARIMA using time series regression
Lundholm Introduction R Time Series
Regression and time series data
auto.arima() handles order selection and differencing (but only checks if errors are stationary).

+ [ ] Order selection using the Akaike and Bayesian information criteria AIC BIC

+ [ ] Create study of time series forecasting using ARIMA or regression
ARIMA order selection.
Create synthetic time series using ARIMA.
Apply various forecasting techniques.
Introduce confusion matrix and ROC curve.
Add spurious random predictors, and show that they decrease forecasting performance.
Discuss Model Variable selection: AIC, AIC, BIC.
Demonstrate that monthly returns have higher autocorrelation than daily returns.

+ [ ] Demonstrate overfitting of ARIMA forecasting model, that more ARIMA parameters decrease the out-of-sample performance (increase MSE).

+ [ ] Perform backtest of ARIMA(p, 0) strategy for a single asset, using a simulated ARIMA series of trending prices
Calculate the standard error of optimal ARIMA strategy parameters using bootstrap, and compare it with regression solution.
Divide the data in two, and find optimal ARIMA parameters in-sample, then apply them out-of-sample.
Demonstrate that increasing the number of ARIMA parameters (p) increases the in-sample performance, 
Demonstrate that for a small number of ARIMA parameters (p) the out-of-sample performance also increases, but as p becomes much greater it decreases.
Demonstrate that the optimal number of ARIMA parameters (p) depends on the number of ARIMA parameters in the simulated ARIMA series of prices.
Demonstrate that applying shrinkage to ARIMA coefficients improves out-of-sample performance.
Perform backtest to find optimal shrinkage parameter.
https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/
https://www.datascience.com/blog/introduction-to-forecasting-with-arima-in-r-learn-data-science-tutorials

+ [ ] Adapt one-month momentum reversal Ben Gum from AXA Rosenberg
The one-month return reversal in equity prices was first documented by Jedadeesh (1990), who found that there was a highly significant negative serial correlation in the monthly return series of stocks. This is in contrast to the positive serial correlation of the annual stock returns. Explanations for this effect differ, but the general consensus has been that the trailing one-month return includes a component of overreaction by investors.  Since 1990, the one-month return reversal effect has decayed substantially, which has led others to refine it. Asness, Frazzini, Gormsen, and Pedersen (2017) refine this idea by adjusting MAX5 (the average of the five highest daily returns over the trailing month) for trailing volatility. They define a measure SMAX (scaled MAX5), which is the MAX5 divided by the trailing month dailyreturn volatility. SMAX is designed to capture lottery demand in excess of volatility. They show that SMAX has an even stronger one-month return reversal than trailing month return.
In this talk, I first replicate the results of Jedadeesh and Asness as benchmark models. I confirm that SMAX outperforms simple return reversal over the test period 1993-2017. However, the effectiveness of SMAX declines substantially over the test period. Using an enhanced combination of return statistics, I improve upon SMAX. I further improve upon SMAX by applying Neural Networks to trailing daily active returns. Note that all of these signals decay substantially in effectiveness over the common test period 1998-2017.

+ [ ] Explain why momentum strategy works, even when trend-following doesn't work
Can a momentum strategy based on ranking work even if trend-following doesn't work?
Demonstrate that trend-following is very hard to trade, but cross-sectional momentum is easier, because it isolates effect of market beta.
Create model of several time series, where each time series is random, but differences between them are autocorrelated.
There's no autocorrelation of returns, but there's autocorrelation of rank statistics.
Study Lewellen: momentum is cross-sectional ranking, meaning winners outperform losers
Autocorrelation is longitudinal ranking, meaning past performance will continue
How is it possible to have zero autocorrelation, but non-zero momentum?

+ [ ] Reproduce time series momentum smile
Moskowitz Time Series Momentum.pdf
Hurst Pedersen AQR Momentum Evidence.pdf

+ [ ] Explain model variable selection using maximum likelihood penalized by AIC and BIC

+ [ ] Adapt from: Mackie Round Turn Trade Backtesting.html
How to distinguish skill versus luck or overfitting
https://opensourcequant.wordpress.com/2018/06/30/round-turn-trade-simulation-in-r/
https://github.com/jaymon0703/R-Finance-2018---Round-Turn-Trade-Simulation

+ [ ] what's this about ? - Add slide to risk_models: describing in-sample and out-of-sample aggregations
after slide Performing Aggregations Over Overlapping Intervals

+ [ ] Explain that there are two types of forecasts
One type of forecasts is about the likelihood of events at a particular time.
For example, the stocks will go up tomorrow.
Another type of forecasts is about the likelihood of events, but without a definite time horizon.
For example, stocks are more likely to go up than go down, for some indefinite time, until the next forecast is made.
Distinguish between forecasts and predictions.

+ [ ] Add Swensen Six ETF portfolio and momentum strategy
https://seekingalpha.com/insight/modern-investing/article/4206506-swensen-six-portfolio-momentum-style
https://seekingalpha.com/article/4078402-momentum-applied-swensen-six-portfolio

+ [ ] Perform backtest of EWMA strategy for single asset
Calculate the standard error of optimal EWMA strategy parameters
Create strategy with two EWMAs, and demonstrate that it performs better in-sample, but worse out-of-sample
Create strategy with multiple EWMAs, and demonstrate that they performs better in-sample, but worse out-of-sample
Demonstrate that applying shrinkage to EWMA coefficients improves out-of-sample performance
Perform backtest to find optimal shrinkage parameter

+ [ ] Create an MA strategy with the return forecast equal to the MA model: weighted moving average over the past p returns 
Calculate the MA coefficients as equal to the partial autocorrelations.
Calculate the partial autocorrelations using average future returns, instead of single-period returns.
Add to the MA model the past High-Low ranges. 
Calculate the partial autocorrelations using RcppArmadillo.

+ [ ] Demonstrate that it's possible to optimize the MA strategy in-sample, so that it produces profits in almost a straight line, but the profits immediately disappear out-of-sample, as if they were arbitraged away by investors 
Demonstrate that as p (the number of past MA returns) increases, the in-sample performance improves, but the out-of-sample performance deteriorates.
Demonstrate that in-sample, the MA strategy performs very well even on random data.
Introduce a constraint on the weights, so that the neighboring weights can't differ by more than say by dp. 
Demonstrate that the out-of-sample performance improves as dp decreases. 
Explain that this constraint is a form of regularization.
Calculate the MA weights over a rolling interval, and perform PCA on the weights.
Determine shape of the first three principal components: flat, tilt, butterfly.
Apply regularization to the MA weights by expressing them as a weighted sum of three principal components: flat, tilt, butterfly.
Demonstrate that the out-of-sample performance improves with stronger regularization (fewer principal components). 

+ [ ] take IB futures course
https://gdcdyn.interactivebrokers.com/en/index.php?f=25228&course=4

+ [ ] take Machine Learning in Finance course by Igor Halperin
https://www.coursera.org/learn/guided-tour-machine-learning-finance

+ [ ] Add books to notes: 
Ang book Financial Data and Models Using R (good, some code)
http://www.cliffordang.com/
Mark Bennett book Financial Analytics with R
Chris Conlan book Automated Trading with R
https://chrisconlan.com/automated-trading-r-apressspringer/
https://github.com/Apress/automated-trading-with-r
C:/Research/R/Tutorials/Conlan_automated_trading_with_r
Wilmott book Frequently Asked Quantitative Finance Questions
Narang book Quantitative and High Frequency Trading (just talk, few examples, and no code)

+ [ ] Explain trading rule heuristics: 
Avoid making binary decisions (buy/not buy), and instead make incremental decisions (buy a little/buy some more/buy even more/...)
Use many different models and rules in parallel, and allocate small amounts of risk to each.
Avoid fitting models with many parameters.
Use rank (order) or count statistics instead of parametric models (like linear regression).

+ [ ] Explain that proper position sizing is as important as having a profitable strategy with a high probability (odds) of winning
Provide an estimate of the statistical edge (odds of winners versus losers) of systematic strategies in practice: best strategies have odds of just a few percent above even odds.
Explain that you can go bankrupt even with a winning (skilled) strategy. 
Calculate the probability of going bankrupt as a function of the strategy odds of winners versus losers.

+ [ ] Adapt from: Matloff book Statistical Modeling.pdf
http://heather.cs.ucdavis.edu/~matloff/132/PLN/probstatbook/ProbStatBook.pdf

+ [ ] Adapt from: Matloff Regression Analysis.pdf

+ [ ] Adapt from: Matloff Regression Classification.pdf

+ [ ] Explain different ways of combining trending and reverting strategies: using simple sum or by biasing the reverting strategy, depending on the direction of the trending strategy

+ [ ] Add dygraphs annotations: vertical lines for technical indicators
http://dygraphs.com/options.html
https://github.com/danvk/dygraphs/issues/889
http://dygraphs.com/tests/hairlines.html
https://stackoverflow.com/questions/7353539/dygraph-vertical-line

+ [ ] Explain that given many signals from an ensemble of models, it's better to first calculate the positions and then to average the positions, instead of averaging the signals and calculating a single positions vector
Averaging the positions reduces the binary risk.

+ [ ] Demonstrate that in a mean-reversion strategy, if the look-back is longer then the signal is more normal so the threshold should be lower
Calculate the moments of the signal as a function of the look-back.

+ [ ] Use strategy objective function which isn't sensitive to small number of winners 
Remove the largest winners from strategy returns before calculating the performance.
Define objective function equal to Sharpe divided by number of trades.

+ [ ] In risk_models.Rnw update all the slides from section:
Package PerformanceAnalytics for Risk and Return Analysis
Remove/replace dependencies on PerformanceAnalytics.

+ [ ] Study different asset allocation functions (rules)
Modify function back_test() so it accepts an asset allocation function ?
Create asset allocation function which takes a permutation of recent returns to calculate weights.
That way every permutation corresponds to a different strategy.
Demonstrate that there's always one asset allocation function that is profitable in a backtest.
Demonstrate that the profitability grows with the number of assets.

+ [ ] Analyze function efficient.portfolio() in Zivot Efficient Portfolios in R.pdf  

+ [ ] update and expand slide The Efficient Frontier and Capital Market Line in portfolio_construction ?
Zivot Efficient Portfolios in R.pdf

+ [ ] Explain that portfolio managers have two types of skill:
Portfolio selection (stock-picking) skill
Market timing skill
Market timing skill is the ability to adjust the portfolio market beta by correctly forecasting future market returns.
Market timing is the act of moving in and out of the market or switching between asset classes based on using predictive methods such as technical indicators or economic data. 

Investment strategies for multiple assets.
Momentum strategy for S&P500 stock portfolio.
Portfolio optimization for multiple assets

+ [ ] Introduce univariate regression
perform regression of future cumulative returns from past cumulative returns
demonstrate that regression works better over longer period of future cumulative returns
introduce multivariate regression 
introduce ARIMA as regression
rolling regression in RcppArmadillo 

+ [ ] Demonstrate that a model with more parameters has bigger parameter standard errors than one with fewer parameters, when both models are calibrated on the same data
Is this a manifestation of conservation of entropy: the information in the parameters cannot exceed the information in the data?
Is this a manifestation of the Cramer-Rao bound and Fisher information?
Demonstrate that calibrating a model with more parameters requires more data, to achieve the same parameter standard errors. 
Demonstrate that parameter shrinkage reduces the standard errors, but increases the model bias (bias-variance tradeoff).
DeMiguel Shrinkage Estimators Portfolio Optimization draft.pdf

+ [ ] Perform simulation to demonstrate that shrinkage reduces estimator variance and standard error, even though it increases its bias
Stein's paradox: Yung Shrinkage Estimators Stein's Paradox
beta shrinkage estimator
http://eranraviv.com/blog/a-shrinkage-estimator-for-beta/

+ [ ] Study effect of shrinkage term in the form sqrt(abs())

+ [ ] Demonstrate that investing in the rolling optimal portfolio is a trend-following strategy  

+ [ ] Read Jonathan Kinlay articles on linkedin

+ [ ] Create slides from homework - deprecated
Calculate autocorrelations and partial autocorrelations by hand.

+ [ ] Improve slides:
Stationary Processes and Their Characteristic Equations
Integrated and Unit-root Processes

+ [ ] Adapt from package andrewuhl/RollingWindow

+ [ ] Create asset price model equal to sum of trending component plus mean-reverting component
Calibrate model using maximum log-likelihood estimation similar to package egcm.
Study the out-of-sample model performance.

+ [ ] Adapt from Brian Reich lectures with R code for statistics, optimization, LASSO regression, SVD, PCA, Kalman filter, machine learning
http://www4.stat.ncsu.edu/~reich/BigData/code/

+ [ ] Adapt from Farrell: logistic regression, Vector Auto-Regression (VAR),
Farrell week10-slides.pdf

+ [ ] Adapt from: Top 10 Machine Learning Algorithms
https://www.kdnuggets.com/2017/10/top-10-machine-learning-algorithms-beginners.html

+ [ ] Adapt from WRDS classroom tools and syllabus topics  
https://wrds-web.wharton.upenn.edu/wrds/classroom/
https://wrds-web.wharton.upenn.edu/wrds/classroom/investments.cfm

+ [ ] Adapt from OTIS Wharton Online Trading & Investment Simulator
https://wrds-otis.wharton.upenn.edu/otis/

+ [ ] Create shiny with shaded dygraphs and toggle shading on and off  

+ [ ] get data from: 
https://www.alphavantage.co/

+ [ ] Adapt from: Simaam Efficient Portfolio Parameter Uncertainty.pdf
https://www.linkedin.com/pulse/2-dynamic-asset-allocation-sector-etfs-majeed-simaan/
https://www.linkedin.com/pulse/asset-allocation-sector-etfs-empirical-perspective-error-simaan/
http://homepages.rpi.edu/~simaam/R.html
https://quantstats.shinyapps.io/yahoo/
Simaam Dynamic Asset Allocation Sector ETF.R
Simaam Asset Allocation Sector ETF.R

+ [ ] Adapt from: Simaam Financial Time Series Using R.pdf
Simaam Financial Time Series Using R.R

+ [ ] Replace calls to quantmod::getSymbols() with get_symbols() ?

+ [ ] Adapt linear programming example from Saldanha Linear Programming.pdf

+ [ ] Adapt from: Bloch ebook Quantitative Portfolio Management.pdf

+ [ ] Adapt from: Simaan Efficient Portfolio Parameter Uncertainty.pdf

+ [ ] Adapt from: 
http://gekkoquant.com/2012/08/29/parameter-optimisation-backtesting-part1/
http://gekkoquant.com/2012/08/29/parameter-optimisation-backtesting-part-2/

+ [ ] Explain that the shape of the efficient frontier depends on the weight constraints
Plot efficient frontier with two different weight constraints (scaling): sum and sum-of-squares.

+ [ ] Demonstrate that the efficient frontier is close to a parabola for small standard deviations, and close to a straight line for large standard deviations  
Explain why for small standard deviations, the efficient portfolio returns are proportional to the square root of their standard deviations (for different risk free rates).
Explain why for large standard deviations, the efficient portfolio returns are proportional to their standard deviations (for different risk free rates).
hint: study the efficient portfolio weights and the portfolio leverage.

+ [ ] Demonstrate that any convex combination of efficient frontier portfolios is also an efficient frontier portfolio  
This is known as the portfolio separation theorem (two fund separation theorem).
https://en.wikipedia.org/wiki/Mutual_fund_separation_theorem
http://www.bearcave.com/finance/long_short_cvar.html
Any efficient portfolio can be expressed as a combination of two other efficient funds (efficient portfolios). 
The efficient frontier consists of convex combinations of any two efficient frontier portfolios.  
The variance of a frontier portfolio is equal to the variance of the minimum variance portfolio plus the square of its return minus the return of the minimum variance portfolio.  
Brunnermeier CAPM Model: slide #53 Deriving the Frontier
CAPM Asset Pricing.pdf
Merton Efficient Frontier Portfolio.pdf

+ [ ] Adapt CAPM, portfolio optimization, and bootstrapping efficient frontier from: C:\Research\R\Tutorials\Zivot\Econ 424 files:
bootstrapPortfoliosPowerpoint.pdf
bootstrapPortfolio.R
portfolio_noshorts.R
demonstrate that the standard error of the means is much bigger than that of the standard deviations.
demonstrate that the standard error of the means is of the same order as the means themselves.
demonstrate that the standard error of the standard deviations is one order less than the standard deviations themselves.

+ [ ] Create function similar to PerformanceAnalytics function create.Efficient.Frontier()

+ [ ] Create portfolio functions:  
Compute global minimum variance portfolio
Compute minimum variance portfolio with target return
Compute tangency portfolio
Compute and plot efficient frontier
Zivot portfolio.r from econ424 - using covariance matrices  
http://faculty.washington.edu/ezivot/econ424/portfolio.r  

+ [ ] Add resource: Schmidt High Performance R Computing.pdf

+ [ ] Explain the difference and consequences between using the correlations of simple returns versus correlations of percentage returns

+ [ ] Adapt from:
https://rviews.rstudio.com/2017/07/21/visualizing-portfolio-volatility/
https://rviews.rstudio.com/2017/07/18/introduction-to-rolling-volatility/
https://rviews.rstudio.com/2017/07/12/introduction-to-volatility/

+ [ ] Expectation Maximization algorithm
Zafeiriou Expectation Maximization Algorithm.pdf
http://gallery.rcpp.org/articles/EM-algorithm-example/

+ [ ] get trial for Techila
https://console.cloud.google.com/launcher/details/techila-public/techila
http://www.techilatechnologies.com/help/techila-distributed-computing-engine/r-techila-distributed-computing-engine.html

+ [ ] Explore: 
https://www.portfoliovisualizer.com/
https://www.portfoliovisualizer.com/examples
https://www.portfoliovisualizer.com/rolling-optimization

+ [ ] Adapt from package parma Portfolio Optimization: parma Vignette.pdf

+ [ ] Always use expanding look-backs, otherwise model may not have enough data  

+ [ ] Adapt portfolio optimization from: 
Trapletti finance.R
Ian Kaplan etf_opt.R

+ [ ] Adapt optimization code for models and portfolios from package NMOF
http://enricoschumann.net/NMOF.htm
http://enricoschumann.net/files/NMOFman.pdf
Schumann NMOF Financial Optimisation.pdf
NMOF Financial Optimisation.pdf
NMOF Vectorised Objective Functions.pdf
C:\Users\Jerzy\Documents\R\win-library\3.3\NMOF\book\C-PortfolioOptimization\R
C:\Users\Jerzy\Documents\R\win-library\3.3\NMOF\book\C-EconometricModels\R

+ [ ] Analyze package caret to see if it performs loops in R or in C++
https://github.com/topepo/caret

+ [ ] Adapt from book R for Data Science

+ [ ] Pkg fImport
yahooBriefing("AAPL")
yahooBriefing

+ [ ] Deprecate file: "quantmod examples.R" in C:\Develop\R\scripts
mostly already extracted, except for last example

+ [ ] what is this?
source(file="C:/Develop/R/scripts/vis_portf.R")

+ [ ] Topic: simulate Parrondo games

+ [ ] Coursera R Data Science Specialization Certificate
https://www.coursera.org/specialization/jhudatascience/1?utm_medium=sem&utm_source=gg&utm_campaign=spn_dss

+ [ ] Read: Sornette Power Law Tail Risk.pdf

+ [x] move slides in investment_strategies.Rnw
Move slides from Backtesting Active Investment Strategies to Active Investment Strategies:
Performance of EWMA Strategies
Simulating EWMA Strategies Using Parallel Computing

+ [x]  Move sections from data_management.Rnw to markets_trading.Rnw:
\section{Stocks, Bonds, and Futures}
\section{Fundamental Company Data}
\section{High Frequency and Intraday Time Series Data}
\section{Package \protect\emph{IBrokers} for Using Interactive Brokers}

+ [x] Create a max Sharpe strategy with the exponentially smoothed excess returns: create a shiny app with a lambda decay slider

+ [x] Explain that under the quadratic sum-of-squares constraint the weights are constrained to a hypersphere, while under the linear sum-of-weights constraint the weights are constrained to a hyperplane

+ [x] Rewrite the overlapping endpoints framework in risk_models.Rnw: 
n_rows is the number of data points.
n_points is the number of periods between neighboring endpoints.
look_back is the number of data points in the look-back interval.

+ [x] Rename n_row to n_rows and n_col to n_cols

+ [x] Remove fwd_points from investment_strategies.Rnw
Instead just use end_points[it_er+1]

+ [x] Combine the data from files sp500.RData sp500_2017.RData sp500_recent.RData

+ [x] move from homework to numerical_analysis.Rnw lecture slides:
Summary: Create a function which simulates an ARIMA process in RcppArmadillo.
Replicate function filter() using RcppArmadillo - adapt code from sim_arima.cpp

+ [x] Add SVXY ETF to the ETF Dataset

+ [x] Create new file called data_management.Rnw, with thematic slides
Move slides about downloading data from time_series_univariate.Rnw
Move slides about Data Input and Output from R_environment.Rnw

+ [x] Calculate the efficient frontier portfolios as a convex combination of any two efficient portfolios  
Select the market portfolio as one portfolio and a portfolio with the maximum expected return as the other portfolio. 
Alternatively, select the minimum variance portfolio as one portfolio and a portfolio with the maximum expected return as the other portfolio. 

+ [x] Explain the benefits of performing a backtest 
Performing a backtest allows finding the optimal trading model parameters.
But the backtest just redefines the problem of finding (tuning) the optimal trading model parameters, into the problem of finding the optimal backtest meta-model parameters.
But the advantage of using the backtest meta-model is that it reduces the number of parameters that need to be optimized.
But the benefit of a dynamic quant strategy is that is has fewer meta-parameters than the number of portfolio weights, and the performance is less critical on the exact knowledge of those meta-parameters.
There are two models in a backtest: the trading model and the backtest (the meta-model).
For example, a momentum trading model has the following parameters: the length of the look-back interval, the lambda decay, and the asset allocation function (rule). 
The backtest meta-model has the following parameters: the bid-offer spread, and the rebalancing frequency.
The parameters of the backtest meta-model are the meta-parameters.
In the case of EWMA, the model has only one parameter (the lambda), and the meta-model has two parameters (look-back interval and rebalancing period) and a rebalancing function (rule).

+ [x] Flip ETF momentum strategy to a mean-reverting model - doesn't produce positive returns

+ [x] Demonstrate that momentum strategy is able to time the market: the beta changes ahead of market moves
Market timing is the act of moving in and out of the market or switching between asset classes based on using predictive methods such as technical indicators or economic data. 
https://www.rdocumentation.org/packages/PerformanceAnalytics/versions/1.4.3541/topics/MarketTiming
Wermers Market Timing.pdf
Henriksson Market Timing.pdf

+ [x] Add transaction costs to simu_ewma()

+ [x] Add Alpha Vantage as main data provider in time_series_univariate.Rnw

+ [x] Change to 252 business days, instead of 260

+ [x] Add files to NYU Classes:
Storn Differential Evolution.pdf
DEoptim.pdf
DEoptim Introduction.pdf
DEoptim Portfolio Optimization.pdf

+ [x] Rename the look_back parameter used for calculating weight_s, to wid_th
To avoid confusing it with other aggregation look-back parameters

+ [x] Change inner_prod=(t(re_turns) %*% re_turns) to cross_prod=crossprod(re_turns)

+ [x] Fix calls to filter(): use rev() to reverse the order of weight_s so that most recent observation have biggest weight

+ [x] Change endpoints calculation: define look_backs as a list of numeric vectors
Calculate aggregations using lapply() loop over the look_backs, instead of sapply()

+ [x] Change endpoints calculation to without the extra 0 at the beginning

+ [x] Create data and script directories
Move data files from C:\Develop\data to C:\Develop\R\lecture_slides\data
Move script files from C:\Develop\R\scripts to C:\Develop\R\lecture_slides\scripts

+ [x] Replace "window" with "interval", and "win\_dow" with "inter\_val", and "win_dow" with "inter_val"

+ [x] Create scatterplot of random portfolios using inverse covariance matrix

+ [x] Explain that Capital Market Line represents levered and delevered portfolios  

+ [x] Derive minimum variance weights  
http://www.bearcave.com/finance/portfolio_equations/  

+ [x] Rename the look-back window for rolling aggregations from win_dow to look_back.

+ [x] Replace xts::.subset_xts() with brackets operator []

+ [x] Replace function RcppRoll::roll_mean() with filter()

+ [x] move the section "Performing Aggregations Over Time Series" from time_series_multivariate to risk_models



###############
### Topics to add

+ [ ] Write backtest loop using lapply() loop in Rcpp Sugar

+ [ ] Adapt Cowles-Jones random walk test from: Liesenfeld Forecasting Asset Returns Cowles-Jones Test.pdf

+ [ ] Adapt about Interactive Brokers API from
https://holowczak.com/installing-ib-gateway-for-linux/
https://holowczak.com/installing-ib-gateway-for-linux/3/

+ [ ] Demonstrate the intraday seasonality of trading volumes in high frequency data - adapt from Chicago presentation and alphaScripts.R
Add to section High Frequency and Intraday Time Series Data in markets_trading.Rnw

+ [ ] Adapt Dynamic Asset Allocation for Sector ETFs from: 
https://www.linkedin.com/pulse/asset-allocation-sector-etfs-empirical-perspective-error-simaan/
https://www.linkedin.com/pulse/2-dynamic-asset-allocation-sector-etfs-majeed-simaan/

+ [ ] Explain market making strategies
Dixon High Frequency Trading Market Making Machine Learning 2017.pdf
Menkveld High Frequency Trading Market Making.pdf
Kearns Market Making Mean Reversion Models.pdf

+ [ ] Explain how to simulate limit orders using OHLC data
Explain why limit orders are better than market orders.
Kim Market Making Trading Hidden Markov Model.pdf

+ [ ] Explain limit orders
https://www.investopedia.com/terms/l/limitorder.asp

+ [ ] Add to statistics.Rnw section non-parametric methods: rank regression

+ [ ] Add to statistics.Rnw quantile regression package quantreg
https://data.library.virginia.edu/getting-started-with-quantile-regression/
https://en.wikipedia.org/wiki/Quantile_regression
quantreg Vignette.pdf
Demetrescu IVX Filter Quantile Regression Forecasting.pdf
Lee IVX Filter Quantile Regression Forecasting.pdf

+ [ ] Add to risk_models.Rnw in section Performing Aggregations Over Time Series: rolling rank regression

+ [ ] Adapt from: Velu Rank Regression VAR Models.pdf

+ [ ] Adapt from: Terpstra Wilcoxon Rank Regression.pdf

+ [ ] Adapt  Rank-Based Estimation and Prediction from: rlme Vignette.pdf

+ [ ] Adapt robust regression from: Martin Robust Regression.pdf

+ [ ] Adapt from: Rana Rank Regression Bootstrap.pdf

+ [ ] Adapt from package mblm: convert rank regression to Rcpp and contact Komsta: lukasz.komsta@umlub.pl
http://www.komsta.net/software

+ [ ] Adapt from: Carriero VAR Models Shrinkage Reduced Rank Regression.pdf
Johansen Reduced Rank Regression.pdf
Use Stock Watson datasets:
http://fmwww.bc.edu/ec-p/data/stockwatson/datasets.list.html
https://www.princeton.edu/~mwatson/Stock-Watson_3u/Students/Stock-Watson-EmpiricalExercises-DataSets.htm
C:\Research\Academic\Stock Watson datasets\us_macro_monthly.xlsx
usmacro_monthly_description.pdf

+ [ ] Rank regression for robust rolling beta estimation - compare with Kalman filter
Sawyer Rank Regression.pdf
Rfit Rank Regression.pdf
https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator
https://en.wikipedia.org/wiki/Rank_correlation
https://stats.stackexchange.com/questions/152517/what-is-reduced-rank-regression-all-about/213063

+ [ ] Adapt from package fromo: Fast Robust Moments in R with Rcpp
https://github.com/shabbychef/fromo

+ [ ] Calculate standard error of optimal portfolio weights
Goldberg Portfolio Optimization Error.pdf
Goldberg Random Matrix Shrinkage Covariance Estimation.pdf

+ [ ] Perform portfolio optimization using matrix algebra, SVD, Cholesky
Use matrix pseudo-inverse of covariance if inverse doesn't exist ?
Pav Markowitz Portfolio Distribution.pdf
Pantaleo Portfolio Optimization Shrinkage.pdf
Potters Portfolio Optimization Shrinkage.pdf
Lee Portfolio Optimization Pseudoinverse Matrix.pdf
Pollak Portfolio Optimization Pseudoinverse Matrix.pdf
http://www.win-vector.com/blog/2010/01/easy-portfolio-allocation/

+ [ ] Introduce package FRAPO for portfolio optimization
https://eranraviv.com/portfolio-construction-r/

+ [ ] Create rstudio cloud project
https://rstudio.cloud/

+ [ ] Create shinyapps project
https://www.shinyapps.io/
https://shiny.rstudio.com/articles/shinyapps.html

+ [ ] Explain how to create github account
https://github.com/

+ [ ] Adapt from (in Python)
https://alphascientist.com/

+ [ ] Package googleComputeEngineR for interacting with Google Cloud from R
https://cran.r-project.org/web/packages/googleComputeEngineR/
https://cloudyr.github.io/googleComputeEngineR/

+ [ ] Introduce Probability of Informed Trading (PIN) model as a technical indicator - package PIN and pinbasic
Package PIN: https://github.com/cran/PIN
Zagaglia Informed Trading PIN Model.pdf
Easley VPIN High Frequency Liquidity.pdf
Collin-Dufresne Kyle Informed Trading PIN Model.pdf
Celik Informed Trading PIN Model.pdf
https://wrds-www.wharton.upenn.edu/pages/support/research-wrds/sample-programs/probability-informed-training-pin/
https://cran.r-project.org/web/packages/pinbasic/vignettes/pinbasicVignette.html
https://cran.r-project.org/web/packages/pinbasic/index.html
https://cran.r-project.org/web/packages/InfoTrad/index.html

+ [ ] Demonstrate that the max Sharpe portfolio is not always close to the max Hurst portfolio - create example of when max Sharpe portfolio is different from the max Hurst portfolio

+ [ ] Calculate the standard error of the Sharpe ratio using parallel bootstrap simulation

+ [ ] Calculate weights for maximum Hurst portfolio using Lagrange multiplier method

+ [ ] Calculate max Sharpe portfolio with constraint that it is orthogonal to market portfolio - can it be calculated using matrix algebra?

+ [ ] Adapt from: Pav Sharpe Ratio Course.pdf
http://www.gilgamath.com/bad-cis.html

+ [ ] Adapt from Pav: Distribution of Maximal Sharpe
http://www.sharperat.io/max-sharpe-one.html
http://www.quantresearch.info/Intro.htm

+ [ ] Calculate confidence interval of Sharpe ratio using bootstrap
Demonstrate that the Sharpe ratio confidence intervals are so wide, that it's hard to distinguish between assets with large Sharpe ratios from those with small Sharpe ratios.
Demonstrate that a very long time series is needed in order determine if the Sharpe ratios of two assets are different from each other.
So ranking assets on their trailing Sharpe ratios makes little sense ?
Use SharpeR package by Steven Pav, and also bootstrap. 
Sharpe ratio as Hotelling's t-squared distribution.  
https://github.com/shabbychef  
Pav Sharpe Ratio Notes Hotelling Statistic.pdf  
SharpeR Vignette.pdf  

+ [ ] SharpeR and MarkowitzR packages by Steven Pav  
finding optimal portfolio in-sample is the same as finding optimal strategy in-sample - both are over-fit and require shrinkage  
Sharpe ratio as Hotelling's t-squared distribution  
https://github.com/shabbychef  
Pav Sharpe Ratio Notes Hotelling Statistic.pdf  
Pav Strategy Overfit.pdf  
SharpeR Vignette.pdf  
Pav Portfolio Optimization.pdf  
Pav Markowitz Portfolio Signal Noise Ratio.pdf  
Pav Markowitz Portfolio Optimization Distribution.pdf  
MarkowitzR Vignette.pdf  
MarkowitzR AsymptoticMarkowitz.pdf  
Britten-Jones Efficient Portfolio Parameter Uncertainty.pdf
Simaan Efficient Portfolio Parameter Uncertainty.pdf

+ [ ] Adapt Damien Challet's drawdown estimator of the Signal to Noise Sharpe ratio
Challet Drawdown Sharpe Ratio.pdf
http://www.sharperat.io/improved-moment-estimator-snr.html
https://github.com/amirsani/pySharpeRratio

+ [ ] Explain treasury yield curve
https://institute.cmegroup.com/products/ZN
Trading Treasury Yield Curve.pdf
Trading Treasury Futures.pdf

+ [ ] Perform Principal Component Analysis (PCA) on a portfolio of stocks, bonds, and currencies
Perform the Engle-Granger two-step cointegration procedure.
Demonstrate Granger causality.

+ [ ] Cointegration package irlba  
Apply Doornik’s method using the SVD to solve the cointegration problem  
Lewis RFinance 2012 Cointegration SVD.pdf  
Doornik Cointegration Analysis SVD QR.pdf
Explain error propagation in matrix inversion use example:
C:\Research\R\R-Finance 2015\Lewis RFinance 2015 Cointegration SVD.html  
https://bwlewis.github.io/rfinance-2017/#/section
https://github.com/bwlewis/irlba

+ [ ] Demonstrate that given any two random price series, you can always find a coefficient that creates a cointegrated portfolio in-sample, but it falls apart out-of-sample

+ [ ] Adapt from Sebastian Fossati and Hauser - very good time series and cointegration with some R
Granger Causality
C:\Research\R\Tutorials\Fossati\e509\Lec8.R
C:\Research\R\Tutorials\Fossati\e509\Lab4.R
Hauser Cointegration Vector Error Correction Autoregressive Model.pdf
Investigate the price series of black and white pepper, PepperPrices from the R library(”AER”) wrt cointegration and calibrate the VECM model.

+ [ ] Add total least squares regression of stock pair
C:\Research\R\Tutorials\Georgakopoulos\rfortraders\Chapter_06

+ [ ] Add Johansen cointegration statistical arbitrage
https://github.com/VermeirJellen/AlgorithmicTrading-Cointegration

+ [ ] Create slides for Engle-Granger two-step cointegration procedure, Augmented Dickey Fuller ADF test
1. identify cointegrated pairs in a portfolio of assets - heatmap,
2. calculate standard error of cointegration factor, 
3. test persistence of cointegrated pairs out-of-sample,
4. identify cointegrated portfolios from cluster analysis,
5. apply ADF test to pairs and portfolios
use sources in: ## trading cointegration pairs trading statistical arbitrage
https://github.com/matthewclegg/egcm
https://github.com/mikeschmitt/pairs-trading
https://www.quantstart.com/articles/Cointegrated-Augmented-Dickey-Fuller-Test-for-Pairs-Trading-Evaluation-in-R
http://gekkoquant.com/2012/10/21/statistical-arbitrage-correlation-vs-cointegration/
http://gekkoquant.com/2012/12/17/statistical-arbitrage-testing-for-cointegration-augmented-dicky-fuller/
http://gekkoquant.com/2017/01/23/investigation-into-the-power-of-co-integration-mean-reversion-tests/
http://davegiles.blogspot.com/2011/04/testing-for-granger-causality.html  
http://davegiles.blogspot.com/2015/10/cointegration-granger-causality.html
http://davegiles.blogspot.com/2011/10/var-or-vecm-when-testing-for-granger.html
http://davegiles.blogspot.com/2016/05/forecasting-from-error-correction-model.html
http://denizstij.blogspot.com/2013/11/stationary-tests-of-time-series-within-r.html
http://denizstij.blogspot.com/2013/11/cointegration-tests-adf-and-johansen.html
https://quant.stackexchange.com/questions/34460/granger-causality-with-stocks-and-cds
https://quant.stackexchange.com/questions/15948/two-correlated-time-series-driver-and-follower/15950
https://quant.stackexchange.com/questions/14865/detecting-and-measuring-lead-lag-effect
https://en.wikipedia.org/wiki/Granger_causality

+ [ ] Adapt from package egcm for Engle-Granger two-step cointegration procedure
https://github.com/matthewclegg/egcm

+ [ ] unit root tests, cointegration, and VAR vector autoregressive models, spurious correlation example  
C:\Research\R\Tutorials\Zivot\Econ 584\Zivot Cointegration.pdf  
Zivot Cointegration Tests.pdf
Zivot VAR Vector Autoregressive Time Series Models.pdf
Phillips-Ouliaris test for cointegration  

+ [ ] Expand on spurious time series regression
http://r-datameister.blogspot.com/2013/12/spurious-regression-of-time-series.html
http://davegiles.blogspot.com/2012/05/more-about-spurious-regressions.html
https://eranraviv.com/spurious-regression-illustrated/
https://eranraviv.com/how-regression-statistics-mislead-experts/

+ [ ] Create slides explaining Johansen test
Demonstrate that unit root test power is poor, by simulating and testing almost stationary ARIMA process. 
The power and size of unit root tests are poor. 
The test's weak power means that they cannot distinguish between a unit root process and a fractionally integrated series with long memory (Baillie, 1996)
Johansen Cointegration.pdf
SVD subset selection: 
Lewis RFinance 2012 Cointegration SVD.pdf
Doornik Cointegration Analysis SVD QR.pdf
https://www.quantstart.com/articles/Johansen-Test-for-Cointegrating-Time-Series-Analysis-in-R
http://www.spiderfinancial.com/support/documentation/numxl/users-guide/statistical-testing/cointegration-test
https://quant.stackexchange.com/questions/8494/cointegrating-relationships-johansen-in-r
https://quant.stackexchange.com/questions/3526/how-to-interpret-results-of-johansen-test
https://quant.stackexchange.com/questions/2076/how-to-interpret-the-eigenmatrix-from-a-johansen-cointegration-test?
https://quant.stackexchange.com/questions/25212/johansen-cointegration-test-interpretation-in-r
http://quant.stackexchange.com/questions/18581/johansen-test-on-two-stocks-for-pairs-trading-yielding-annoying-results
http://r.789695.n4.nabble.com/Testing-for-cointegration-Johansen-vs-Dickey-Fuller-td926500.html

+ [ ] Determine the lead-lag relationships between asset returns from their correlations  
Find which one leads by applying Vector Autoregressive VAR model and Granger causality test.
Study the effect of longer lookback intervals.
Wu Leader Lagged Correlation.pdf
vars Vignette.pdf
VAR Models R Package vars.pdf
DeMiguel VAR Model Stock Selection Forecasting.pdf
Ni Bayesian VAR Model Estimation.pdf
Barigozzi Nets Lasso Network Estimation for Time Series.pdf

+ [ ] Vector autoregressive VaR models with LASSO shrinkage package nets by Christian Brownlees
Barigozzi Network VAR Models.pdf
vars.pdf
nets.pdf
https://github.com/ctbrownlees/R-Package-nets

+ [ ] Create slides for pairs trading  
1. trade pairs in-sample and out-of-sample,
2. demonstrate that using ensemble of cointegration factors produces higher Sharpe out-of-sample. 
use sources in: ## trading cointegration pairs trading statistical arbitrage
http://quantdevel.com/public/html/testForCoint.html
http://www.rfortraders.com/lecture-4-regression-and-pairs-trading/
http://gekkoquant.com/2013/01/21/statistical-arbitrage-trading-a-cointegrated-pair/
https://stackoverflow.com/questions/24051503/filter-xts-objects-by-common-dates
https://github.com/dankim93/Pairs-Trading-Project
C:\Research\R\Tutorials\Pairs-Trading-Project-master
https://github.com/Jackal08/QuantInsti-Final-Project-Statistical-Arbitrage
https://www.linkedin.com/pulse/statistical-arbitrage-strategy-r-jacques-joubert
https://github.com/justinlent/PairTradeR

+ [ ] Adapt pairs trading from package PairTrading (removed from CRAN)
http://mockquant.blogspot.com/2011/10/introduction-to-pairtrading-package.html

+ [ ] Adapt from packages partialCI and partialAR for partial cointegration procedure
https://github.com/matthewclegg/partialCI
https://github.com/matthewclegg/partialAR

+ [ ] Explain steps of statistical arbitrage
1. determine cointegrated portfolio either using Engle-Granger two-step cointegration procedure, or Johansen VAR and VECM models.
2. estimate time-varying portfolio weights using stochastic control.
3. determine optimal trading parameters and stop-loss.

+ [ ] Trade Hurst model
http://timelyportfolio.blogspot.com/2011/06/exploring-market-with-hurst.html
Qian Rashid Hurst Predictability.pdf

+ [ ] Explain that a static 60 bonds/40 stocks portfolio loses when there's inflation
https://www.marketwatch.com/story/your-portfolio-may-be-riskier-than-you-think-2018-10-11

+ [ ] Backtest a market-timing active asset allocation strategy which rebalances between stocks and bonds, using AR(p) plus logistic function
The single allocation weight to stocks can be a function of forecast volatility, yield curve slope, VIX curve slope, etc.
https://alphaarchitect.com/2017/03/23/do-you-rebalance-your-portfolio-you-are-a-market-timer/
Taxonomy of active asset allocation strategies:
https://www.investopedia.com/investing/6-asset-allocation-strategies-work/
https://seekingalpha.com/article/4138204-40-shades-tactical-asset-allocation-across-bull-bear-markets

+ [ ] Explain that active asset allocation ETFs have performed poorly: AdvisorShares Tactical ETF (GTAA)
https://www.moneysense.ca/columns/the-failed-promise-of-market-timing/

+ [ ] Backtest different rebalancing strategies between stocks and bonds
The rebalancing rules can be: maintain constant dollar allocations, constant relative risk allocations, etc.

+ [ ] Incorporate ideas from and contribute to Matt Brigida Teaching Resources with R/Shiny
https://github.com/Matt-Brigida
https://github.com/Matt-Brigida/portfolio-theory

+ [ ] Explore RCode modern environment for R
https://www.pgm-solutions.com/rcode

+ [ ] Explain difference between covariance matrix regularization versus shrinkage and the tradeoffs between the two
https://github.com/yanyachen/FinCovRegularization
https://github.com/arorar/covmat
https://github.com/rstats-gsoc/gsoc2015/wiki/Covariance-Matrix-Estimators
https://github.com/AEBilgrau/correlateR

+ [ ] Banbura Vector Autoregressive Bayesian Shrinkage Dynamic Models.pdf
Banbura Forecasting Vector Autoregressive Bayesian Models.pdf
https://github.com/clementcarrier/ez

+ [ ] Introduce a zoo of OHLC technical indicators, and perform their PCA analysis

+ [ ] Backtest an AR(p) model for forecasting returns from a large "kitchen sink" design matrix composed of a zoo of many technical indicators
Apply dimensionality reduction and shrinkage to the inverse of the design matrix.
Calculate the standard errors of the forecasts as a function of the number of indicators and the shrinkage intensity.

+ [ ] Add mean-reverting stat-arb strategy: buy lowest decile stocks and sell highest decile stocks
Calculate skew of returns

+ [ ] Expand slide Integrated and Unit-root Processes
Explain unit root process
create slide for Augmented Dickey-Fuller ADF test
perform ADF test as function of length "n"
adf.test(cumsum(rnorm(n)))
show that p-val doesn't become big until "n" is big
ADF is weak test (doesn't reject false hypothesis)
compare with ADF test on DAX
create synthetic time series using ARIMA
simulate and plot ARIMA AR(1) processes with different coefficients
show how diverges if unit root
perform ADF test
http://robotwealth.com/exploring-mean-reversion-and-cointegration-with-zorro-and-r-part-1/  
http://robotwealth.com/exploring-mean-reversion-and-cointegration-part-2/  

+ [ ] Add slides explaining PACF: borrow code from homework
Demonstrate that for an ARIMA(p, q) process, only the autocorrelations up to order q are non-zero, and only the partial autocorrelations up to order p are non-zero. 
https://stats.stackexchange.com/questions/281666/how-does-acf-pacf-identify-the-order-of-ma-and-ar-terms

+ [ ] Explain risk-management of algorithmic (systematic) strategies
Portfolio weights to target expected volatility.
Stop-loss limits.

+ [ ] Add stop-loss to backtest

+ [ ] Add package reticulated for Python
https://blog.rstudio.com/2018/10/09/rstudio-1-2-preview-reticulated-python/

+ [ ] Demonstrate that adding jump noise to price data creates spurious profits in a mean-reverting strategy - but only if we trade immediately
Show how to scrub the data using a Hampel (median) filter: borrow code from homework.

+ [ ] Create backtesting study of time series data scrubbing using Hampel median filter - borrow code from homework
Explain Type I and Type II errors
Type I error is rejecting a true null hypothesis
power of test
http://dsp.stackexchange.com/questions/26552/what-is-a-hampel-filter-and-how-does-it-work
https://en.wikipedia.org/wiki/Median_filter
use code from "demo_HighFreq.R" and "hfreq_aggregation.R"
1. create xts of smooth or random prices with changing vol
2. add random jump noise to it
3. filtering define scrubbing function with two params: vol estimation window and noise threshold
apply filtering to remove jump noise by applying: filter function, caTools, TTR, highfrequency package, etc. (compare speed)
http://www.cookbook-r.com/Manipulating_data/Calculating_a_moving_average/
http://stackoverflow.com/questions/743812/calculating-moving-average-in-r
4. optimize filter parameters and create ROC curve
5. add jump noise with variable volatility
6. optimize filter parameters in-sample: study bias-variance tradeoff with regards to window length, Precision and Recall tradeoff
7. create rCharts and shiny visualizations
8. apply best in-sample filter parameters to out-of-sample data
second version:
create a csv file with time series data plus some bad text data 
read csv file and coerce to numeric
format the dates and times
find bad data and scrub it
create zoo and plot it

+ [ ] Create a rolling Hampel filter using RcppArmadillo

+ [ ] Create a market timing strategy using interest rate curve as a contrarian indicator: go short when IR curve is bull steepening
https://www.bloomberg.com/news/articles/2018-04-19/top-recession-indicator-makes-a-lousy-sell-signal-for-stocks

+ [ ] Calculate the beta convexity (skew) as difference between bull-market and bear-market betas
http://jonathankinlay.com/2017/05/beta-convexity/
Granger CAPM Beta Skew.pdf
Calculate the betas using OHLC prices.

+ [ ] Create a strategy with low beta convexity
http://jonathankinlay.com/2018/09/beating-the-sp500-with-a-low-convexity-portfolio/
Calculate bull-market and bear-market betas using only positive or negative returns: the difference between bearish minus bullish betas is equal to the beta convexity

+ [ ] Add package reticulate for calling Python from R

+ [ ] Adapt from Kris Longmore Interactive Brokers Introduction to Algorithmic Trading: no code, but good verbiage
https://www.interactivebrokers.com/en/index.php?f=25244&vid=17779
https://www.interactivebrokers.com/en/index.php?f=25244&vid=17799
https://www.interactivebrokers.com/en/index.php?f=25244&vid=17800
https://www.interactivebrokers.com/en/index.php?f=25244
adapted from
https://robotwealth.com/

+ [ ] Demonstrate that stock expected returns are proportional to market illiquidity
Amihud Stock Market Premiums Liquidity.pdf

+ [ ] Explain trade order types: market, limit, split spread, adaptive algo
Cesari Exchange Trade Execution.pdf
Bialkowski VWAP Trading Strategies.pdf
Split spread orders are orders priced within the spread between the bid price and ask price. These orders yield significant price improvement when they fill, and may earn you exchange rebates for adding liquidity.
https://www.interactivebrokers.com/en/index.php?f=26685
Adaptive algo orders use IB's smart routing to achieve a fast fill at the best all-in price.
https://www.interactivebrokers.com/en/index.php?f=19091

+ [ ] Adapt from: downloading raw market data using IBrokers::reqMktData() without eventWrapper
https://stat.ethz.ch/pipermail/r-sig-finance/2011q3/008232.html

+ [ ] Adapt technical indicator timing ability from: 
Lissandrin Testing Technical Indicator Forecasting.pdf
Hsu Technical Trading Strategy Currencies.pdf
Lo Technical Trading.pdf

+ [ ] Explain Multidimensional Scaling
http://qusma.com/2014/06/11/visualizing-similarity-multiple-time-series/
https://en.wikipedia.org/wiki/Multidimensional_scaling

+ [ ] Explain Dynamic Time Warping
https://en.wikipedia.org/wiki/Dynamic_time_warping
http://qusma.com/2013/12/30/reverse-engineering-dynamichedges-alpha-curves-part-1-3-dynamic-time-warping/

+ [ ] Calculate constant maturity VIX futures for every date in a range of dates, from CBOE settlement data, in R and in Rcpp

+ [ ] Adapt low volatility investing from:
https://github.com/johngil/gilheany.thesis
C:\Research\Academic\gilheany_low_vol_investing
Gilheany Low Volatility Investing.pdf

+ [ ] Add low volatility anomaly  
Boudt Low Volatility Anomaly High Frequency Data.pdf
Gray Low Volatility Anomaly.pdf  
Baker Low Volatility Anomaly.pdf  
Edwards Low Volatility Anomaly.pdf
Li Low Volatility Anomaly FAJ.pdf  
Han Volatility Decile Cross-Sectional Momentum Anomaly.pdf  
Vliet Volatility Expected Returns.pdf  

+ [ ] Add package IButils
https://github.com/enricoschumann/IButils
http://enricoschumann.net/R/packages/IButils/index.htm

+ [ ] Add packages qmao and twsInstrument

+ [ ] Adapt xts Cheat Sheet
https://www.datacamp.com/community/blog/r-xts-cheat-sheet

+ [ ] Create constant maturity futures prices.
Plot the futures curve over time.
Perform PCA.

+ [ ] Downloading data from Bloomberg: adapt from data_scripts.R

+ [ ] Add opening and closing file connections using file() and file.create()

+ [ ] Adapt from
https://www.qplum.co/investing-library

+ [ ] Adapt from: 
https://www.datacamp.com/courses/model-a-quantitative-trading-strategy-in-r/

+ [ ] Adapt backtest code from package PMwR
http://enricoschumann.net/R/packages/PMwR/manual/PMwR.html
Schumann package Portfolio Management with R.pdf
Schumann package Portfolio Management with R.html
Schumann PMwR.R

+ [ ] Adapt from Dao Variance Trend Following Strategies.pdf
Demonstrate that long option strategies have positive return skew due to positive convexity with respect to the underlying returns.
Demonstrate that long option strategies provide positive returns if Hurst ratio (variance ratio) of the underlying returns is greater than 0.5.
Demonstrate that trend-following and momentum strategies also provide positive returns if Hurst ratio is greater than 0.5, similar to long option strategies.
Calculate the performance of a trend-following strategy as a function of the Hurst ratio.
Simulate returns with different Hurst ratios, and produce signature plots.
Explain that CTA's follow trend-following and momentum strategies, and that explains their positive return skew.
Explain that CTA's are similar to long option strategies, so they perform better in periods of high market volatility. 
("The performance of trend-following strategies can be ascribed to the difference between long- and short-term realized variance.")
Explain that hedge fund returns have negative convexity and skew, so they perform worse in periods of high market volatility. 
Demonstrate that trend-following EWMA strategy returns have more positive skew than underlying asset, and mean-reverting strategy returns have more negative skew.
Download hedge fund and CTA data from Barclayhedge and apply the Merton-Henriksson and reynor-Mazuy tests.
Martin Momentum Skew Returns.pdf
Dao Variance Trend Following Strategies.pdf

+ [ ] Add slide explaining difference between trend-following versus momentum strategies

+ [ ] Add slide about Barclayhedge Hedge Fund & CTA Research Library and its free data for indexes
https://www.barclayhedge.com/research/

+ [ ] Add slides with scripts for loading ETF time series from CSV files, adapt code from utility_scripts.R and data_scripts.R

+ [ ] Demonstrate that stock returns display mean reversion in good times and they display momentum in bad times
Huang Stock Forecasting.pdf

+ [ ] Explain that a strategy that has autocorrelated returns can be improved by trading it, but it strongly depends on the transaction costs (?)
Autocorrelations of strategy returns indicate presence of additional market factors that strategy doesn't account for.
strategy returns autocorrelations factor

+ [ ] Demonstrate that the z-scores (t-values) of the residuals of time series regressions of prices are increasingly lepto-kurtic for longer time periods, because the residual volatility drops and is time-dependent

+ [ ] Adapt technical indicator strategy using GARCH
https://medium.com/auquan/time-series-analysis-for-finance-arch-garch-models-822f87f1d755

+ [ ] Adapt from introduction to statistical learning:
http://www.rnfc.org/courses/isl/

+ [ ] Add heatmap to investment_strategies  
heatmap(pnl_s, Colv=NA, Rowv=NA, col=c("red", "blue"))

+ [ ] Explain backtest overfitting
Hsu Strategy Backtesting Overfitting Data Mining Cross-validation Bootstrap.pdf
https://opensourcequant.wordpress.com/2018/08/04/a-replication-of-the-practical-application-section-in-the-probability-of-backtest-overfitting-bailey-et-al/

+ [ ] Explain backtest overfitting and the Triple Penance Rule
Prado Portfolio Allocation Trading Meta-Strategies.pdf
Prado Data Mining False Discovery.pdf

+ [ ] Adapt Backtest Overfitting Demonstration Tool (BODT) and the Tenure Maker Simulation Tool (TMST) from: 
Bailey Borwein Strategy Backtesting Overfitting Cross-validation.pdf

+ [ ] Create RcppArmadillo function for calculating rolling z-scores of the residuals of a rolling regressions of time series of prices, using Kalman filter
Choudhry GARCH Kalman Stock Beta Forecasting.pdf
Jain GARCH Stock Beta Forecasting.pdf

+ [ ] Create RcppArmadillo function for calculating rolling z-scores of the residuals of rolling regressions of time series of prices
Add as a technical indicator the z-scores of residual of the rolling regressions of time series of prices.
Perform rolling regressions over trading time - using a time-dependent look-back interval, so that the look-back interval always spans the same traded volume. 
Inoue Rolling Regressions Time Series Bias Variance Tradeoff.pdf

+ [ ] Explain in detail single time series regression: the time series of prices against its time index 
Explain the difference between the residuals of the regression of the time series of prices, versus the scaled returns.

+ [ ] Explain the need to center and scale the technical indicators, but without data snooping, using rolling regressions over a look-back interval

+ [ ] Demonstrate that the daily OHLC skew: sk_ew <- ((hi_gh+lo_w) - (op_en+clo_se)) is highly correlated to the daily skew calculated directly from minutely data.

+ [ ] Create study of OHLC technical indicators
Create matrix of 6 technical indicators formed by differencing the four columns of OHLC data. 
Calculate the correlation matrix of the indicators together with daily returns, to show that only 4 indicators are somewhat independent: re_turns, sk_ew, op_en-hi_gh, and clo_se-hi_gh.
Scale the indicators using a sigmoid (logistic) function, to reduce the effects of very large values.
Find the optimal scaling parameter.
Average the indicators over a rolling look-back interval, to improve their predictive power by reducing the effects of noise.
Demonstrate that the predictive power increases but only up to a point because of bias-variance tradeoff.
Find the optimal look-back interval.

+ [ ] Create example trading strategy for VTI, which uses static weights calculated from regressions over a design matrix
Create design matrix with many technical indicators in columns.
Demonstrate that taking averages over the past values of indicators improves their predictive power, but only up to a point: this is bias-variance tradeoff.
Demonstrate that the bias-variance tradeoff depends on the level of volatility.
Split data in two: in-sample and out-of-sample.
Perform regression of future returns over the design matrix in-sample, and calculate the weights. 
Demonstrate that performance is better if future returns are the average over many days in the future.
Apply the weights to the design matrix out-of-sample, lag the resulting signal, and trade VTI.
Explain that the regression is biased by the returns in periods of high volatility, so the out-of-sample performance is also good in periods of high volatility, but poor otherwise.
Subset the data to exclude periods of high volatility.
Apply shrinkage and dimensionality reduction.

+ [ ] Create shiny app for exploring trading strategy for OHLC technical indicators
Create sliders for weights, scaling and smoothing (look-back).

+ [ ] Apply Linear Discriminant Analysis lda() to classify future returns as either positive or negative
https://rstudio-pubs-static.s3.amazonaws.com/35817_2552e05f1d4e4db8ba87b334101a43da.html
https://www.displayr.com/linear-discriminant-analysis-in-r-an-introduction
https://rpubs.com/Nolan/298913

+ [ ] Explain that the lower order principal components represent systematic risk factors, while the higher order PC's represent idiosyncratic risk (which tends to resemble random noise)
Express stock prices as weighted average of systematic risk factors plus idiosyncratic risk.
Demonstrate that the idiosyncratic risk resembles random noise, and can be traded using mean-reverting strategies.

+ [ ] Simulate a vector of returns from buying lottery tickets, and calculate its mean, standard deviation, skew, and kurtosis
Plot the histogram of returns.
Plot the moments as function of ticket price and payout probability.
Simulate random wealth paths for stocks and for lottery tickets, and plot the probability distributions of terminal wealth.
Explain that the return distribution for buying lottery tickets has positive skew but negative mean.  Vice versa for selling lottery tickets.
Explain that return distribution for stocks positive mean but negative skew, just like for selling lottery tickets.

+ [ ] Use slides for utility function and investor risk preferences for large odd moments and small even moments
Demonstrate that investors with a logarithmic utility desire positive and large odd moments, and small even moments.

+ [ ] Derive CAPM from utility 
Show that logarithmic utility implies max Sharpe.

+ [ ] Add utility function for constant relative risk aversion (CRRA)  
https://en.wikipedia.org/wiki/Isoelastic_utility

+ [ ] Futures contracts conventions
https://www.investopedia.com/university/how-to-trade-e-mini-futures-contracts/e-mini-specifications.asp
http://emini-watch.com/emini-trading/emini-futures/

+ [ ] Adapt from: 
CME Trading Treasury Futures.pdf
CME Trading Treasury Yield Curve.pdf

+ [ ] Explain the differences between different objective functions for measuring strategy performance 
Total return of strategy is too sensitive to a small number of winning trades.
Correlation between forecast and actual returns is less sensitive to small number of winning trades.
Maximize skill objective function equal to: market timing gamma coefficient (Merton-Henriksson test), alpha coefficient, or information ratio.

+ [ ] Explain Grinold's Fundamental Law of Active Management (FLAM)
Outperformance is achieved by a combination of skill and breadth (trading frequency).
Models that trade more frequently perform better because they diversify their risk of being wrong.
Hallerbach Market Timing Strategies.pdf
Grinold Synopsis Active Portfolio Management.pdf  

+ [ ] Use coin flip puzzle to demonstrate difficulty of testing manager skill
Demonstrate that it's impossible to confirm skill of strategy that trades infrequently.
C:\Develop\R\scripts\coin_flips.R

+ [ ] Portfolio optimization using Omega ratio  
Gilli Omega Portfolio Optimization.pdf
Shaw Portfolio Optimization CVaR Omega Utility.pdf
Keating Omega Performance Measure.pdf

+ [ ] Dynamic factor models package dlm
http://lalas.github.io/quantitativeThoughts/r/2014/09/01/dlmTutorial.html
https://stats.stackexchange.com/questions/164992/how-to-specify-var-dynamics-of-factors-in-dynamic-factor-model-in-r
Lalas State Space Models Kalman Filter.html
Bai Dynamic Factor Model Estimation.pdf
Poncela Dynamic Factor Models Kalman Filter.pdf
Bai Large Dimensional Factor Analysis.pdf
Bai Forecasting Factor Models Targeted Predictors.pdf
Meng Rolling Beta Factor Model.pdf
Barigozzi Dynamic Factor Models.pdf
Stock Multifactor Forecasting.pdf
Harvey Bootstrap Factor Models.pdf

+ [ ] Apply Kalman filter state space model for calculating rolling betas, trend slope (past returns)
Introduce state space model and explain that their optimal solution is obtained using the Kalman filter.
Demonstrate that Kalman filter is a generalization of exponential smoothing.
Explain that Kalman filter adapts its smoothing strength depending on the level of volatility.
Demonstrate that Kalman filter achieves a better bias-variance tradeoff than linear regression?
http://www4.stat.ncsu.edu/~reich/BigData/code/kalman.html
http://www4.stat.ncsu.edu/~reich/BigData/code/kalman.R
C:\Research\Academic\Brian Reich\kalman.R
Regression with time-varying beta parameters.
http://past.rinfinance.com/agenda/2012/workshop/Zivot+Yollin.pdf
https://sites.ualberta.ca/~sfossati/e509/files/slides/Lec4.pdf
http://bilgin.esme.org/BitsBytes/KalmanFilterforDummies.aspx  
http://intelligenttradingtech.blogspot.com/2010/05/kalman-filter-for-financial-time-series.html  
http://stats.stackexchange.com/questions/8055/how-to-use-dlm-with-kalman-filtering-for-forecasting  
http://stats.stackexchange.com/questions/16841/is-the-kalman-filter-actually-forecasting
https://magesblog.com/post/2015-01-06-kalman-filter-example-visualised-with-r/
http://www.magesblog.com/2015/01/extended-kalman-filter-example-in-r.html  
http://www.bearcave.com/finance/random_r_hacks/kalman_smooth.html
Arnold Kalman Filter Expectation Maximization.pdf  
Tusell Kalman Filtering in R.pdf  
Sorensen Kalman Filter.pdf  
Prado Kinetic Component Analysis Forecasting.pdf  
Bruder Momentum Indicators Kalman Filter SVM.pdf  
ZivotYollin2012.pdf
Jingtao Filtering Momentum Strategy.html ?

+ [ ] Create pairs strategy using Kalman filter for beta
Forecast the volatility using GARCH or EWMA, and apply the volatility forecasts to calculate Kalman gain.

+ [ ] Apply Kalman to GARCH
Ferreira GARCH Volatility Kalman.pdf

+ [ ] Apply Kalman to PCA
https://people.eecs.berkeley.edu/~jordan/courses/281A-fall04/lectures/lec-11-2.pdf

+ [ ] how a Kalman filter works
Kalman Explained.pdf
Kalman Explained Detail.pdf
Kalman Filter Simple.pdf
http://www.cl.cam.ac.uk/~rmf25/papers/Understanding%20the%20Basis%20of%20the%20Kalman%20Filter.pdf
http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/
http://www4.stat.ncsu.edu/~reich/BigData/code/kalman.html

+ [ ] Implement Kalman filter in Rcpp using RcppArmadillo
RcppArmadillo intro.pdf
RcppArmadillo Eddelbuettel 2014.pdf
https://github.com/eddelbuettel/rcppkalman
http://dirk.eddelbuettel.com/code/rcpp.kalman.html

+ [ ] Write fast Kalman filter in RcppArmadillo, adapt from package FKF ? (very old)
https://github.com/cran/FKF

+ [ ] Explain that models with more parameters are more fragile 

+ [ ] Explain that for fat-tailed distributions, permutation tests are better than parametric tests: Kenneth Lange book Numerical Analysis for Statisticians, chapter Permutation Tests and the Bootstrap
Permutation tests don't have simple solutions and rely on numerical computations.
C:\Research\Machine Learning\Efron Bootstrap Methods.pdf

+ [ ] P-hacking: simulate curing cancer with jelly beans: false discovery rate, p-value hacking
Demonstrate that risk of p-hacking increases with number of trials (number of jelly bean colors).
Demonstrate that out-of-sample the cure doesn't work.
Calculate how big should be sample size to avoid p-hacking.
Ioannidis Why Most Published Research Findings Are False.pdf
Taleb P-Value Distribution.pdf

+ [ ] Explain risk of data mining (p-hacking, synonyms significance inflation, multiple testing), and false discovery rate  
Demonstrate that the effects of p-hacking can be reduced by not selecting the optimal parameters, but instead selecting a range of parameters around the optimal value.
https://en.wikipedia.org/wiki/Look-elsewhere_effect  
create example of data mining: create tech indicator with several parameters  
http://datagrid.lbl.gov/backtest/  
http://www.financial-math.org/software/  

+ [ ] Deflated Sharpe ratio
https://github.com/braverock/quantstrat/blob/master/R/deflated.Sharpe.R
Bailey Prado Deflated Sharpe Ratio Overfitting.pdf  

+ [ ] Adapt packages ttrTests and fTrading for backtesting Technical Trading Rules  
White Strategy Backtesting Overfitting Data Mining Cross-validation Bootstrap.pdf
Suhonen Backtest Overfitting.pdf
Beaudan Backtest Overfitting.pdf
http://www.inside-r.org/packages/cran/ttrTests/docs/dataSnoop  
https://www.linkedin.com/in/david-st-john-96798745  

+ [ ] Controlling the false-discovery rate using Bonferroni method Sidak correction  
http://www.alexchinco.com/screening-using-false-discovery-rates/  
http://eranraviv.com/sample-data-snooping/  
http://eranraviv.com/modern-statistical-discoveries/  
https://opensourcequant.wordpress.com/2018/08/04/a-replication-of-the-practical-application-section-in-the-probability-of-backtest-overfitting-bailey-et-al/
Bailey Prado Strategy Backtesting Overfitting Cross-validation.pdf  
Bailey Prado Strategy Backtesting Overfitting.pdf  
Harvey Backtesting Data Mining Bonferroni Adjustment.pdf  
Harvey Evaluating Trading Strategies.pdf  
White Strategy Backtesting Overfitting Data Mining Cross-validation Bootstrap.pdf  

+ [ ] Marcos Lopez de Prado: CSCV paper The Probability of Backtest Overfitting
https://gist.github.com/jaymon0703/ffef90ee08cbc8a7c2017a6a7bfd876d

+ [ ] optimize a strategy using a portfolio constraint so that it's 50% long beta 
The idea is that this constraint is equivalent to a portfolio of 50% quant strategy plus 50% long beta. 
Quant strategies are uncorrelated to market portfolio, so it's best to combine the two.

+ [ ] Adapt from O’Shaughnessy Factors from Scratch
http://osam.com/Commentary/factors-from-scratch

+ [ ] Adapt from Blitz factor investing tutorial
https://factorinvestingtutorial.wordpress.com/hello/

+ [ ] Factor model regularization: 
Fan Factor Model Regularization.pdf
Fan Covariance Regularization.pdf

+ [ ] Use Kelly rule to allocate between cash and stocks as the level of stock predictability (forecastability) changes
Create a function which measures the level of predictability based on volatility, correlation, Hurst, etc.

+ [ ] Calculate the Kelly formula when the probability of winning is uncertain  
Consider different distributions of the probability of winning.
Sinclair Kelly Confidence Intervals.pdf

+ [ ] Introduce Randomization Test: feed random data into the strategy, to verify if it produces positive returns
If a strategy produces positive returns on random data then it's a problem.

+ [ ] Calculate the weights of the maximum alpha portfolio using matrix algebra
It's a linear programming problem that requires box constraints to limit leverage, and prevent excessive shorting of assets with small or negative alpha.
This solution if no negative weights: the asset with the highest alpha has weight equal to 1, and remaining assets have weights equal to zero.

+ [ ] Solve linear and quadratic programming problems by hand in R and in Rcpp

+ [ ] Introduce Safety first portfolio models
adapt from: Engels Portfolio Optimization.pdf

+ [ ] Introduce Value at Risk portfolio optimization, adapt from: Engels Portfolio Optimization.pdf
Introduce Elliptical distributions.
Demonstrate that minimizing the variance is the same as minimizing the Value at Risk, when returns are elliptically distributed.
Define the optimal Telser portfolio as the portfolio that maximizes expected return subject to a shortfall constraint.

+ [ ] Adapt from Bailey Borwein Portfolio Optimization Overfitting.pdf

+ [ ] Add slide about best way to calculate rolling beta using zero intercept regression
https://stackoverflow.com/questions/7333203/linear-regression-with-a-known-fixed-intercept-in-r
Demonstrate that zero intercept beta has higher bias but lower variance (bias-variance tradeoff).
Calculate rolling zero intercept beta and demonstrate that it has lower realized variance.

+ [ ] Create bias-variance tradeoff graphs
Create bias-variance tradeoff example for multivariate regression: compare multivariate regression with multivariate regression constrained to a single beta coefficient.
Calculate total error as the sum of bias plus variance, using bootstrap simulation.
Demonstrate that constrained multivariate regression has bias but has lower total error.
Explain that the variance increases with the number of model parameters, so regularization involves reducing the number of model parameters.
Explain that models with more parameters will tend to overfit the noisy data, so their variance will increase because of that.
Aswani Regression Shrinkage Bias Variance Tradeoff.pdf
Scott Fortmann-Roe: out of sample prediction error
http://scott.fortmann-roe.com/docs/MeasuringError.html
Scott Fortmann-Roe: bias-variance tradeoff and knn clustering
http://scott.fortmann-roe.com/docs/BiasVariance.html
bias_variance_tradeoff.png
bias_variance_tradeoff2.png

+ [ ] Create shiny for pairs trading
Hoang Johansen Cointegration Statistical Arbitrage.pdf
https://htran.shinyapps.io/pairs_trading/

+ [ ] Add R compiler: compiler::cmpfun()

+ [ ] Add unit root test in Rcpp
https://github.com/olmallet81/URT

+ [ ] Add slides for unit root tests and cointegration
http://quantdevel.com/public/html/testForCoint.html
ADF test for unit roots  
package urca  

+ [ ] Add unit root ADF tests packages tseries fUnitRoots
ADF and MacKinnon tests
http://fabian-kostadinov.github.io/2015/01/27/comparing-adf-test-functions-in-r/
http://denizstij.blogspot.com/2013/11/stationary-tests-of-time-series-within-r.html

+ [ ] Introduce statarb
select warmup data and perform PCA to determine factors
perform rolling PCA and calculate factors and z-scores
sort on z-scores and go long and short
define trading rules: entry, exit, stop-loss

+ [ ] Perform PCA, select clustered sub-portfolios, and perform PCA on the sub-portfolios
Study if second PC of sub-portfolios is mean-reverting, and if it's persistent out-of-sample.

+ [ ] Add slide with PCA percentage of variance explained to time_series_multivariate
calculate by hand
summary(reg_model)

+ [ ] Principal component analysis PCA adapt from: CFM Principal Component Market Factors.pdf

+ [ ] Fundamental factor models adapt from: Zivot Factor Models.pdf
C:\Research\R\Tutorials\Zivot\research\factorModels.R

+ [ ] Regularization James-Stein shrinkage of covariance matrices
https://rviews.rstudio.com/2017/08/22/stocks/
http://strimmerlab.org/software/corpcor/
https://github.com/cran/corpcor
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2748251/
https://en.wikipedia.org/wiki/James%E2%80%93Stein_estimator

+ [ ] Adapt from: covmat package for estimating convariance matrices using shrinkage and Random Matrix Theory
https://github.com/rstats-gsoc/gsoc2015/wiki/Covariance-Matrix-Estimators  
https://github.com/arorar/covmat

+ [ ] Adapt from: tawny package for regularizinging correlation matrices using random matrix theory and shrinkage estimation  
Rowe Random Matrix Shrinkage Covariance Estimation.pdf  
Gatheral Random Matrix Shrinkage Covariance Estimation.pdf  
Plerou Random Matrix Correlation Estimation.pdf  
Goldberg Random Matrix Shrinkage Covariance Estimation.pdf  

+ [ ] visualize correlation matrices in R
https://github.com/JamesMarquezDev/Jupyter-Notebooks-Statistic-Walk-Throughs-Using-R/blob/master/correlation_matrices_in_r.ipynb
http://jamesmarquezportfolio.com/correlation_matrices_in_r.html

+ [ ] Define stock skewness as ratio of downside beta divided by upside beta - use OHLC data
Sort stocks by their rolling skewness, and check if it has forecasting ability.

+ [ ] Add slide explaining, summarizing conclusions about quant trading strategies:
It's very hard for quant strategies to beat a static stock and bond portfolio.
It's very hard to identify, distinguish a good quant strategy from a bad one, especially if it trades infrequently.
Trend-following and mean-reverting quant strategies tend to be uncorrelated, so it's best to combine them.
Good quant trading strategies tend to be uncorrelated with stocks, so it's best to combine quant strategies with stocks.

+ [ ] Explain that rolling backtest makes sense only if standard errors of meta-parameters are less than the standard errors of model parameters (?)
In other words, rolling backtest reduces parameter uncertainty.
No, meta-parameter uncertainty is still large, but pnl is less sensitive to meta-parameter value, so it doesn't matter.

+ [ ] Explain that backtesting is picking best performing model or asset over time
How much data is needed to achieve a given confidence level that we're picking the actual best performing model?
read: Pav Strategy Overfit.pdf slide #6
Standard error of Sharpe ratio decreases as square root of time interval length: 
SE(SR) ˜ SR / sqrt(T)
required sample size decreases as square of Sharpe ratio: 
n ˜ ? / ?^2
where ? is proportional to type I and type II error rates (Lehr's rule)
how do these formulas change for non-Gaussian distributions?

+ [ ] Adapt scripts for testing manager skill
Use bullet points under Benchmarking portfolio management skill, in file Systematic Investment Strategies.md
C:\Develop\R\scripts\select_manager.R
Demonstrate that active managers are likely to underperform the index, unless they have extraordinary skill.
The best performing stocks drive the index performance, while most stocks in the index perform relatively badly. 
So randomly picking stocks from the index will result in portfolios which underperform the index.
Heaton Stock Index Selection Active Portfolio Management.pdf  
https://www.bloomberg.com/view/articles/2015-11-11/why-indexing-beats-stock-picking
https://www.bloomberg.com/news/articles/2017-04-09/lopsided-stocks-and-the-math-explaining-active-manager-futility
package PeerPerformance
https://github.com/ArdiaD/PeerPerformance

+ [ ] Add slide where data is split in half, with calibration in first half and out-of-sample performance in second half
Demonstrate that this performs better than rolling backtest

+ [ ] Add backtest slides to section Performing Aggregations Over Time Series in risk_models.pdf
perform backtest in parallel using the map/reduce (split-apply-combine) procedure 
expand the slide Simulating EWMA Strategies Using Parallel Computing in investment_strategies.pdf

+ [ ] Create slide with bullet points of backtesting: collect historical data (returns, etc.), aggregate data into performance statistics (Sharpe ratio, etc.), apply trading rule and form portfolio, test portfolio performance out-of-sample
adapt language from Arman Arkilic capstone project.md

+ [ ] Adapt backtest code from package cv.ts
http://moderntoolmaking.blogspot.com/2011/11/functional-and-parallel-time-series.html
http://moderntoolmaking.blogspot.com/2011/11/time-series-cross-validation-2.html
https://github.com/zachmayer/cv.ts
http://robjhyndman.com/researchtips/tscvexample
# foreach package for parallelized backtesting with foreach
http://blog.revolutionanalytics.com/2009/05/parallelized-backtesting-with-foreach.html
# backtesting with elastic net, LASSO, glmnet and caret
https://quantmacro.wordpress.com/2016/04/26/fitting-elastic-net-model-in-r/

+ [ ] A backtest can only reject a potential strategy, but it can't predict its future success
Historical data can never be long enough to capture all the possible Black Swan events that can occur in the future, so a backtest can't tell us if a strategy will fail miserably. 
But if a strategy has failed in a backtest, then it's very likely to fail again in the future.

+ [ ] Adapt from: Harvey Evaluating Trading Strategies.pdf
Harvey Backtesting Data Mining Bonferroni Adjustment SSRN.pdf

+ [ ] Demonstrate that in backtest, an ensemble of EWMA strategies out-performs any single EWMA strategy out-of-sample
make ensemble weights dependent on correlations, to avoid over-weighting similar strategies
use minimum correlation portfolio model

+ [ ] Calculate confidence interval of strategy parameters as function of length of data used for calibration and total number of trades
Show that confidence interval increases with total number of trades, so strategy which trades infrequently requires very long backtest which may exceed available data.
SharpeR Vignette.pdf
Lo Sharpe Ratio Statistics.pdf
http://robotwealth.com/optimal-data-windows-for-training-a-machine-learning-model-for-financial-prediction/

+ [ ] Futures price prediction using the order book data
http://blog.kahutrading.com/2012/03/futures-price-prediction-using-order.html

+ [ ] Add slide constrained portfolio optimization using penalty terms: sum of weights equal to 1
This is an objective function equal to the portfolio variance plus a penalty term for the weight constraint: sum(weight_s) == 1.
object_ive <- function(weight_s, re_turns) {
  var(re_turns %*% weight_s) + 
    (sum(weight_s) - 1)^2
}  # end object_ive
You can then perform portfolio optimization for minimum variance, with the weight constraint:
op_tim <- optim(par=rep(1.0, NCOL(re_turns)),
                fn=object_ive,
                method="L-BFGS-B",
                upper=rep(1, NCOL(re_turns)),
                lower=rep(-1, NCOL(re_turns)),
                re_turns=re_turns)
weight_s <- op_tim$par
var(re_turns %*% weight_s)

+ [ ] Add slide calculating minimum CVaR portfolio: historical
Explain how Rglpk::Rglpk_solve_LP() works in case of minimum CVaR portfolio:
The (unkown) weights are applied to the portfolio, plus additional weights are applied to the individual returns at each point in time.
Rglpk_solve_LP() tries to maximize the product of the obj vector parameter times the (unkown) weights.
Since the obj vector elements are negative, the weights are pushed towards zero.
At the same time the mat constraints require the weights to be larger, because some of the individual returns are negative.
So the only way to maximize the obj product is to make the individual returns less negative, but adjusting the portfolio weights.

+ [ ] Add slide CVaR portfolio optimization using linear programming optimization

+ [ ] Calculate standard error of stock beta as function of time series length and level of volatility
Perform same analysis for eigenvectors and eigenvalues.
Simulate returns or bootstrap historical returns, and calculate standard errors of betas, alphas and sharpe ratios.
Demonstrate that sampling at higher frequency doesn’t reduce standard errors.
Calculate how many years of data are need to reduce standard errors to tolerable level.
Explain that stock betas are useless because they have huge standard errors.
Since beta depends on time, we are not able to measure beta.

+ [ ] Rolling portfolio optimization with shrinkage

+ [ ] Add slide portfolio optimization with elastic net shrinkage  

+ [ ] Constrained portfolio optimization shrinkage  
http://www.finance-r.com/s/efficient_frontier_fPortfolio/complete/  
http://www.finance-r.com/s/simple_portfolio_optimization_tseries/complete/  
http://www.portfolioprobe.com/2011/04/28/a-test-of-ledoit-wolf-versus-a-factor-model  
http://quant.stackexchange.com/questions/10101/portfolio-optimization-shrinkage-of-covariance-matrix-when-data-is-available  
https://systematicinvestor.wordpress.com/2011/11/11/resampling-and-shrinkage-solutions-to-instability-of-mean-variance-efficient-portfolios/  
https://systematicinvestor.wordpress.com/2013/10/29/updates-for-proportional-minimum-variance-and-adaptive-shrinkage-methods/  
http://quant.stackexchange.com/questions/1504/robust-portfolio-optimization-re-balancing-with-transaction-costs  
Golts Constrained Shrinkage Portfolio Optimization.pdf  
Demiguel Shrinkage Estimators Portfolio Optimization.pdf  
Ledoit Wolf Covariance Shrinkage Estimators Portfolio Optimization.pdf 

+ [ ] Adapt optimization techniques from:
Bolker Optimization Methods.pdf
Yollin Optimization.pdf
Boudt DEoptim Large Portfolio Optimization.pdf

+ [ ] Add slide portfolio optimization using package Deoptim: example of portfolio optimization
Ardia DEoptim Portfolio Optimization.pdf  
Boudt DEoptim Large Portfolio Optimization.pdf  
Boudt PortfolioAnalytics Portfolio Optimization CVaR Budgets.pdf
CRAN Task View Empirical Finance
http://cran.r-project.org/web/packages/DEoptim/vignettes/DEoptimPortfolioOptimization.pdf

+ [ ] Demonstrate how to fix singular correlation matrix
first generate singular correlation matrix
package corpcor

+ [ ] Adapt from: Bailey Prado Stop Loss Rules.pdf

+ [ ] Adapt from: 
https://www.linkedin.com/pulse/secret-investing-canada-kurtis-hemmerling/

+ [ ] Simulate GARCH model using random returns  
use rugarch function ugarchsim()
https://faculty.washington.edu/ezivot/econ589/econ589univariateGarch.r
econ589/econ589univariateGarch.r
Burns GARCH Modeling.pdf

+ [ ] GARCH volatility models adapt from:
http://quant.stackexchange.com/questions/27755/garch-volatility-modeling-squared-returns-and-convergence
Reider Volatility Stochastic Volatility Models.pdf
Reider GARCH Volatility Models.pdf
Engle GARCH Volatility Models.pdf

+ [ ] Volatility forecasting using Kalman filter
Theoret Kalman Volatility Forecasting.pdf

+ [ ] Calculate standard errors of GARCH volatility forecasts using bootstrap simulation

+ [ ] Introduce GARCH models and volatility forecasting  
http://models.cliffordang.com/garch11.R
http://eranraviv.com/multivariate-volatility-forecast-evaluation/
simulate stocks as ARMA + GARCH model
show that it has time dependent volatility
fit stock returns into ARMA + GARCH model
calculate standard errors of GARCH model parameters and demonstrate that GARCH models require large amount of data to calibrate
Brownlees Engle Volatility Forecasting.pdf

+ [ ] ARIMA GARCH strategy  
Halls-Moore ARIMA GARCH Strategy.pdf  

+ [ ] Create EWMA and GARCH examples from package GARPFRM  

+ [ ] Rcpp examples for GARCH
http://systematicinvestor.github.io/Exponentially-Weighted-Volatility-RCPP
http://unstarched.net/r-examples/rmgarch/fast-ewma-filtering-of-time-vayring-correlations/

+ [ ] Incorporate GARCH scripts
https://theaverageinvestor.wordpress.com/category/r/
http://www.quintuitive.com/category/research/armagarch/
http://www.quintuitive.com/

+ [ ] Estimating GARCH parameters using packages rugarch and fGarch problems
https://ntguardian.wordpress.com/2017/11/02/problems-estimating-garch-parameters-r/

+ [ ] Add package rugarch  
http://unstarched.net/r-examples/rugarch/a-short-introduction-to-the-rugarch-package/

+ [ ] Add package tseries GARCH volatility models  

+ [ ] Calibrate into simulated GARCH data and show how the standard error of parameter estimates depends on the number of data points

+ [ ] Perform backtest of GARCH model, and calibrate it using variance targeting  
use DEoptim
http://unstarched.net/2013/01/07/does-anything-not-beat-the-garch11/
rolling GARCH:
http://stackoverflow.com/questions/25732348/volatility-forecast-with-for-loop-for-garch-family-model
calibrating GARCH model requires a minimum of about 2,000 observations i.e. 10 years of daily data.  
if less than 1,000 observations are available, then better to just pick some reasonable parameter values.  
the intraday seasonality of volatility makes it harder to use intraday data to calibrate GARCH model  
http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/

+ [ ] Calculate PACF and fit GARCH for all the variance estimator methods  

+ [ ] Simulate time-varying volatility process
Models of stock returns: Pareto distribution, stochastic volatility, Heston model, 
https://github.com/daleroberts/heston
http://models.cliffordang.com/hestonSV.R

+ [ ] Slide Simulating Stochastic Volatility

+ [ ] Create GARCH examples from package highfrequency  

+ [ ] Fit returns into Student t-distribution, Cauchy, and Pareto distribution
Explain Method of Moments
Explain fitting return time series distribution using expectation-maximization algorithm
MASS::fitdistr
Show that the Cauchy and Pareto distributions have infinite variance but have finite MAD.
Create distribution with large skew - Poisson
Student t-distribution as model for stocks: power law decay, instead of exponential ?
Shalizi: pareto.R  
http://edge.org/response-detail/25401  
http://datascienceplus.com/modelling-dependence-with-copulas/  
http://stats.stackexchange.com/questions/52609/fitting-t-distribtution-to-financial-data  
# define heteroskedasticity as the variability of the variance
http://www.investopedia.com/terms/h/heteroskedasticity.asp
Heteroskedasticity is when the standard deviations of a variable, monitored over a specific amount of time, are nonconstant. 
Heteroskedasticity often arises in two forms: conditional and unconditional. 
Conditional heteroskedasticity identifies nonconstant volatility when future periods of high and low volatility cannot be identified. 
Unconditional heteroskedasticity is used when future periods of high and low volatility can be identified.

+ [ ] Analytic solution of the Ornstein-Uhlenbeck OU process solve pde
Grabovsky Statistical Arbitrage Pairs Trading.pdf
Thierfelder Ornstein-Uhlenbeck Process.pdf

+ [ ] Adapt trending Ornstein-Uhlenbeck, stochastic time series Feynman-Kac Theorem, Girsanov Theorem from:
Thierfelder Ornstein-Uhlenbeck Process.pdf

+ [ ] Fitting calibration maximum likelihood Ornstein-Uhlenbeck OU process
Berg Ornstein-Uhlenbeck Calibration.pdf
Smith Ornstein-Uhlenbeck Calibration.pdf
Temnov Ornstein-Uhlenbeck Trading.pdf
http://r.789695.n4.nabble.com/Ornstein-Uhlenbeck-td2991060.html
https://rpubs.com/snowdj/oualberta
https://renkun.me/2014/04/15/fit-an-ornstein-uhlenbeck-process-with-discrete-time-series-data/
multiply returns times lagged prices minus constant
relation of Ornstein-Uhlenbeck OU process to ARIMA

+ [ ] Demonstrate how to fit time series of returns into normal distribution model using maximum log-likelihood estimation 
Explain that maximum log-likelihood estimation of any model is a two-step procedure:
First perform regression to calculate residuals.
The residuals are a function of the model parameters obtained from regression. 
Second, fit the residuals into normal distribution 

+ [ ] Explain that individual prices are almost impossible to forecast, but prices of some portfolios may be possible to forecast.
Examples of portfolios possible to forecast: pairs, max Sharpe.
But then the problem is, do these remain stable out-of-sample?
Do pairs remain cointegrated?

+ [ ] Perform rolling regression with shrinkage

+ [ ] Demonstrate shrinkage and the bias-variance tradeoff applied to multiple regression  
Demonstrate that shrinkage is more powerful when the signal-to-noise is low.
Point out that there is no formula for the optimal amount of shrinkage that should be applied to obtain the lowest MSE, so cross-validation is neeeded to calculate the optimal shrinkage amount. 
http://eranraviv.com/shrinkage-in-statistics/

+ [ ] Adapt shrinkage LASSO regression, SVD, PCA using glmnet
http://www4.stat.ncsu.edu/~reich/BigData/code/lasso.html
https://quantmacro.wordpress.com/2016/04/26/fitting-elastic-net-model-in-r/
https://onlinecourses.science.psu.edu/stat857/node/137

+ [ ] Adapt SVD and PCA from:
https://poissonisfish.wordpress.com/2017/01/23/principal-component-analysis-in-r/
http://www4.stat.ncsu.edu/~reich/BigData/code/svd_v_eigen.html

+ [ ] lift LaTeX formulas:
https://web.stanford.edu/~hastie/glmnet/glmnet_beta.html

+ [ ] Adapt EWMA moving average indicators from: 
C:\Research\R\R-Finance 2016\Service Dual Moving Average Indicators Automated Trading.pdf
Sample R code from Christian Silva presentation "Moving averages strategies" at R/Finance 2013
http://rpubs.com/silvaac/6165

+ [ ] Create several EWMA time series (current price minus EWMA price) for several different decay factors
Perform regression of returns on the EWMA time series

+ [ ] Create correlation heatmap
http://blog.revolutionanalytics.com/2014/08/quantitative-finance-applications-in-r-8.html

+ [ ] Use outer() to create heatmap and to find optimal trading parameters
Use statarb_sharpe_ratio.R
Interpolate the heatmap using package raster.
Plot an interactive perspective plot of heatmap using package rgl.
sharpe_matrix_dense <- raster::raster(sharpe_matrix)
sharpe_matrix_dense <- raster::disaggregate(sharpe_matrix_dense, fact=c(5, 5), method="bilinear")
sharpe_matrix_dense <- raster::as.matrix(sharpe_matrix_dense)
rgl::persp3d(z=sharpe_matrix_dense, col="green", zlab="", main="sharpe_matrix")

+ [ ] Estimate Hurst exponent for an xts time series of prices using variance ratios  
use package pracma 
Demonstrate that if prices follow geometric Brownian motion then the Hurst exponent is equal to 1, 
If prices are mean-reverting then the Hurst exponent is less than 1, 
If prices are trending then the Hurst exponent is greater than 1, 
Simulate prices for OU prices and calculate variance ratios for different values of mean-reversion parameter.
Plot Hurst exponent as function of mean-reversion parameter.
# calculate Hurst exponent using variance ratios for non-xts
hurst_exp <- function(da_ta, l_ag=4) {
  len_gth <- length(da_ta)
  var(da_ta[-(1:l_ag)]-da_ta[-((len_gth-l_ag+1):len_gth)])/var(da_ta[-1]-da_ta[-len_gth])/l_ag
}  # end hurst_exp

+ [ ] Adapt from testing the Efficient Market Hypothesis
Lo-MacKinlay Variance Ratio Test
https://github.com/StuartGordonReid/emh

+ [ ] Adapt from Hurst exponent with Python code
https://robotwealth.com/demystifying-the-hurst-exponent-part-1/
https://robotwealth.com/demystifying-the-hurst-exponent-part-2/
Demonstrate that for short time frames, the Hurst is less than 0.5, so it's better to trade mean-reversion trading strategies. 
Demonstrate that for long time frames, the Hurst is greater than 0.5, so it's better to trade momentum or trend-following trading strategies. 

+ [ ] Create slides for mean reversion tests: ADF and Hurst
demonstrate that power of mean reversion tests is weak and it increases with length of time series
apply tests to short samples of time series data and demonstrate that sometimes they are mean reverting  
study Lo and MacKinlay variance ratio test in: 
Kinlaw Variance Ratio Correlation Term Structure.pdf  
packages vrtest and pracma  
https://github.com/cran/pracma/blob/master/R/hurst.R

+ [ ] Demonstrate that term structure of variance may be caused by autocorrelation
simulate an autocorrelated series and calculate its term structure of variance
plotly or shiny plot the variance ratio as function of autocorrelation
stochastic (unobservable) drift term may cause autocorrelation, even if returns are iid and lognormal
http://www.portfolioprobe.com/2011/11/08/the-mystery-of-volatility-estimates-from-daily-versus-monthly-returns/

+ [ ] Create slides for packages sde and yuima for Ornstein-Uhlenbeck ?
sde.sim()

+ [ ] Simulate Ornstein-Uhlenbeck OU process AR(1) model and trade it  
http://quant.stackexchange.com/questions/1260/r-code-for-ornstein-uhlenbeck-process
https://cran.r-project.org/web/packages/Sim.DiffProc/index.html
https://cran.r-project.org/web/packages/yuima/index.html
Create scatterplot of returns versus lagged prices.
Create plot with multiple OU processes.
Forecast returns and demonstrate that forecasting is easier with stronger mean-reversion.
Bertram Statistical Arbitrage Trading Solutions.pdf

+ [ ] Add Stanford Lisa Borland course MSE448 Big Financial Data for Algorithmic Trading (in Python)
http://web.stanford.edu/class/msande448/

+ [ ] WRDS research database SAS sample queries
https://wrds-web.wharton.upenn.edu/wrds/research/applications/index.cfm

+ [ ] WRDS research database SAS query replicating the momentum strategies of Jegadeesh and Titman - momentum crashes
https://wrds-www.wharton.upenn.edu/pages/support/replicating-momentum-strategies-jegadeesh-and-titman-jf-1993/

+ [ ] Files sp500_ohlc_prices.Rdata and sp500_ohlc_prices_permno.csv contain the data frame sp500_ohlc_prices  
File sp500_1997.csv contains S&P500 index constituents from 1997. 
Map PERMNO to gvkey and vice versa in file sp500_1997.csv using CRSP_Compustat_merged.csv
Aggregate by PERMNO to find the TICKER symbols assigned to PERMNO.
Aggregate by PERMNO into an environment of OHLC time series with volumes and adjustment factors.

+ [ ] WRDS database overview CRSP, Compustat, tickers, identifiers, conventions, formats
Compustat uses GVKEY identifier.
CRSP uses PERMNO and PERMCO identifiers.
https://wrds-web.wharton.upenn.edu/wrds/research/applications/linking/CRSP_COMPUSTAT_merged/
http://www.ruidaiwrds.info/data/linking-crsp-and-compustat
https://wrds-web.wharton.upenn.edu/wrds/query_forms/navigation.cfm?navId=120
The CRSP/Compustat Merged Database (CCM) contains only Compustat data items, but can be searched by CRSP's PERMNO and PERMCO in addition to Compustat's GVKEY. 
Merging this data with the CRSP stock data requires an additional step.

+ [ ] linking CRSP and Compustat databases
http://www.ruidaiwrds.info/data/linking-crsp-and-compustat
https://libguides.princeton.edu/MatchFinancial

+ [ ] Add tidyquant by Matt Dancho
Integrates the quantitative analysis functionality of xts/zoo, quantmod ttr and performance analytics.
Designed for the data science workflow of the tidyverse.
https://github.com/mdancho84
https://www.linkedin.com/pulse/introduction-portfolio-returns-jonathan-regenstein/

+ [ ] Constant Proportion Portfolio Insurance (CPPI)

+ [ ] Add cheatsheet slide: coercing objects to and from time series: xts(), as.numeric(), zoo::coredata(), 

+ [ ] Add cheatsheet slide: how to explore and inspect objects: class(), dim(), attributes(), str(), summary()

+ [ ] Ross Bennett:
file:///C:/Research/R/Packages/PortfolioAnalytics%20Bennett/presentation.html
C:\Research\R\Packages\PortfolioAnalytics\R\optimize.portfolio.R
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r
http://comisef.wikidot.com/tutorial:tangencyportfolio
http://www.calculatinginvestor.com/2011/06/07/efficient-frontier-1/
http://www.calculatinginvestor.com/2011/06/14/efficient-frontier-part-2/

+ [ ] Guy Yollin package MPO for book "Modern Portfolio Optimization"
C:\Research\R\Packages\mpo\pkg\R
C:\Research\R\Packages\mpo\kirk\MVO\constraints_tutorial.pdf
C:\Research\R\Packages\mpo\kirk\MVO\efront.constrained.r
C:\Research\R\Packages\mpo\kirk\MVO\efrontplot.shiny.R

+ [ ] Add package ROI (R Optimization Infrastructure): interface to the Rglpk package and the quadprog package to solve linear and quadratic programming problems  
Solves convex optimization problems: maxmimize portfolio return subject leverage
ECON457 R lab 3 Optimization in R: ROI_lab03.Rmd ROI_lab03.nb
https://moderndata.plot.ly/portfolio-optimization-using-r-and-plotly/

+ [ ] Create slides for packages ROI (R Optimization Infrastructure) and Rglpk

+ [ ] Adapt from ECON457 optimization in R - mostly linear and quadratic programming and package ROI
C:\Research\R\Tutorials\ECON457 optimization in R.html

+ [ ] Create estimator of slope (returns), equal to difference of prices over lookback interval, and study the bias-variance tradeoff  
Simulate prices as the sum of deterministic sine function plus stochastic normal noise.
The objective is to estimate the slope of the deterministic sine function.
Create estimator of the slope of prices equal to the difference of prices over lookback interval. 
Demonstrate that the estimator variance increases with shorter lookback interval.
Demonstrate that the estimator bias increases with longer lookback interval.
Calculate the lookback interval with optimal bias-variance tradeoff and best performance.
Demonstrate that the optimal lookback interval increases with higher noise level.

+ [ ] Create strategy with EWMA indicator equal to difference of two EWMAs: short lookback interval minus long lookback interval  
Demonstrate that indicator is related to slope of price curve, and plot both.
Calculate correlations between indicators with different EWMA parameters, and create heatmap of correlations over matrix of EWMA parameters, to demonstrate that correlations are very high.
Implement binary trading rule, with the position equal to the absolute value of the lagged EWMA indicator (flips to long when the short EWMA crosses over the long EWMA from below, and flips to short when the short EWMA crosses over the long EWMA from above).
Implement trading rule that trades continuously with position proportional to the EWMA indicator.
Create heatmap of EWMA strategy PnL over matrix of EWMA parameters.
Find optimal parameters in-sample.
Demonstrate that the indicator is autocorrelated, so it may be better to trade on the forecasts of the indicator, instead of the indicator itself.
Demonstrate that the forecasts of the indicator are equal to the indicator differences over a lag period, and are related to the price curvature (second derivative of prices).  Plot the indicator forecasts and the price curvature.
Demonstrate that the indicator forecasts have high variance, so it's better to use more biased forecasts with more lag.
Study the bias-variance tradeoff of the forecasts of the indicator as a function of the lag period.

+ [ ] Create simple EWMA strategy: trend-following and mean-reverting
Find optimal parameters in-sample.
Demonstrate that the Sharpe of returns optimized in-sample decrease with the length of time series.

+ [ ] Find optimal in-sample parameters over rolling windows, and demonstrate that optimal parameters have zero autocorrelation to each other.

+ [ ] Create EWMA strategy using average over whole range of parameters, and demonstrate that it outperforms out-of-sample any single EWMA strategy with parameters optimized in-sample.

+ [ ] Demonstrate that the EWMA volatility estimator is an example of shrinkage and bias-variance tradeoff  
Simulate Brownian motion with deterministic, time-dependent volatility, and estimate the volatility using different EWMA lambda parameters.
Calculate the MSE of the volatility estimator, and find the lambda parameter which minimizes the MSE.
Demonstrate that the optimal lambda parameter depends on the signal-to-noise ratio and the rate at which volatility changes.
http://eranraviv.com/shrinkage-in-statistics/

+ [ ] Demonstrate bias-variance tradeoff when estimating volatility using EWMA
create study of bias-variance tradeoff using volatility estimation example:  
http://scott.fortmann-roe.com/docs/BiasVariance.html  
create xts of random prices with changing time-dependent deterministic vol parameter,  
estimate volatility use look-back interval parameter,  
too short look-back interval increases variance,  
too long look-back interval increases bias,  
tune filter parameters in-sample: study bias-variance tradeoff,  
create rCharts and shiny visualizations  
plot MSE as function of lambda

+ [ ] Demonstrate that for zero correlations, the optimal portfolio coefficients are equal to the t-values (Sharpe ratios) of the assets.

+ [ ] Simulate momentum strategy based on P/E ratios  
Gray PE Ratio Momentum Stock Forecasting.pdf

+ [ ] Simulate binomial volatility pumping harvesting
demonstrate that long-term portfolio returns increase thanks to rebalancing
demonstrate that positive expected logarithmic growth rate can be achieved even when both assets individually have negative expected logarithmic growth rates.
Witte Trading Volatility Pumping Harvesting.pdf

+ [ ] Calculate the standard errors of VaR and CVaR  
demonstrate that the standard error increases with the confidence level, because the number of observations decreases
demonstrate that the standard error decreases as the size of the lookback window increases, because the number of observations increases
show that VaR has a huge standard error and is therefore useless
show that CVaR has a bigger standard error than VaR
CVaR has an even bigger standard error than VaR, and is therefore useless for very large number of risk factors estimated using short span of data. 
Jon Danielsson and Chen Zhou have demonstrated that to accurately estimate CVAR at 5% confidence would require decades of price history, something that simply doesn't exist for many assets.
Danielsson CVAR Estimation Standard Error.pdf
http://www.bloomberg.com/view/articles/2016-05-23/big-banks-risk-does-not-compute
# reproduce these plots
http://www.modelsandrisk.org/VaR-and-ES/

+ [ ] Create slides about creating R packages and rcpp packages

+ [ ] Create an R package from cpp code and compile it using Rcpp

+ [ ] Demonstrate that portfolio optimization is extremely sensitive to small changes in assumptions: plot efficient frontiers for slightly different returns
http://www.pionline.com/article/20031222/PRINT/312220715/markowitz-says-michaud-has-built-a-better-mousetrap
Portfolio optimizers amplify errors in expected returns.

+ [ ] Adapt robust portfolio optimization by incorporating estimation errors: 
Lai Robust Portfolio Optimization.pdf
study Lai's NPEB estimator (has great out-of-sample performance)
Ceria Robust Portfolio Optimization.pdf
Portfolio optimization with bootstrap and shrinkage.
Jin Robust Portfolio Optimization.pdf
Ban Robust Portfolio Optimization.pdf
DeMiguel Parameter Uncertainty Multiperiod Portfolio Optimization Transaction Costs.pdf
DeMiguel Shrinkage Portfolio Optimization.pdf
DeMiguel Shrinkage Estimators Portfolio Optimization.pdf
Becker Robust Portfolio Optimization.pdf
Michaud Portfolio Resampling.pdf

+ [ ] Michaud Resampled Efficiency Portfolio Optimization (patented)  
Resampled random portfolios performs better out-of-sample.
https://en.wikipedia.org/wiki/Resampled_efficient_frontier
https://newfrontieradvisors.com/Research/Articles/MichaudResampledEfficiency.html  
https://systematicinvestor.wordpress.com/2011/11/11/resampling-and-shrinkage-solutions-to-instability-of-mean-variance-efficient-portfolios/  
Michaud Portfolio Resampling.pdf

+ [ ] Demonstrate tha combining the 1/N portfolio with the Markowitz portfolio improves out-of-sample performance  
Adapt from: Tu Rolling Portfolio Optimization.pdf.
The 1/N rule outperforms Markowitz out-of-sample.
The MacKinlay and Pastor strategy also performs well out-of-sample.

+ [ ] Adapt from Pav code for Cochrane Asset Pricing  
https://github.com/shabbychef/coursera_ap2013  

+ [ ] Adapt from: quantbros  
http://quantbros.com/category/tutorial/

+ [ ] Explain Optimism of the Training Error Rate
http://eranraviv.com/optimism-training-error-rate/
https://stats.stackexchange.com/questions/88912/optimism-bias-estimates-of-prediction-error

+ [ ] Explain Fama-MacBeth two-pass regressions to explain cross-sectional returns/values by factors  
Fama-MacBeth two-pass regressions to explain cross-sectional returns/values by factors  
Cochrane Asset Pricing.pdf  
Campbell Market Factors Stock Forecasting.pdf  
Harvey Bootstrap MacBeth Factor Models.pdf  
http://quant.stackexchange.com/questions/16855/how-to-test-the-5-factor-capm-of-fama-french-2014  
http://quant.stackexchange.com/questions/17125/please-give-a-step-by-step-explanation-on-how-to-build-a-factor-model
http://quant.stackexchange.com/questions/8697/r-fast-and-efficient-way-of-running-a-multivariate-regression-across-a-really
factorAnalytics fitTsfm_vignette.pdf

+ [ ] Create shiny dashboard with Fama-French model
https://www.linkedin.com/pulse/r-shiny-fama-french-jonathan-regenstein
https://www.interactivebrokers.com/en/index.php?f=25244&vid=18409

+ [ ] Explain Fama-French model, Barra model
http://quant.stackexchange.com/questions/16855/how-to-test-the-5-factor-capm-of-fama-french-2014  
http://quant.stackexchange.com/questions/17125/please-give-a-step-by-step-explanation-on-how-to-build-a-factor-model
http://quant.stackexchange.com/questions/8697/r-fast-and-efficient-way-of-running-a-multivariate-regression-across-a-really
factorAnalytics fitTsfm_vignette.pdf
analyze function fitFfm()  
Perform sorts on the "stock" data frame from factorAnalytics - file Stock.df.RData
stock is used by function fitFfm()

+ [ ] Add Cauchy distribution to plotting.Rnw or risk_models.Rnw  
https://rviews.rstudio.com/2017/02/15/some-notes-on-the-cauchy-distribution/

+ [ ] Pricing anomalies: size, value, momentum, volatility  

+ [ ] Estimate correlation matrix for synthetic, colinear time series: study how correlation matrix becomes singular as one column of time series becomes colinear with the others

+ [ ] Create slides for categorizing S&P500 constituents using equity sector data.
create cap-weighted sub-portfolios: plot their performance, calculate rolling betas, etc.
Calculate sector correlations and heatmaps.

+ [ ] Create random OHLC data and pass it through EWMA strategy to test for data snooping

+ [ ] Create rebalancing strategy for portfolio with two assets: stock index plus bond index  
http://www.capitalspectator.com/portfolio-analysis-in-r-a-6040-us-stockbond-portfolio/  
Create portfolio return scatterplot and show that it's negatively skewed, because rebalancing strategy is equivalent to selling put options  
Demonstrate that a strategy using asset rebalancing to maintain constant market value adds risk  
Granger Portfolio Rebalancing Momentum Trend Following.pdf  
Qian Asset Allocation Portfolio Rebalancing Alpha.pdf  
Qian Asset Allocation Portfolio Rebalancing.pdf  

+ [ ] Create EWMA mean-reverting strategy with large tail risk: demonstrate that it's like selling far out-of-money options, and that it has very high Sharpe, but that it infrequently blows up

+ [ ] Simulate stop loss trading rule, and demonstrate that it only works in trending markets, but loses money in mean-reverting markets

+ [ ] Create Bollinger bands mean-reversion strategy

+ [ ] Create interactive dygraphs or plotly by first pre-calculating model output time series and saving to file, and passing the data through plotting function

+ [ ] Create Rcpp function for range volatility estimator  
http://quant.stackexchange.com/questions/2589/how-to-calculate-historical-intraday-volatility/3264#3264

+ [ ] Create slides for Rcpp using Rcpp RFinance_2015.pdf, Rcpp Getting Started.pdf, and RcppExamples.pdf
http://gallery.rcpp.org/articles/first-steps-with-C++11/
http://adv-r.had.co.nz/Rcpp.html

+ [ ] Rcpp: adapt from Farnsworth Econometrics in R.pdf: Calling C functions from R

+ [ ] Rcpp: create simple Rcpp function with logistic map - adapt from LearningRcpp  
https://github.com/rossb34/LearningRcpp

+ [ ] Adapt parallel Rcpp C++ code from package roll by Jason Foster - uses RcppArmadillo and RcppParallel
https://cran.r-project.org/web/packages/roll/index.html  
https://github.com/jjf234/roll

+ [ ] Create Rcpp function to perform parallel bootstrap in C++  
http://www4.stat.ncsu.edu/~reich/BigData/code/boot.html
http://www.onthelambda.com/2014/06/27/squeezing-more-speed-from-r-for-nothing-rcpp-style/
https://blog.rstudio.org/2016/01/15/rcppparallel-getting-r-and-c-to-work-some-more-in-parallel/
https://rcppcore.github.io/RcppParallel/
https://github.com/RcppCore/RcppParallel
https://github.com/RcppCore/Rcpp
http://gallery.rcpp.org/articles/rcpp-sgd/

+ [ ] Create functions that call ML C++ libraries based on packages RcppShark and RcppMLPACK

+ [ ] Fit VTI returns into t-dist and Generalized Lambda Distribution (GLD) by using Method of Moments:
https://www.r-bloggers.com/quantitative-finance-applications-in-r-4-using-the-generalized-lambda-distribution-to-simulate-market-returns/
https://www.r-bloggers.com/the-generalized-lambda-distribution-and-gldex-package-fitting-financial-return-data/

+ [ ] Create option examples from GARPFRM package  
demonstrate that call option returns have more positive skew than underlying asset
C:\Develop\R\fin_engine\vignettes
http://rossb34.github.io/GARPFRM_shiny/
optionSpec()
optionValue()
impliedVolatility()
computeGreeks()


# company identifiers symbols codes

CRSP codes
http://www.crsp.com/products/documentation/entity-keywords-and-usage
CRSP PERMNO, (permanent and unique 5-digit issue identification number assigned by CRSP) of an issue
CRSP PERMCO, (permanent and unique 5-digit company identification number assigned by CRSP) of an issue

SEC EDGAR codes
CIK (Central Index Key) — This is a publicly available number the SEC assigns to each filer. ...
CCC (CIK Confirmation Code) — A filer uses this code, in conjunction with a CIK number, in an EDGAR submission to verify its identity.

###

Sharadar discount
INPAV-100P-HWNT_SF0

###

+ [ ] Specify sources of historical point-in-time fundamental data

+ [ ] Scrape fundamental data from Yahoo or Google using getFinancials() from package quantmod
compare the fundamental data obtained from different sources
get stock statistics from Yahoo using XML, quantmod, plyr packages
http://allthingsr.blogspot.com/2012/10/pull-yahoo-finance-key-statistics.html
http://stackoverflow.com/questions/3693189/programmatic-api-for-downloading-historical-financial-statements

+ [ ] Download from Quandl RAYMOND financial ratios data for a list of companies
Fundamental data on Quandl is all premium.
harmonized database site:quant.stackexchange.com
https://www.quandl.com/data/RAYMOND-Raymond
https://www.quandl.com/data/RAYMOND-Raymond/documentation/documentation
http://quant.stackexchange.com/questions/17315/where-can-i-get-historical-fundamental-data-for-multiple-companies-in-a-single-c
http://quant.stackexchange.com/questions/22339/data-exported-from-capital-iq-factset-bloomberg-compustat

+ [ ] Add package TAQMNGR for processing high frequency data after it's downloaded from WRDS
# TAQMNGR processes raw data from WRDS (Wharton Research Data Service)
http://cran.r-project.org/web/packages/TAQMNGR/

+ [ ] quandl S&P500 index constituents
https://gist.github.com/ttmmghmm/28e88fbf4c20a15cbfb3

+ [ ] Adapt from Hugen WRDS Value Strategies.pdf

+ [ ] Download from WRDS S&P500 Stock index constituents and prices  
https://wrds-web.wharton.upenn.edu/wrds/query_forms/navigation.cfm?navId=84
https://faq.library.upenn.edu/business/faq/45457
https://lippincottlibrary.wordpress.com/2014/09/24/a-few-wrds-about-the-sp-500/
https://asklib.library.hbs.edu/friendly.php?slug=faq/47512

+ [ ] Download company fundamental data from WRDS
https://wrds-web.wharton.upenn.edu/wrds/query_forms/navigation.cfm?navId=84
https://wrds-web.wharton.upenn.edu/wrds/demo/demoform_compustat.cfm
https://wrds-web.wharton.upenn.edu/wrds/ds/comp/fundafinstat/index.cfm

+ [ ] Recreate CRSPpanel.txt fundamental financial data for 265 S&P500 stocks  
trellis plots  
nice barchart, dotplot, bwplot, and data munging  

+ [ ] Download fundamental financial ratios data using quantmod
# Google query:
r quantmod fundamental data

+ [ ] Download U.S. stock fundamental data from simfin, based on reports submitted to EDGAR SEC
https://simfin.com/

+ [ ] Create slide for Dow Jones Industrial Average DJIA stock index

+ [ ] Adapt code for manipulating S&P 500 CRSP and Compustat data from WRDS
https://github.com/alexchinco/CRSP-Data-Summary-Statistics-by-Industry-

+ [ ] WRDS and R using package DBI
https://wrds-web.wharton.upenn.edu/wrds/support/Accessing%20and%20Manipulating%20the%20Data/_007R%20Programming/_001Using%20R%20with%20WRDS.cfm
https://wrds-web.wharton.upenn.edu/wrds/support/Accessing%20and%20Manipulating%20the%20Data/_001Access%20Methods.cfm

+ [ ] WRDS dataset list
https://wrds-web.wharton.upenn.edu/wrds/tools/variable.cfm
# example SAS queries for TAQ
https://wrds-web.wharton.upenn.edu/wrds/support/Data/_003Sample%20Programs/TAQ/index.cfm

+ [ ] Slides for package h5 for hdf5 files

+ [ ] Slides with script to load and analyze hdf5 file train.h5 with kaggle data

+ [ ] Black-Litterman model
http://www.blacklitterman.org/
https://systematicinvestor.wordpress.com/2011/11/16/black-litterman-model/
https://cran.r-project.org/web/packages/BLCOP/

+ [ ] Neural network trading example package nnet
adapt from: C:/Develop/R/scripts/Torgo_stock_trading.R  
http://www.dcc.fc.up.pt/~ltorgo/DataMiningWithR/code3.html

+ [ ] Create XIV VXX ZIV strategies
http://www.wikinvest.com/index/Volatility_Index_(VIX)

+ [ ] MUD statistical arbitrage trading strategy: sell the quantile of stocks that are up the most, and buy the quantile that are down the most  

+ [ ] Add to time_series_multivariate  
show that CAPM holds by construction when the market portfolio is chosen to be the efficient frontier (maximum Sharpe) portfolio.  
CAPM model is another way of saying that the market portfolio is the maximum Sharpe portfolio and lies on the efficient frontier. 
Can Security Market Line (SML) be derived from Capital Market Line (CML)?  
Yes, because if we choose the most efficient portfolio (maximum Sharpe) as the reference (market) portfolio for CAPM, then the idiosyncratic asset returns will have a cumulative sum equal to zero.  
When the market portfolio is chosen to be the maximum Sharpe portfolio, then the sums of idiosyncratic returns are zero, and all assets lie exactly on the Security Market Line (SML). 
When individual asset returns are regressed on the efficient (maximum Sharpe) portfolio returns, then their idiosyncratic residuals are uncorrelated to the efficient portfolio returns, because if they weren't then a more efficient portfolio could be constructed using those residuals.  
But the idiosyncratic returns can be correlated with each other.  
individual asset variance is the sume of beta squared times market variance plus idiosyncratic variance

+ [ ] Add to section Portfolio Optimization
two-asset portfolio
portfolio constraints: box and leverage
\subsection{Portfolio Leverage Constraint Optimization}
efficient frontier
portfolio return objectives
https://datashenanigan.wordpress.com/2016/05/24/a-gentle-introduction-to-finance-using-r-efficient-frontier-and-capm-part-1/

+ [ ] Fix slide Random Portfolios in portfolio_construction: don't scale by 100 and include risk-free rate  

+ [ ] Kyle Balkissoon overnight effect R/Finance presentation - lame
C:\Research\R\R-Finance 2016\KyleBalkissoon.pdf

+ [ ] Kyle Balkissoon: Portfolio Optimization - only PortfolioAnalytics
http://kkb.io/2016/10/26/portfolio-optimization/

+ [ ] Fix lecture slides prepared with older version of package factorAnalytics  

+ [ ] Demonstrate that an ensemble of VWAP strategies outperforms any single VWAP strategy
an ensemble of VWAP strategies is a combination of VWAP strategies with all possible window parameters.

+ [ ] Jensen alpha examples of how alpha can be generated: either by timing the market and by selecting optimal portfolio ex-post (through hindsight)  
calculate Jensen alpha for SPX (for example) and demonstrate that it's close to zero  
calculate Jensen alpha for timed SPX: buy SPX at lows and sell at highs  
calculate Jensen alpha for ex-post portfolio: optimize portfolio in-sample to obtain highest alpha  

+ [ ] Add risk-free rate to PortfolioAnalytics code  

+ [ ] Simulate volatility targeting strategy  
https://seekingalpha.com/article/3280795-a-random-beat-down-of-wall-street

+ [ ] Add stylized facts of asset return distributions
statistical empirical properties of asset returns
fat tails
time dependent volatility
autocorrelation of volatility
assymetric volatility: higher when prices drop
volume and correlation increase with volatility
Cont Empirical Stylized Facts Asset Returns.pdf
Cont Volatility Clustering Agent–Based Models.pdf

+ [ ] Create risk parity strategy
First day of every month, sell all portfolio holdings at market. Same day, buy 50 random stocks from the S&P500 constituents. Weight positions by inverse volatility, i.e. simple vola parity sizing. Always be fully invested.
http://www.followingthetrend.com/2015/06/a-random-ass-kicking-of-wall-street/
# risk parity by Bridgewater Associates
https://www.linkedin.com/pulse/our-thoughts-risk-parity-all-weather-ray-dalio
# review of risk parity
http://unstarched.net/2013/12/17/a-review-of-risk-parity/ 

+ [ ] Implement minimum variance, risk parity, HRP, and maximum diversification portfolios, and backtest their performance
Choueifaty Maximum Diversification Portfolios.pdf
Choueifaty Maximum Diversification Portfolios JPM.pdf
Clarke Maximum Diversification Portfolios.pdf
Qplum Maximum Diversification Portfolios.pdf
Lohre Maximum Diversification Risk Parity.pdf
Meucci Diversification Optimization.pdf
Damschroder Maximum Diversification Portfolios
https://quant.stackexchange.com/questions/7905/how-to-implement-maximum-diversification-in-r

+ [ ] Introduce Hierarchical Risk Parity (HRP), the Gerber Statistic, and the Critical Line Algorithm (CLA)  
http://gallery.rcpp.org/articles/hierarchical-risk-parity/
https://github.com/RcppCore/rcpp-gallery/blob/gh-pages/src/2016-05-27-HRP.Rmd
http://nextlevelanalytics.github.io/2016/05/30/Gerber_Statistic_and_Hierarchical_Risk_Parity/

+ [ ] Explain that (taken from Prado Portfolio Optimization Hierarchical Risk Parity slides.pdf):
The condition number of a covariance matrix is the ratio between its highest and smallest (in moduli) eigenvalues.
The more correlated the assets, the higher the condition number, and the more unstable is the inverse matrix.
Demonstrate the above using synthetic data - create a shiny app.

+ [ ] Merton model: simulate dynamic investment and consumption strategies  
stochastic control theory 
Merton Dynamic Consumption and Portfolio Choice  
simulate Merton consumption wealth model  
Guasoni Merton Optimal Consumption Utility Shortfall Aversion.pdf  
An Merton Utility Asset Allocation.pdf  
https://en.wikipedia.org/wiki/Intertemporal_portfolio_choice  
https://en.wikipedia.org/wiki/Merton%27s_portfolio_problem  

+ [ ] TTR rolling regression: analyze rollSFM(), and create script with its code, and create example of using rollSFM()
rollSFM()

+ [ ] Explain R6 classes and package
https://adv-r.hadley.nz/r6.html

+ [x] Performing rolling aggregations
TTR rolling aggregations:
runSD()
runMedian()
runMAD()
explain, summarize, and benchmark rolling functions over margins:
package stats: runmed()
package zoo: rollmean()
package TTR: runMAD()
package caTools: runmad()

+ [ ] Study tenor (maturity) dependence of mean, variance, skewness, and kurtosis
show that skewness and kurtosis decay with time

+ [ ] Calculate tail shape of return frequency distribution and demonstrate power law

+ [ ] High-Frequency Financial Data Analysis
C:\Research\R\Tutorials\Guy Yollin Presentations
HF Tick Data Analysis.pdf
HFDA.pdf

+ [ ] Create Risk Measures (VaR and ES) examples from package GARPFRM  

+ [ ] Provide examples showing when forecasting and VaR models fail due to human-induced events: CHF currency, corporate events (mergers, takeovers, defaults)

+ [ ] Provide example showing when VaR isn't additive (coherent), show that ES is coherent  

+ [ ] generating random OHLC time series  

+ [ ] Implement plotting of xts OHLC time series using candleChart()
http://www.quantmod.com/examples/charting/

+ [ ] Add example forecasting stock returns using Smarket data from package ISLR James book Statistical Learning in R.pdf

+ [ ] Create MUD strategy for S&P500 stocks, and show how performance dropped over time  

+ [ ] Create CAPM examples from GARPFRM package  
C:\Develop\R\fin_engine\vignettes
efficient frontiers
http://rossb34.github.io/GARPFRM_shiny/

+ [ ] Bootstrapping time series of prices and OHLC time series in parallel  

The no drift assumption is a good approximation when the dimensionless parameter µvT/s is small

+ [ ] Demonstrate that aggregating to longer periods (tenor, time scale) makes the distribution of returns more Gaussian and reduces skew and kurtosis
The distributions of returns are increasingly fat-tailed as data frequency increases (smaller interval sizes) and are hence distinctly unstable.
use function to_period() as follows:
aggregate to longer periods
calculate returns, variance, skew, kurtosis, Sharpe
plot distribution of returns
calculate returns using hfreq prices over non-overlapping periods of varying length (tenor)
calculate at different time agg horizons:
	returns, variance, skew, kurtosis, Sharpe
calculate and study the tenor dependence (term structure) of:
mean, variance, skewness, and kurtosis
show that skewness and kurtosis decay with longer tenor
show that mean returns grow like t, 
variance grows like sqrt(t), 
skewness decays like 1/sqrt(t), 
kurtosis decays like 1/t, 
https://quantivity.wordpress.com/2012/10/23/volume-clock-gaps-and-goog/

+ [ ] Demonstrate that using trading time makes the distribution of returns more Gaussian and reduces skew and kurtosis
Easley Volume Clock Trading Paradigm.pdf

+ [ ] Package ROCR for Visualizing the Performance of Scoring Classifiers

+ [ ] nonlinear time series BDS test
fNonlinear.pdf
tseries.pdf

+ [ ] Create plotly portfolo optimization slides
http://moderndata.plot.ly/portfolio-optimization-using-r-and-plotly/

+ [ ] Add plotly OHLC chart examples - create account
https://plot.ly/r/
https://plot.ly/javascript/candlestick-charts/
http://moderndata.plot.ly/interactive-r-visualizations-with-d3-ggplot2-rstudio/
http://moderndata.plot.ly/r-python-matlab-dashboards-graphs-with-d3-js-webgl/
http://moderndata.plot.ly/interactive-r-visualizations-with-d3-ggplot2-rstudio/
https://plot.ly/quandl/?code=GOOG/AMEX_LVOL

+ [ ] Create dygraphs slides for OHLC time series
https://github.com/danielkrizian/rChartsDygraphs
https://github.com/danvk/dygraphs/pull/538
http://dygraphs.com/tests/plotters.html

+ [ ] Create plotly slides for OHLC time series
http://moderndata.plot.ly/candlestick-charts-using-plotly-and-quantmod/

+ [ ] Convert all lectures from Sweave LaTeX to knitr R Markdown ?  what about two-column layout?
http://jeromyanglim.blogspot.com/2012/06/how-to-convert-sweave-latex-to-knitr-r.html
http://stackoverflow.com/questions/20934148/sweave-to-r-markdown-file-conversion-code-or-converters-available
http://pandoc.org/

+ [ ] Create online interactive documents using .Rmd files on RPubs  

+ [ ] using hfreq return data, estimate daily data: mean return, variance, skewness and kurtosis
show that daily returns are not autocorrelated, 
show that daily variance is autocorrelated, 
maybe also skewness and kurtosis
fit ARIMA into daily data
fit GARCH model using hfreq data

+ [ ] Adapt code from package deSolve DLL models  

+ [ ] Ryan Haffen trelliscope, tessera

+ [ ] Use following data:  
data(package="factorAnalytics")  
C:\Research\R\Packages\factorAnalytics\extdata  
data(package="GARPFRM")  
data(package="mpo")  

+ [ ] QMJ Quality Minus Junk Factor
http://timelyportfolio.blogspot.com/2014/04/all-factors-more-looks.html
qmj package
https://github.com/anttsou/qmj

+ [ ] Supervised Principal Components PCA regression package superpc  
http://statweb.stanford.edu/~tibs/superpc/
http://statweb.stanford.edu/~tibs/superpc/tutorial

+ [ ] Principal component regression PCR and Supervised Principal Components
http://www.milanor.net/blog/performing-principal-components-regression-pcr-in-r/
write full PCR code, then compare with package roll  
create synthetic data and show that PCR outperforms ordinary regression when noise is high  
show that using all the PCAs is equivalent to ordinary regression
https://en.wikipedia.org/wiki/Principal_component_regression

+ [ ] Principal Component PCA clusters example - adapt
https://plot.ly/r/github-getting-started-for-data-scientists/

+ [ ] Explain stock clustering as an example of unsupervised learning
Raffinot Portfolio Optimization Hierarchical Clustering.pdf
https://github.com/gjanesch/Stock-Clustering

+ [ ] Perform k-means clustering by hand and compare to Principal Component Analysis PCA
https://predictivealpha.wordpress.com/tag/random-portfolios/

+ [ ] Higher Moments Factor Models  
Boudt Asset Allocation Utility Higher Moments Factor Models.pdf
Boudt Asset Allocation Higher Moments Factor Models.pdf

+ [ ] Modify Security Market Line?  

+ [ ] Random portfolios  
https://seekingalpha.com/article/3967318-trade-like-chimp-unleash-inner-primate
https://predictivealpha.wordpress.com/tag/random-portfolios/
draw scatterplot of random portfolios, model on:
https://quantstrattrader.wordpress.com/2015/09/10/monte-carlo-in-asset-allocation-tests/  
http://www.portfolioprobe.com/2012/02/27/realized-efficient-frontiers/
Novomestky package: rportfolios  
Random portfolios with constraints: random_portfolios from PortfolioAnalytics  
Stein Random Portfolios Fund Analysis.pdf  
Resampling Methods Bootstrap Cross Validation Random Portfolios  
http://quantbros.com/parallelized-simple-random-constrained-portfolio-generation/
TechilaEfficientFrontier.R
http://www.capitalspectator.com/skewed-by-randomness-testing-arbitrary-rebalancing-dates/  
http://www.capitalspectator.com/using-random-portfolios-to-test-asset-allocation-strategies/  
https://gist.github.com/jpicerno1/fbc2e589023be56dde42  
https://gist.github.com/jpicerno1/af88861bcbbb80687cfb  
http://www.burns-stat.com/documents/tutorials/the-statistical-bootstrap-and-other-resampling-methods-2/  

+ [ ] Add Capital Market Line  
plot efficient frontier plus capital market line
http://zoonek.free.fr/blosxom/R/2012-06-01_Optimization.html  
https://gist.github.com/jpicerno1/565be39ca4226ecd004c  
http://www.capitalspectator.com/efficient-frontier-portfolios-impractical-but-still-useful/  
http://moderndata.plot.ly/portfolio-optimization-using-r-and-plotly/
Portfolio optimization: mean-variance efficient portfolios, efficient frontier, Capital Market Line, in portfolio_construction.Rnw

+ [ ] Portfolio optimization with different objective functions - VaR, CVaR,  
Ian Kaplan (UofWash) minimum variance and tangency portfolios, CVaR portfolio optimization, ETF portfolios, Wharton Research Data Service (WRDS) data set and Factor Model Factors  
http://www.bearcave.com/finance/  
using fPortfolio package:  
http://www.bearcave.com/finance/portfolio_equations/  
Shaw Portfolio Optimization CVaR Omega Utility.pdf  
Yollin Optimization.pdf
# uses function portfolio.optim from package tseries
Yollin Portfolio Optimization.pdf

+ [ ] Add package tseries portfolio.optim() for calculating mean-variance efficient portfolios  

+ [ ] Portfolio optimization using optim  
can mean variance portfolio optimization be converted to min variance optimization ?  
different objective functions,  
constraints

+ [ ] Portfolio rebalancing  
C:\Research\R\Packages\PortfolioAnalytics Bennett
C:\Research\R\Packages\PortfolioAnalytics Bennett Random Portfolios Swarm Optimization.pdf
C:\Research\R\Packages\PortfolioAnalytics Bennett\moment_estimation_notes.txt
PortfolioAnalytics Bennett Random Portfolios Swarm Optimization.pdf  
C:\Research\R\Packages\PortfolioAnalytics Bennett  
https://github.com/rossb34/PortfolioAnalyticsPresentation2015  
analyze PortfolioAnalytics function optimize.portfolio.rebalancing()

+ [ ] Zivot bootstrap portfolios - bootstrap mean, sd, weights  
C:\Research\R\Tutorials\Zivot\Econ 424\bootstrapPortfoliosPowerpoint.pdf  
C:\Research\R\Tutorials\Zivot\Econ 424\bootstrapPortfolio.R  

+ [ ] Adapt from C:\Research\R\Packages\PortfolioAnalytics\demo\demo_efficient_frontier

+ [x] mean-variance portfolio optimization using quadratic programming package quadprog
http://www.wdiam.com/2012/06/10/mean-variance-portfolio-optimization-with-r-and-quadratic-programming/
http://blog.ryanwalker.us/2014/01/solving-quadratic-progams-with-rs.html
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r
https://quant.stackexchange.com/questions/31743/dmat-argument-in-solve-qp-r-function-cov-or-2cov

+ [ ] Guy Yollin functions effFrontier() and maxSharpe() call the function portfolio.optim() from package tseries  
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r/  
C:\Research\R\Tutorials\Guy Yollin Presentations  
Levy Alpha Sharpe Portfolio Optimization.pdf  

+ [ ] Introduce the Gerber Statistic  
http://nextlevelanalytics.github.io/2016/05/26/Gerber/

+ [ ] Portfolio Optimization using the Gerber Statistic  
Gerber Statistic Portfolio Optimization.pdf

+ [ ] Adapt description of Ultra High-Frequency Data(UHFD) and exchanges from: Brownlees High Frequency Data Management.pdf

+ [ ] using hfreq prices, calculate beta
calculate separate betas using intraday returns and using overnight returns
calculate separate betas using open-to-close returns and using close-to-open overnight returns
test CAPM
Bollerslev High Frequency Market Factors CAPM Model.pdf

+ [ ] Add slides to section High Frequency and Intraday Time Series Data in risk_models.Rnw
use HighFreq package slides from 2015 presentations RFinance_2015.Rnw and EARL_Boston_2015.Rnw
Running volatility estimation using OHLC data - compare to closing vol
estimate variance of volatility estimator
Volume-Weighted Average Price Indicator
Running regression estimation using OHLC data - compare to closing regression

+ [ ] Develop range OHLC estimators for skewness and kurtosis

+ [ ] Introduce seasonal and trend decomposition  
https://anomaly.io/seasonal-trend-decomposition-in-r

+ [ ] Study Hawkes process as model for asset returns with decaying skewness and kurtosis  

+ [ ] Kelly criterion
KellyRatio.R
create charts of random time series of wealth with different expected pv and growth rates
create charts of random time series of ruin
create terminal wealth charts
as function of betting fraction
as function of probability
as function of odds

+ [ ] Kelly in R:
simulate binary betting strategy using "for" loops and/or "apply"
then also simulate using vector functions
which betting fraction maximizes expected terminal wealth? - step-wise
which betting fraction maximizes expected growth rate? - Kelly
calculate SR of binary betting strategy
which betting fraction maximizes SR?

+ [ ] Kelly in R:
calculate utility as function of betting fraction, from empirical time series of returns, 
compare with Kelly from variance alone
include skew and kurtosis

+ [ ] Kelly for negative betting fraction (shorting)
Kelly for betting fraction greater than 1 (leverage)

+ [ ] Kelly proofs:
find optimal betting fraction, assuming you know the future number of wins and losses
find max expected log of wins and losses
extend Kelly formula to higher moments

+ [ ] Shlok Datye: Kelly Criterion and Optimal-f
http://shlok.is/thesis
Shlok Kelly Optimal-f Criteria.pdf
# Kelly Criterion and Optimal-f
https://alphaism.wordpress.com/2012/04/13/testing-kelly-criterion-and-optimal-f-in-r/
Vince Kelly Optimal-f Criteria.pdf

+ [ ] Replace "look_back" and "win_dow" with "inter_val" - deprecated

+ [ ] Demonstrate that positive correlation doesn't translate into similar long-term returns
develop the contrived hypothetical example in: Kinlaw Variance Ratio Correlation Term Structure.pdf  
demonstrate that the term structure of correlation decreases with tenor  
show that correlation depends on time scale, and decreases with shorter time scale  
on short time scales correlation is very small  
on intermediate time scales correlation is greater  
on long time scales correlation is lower  
study Lo and MacKinlay variance ratio test in: 

# lame
http://stackoverflow.com/questions/25340257/how-to-import-fundamentals-for-stocks-by-using-quandl-package
# GICS Sectors data spreadsheet download
http://stackoverflow.com/questions/11339993/getting-stocks-by-industry-via-yahoo-finance
http://www.reddit.com/r/investing/comments/1f6kjt/anyone_know_where_i_can_find_a_data_set_of/
https://www.quantopian.com/posts/creating-an-algorithm-that-uses-fundamental-data
https://www.quantopian.com/posts/using-the-fetcher-with-quandl

# Stock market historical data
http://opendata.stackexchange.com/questions/4116/stock-market-historical-data

# download hfreq data from Quandl
# get Quandl trial license and download VIX S&P futures data ? use WRDS instead

# create lecture slides for:
https://ropensci.org/
https://plot.ly


+ [x] Add forecasting using ARIMA
Backtest forecasting using ARIMA and a simulated AR time series.

+ [x] Downloading data from tiingo
https://www.tiingo.com/
http://blog.fosstrading.com/2018/04/goodbye-google-hello-tiingo.html

+ [x] Calculate constant maturity VIX futures - calculate VIX futures term structure from CBOE settlement data.
https://quantstrattrader.wordpress.com/2017/04/27/creating-a-vix-futures-term-structure-in-r-from-official-cboe-settlement-data/

+ [x] Demonstrate that mixture of two normal distributions has fat tails lepto-kurtosis
Demonstrate that normal mixture model is similar to Student's t-distribution.

+ [x] Add slide about VIX crash on February 5th 2018

+ [x] Introduce SVXY short VIX futures ETF

+ [x] Chain futures data

+ [x] Add package iBrokers to thematic slides file data_management.Rnw

+ [x] Add package data.table to thematic slides file data_management.Rnw

+ [x] Principal component regression PCR

+ [x] Explain how to create pairs and portfolios in Interactive Brokers
https://www.interactivebrokers.com/en/index.php?f=744

+ [x] Calculate coefficients of multiple linear regression using function solve()

+ [x] Add formula for slope of tangency portfolio using derivative of efficient frontier.
Compute tangency portfolio in two different ways: from derivative of efficient frontier, and from Sharpe portfolio weights.

+ [x] Calculate the efficient frontier under sum of weights constraint using matrix algebra in two steps:
Calculate the minimum variance portfolio
Calculate the minimum variance portfolio under the constraint that it has a fixed target return
Demonstrate that efficient frontier is a parabola in sigma-squared-mu space
Demonstrate that efficient frontier is a hyperbola in sigma-mu space

+ [x] Demonstrate that the PCA with the smallest eigenvalue is the minimum variance portfolio

+ [x] Demonstrate that GARCH model returns have excess kurtosis, and fit them into t-distribution

+ [x] Perform Principal Component Analysis PCA by hand using optimization
update time_series_multivariate.Rnw

+ [x] Simulate Ornstein-Uhlenbeck OU process using Rcpp

+ [x] Demonstrate that a combination of momentum and static buy-and-hold strategies produces a better Sharpe ratio than the individual strategies alone

+ [x] Create slides for improved version of Performing Overlapping Aggregations in investment_strategies.Rnw

+ [x] Create shiny interactive plot of EWMA strategy 

+ [x] Demonstrate that returns of trend-following and mean-reverting strategies are negatively correlated
demonstrate that a combination of trend-following and mean-reverting strategies has better Sharpe ratio than the individual strategies

+ [x] Create shiny for two EWMA strategy, with performance in output

+ [x] Add slide for shiny plots

+ [x] Create shiny for EWMA model and assign it as homework

+ [x] Simulate geometric Brownian motion

+ [x] Add slide for markdown and knitr documents containing interactive charts
Use blog web pages.

+ [x] Explain, summarize, and benchmark rolling functions over endpoints:
rollapply
apply.rolling
period.apply
period.sum

+ [x] Demonstrate that squared returns are autocorrelated, but squared ranges are not autocorrelated  

+ [x] Robust measures of centrality, dispersion, and skewness MAD

+ [x] OHLC variance estimators  

+ [x] Explain why range variance estimators have bias and they underestimate variance

+ [x] Explain the effect of aggregation frequency and observation (measurement) units on the time scaling of variance  

+ [x] Create dygraphs slides for time series

+ [x] Create package fin_engine, a clone of GARPFRM package  

+ [x] Change start_points in time_series_univariate: make it consistent with HighFreq::roll_apply(): win_dow is the size of the lookback window, equal to the number of data points used for applying the aggregation function (including the current point)  
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))]
instead of:
start_points <-  end_points[c(rep_len(1, win_dow), 1:(len_gth-win_dow))] + 1

+ [x] Review Optimal Mean Reversion Trading: mostly math from his papers  
Redemption Code:	F3P8XXBB7SKVXFZNX6KP
https://bookshelf.vitalsource.com/#/books/9789814725934/cfi/6/2!/4/2/2@0:66.1

+ [x] Convert all code from nrow() and ncol() to NROW() and NCOL()  

+ [x] update ETF list and etf_data.Rdata

+ [x] hw/test: eapply over hypothesis tests 

+ [x] Create package rutils: Utility Functions for Financial Data Management and Modeling

+ [x] Downloading S&P500 stock price data with R
https://grollchristian.wordpress.com/2013/08/07/sp500-stock-price-data/

+ [x] Stock index constituents and meta-data  
https://www.quandl.com/blog/useful-lists

+ [x] Download data for all S&P500 stocks from Quandl
Quandl API Key:	pUJi9Mv3V9CD3Js5s7Rx
https://www.quandl.com/blog/quandl-launches-intraday-data-2

+ [x] update HighFreq package


### deprecated

+ [ ] Adapt Rcpp C++ code from package RcppRoll by Kevin Ushey - doesn't use RcppArmadillo
Install the package RcppRoll as follows:
install.packages("RcppRoll")
https://cran.r-project.org/web/packages/RcppRoll/index.html
https://github.com/kevinushey/RcppRoll

+ [ ] Adapt Rcpp C++ code from package RcppMovStat - very basic, doesn't use RcppArmadillo
https://github.com/peleonard/RcppMovStat




###############
### homework topics existing best

# ask students to fix code that has been corrupted with a bug - take large chunks of good code and corrupt it with a bug
For example:
Download from Interactive Brokers daily historical data for expired VIX futures, starting with the July 2017 contract, through August 2018.
Load VIX time series data from csv files into an environment.
Chain together VIX futures prices in a loop.
Calculate a vector of constant maturity VIX futures prices in a loop.

# Summary: Perform a rolling portfolio optimization 
# over annual intervals, calculate optimized portfolio 
# weights in each year, and apply them to out-of-sample 
# returns in the following year.

# Summary: Backtest a rolling portfolio optimization strategy 
# using the regularized inverse of the covariance matrix.

# Summary: Backtest an AR(p) model for forecasting the trading volumes. 

# Summary: Coerce the time indices of all the xts series 
# in an environment, from class POSIXct to class Date.

# Summary: Calculate efficient portfolios with the 
# lowest variance given a fixed target return.

# Summary: Create a function which calculates the rolling 
# variance of an xts series over a look-back interval using Rcpp.

# Summary: Create a function which calculates the rolling 
# weighted sum of an xts series over a look-back interval,
# using RcppArmadillo.

# Calculate the maximum Sharpe ratio portfolio weights

# Summary: Calculate the standard errors of the Yang-Zhang 
# and the close-to-close variance estimators using bootstrap 
# simulation.

# Summary: Create an Rcpp function which simulates 
# the GARCH model using Rcpp.

# Calculate the CVaR minimum portfolio weights using 
# linear programming and function Rglpk::Rglpk_solve_LP().

# Summary: Create a function which simulates an EWMA 
# trading strategy based on two EWMA averages.

# Summary: Calculate the number of trades in an 
# EWMA strategy, and plot the number of trades as 
# a function of the lambda decay parameter.

# Simulate a long-short trading strategy based on two VWAPs
number of trades
winners losers
success rate
fix data snooping

# Summary: Identify bad data in a time series using 
# a Hampel median filter.  Optimize the filter parameters 

# Summary: Calculate the maximum drawdown of a time series.

# Summary: Create a function called lm_r(), which performs 
# regularized multivariate regression and returns a matrix 
# of regression coefficients, their standard errors, t-values, 
# and p-values.

# Summary: Calculate the eigenvectors and eigenvalues
# of the covariance matrix of returns as a function of 
# the number of time periods using RcppArmadillo.

# Summary: Calculate performance of random sub-portfolios
# of S&P500 constituent stocks.

# Summary: Combine data for the S&P500 constituents,
# and stitch the newer data to the older data.

## backtesting models

# Summary: Perform multiple back-tests of momentum strategies 

# Optimize the weights and find the maximum Sharpe 
# for a portfolio with and without the VWAP strategy. 

# Summary: Calculate the betas for a list of ETFs.
# Calculate the beta convexity (skew) as the difference 
# between bull-market and bear-market betas.

# Summary: calculate a matrix of the best performing ETFs
# in each year.  Create a scatterplot of alphas for the
# years 2008 and 2009.

# Summary: Fit t-distributions with different degrees 
# of freedom into VTI returns.

# Summary: Select recurring times of day from OHLC time series 
# bar data without using the "T notation".

# Summary: Perform interval aggregations on an OHLC time 
# series, to obtain an OHLC series with lower periodicity, 
# similar to function to.period() from package xts, or 
# function to_period() from package rutils.

# Summary: Calculate the total yearly trading volumes 
# of HighFreq::SPY, and plot it with custom axis.

# Perform an sapply() loop to calculate a named vector 
# containing the number of NA values in the columns
# of rutils::etf_env$re_turns.

# Summary: Remove extreme returns from a time series,
# and plot the cumulative returns.

# Summary: Identify the dates with extreme returns.

# Summary: Create a function called end_marks() which
# calculates the end points of an xts series, similar
# to the function endpoints() from package xts.

# Summary: List the class and dimension attributes 
# of objects in the environment rutils::etf_env.


###############
### homework and test ideas

+ [ ] grep etf_list
# Find Switzerland ETFs
sym_bols <- etf_list[grep("Switz*", etf_list$Name), ]
# Find Sector ETFs but only Equity
sector_etfs <- etf_list[grep("Sect*", etf_list$Name), ]
sector_etfs <- sector_etfs[grep("Equity*", sector_etfs$Fund.Type), ]



+ [ ] Read the RData file sp500.RData, and write all the time series into separate CSV files using function data.table::fwrite()
dir_name <- "C:/Develop/R/lecture_slides/data/SP500/"
load("C:/Develop/R/lecture_slides/data/sp500.RData")
file_names <- eapply(env_sp500, function(x) {
  file_name <- rutils::get_name(colnames(x)[1])
  data.table::fwrite(data.table::as.data.table(x), file=paste0(dir_name, file_name, ".csv"))
  file_name
})
names(file_names)

+ [ ] Perform rolling portfolio optimization strategy from investment_strategies
Create function.
Multi-plot with vector of look-back parameters.
Find best endpoints and look-back parameters.
Calculate the time series of strategy market beta.
Calculate skew and perform market timing tests.
Plot distribution of returns.
Apply shrinkage and find best alpha.

+ [ ] Backtest a minimum variance portfolio strategy and create a shiny with two parameters: look-back interval and shrinkage intensity
+ [ ] Perform rolling minimum variance strategy for S&P500 portfolio
+ [ ] Create a rolling portfolio optimization strategy for minimum variance using HighFreq::roll_portf()
+ [ ] Calculate the maximum Sharpe and the minimum variance portfolio weights from the regularized inverse of the covariance matrix, in R and in RcppArmadillo
calculate the maximum Sharpe ratio portfolio weights - adapt sharpe_weights()


+ [ ] Create app_roll_portf4.R for rolling portfolio optimization strategy using HighFreq::roll_portf(), and apply it to S&P500 portfolio

+ [ ] Modify the shiny app app_roll_portf2.R to make it look like app_roll_portf3.R
Add input for end points Interval: 
column(width=4, selectInput("inter_val", label="End points Interval", choices=c("weeks", "months", "years"), selected="months")),

+ [ ] Create kitchen-sink multi-factor ARIMA model with a design matrix from multiple indicators: EWMA with different lambdas, volatilities, etc.
Apply shrinkage to the ARIMA calibration (regression) and calculate the one-step-ahead forecasts and their standard errors.
Use ARIMA model without intercept.

+ [ ] Calibrate ARIMA model over rolling look-backs, using matrix algebra, calculate standard errors
Demonstrate that standard errors increase with more ARIMA parameters and shorter look-back interval.

+ [ ] Backtest a strategy which uses the standard error of the one-step-ahead regression forecast: use z-score as forecast

+ [ ] Backtest a rolling portfolio optimization strategy with Lasso shrinkage using DEoptim over monthly endpoints
Use subset of S&P500 stocks and use as reference their average.
Create shiny.

+ [ ] Backtest a momentum portfolio strategy for beta convexity and create a shiny with two parameters: look-back interval and shrinkage intensity

+ [x] Create a function called lm_r(), which performs regularized multivariate regression and returns a matrix of regression coefficients, their standard errors, t-values, and p-values.

+ [ ] Replicate function sim_ou_rcpp() using RcppArmadillo - hint: adapt code from sim_arima.cpp

+ [ ] Calculate VIX futures term structure for several dates, and perform PCA
https://quantstrattrader.wordpress.com/2017/04/27/creating-a-vix-futures-term-structure-in-r-from-official-cboe-settlement-data/

+ [ ] Simulate an investment strategy which ramps up its notional based on the trailing performance of a portfolio manager.  
Imagine a portfolio manager with no skill, whose returns are binary, with a 50% probability of earning one dollar, and a 50% probability of losing one dollar.
Imagine an investor who follows a conservative strategy of increasing (doubling) his invested capital after each positive return.  
The investor withdraws all his capital after after a single loss.
Demonstrate that the investor returns have negative skew, because small gains are always followedd by a large loss.

+ [ ] Write and read time series from csv files, directly using write.table() and read.table(), instead of write.zoo() and read.zoo()

+ [ ] Load ETF time series from XLS files, with badly formatted dates: first save data down to CSV files, and adapt code from utility_scripts.R

+ [x] Backtest an AR(p) model for forecasting the trading volumes.

+ [x] Calculate the betas for a list of ETFs
Calculate the beta convexity (skew) as the difference between bull-market and bear-market betas.

+ [x] Load VIX time series data from csv files into an environment

+ [x] Chain together VIX futures prices in a loop

+ [x] Load VIX time series data from csv files into an environment

+ [x] Download from Interactive Brokers daily historical data for expired VIX futures, starting with the July 2017 contract, through August 2018.

+ [x] Create a function which simulates an ARIMA process in RcppArmadillo

+ [ ] Create a function which calculates the rolling variance of an xts series over a look-back interval using Rcpp 

+ [ ] Create a function which calculates the rolling weighted sum of an xts series over a look-back interval using RcppArmadillo

+ [ ] Create a function which calibrates Ornstein-Uhlenbeck process using regression, calculates t-values, and returns a matrix of calibrated parameters and their t-values

+ [ ] Create shiny app for Ornstein-Uhlenbeck process
simulate multiple OU, to demonstrate how the paths change as the strength of mean reversion is increased

+ [ ] Demonstrate that for the log-normal distribution, the standard error of the higher moments increases relative to their value (higher moments are increasingly noisy)
Perform bootstrap in parallel to estimate the standard errors.
Therefore higher moments are not well suited for forecasting.

+ [ ] Demonstrate that performing PCA on unscaled variables produces very large loadings for variables with high variance, and creates over-dependence of principal components on variables with high variance
https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/

+ [ ] Modify function back_test():
return list with performance stats: Sharpe, number of trades, trading volume ?
compare speed when weights aren't returned

+ [ ] Perform loop in parallel to run back_test() over vector of look-back intervals and calculate matrix of performance stats: Sharpe, number of trades, trading volume

+ [ ] Simulate multiple momentum strategies for S&P500, with different wid_th parameters to calculate past returns, but use the same rolling variance
create shiny Rmd file

+ [ ] Demonstrate that maximum Sharpe portfolio weights obtained from inverse matrix are equal to weights obtained from optimization using quadprog::solve.QP() or optim()

+ [ ] For S&P500 portfolio, find using quadprog: minimum variance, maximum returns, with weights between -1 and 1, sum equal to 1

+ [ ] Create acf function that calculates acf for vector of lags in sapply() loop, and plots the acf plot

+ [ ] Calculate EWMA variance using Rcpp based on slide for calculating weighted rolling sum in numerical_analysis.Rnw

+ [ ] Calculate EWMA variance using filter() and sapply()
microbenchmark with roll::roll_var()

+ [ ] Calculate volatility, skew, and kurtosis over non-overlapping intervals
create scatterplot of skew or kurtosis as function of volatility
show that in periods of high volatility the kurtosis is lower

+ [ ] Download some data using getSymbols() using a limited time range, and save in Rmd and CSV files
Then download more data using getSymbols(), read the data from the files, and combine the two using rbind in a loop and mget().

+ [ ] Calculate the standard errors of all the different TTR variance estimators using parallel bootstrap
meth_ods <- c("close", "garman.klass", "rogers.satchell", "gk.yz", "yang.zhang")
boot_strap <- sapply(1:100, function(x) {
# create random OHLC
  oh_lc <- HighFreq::random_ohlc()
# calculate variance estimates
  sapply(meth_ods, function(meth_od) {
    sqrt((6.5*60)*mean(na.omit(TTR::volatility(oh_lc, N=1, calc=meth_od))^2))
  })  # end sapply
})  # end sapply

+ [ ] Read the giant data frame in the file sp500_ohlc_prices_permno.csv using data.table::fread()
sp500_ohlc_prices <- read.csv("C:/Develop/data/WRDS/sp500_ohlc_prices_permno.csv", header=TRUE, stringsAsFactors=FALSE)
save(sp500_ohlc_prices, file="C:/Develop/data/WRDS/sp500_ohlc_prices.Rdata")
Perform the map/reduce (split-apply-combine) procedure to convert the data frame into multiple xts series, in an environment.
Save the xts series into individual csv files in a directory.

+ [ ] Define end points over equally spaced business days (rows of data), with a stub interval either at the end or at the beginning

+ [ ] Define end points over equally spaced calendar days, with a given start date and end date (different from the start and end of the data), with a stub interval either at the end or at the beginning

+ [ ] Perform backtest of strategy which rebalances at every point (without endpoints), using only vectorized functions

+ [ ] Perform backtest of strategy which chooses best and worst performing ETFs based on their Sharpe ratios 
scale weights so that strategy volatility is constant

+ [ ] Read csv file with S&P500 constituents and calculate pivot tables by GICS Sector and GICS Sub Industry
sp500_Yahoo 04-02-16.csv

+ [ ] Calculate the probability of obtaining 80 heads in 100 tosses for a biased coin with 60% heads and 40% tails  
Use binomial function, and also use approximation using normal function.

+ [ ] Brownian bridge puzzle: given a deck of 52 cards, every time you randomly choose a red card you're account increases by $1, but if you choose a black card you're account decreases by -$1
At any point you can choose to continue playing, or to stop and keep your net wins.
The optimal strategy is to stop playing if the current net wins are greater than the expected value of wins from continuing to play.
Calculate the expected value of the optimal strategy, assuming you start with zero in your account.
This puzzle is a free boundary problem related to Brownian bridges:
http://puzzles.nigelcoldwell.co.uk/fourteen.htm
https://math.stackexchange.com/questions/380571/a-boundary-crossing-result-for-discrete-brownian-bridge
https://math.stackexchange.com/questions/638846/running-maximum-for-geometric-brownian-motion
https://math.stackexchange.com/questions/515162/brownian-bridge-distribution-sup-a-leq-u-leq-b-fracw0u-sqrtu1
Law of the iterated logarithm
https://en.wikipedia.org/wiki/Law_of_the_iterated_logarithm
# Solution code using recursive function in R:
stra_tegy <- function(cash, positive, negative) {
  # cat(paste("args=", cash, positive, negative, "\n"))
  pro_b <- positive/(positive + negative)
  if (positive==0)
    max(cash, 0)
  else if (negative==0)
    max(cash + positive, 0)
  else
    max(cash, 
        pro_b*stra_tegy(cash+1, positive-1, negative) + 
          (1-pro_b)*stra_tegy(cash-1, positive, negative-1))
}  #end stra_tegy
stra_tegy(0, 3, 3)
stra_tegy(0, 5, 5)
# Solution code using loops in R:
n_pos <- 26
stra_tegy <- outer(n_pos:0, n_pos:0, function(positive, negative) 
  (negative - positive))
stra_tegy[, n_pos+1] <- 0
stra_tegy[n_pos+1, ] <- n_pos:0
prob_s <- outer(n_pos:0, n_pos:0, function(positive, negative) 
  positive/(positive + negative))
prob_s[, n_pos+1] <- 0
for (i in n_pos:1) {
  for (j in n_pos:1) 
    stra_tegy[i, j] <- max(stra_tegy[i, j], 
                           prob_s[i, j]*stra_tegy[i+1, j] + (1-prob_s[i, j])*stra_tegy[i, j+1])
  for (j in n_pos:1) 
    stra_tegy[j, i] <- max(stra_tegy[j, i], 
                           prob_s[j, i]*stra_tegy[j+1, i] + (1-prob_s[j, i])*stra_tegy[j, i+1])
}  # end for
stra_tegy[1, 1]

+ [ ] Calculate the frequency distribution of the maximum value of a Brownian bridge process
http://risklatte.com/Articles/QuantitativeFinance/QF176.php
Brownian bridge process can describe the price of a risk-free bond as it approaches maturity.
https://quant.stackexchange.com/questions/10960/usage-of-brownian-bridge
https://quant.stackexchange.com/questions/31036/brownian-bridge-density-and-risk-neutral-density-for-derivative-pricing
https://quant.stackexchange.com/questions/10960/usage-of-brownian-bridge

+ [ ] Create plot of Market portfolio weights as a function of the risk free rate  
Create plot of the returns and standard deviation of the Market portfolio as a function of the risk free rate.
Demonstrate that the Market portfolio depends on the risk free rate: higher risk free rate forces higher standard deviation.
Demonstrate that for larger risk-free rates, the market portfolio is more highly levered, with a smaller weight for bonds  

+ [ ] update: create plot with multiple Capital Market Lines (CML) and Market Portfolios

+ [ ] Calculate and plot the efficient frontier using the quadprog package
http://blog.streeteye.com/blog/2012/01/portfolio-optimization-and-efficient-frontiers-in-r

+ [ ] Create shiny app for efficient frontier, with inputs for risk_free, correlation, and individual asset returns  

+ [ ] Create estimator of price curvature (second derivative), and repeat all the tasks for the estimator of slope (returns)
Demonstrate that the noise level has an even greater effect.

+ [ ] Demonstrate that long-term returns are dominated by the tails of the return distribution:
calculate wealth of S&P 500 Index if investor avoids the 10 worst trading days, or misses best trading days.

+ [ ] Calculate the number of years of data needed to select the best manager, with 95% confidence, as function of excess Sharpe ratio
adapt from select_manager.R and select_manager.Rmd
plot with plotly

+ [ ] Provide trading strategy code with data snooping, and ask students to fix it

+ [ ] Add transaction costs to simu_ewma()

+ [ ] Create random OHLC data and pass it through EWMA strategy to test for data snooping

+ [x] Simulate rolling portfolio optimization strategy using regularized inverse 
Calculate the corresponding maximum Sharpe and the minimum variance portfolio weights, in R and in RcppArmadillo.
Create a shiny app in an R file.

+ [x] Combine data for the S&P500 constituents, and stitch the newer data to the older data

+ [x] Calculate the standard errors of the Yang-Zhang and the close-to-close variance estimators using bootstrap simulation
Demonstrate that the Yang-Zhang estimator has much smaller standard error than the standard close-to-close variance estimator.
Calculate the standard errors of both variance estimators by bootstrapping minutely SPY prices.

+ [x] Simulate many ARIMAs with increasing coefficients to 1, and calculate a vector of ADF statistics - already in lecture notes

+ [x] Use filter() to simulate an ARIMA and its integrated series - already in lecture notes

+ [x] Rework in RcppArmadillo the code on slide titled Eigenvalues of the Covariance Matrix

+ [x] Simulate Ornstein-Uhlenbeck process using Rcpp
solution is rcpp_ou.cpp

+ [x] Calculate the time series of the index price from the components from the S&P index data in file sp500.RData
select ten equal dollar-weighted random sub-portfolios from the S&P index data in file sp500.RData
for the end of each year, calculate the percentage of sub-portfolios that underperform the index average

+ [x] Simulate GARCH model using Rcpp, for a grid of alpha and beta parameters
Calculate kurtosis and plot heatmap of kurtosis.
Find alpha and beta parameters that produce biggest kurtosis.
Calculate Jarque-Bera test statistic, and the p-value.
Plot heatmap of Jarque-Bera test statistic.

+ [x] Simulate GARCH model using Rcpp

+ [x] Fit t-distributions with different degrees of freedom into VTI returns
Also fit other distributions, like normal or cauchy distributions.
Calculate the Kolmogorov-Smirnov and Chi-squared test statistics for the fitted distributions and find which fits best.
Find which value of degree of freedom provides best fit, based on goodness of fit tests.

+ [x] Calculate list of dates with extreme returns either above +3% or below -3% for all EuStockMarkets columns
Remove extreme returns from DAX returns, and calculate the cumulative DAX returns.
Coerce DAX EuStockMarkets into xts and plot it using dygraphs.

+ [x] Calculate backtest performance as function of meta-parameters: look-back interval
optimize meta-parameters

+ [x] Create functional which performs backtest 
arguments: time series of past_rets and fwd_rets, 
output: time series of backtest returns

+ [x] Create functional which performs look-back and look-forward aggregations using single lapply() loop
arguments: agg_fun=sum, re_turns, end_points?, look_back, re_balance,
output: time series of past_rets and fwd_rets

+ [x] Calculate time series of model returns using parallel parLapply()

+ [ ] Calculate correlation matrix of returns from ensemble of EWMA strategies

+ [ ] Create data frame with latest fundamental data for S&P500 companies from usfundamentals data

+ [ ] Create time series of fundamental data for MSFT from usfundamentals data

+ [ ] Create time series of S&P500 stock fundamental data since 2011, using data files from Linelane
C:\Develop\data\usfundamentals

+ [ ] Create R Markdown document containing dygraphs and plotly plots

+ [ ] Perform non-overlapping aggregations using roll_agg(): volume, volatility, regress - already assigned ?

+ [x] Download U.S. stock fundamental data from Linelane, based on reports submitted to EDGAR SEC
http://usfundamentals.com/
https://www.reddit.com/user/usfundamentals
C:\Develop\data\usfundamentals
https://www.reddit.com/r/investing/comments/4qxjr6/ive_processed_1tb_of_secs_data_to_extract/

+ [ ] load BRK-B, BF-B, and a few other stocks into existing environment object, without reloading stocks already the environment
provide students with existing environment object

+ [ ] Calculate cap-weighted sub-portfolios for industry, size, and quality sub-portfolios for the S&P500 stocks
calculate monthly performance tables and rank the industries
determine if the rankings are persistent (autocorrelated) or not

+ [ ] Create cap-weighted, price-weighted, and equal-market-value-weighted portfolios
rebalance weekly the equal-market-value-weighted portfolio
calculate the PnL from the rebalancings

+ [ ] Rebalance monthly two-asset portfolio to maintain: equal market value weights, equal risk weights  
make sure to rebalance on the last workday of every month  

+ [ ] Subtract two lagged columns of OHLC time series by using as.vector()
jump_s[which_periods] <- as.vector(oh_lc[which_periods, 1]) - as.vector(oh_lc[which_periods-1, 4])

+ [ ] Recreate function remove_jumps() to remove overnight close-to-open jumps from OHLC  

+ [ ] Find the minimum volatility portfolio, loop over volatility and find maximum return portfolios (that's efficient frontier), and plot the efficient frontier  

+ [ ] what is CAPM alpha of VWAP strategy?
where is VWAP strategy on CAPM scatterplot?
draw the Efficient Frontier
Is it possible to combine SPY with VWAP strategy to achieve higher Sharpe than either of them alone?

+ [x] Create functional which performs overlapping aggregations using lapply()
roll the function simu_ewma() over overlapping windows, and collect statistics
find optimal parameters and apply them out-of-sample

+ [x] Create shiny for simu_ewma() trading an Ornstein-Uhlenbeck process

+ [x] Trade an Ornstein-Uhlenbeck process using simu_ewma()

+ [x] loop over correlations in two-asset portfolio, find maximum Sharpe, and plot efficient frontiers in different colors  

+ [x] Calculate number of trades in EWMA strategy as function of lambda decay parameter, and create shiny

+ [x] Create function for trading strategy with two EWMA, and plot prices with two EWMA plus shading

+ [x] Create shiny for two EWMA strategy, with two sliders and also input for window size

+ [x] Perform aggregations over OHLC to reproduce function to_period() from package rutils  

+ [x] Calculate volatility estimates using all the different "calc" methods in function volatility() from package TTR  

+ [x] Calculate daily close-to-open volatility and open-to-close volatility

+ [ ] Recursively rbind() a list of objects, such as xts time series - reproduce do_call_rbind()

+ [x] Convert the date and time to different time zones  

+ [x] Create a vector of dates that are the last workdays of every month  

+ [ ] Calculate standard deviation, skewness, and kurtosis of SPY returns in each year using sapply loop  
plot histograms of returns in each year in panels

+ [ ] Calculate SPY moments in each month, in each year, 

+ [ ] Benchmark runmed with runquantile and runMedian
benchmark TTR::runMAD() with caTools::runmad()

+ [ ] Calculate standard errors of variance estimators using bootstrap - parallel version

+ [ ] Reproduce function melt() from package reshape2
http://stackoverflow.com/questions/3777174/plotting-two-variables-as-lines-using-ggplot2-on-the-same-graph
http://www.wekaleamstudios.co.uk/posts/melt/

+ [ ] Calculate rolling/sliding volatility
regress against volume
regress levels and changes in levels at different horizons
extract stats into vector
perform sapply over window size and agg horizons
select different market regimes

+ [ ] Explain Sharpe ratio as a t-statistic
simulate Sharpe ratios
create distribution of Sharpe ratios

+ [ ] Create function that performs hypothesis testing in a loop over parameters
create wrapper function for hypothesis testing functions

+ [x] Calculate data frame of hypothesis test statistics for returns data
sapply over sym_bols and extract:
Shapiro-Wilk Test of Normality
Jarque-Bera Test of Normality
sort by most/least normal
save to comma-delimited CSV file

+ [ ] Calculate data frame of perf stats for price data and
create data frame
save to comma-delimited CSV file
use table.Stats()
sd, MAD, skew, kurt, alpha, beta, max drawdown, 

+ [ ] Expand code from slide:
Downloading Time Series Data Using Package quantmod

+ [ ] Extract "Adjusted" and "Volume" columns
etf_series_ad <- do.call(merge, 
                  eapply(env_data, Ad)[sym_bols])

plot with quantmod
chartSeries(blah, theme=chartTheme("white"))
chart_Series(blah, name="SPY")


+ [ ] Reading and Writing data frame or xts Series With Date-time Index from txt and csv files


+ [ ] Idea for homework:
modify get.hist.quote to download from any URL
add extra argument for URL, with default:
http://ichart.yahoo.com/table.csv


+ [ ] Idea for homework:
provide list of tickers
tickers for Asset Allocation exercises
sym_bols <- c("VTI", "VEU", "IEF", "VNQ", "DBC", "XLY", "XLP", "XLE", "XLF", "XLV", "XLI", "XLB", "XLK", "XLU", "IWB", "IWD", "IWF", "IWM", "IWN", "IWO", "IWP", "IWR", "IWS", "IWV", "IWW", "IWZ")

? download descriptive data ticker (name, industry, sector, etc.)
? format data frame of descriptive data: columns and rows

read etf database file called "etf_list.csv" into data frame called "etf_list", using "read.csv"
subset etf_list to include only those ETF's in sym_bols, using "%in%" operator

create a data directory on your computer, and save all files to that directory 
remember the location of that data directory for future use
? save description data to CSV file


? using description data frame

download 10yrs of data for list of sym_bols, and call it "zoo_series"
Use get.hist.quote() and lapply() loop,
For each sym_bol download fields "AdjClose" and "Volume",
the zoo_series data lapply returned is a list - each list element is a zoo object,
assign names() attribute to zoo_series, equal to sym_bols vector - result should be named list,

flatten zoo_series into a single zoo object, using do.call() and merge(),
assign new names() to zoo_series, in the format "XLI.Close", "XLI.Volume", etc.
Use sapply() and paste(),



###############
## save data for future load

save(env_data, sym_bols, etf_series_ad, etf_rets, etf_list, ret_stats, etf_perf_stats, file='etf_data.Rdata')

save(
maxSR_DEOpt, maxSR_DEOpt_xts, maxSR_ROI, maxSRN_DEOpt, maxSRN_DEOpt_xts,
maxSTARR_DEOpt, maxSTARR_DEOpt_xts, maxSTARR_RP, minES_ROI, minES_ROI_xts,
plot_portf, portf_init, portf_maxSR, portf_maxSRN, portf_maxSTARR,
portf_minES, portf_names, risk_ret_points,
weights_1h, weights_2h,
period_stats, pnl_xts,
file="C:/Develop/data/portf_optim.Rdata")

###############
# end save data for future load



###

# Dupoyet High Frequency Self Organizing Critical Markets

# use of systematic investor part 1.r
http://timelyportfolio.blogspot.com/2012/02/simplified-example-of-systematic.html
https://gist.github.com/timelyportfolio/1793607


# Yahoo explains its data
https://help.yahoo.com/kb/finance/historical-prices-sln2311.html


########################
### emails announcements

# Next Spring the portfolio course will be extremely interesting, since I will add even more topics on trading via the API of Interactive Brokers.

# I would be very happy to have you as a student.
I am teaching in the Spring semester 2019 two very interesting courses:
FRE-6871 R in Finance
FRE-7241 Algorithmic Portfolio Management

# grading policies
The problem with applying such a fixed scale to translate numerical scores into letter grades is that it doesn't take into account the difficulty of the assignments, which may differ between courses.
In the case of this class (FRE7241), I have made it easier by providing test outlines several days in advance.  As a result most students received almost perfect scores, but you didn't.
In the first lecture, on the slide titled "Course Grading Policies" I explained that:
Very high numerical scores close to the maximum won’t guarantee an A letter grade, since grading will also depend on the difficulty of the assignments.

# Attached is the outline file for test #2. 
The outline file contains only some of the assignments for test #2.  It is designed to help you prepare for the test.
The actual file for test #2 will contain some additional (extra) assignments. 
You don't need to submit (upload) the outline file.  Please finish the assignments in the outline file, and have it ready for the test.  

## jobs
Marto Capital is looking for an intern to help in developing risk parity and alpha strategies.  The strategies can invest in interest rate futures, bonds, currencies, and commodities, and they depend on macroeconomic data such as inflation, GDP growth rates, etc.
The job requires knowledge of econometrics, financial markets, and R programming.

Please contact Michael Marco, Director of Research, at:
michael.marco@martocapital.com

##

Please change your default settings in Linkedin so that you receive alerts for new postings.

##

For FRE-7241 Algorithmic Portfolio Management I need a grader.  The GA's responsibilities will be grading and answering student questions during office hours.
Preference is for student who has already taken FRE-7241 or FRE-6871, or who has strong R programming skills.

Dear Students,
Welcome to FRE7241 Algorithmic Portfolio Management Spring 2019 second half.  
Please see attached the syllabus.  
I uploaded the syllabus to NYU Classes. 
I'm glad to see that so many students have registered for this course.  
This course will be focused on the applications of the R language to computer-driven investment, and will require extensive coding (programming).  So students should have some programming experience with the R language and with other languages such as C++ or Python.  Therefore I highly recommend that you also take FRE6871 R in Finance, which is an introduction to the R language.  On the positive side, the programming assignments will mostly involve modifying code from the lecture notes.  So students don't have to be programming experts, provided they allocate enough time to study the lecture notes in great detail.
But many students find this course to be difficult, especially those without programming experience.  The R language is considered to be challenging, so students should have programming experience with the R language and with other languages such as C++ or Python.  
I highly recommend that you also take this semester the C++ courses by professor Song Tang (FRE6883, FRE7831) and the ML course by professor Igor Halperin (FRE9733).

Dear Students,
I uploaded an improved IB script for paper trading through Interactive Brokers using package IBrokers.
It's a simple and naive market-making strategy using limit orders.  It's designed to illustrate how the package IBrokers can be used for trading.  It can be used to study the risks of market-making.  You can also modify it and improve it.  Please let me know if you have questions, or if you would like to share your progress.

Dear Students,
You don't need to worry that you will be required to write extensive C++ code for FRE7241.  The whole point of the course is to demonstrate how to write concise code in R and high-level C++ libraries to produce powerful analysis.  So the C++ code you will be writing will be around a dozen lines for each exercise.  Besides, you will mostly be required to adapt and modify existing C++ code, not to write it from scratch.  And the C++ code will be mostly using higher-level libraries, like Armadillo:
http://arma.sourceforge.net/
You can take the FRE6871 and FRE7241 courses concurrently, but that will be a heavy workload.  It would be better to take FRE6871 in the Spring and FRE7241 in the Fall.

Dear Students,
I encourage you to start studying R before the course begins.  For this purpose I have uploaded the following materials to NYU Classes:

FRE6871_Lecture_1.pdf	is the introductory lecture from last semester.
data_structures.pdf
expressions.pdf	(skip section "Debugging and Exception Handling")
functions.pdf	(skip section "Object-Oriented Programming in R")
plotting.pdf
R_environment.pdf	(skip section "Running R Scripts and Batch Processes")
data_management.pdf
packages.pdf

Please download all the Resources files from NYU Classes.
The *.pdf files contain the narration text, formulas, and R code. Most slides have narration and formulas on the left panel, and the corresponding R code on the right panel.  You should read the narration and at the same time run the R code in RStudio.  I have also uploaded the corresponding *.R files containing the R code in the lecture slides, so that students can easily execute the code as they read the lecture slides. 

The introductory lecture explains how to install R and RStudio (please re-install the newest versions).  

# deprecated
But I must warn you that many students find this course to be difficult.  The R language is considered to be very challenging, so this course requires strong programming skills and experience.  Students should therefore have extensive programming experience with the R language and other languages such as C++ or Python.  
The course FRE6871 R in Finance is designed as an introduction to R, and to important applications to finance, like building credit scoring models using logistic regression, and pricing options using Monte Carlo simulation.  FRE7241 Algorithmic Portfolio Management is designed as a followup course for teaching applications of R to portfolio management.  I recommend taking these courses either sequentially (first FRE6871 and then FRE7241) or concurrently.
In this course you'll learn how to apply the R programming language to quantitative portfolio management, like volatility forecasting, the Capital Asset Pricing Model (CAPM), portfolio optimization, and active portfolio management strategies.  You'll also learn how to apply machine learning techniques, like model parameter regularization (shrinkage), strategy backtesting (cross-validation), and the bias-variance tradeoff. 
Students with less programming experience are encouraged to first take FRE6871 R in Finance.  Students should also have knowledge of basic statistics (random variables, estimators, hypothesis testing, regression, etc.)

It may be helpful for you to prepare by taking some free online courses: 
http://tryr.codeschool.com/
https://www.datacamp.com/courses/free-introduction-to-r
https://www.datacamp.com/courses/intermediate-r
https://www.datacamp.com/introduction-to-statistics
https://www.datacamp.com/courses/statistical-inference-and-data-analysis
# /deprecated

I uploaded the syllabus and other course materials to NYU Classes.

You may download the previous lecture slides from here:
https://drive.google.com/drive/u/1/folders/0Bxzva1I0t63vVGEtaXNIY1JMa00

Regards,  Jerzy Pawlowski
NYU Tandon, Finance and Risk Engineering

Dear Students,
Below is the link to the survey results for the FRE7241 course.  13 students answered so far, and the feedback is pretty positive.  But one area that still needs improvement are test instructions.

https://www.surveymonkey.com/results/SM-P76ZVKKJ/

## GA

Can you please send a message to all students via NYU Classes announcing that you will be the GA?
Also please ask students for the most convenient time for office hours, and then announce to them when you'll be holding office hours.
Please read the first lecture slides with instructions for grading and submission of assignments.


Dear Students,
I would like to hire two Graduate Assistants for grading my courses: 
FRE-6871 R in Finance
FRE-7241 Algorithmic Portfolio Management

The GA positions require strong programming experience in R.
The jobs are posted on CareerNet, so please apply through CareerNet.
You may also contact Jonnett R Romano (jonnett.romano@nyu.edu).
If you decide to apply for the GAs positions, then please send me your resume to my email.

Best Regards,  Jerzy Pawlowski


## The IB paper trading accounts have been kindly provided by Interactive Brokers to students for this course.  They will allow you to test your trading strategies on live data, in addition to backtesting.
But there seems to be a problem with the market data permissions for the accounts, so you can't download data.  I will ask IB to fix it and I will get back to you next week.


## Google drive

Dear Students,
I uploaded many lecture slides to Google drive:
https://drive.google.com/folderview?id=0Bxzva1I0t63vVGEtaXNIY1JMa00&usp=sharing

I encourage you to study them, and I welcome your questions via NYU Classes forums or in class.


## grading

Dear Students,
As stated in the FRE6871 syllabus: 
"The final course letter grade will be derived from the cumulative scores obtained for all the homeworks and tests."
However, there is no fixed formula for assigning a letter grade from the cumulative score.  Over half of students received letter grades of "A" or "A-", which I think is very generous.

## tests

Dear Students,
Please upload your test file to NYU Classes by 7:00 PM.

Dear Students,
Here are some suggestions that may help you on the tests.

Don't leave assignments unanswered because you won't get partial credit.  At least try to copy some lecture code that makes sense for the assignment.
First, search the lecture code for keywords and function names mentioned in the instructions.
Second, copy lecture code that makes sense for the assignment.
Third, modify that lecture code as best you can.
Fourth, ask for hints from me.

Dear Students,
There will be an in-class test this Tuesday, October 4th.
The test will start at 6:30 PM, and will last 60min until 7:30 PM.
I will upload the test file at 6:30 PM to NYU Classes.
The lecture will start at 6:00 PM, as usual.  
You must bring your laptops and be able to log into WiFi.

The test will be based on lecture notes, so please study the topics below.

In Part I you will be asked to perform the following:
Apply the function filter_prices() from test #3 over overlapping 12-month intervals in the past. 
Define end points at the end of each month using function endpoints() from package xts.
Calculate a time series of trailing 12-month optimal thresholds, and the associated true positive and false positive rates, using function sapply() and an anonymous function.
Calculate the trailing 12-month volatility, defined as the standard deviation of daily returns, using functions sapply() sd(), index(), xts(), and diff_xts() from package rutils.
Plot in multiple panels using the functions chart_Series() and add_TA().
Plot scatterplots using function plot(). 

In Part II you will be asked to perform the following:
Create a function which calculates the volume-weighted average price (VWAP) of an OHLC time series.
The function should return an xts series with a single column containing the VWAP of the adjusted close prices.
You can use functions Ad(), Vo() and roll_sum() (defined in the lecture slides).
You can also use functions paste0(), strsplit(), and colnames(), to change the column name.
You cannot use for() or sapply() loops of any kind.
Calculate the same VWAP using function VWAP() from package TTR. 
Find which elements are significantly different between the two results (absolute difference is greater than 0.01).
Benchmark the speed of of the two functions using function microbenchmark() from package microbenchmark.
Find the crossing points of VWAP with prices, and create plots with background shading, using functions chart_Series() and add_TA().


benchmark it to function VWAP()
# from package TTR, and create plots.


Performing hypothesis tests and extracting test statistics.
Plotting scatterplots of test statistics. 
Performing apply() and sapply() loops over vectors. 
Plotting xts series using chart_Series() from package quantmod. 
Passing arguments to functions through the dots "..." argument of sapply(). 
Sorting data frames on columns.
Saving data frames to comma-delimited CSV files.
Calculating Median Absolute Deviation over a rolling window.
Lagging and advancing time series.
Identifying bad data in a time series using a Hampel median filter.  
http://www.mathworks.com/help/signal/ref/hampel.html
http://dsp.stackexchange.com/questions/26552/what-is-a-hampel-filter-and-how-does-it-work
Identifying type I and type II errors in hypothesis tests. 
Plotting Receiver Operating Characteristic (ROC) curves. 
http://www.joyofdata.de/blog/illustrated-guide-to-roc-and-auc/
Optimizing filter parameters in-sample, and backtesting their performance out-of-sample. 


Formatting dates into months and years. 
Using anonymous functions with apply(). 
Performing apply() and eapply() loops over matrices, data frames, xts series, and environments. 
Extracting objects from environments using get(). 
Flattening lists using do.call() and rbind() or merge().
Calculating equally spaced end points over OHLC time series. 
Performing interval aggregations over OHLC time series.
Plotting with custom "x" axis using plot() and axis(). 

Coercing integers and strings to "POSIXct" date-time objects. 
Converting dates into days of the week. 
Using functions from package lubridate, 
Converting the date and time to different time zones.

Calculating downside deviations, and Sortino and Calmar ratios. 
Defining objective functions for portfolio optimization. 
Performing portfolio optimizations using optim(). 
Plotting scatterplots of random portfolios. 

Searching in strings for sub-strings using grep() and glob2rx(). 
Extracting columns from OHLC data. 
Extracting data from output of function table.Drawdowns(). 
Assigning objects to environments using assign(). 
Invisibly returning values using invisible(). 
Creating functions that produce side effects. 
Subsetting data frames using logical operators. 
Subsetting xts series to specified dates and endpoints. 
Extracting the time index from xts series. 
Converting dates into days of the week. 
Calculating percentage returns from prices. 
Coercing integers and strings to "POSIXct" date-time objects. 

You will need to use the following functions:
coredata(), unname(), shapiro.test(), jarque.bera.test(), sapply(), na.omit(), t(), plot(), text(), order(), write.csv(), TTR::runMedian(), TTR::runMAD(), rutils::lag_xts()

seq(), as.Date(), Sys.Date(), weekdays(), as.POSIXct(), Sys.timezone(), format(), Sys.setenv()

You will need to use the following functions:
format(), as.POSIXct(), names(), unique(), index(), coredata(), get(), sapply(), eapply(), is.xts(), xts(), unlist(), dim(), rbind(), merge(), do.call(), plot(), axis(), to_period() from package rutils, the %in% operator, and anonymous functions


You will need to use the following functions:
apply(), sapply(), SortinoRatio(), CalmarRatio(), optim(), xts(), chart_Series(), seq(), runif().

Ad(), Vo(), assign(), table.Drawdowns(), invisible(), grep(), and glob2rx()
grep(), glob2rx(), Cl(), 
sum(), is.na(), read.csv(), write.csv(), endpoints(), weekdays(), index(), tail(), log(), diff(), which(), which.max(), which.min().


###

Dear Students,
Please create your personal account on Stack Exchange:
http://stackexchange.com/

Please add Stack Overflow as one of your communities on Stack Exchange.


###

Dear Students,
There will be a test this Tuesday, September 11th.  I will upload an outline file with assignments that will help you prepare for the test.

You are required to install packages rutils and HighFreq before the next class this Tuesday.  You will not be able to take the test without those packages.  If you're not able to install those packages then please send me a message via NYU Classes with a Minimal Working Example.

If you're not able to install package rutils, then you can copy directly from the source code of rutils available on github:
https://github.com/algoquant/rutils/blob/master/R/rutils.R

Copy and paste the required rutils functions into your solution code, and call them directly:
diff_xts()
instead of: 
rutils::diff_xts()

You can download the source code of rutils into your local drive, by going into this page:
https://github.com/algoquant/rutils

And then click on the green button on the right that says "clone or download".
Github will download a zip file with a directory structure.  In the data directory there's a file called etf_data.RData.  
You can load etf_data.RData into R using load().

Please download all the Resources files from NYU Classes.

# Dear Students,
Please do not send me personal emails with class questions.
Instead please send questions via NYU Classes.

# Dear Students,
Installing all the required R packages is mandatory.
But we won't be using the packages roll, rutils, and HighFreq in the next few weeks, so you have time to install them later.

# Before the class please install on your laptops R and RStudio: 
http://cran.us.r-project.org
https://www.rstudio.com/products/rstudio/download/
Install only the 64-bit version of R, without the 32-bit version.
Uncheck the box for the 32-bit version!
If you already have a previous R installation, then upgrade R and RStudio to the newest versions.  

Next install only the 64-bit version of Rtools for Windows:
Uncheck the box for the 32-bit version!
Check the box for adding to PATH!
https://cran.r-project.org/bin/windows/Rtools/Rtools33.exe

If you get error messages then first check the system PATH variable to ensure that it contains the directories with R executable and the gcc compiler under Rtools.  If needed edit the PATH variable.  
Under Windowz10 you can edit the PATH variable by going to Control Panel and selecting System:
Control Panel \ System and Security \ System
Next select "Advanced system settings" and then select "Environment Variables".
Click on the tab "Advanced". 
Add or edit the system PATH variable so it contains the directory with the gcc compiler under Rtools.
For example, I have the following path:
C:\Program Files\R\R-3.5.1\bin\x64
C:\Rtools\bin
(But your installation may be different.)

If you have Mac/OSX then install the newest version of Xcode from this website (make sure to install only the 64-bit version of Xcode): 
https://developer.apple.com/xcode/
or
https://cran.r-project.org/bin/macosx/tools/

Next if you have Mac/OSX then install gfortran from this website:
https://gcc.gnu.org/wiki/GFortranBinaries
https://gcc.gnu.org/wiki/GFortran
You can read more about installing Xcode and gfortran here:
https://kingaa.github.io/mac-fortran.html
http://thecoatlessprofessor.com/programming/openmp-in-r-on-os-x/#after-3-4-0

Install the R package devtools using the R command:
install.packages("devtools")

Verify that Rtools is working properly by running these commands in R:
devtools::find_rtools()
devtools::has_devel()

Next install the following R packages: lubridate, microbenchmark, tseries, xts, ggplot2, dygraphs, plotly, animation, shiny, htmltools, knitr, rmarkdown, Rcpp, RcppArmadillo, matrixStats, profvis, ISLR, DEoptim, PerformanceAnalytics, and PortfolioAnalytics.

You can install them using the R command:

install.packages(c("Rcpp", "RcppArmadillo"), type="source")
install.packages(c("lubridate", "microbenchmark", "tseries", "plotly", "animation", "PerformanceAnalytics", "PortfolioAnalytics"))

If any of these packages are not available for the current version of R then install them with type="source".  For example:

install.packages(c("colorspace", "scales", "lazyeval", "plyr", "tibble", "ggplot2"), type="source")
install.packages(c("lmtest", "stringi", "rlang"), type="source")
install.packages(c("data.table", "zoo", "xts", "jsonlite", "dygraphs", "later", "promises", "httpuv", "mime", "rlang", "shiny", "htmltools", "knitr", "rmarkdown", "matrixStats", "profvis", "ISLR", "DEoptim", "PerformanceAnalytics", "PortfolioAnalytics"), type="source")


Next install the packages quantmod and TTR from GitHub as follows:
devtools::install_github(repo="joshuaulrich/quantmod", type="source")
devtools::install_github(repo="joshuaulrich/TTR", type="source")

Next install the packages rutils, HighFreq, and roll from GitHub as follows:
devtools::install_github(repo="algoquant/rutils", type="source")
devtools::install_github(repo="algoquant/HighFreq", type="source")
devtools::install_github(repo="jjf234/roll", type="source")

Next install the packages qmao and twsInstrument:
install.packages("qmao", repos="http://r-forge.r-project.org")
install.packages("twsInstrument", repos="http://r-forge.r-project.org")

Next install quadprog:
devtools::install_github("cran/quadprog", type="source", INSTALL_opts="--merge-multiarch")

Next under Windowz install Rglpk and glpkAPI:
install.packages("Rglpk", type="source", dependencies=TRUE)
install.packages("glpkAPI", type="source")

If you have Mac/OSX then you may need to download glpk first:
http://www.gnu.org/software/glpk/
http://ftp.gnu.org/gnu/glpk/
If you have Mac/OSX then install glpk using Homebrew:
brew install glpk
https://brew.sh/
http://osxdaily.com/2018/03/07/how-install-homebrew-mac-os/
https://www.howtogeek.com/211541/homebrew-for-os-x-easily-installs-desktop-apps-and-terminal-utilities/
# Read more here:
http://arnab-deka.com/posts/2010/02/installing-glpk-on-a-mac/
http://hichenwang.blogspot.com/2011/08/fw-installing-glpk-on-mac.html

Then install Rglpk and glpkAPI:
install.packages("Rglpk", type="source", dependencies=TRUE)
install.packages("glpkAPI", type="source")

# If you have problems with installing packages then please send a request to the GA using NYU Classes and copy me.
Please provide the text or screenshots of error messages.
Specify your operating system, Windows or OSX, and version.
Did these commands produce any errors?

You can read more here:
http://thecoatlessprofessor.com/programming/installing-rtools-for-compiled-code-via-rcpp/

Dear Students,
Installing all the packages, including HighFreq, is a prerequisite for this course, and you can't finish this course without installing all the packages.  
Please send an email request for assistance via NYU Classes to the GA and copy me.  Please include a minimal working example.

If you're having problems installing some R packages, then follow these steps:

Remove your R installation and reinstall only 64-bit R, without 32-bit R.
Reinstall Rtools and make sure it installs the gcc compiler.
Run sessionInfo() and make sure you have installed 64-bit R and 64-bit RTools.

You can read more here:
http://thecoatlessprofessor.com/programming/installing-rtools-for-compiled-code-via-rcpp/


############## deprecated ##############
The reason you're getting the error is that the standard compiler under Mac/OSX doesn't support the OpenMP feature for parallel computing.  Installing GFortran from the link below should solve the problem.
https://gcc.gnu.org/wiki/GFortranBinaries
https://gcc.gnu.org/wiki/GFortran
But you can install a compiler extension that supports the OpenMP feature.  Many Mac/OSX users have struggled with installing compiler extensions for OpenMP, and there are quite a few articles with solutions.  I don't have a Mac, so the best I can do is provide you with the links to articles offering solutions.
You can read more about this issue and how to solve it here:
http://thecoatlessprofessor.com/programming/openmp-in-r-on-os-x/#after-3-4-0
http://thecoatlessprofessor.com/programming/openmp-in-r-on-os-x/#gui-clang4

If you still have problems, then try solutions from here (follow jounih instructions):
https://github.com/ppwwyyxx/OpenPano/issues/16
https://github.com/velocyto-team/velocyto.R/issues/2

Next install the package RQuantLib as follows:
install.packages("RQuantLib", type="source")

Next install the package factorAnalytics as follows:
install.packages("factorAnalytics", type="source", repos="http://r-forge.r-project.org")

Also install the packages RcppRoll as follows:
install.packages("RcppRoll")

Installing package rgl on a Mac/OSX may require installing XQuartz first.
Here are the links:
http://stackoverflow.com/questions/33634871/installing-rgl-package-in-r-mac-osx-el-captian-fixed
http://stackoverflow.com/questions/32747616/installing-accessing-rgl-package-in-mac-yosemite
or:
http://stackoverflow.com/questions/9878693/error-in-loading-rgl-package-with-mac-os-x

Please install the following packages:
dplyr
tidyr
latticeExtra
directlabels

install.packages(c("PortfolioAnalytics", "factorAnalytics", "PortfolioAttribution", "FinancialInstrument", "quantstrat", "blotter"), type="source", repos="http://r-forge.r-project.org")
install.packages("xtsExtra", repos='http://r-forge.r-project.org')
install.packages(c("lmtest", "lubridate", "quantmod", "TTR", "PerformanceAnalytics", "Quandl", "ROI", "ROI.plugin.quadprog", "ROI.plugin.glpk", "DEoptim", "NMOF"))
install.packages(c("dplyr", "ggvis", "shiny", "knitr", "rmarkdown", "nycflights13", "babynames", "forecast", "devtools"))

############## end deprecated ##############

Friedrich,
If I understand correctly, you want 5 or 10 second OHLCV time series bar data for stocks.
Yes, my package HighFreq has the function save_scrub_agg() for scrubbing and aggregating TAQ time series into OHLCV time series.
The package vignettes: managing_time_series.html and HighFreq.pdf explain how to perform the aggregation.  They're both on github.

The function save_scrub_agg() assumes a certain format of the TAQ data.  You can find an example of that format in the SPY_TAQ dataset.
Run these commands:
ls("package:HighFreq")
tail(HighFreq::SPY_TAQ)

Have you looked at package highfrequency by Kris Boudt?  It also has scrubbing and aggregation functions, but I decided to write my own because I wasn't totally happy with the speed and features of package highfrequency.
http://cran.r-project.org/web/packages/highfrequency/index.html
https://github.com/jonathancornelissen/highfrequency
http://highfrequency.herokuapp.com/


Have you considered the CRSP database (part of WRDS) for downloading the TAQ data?
https://wrds-web.wharton.upenn.edu/wrds/

I have downloaded some data from there, but not TAQ.  I have used TAQ data from other friendly sources.


########################

Resources:

# ECON 424/AMATH 462:  Introduction to Computational Finance and Financial Econometrics
http://faculty.washington.edu/ezivot/econ424/econ424.htm
http://faculty.washington.edu/ezivot/econ424/424syllabus.htm
http://faculty.washington.edu/ezivot/econ424/424notes.htm
http://faculty.washington.edu/ezivot/econ424/R_hints.htm

# Jeff Ryan
quantmod Workshop.pdf

# quantmod and quantstrat
C:\Research\R\Tutorials\Guy Yollin Presentations
Efficient Indexes Factor Models.pdf
quantmod.pdf

# Vinod good cointegration
C:\Research\R\Tutorials\Vinod\Econometrics\exercises3.pdf

# Tsai Skewness Kurtosis Asset Allocation.pdf

# project ReturnAnalytics (packages  PortfolioAnalytics and PerformanceAnalytics)
C:\Research\R\Packages\PerformanceAnalytics\doc

Meucci Dynamic Allocation Strategies

# Alexios Ghalanos packages rugarch parma
http://unstarched.net/

Bailey Prado Portfolio Optimization Algorithm
Didenko Random Forest Ensemble Learning Portfolio Views
Fossati time series with some R:	C:\Research\R\Tutorials\Fossati\e509

# R examples in:
C:\Research\R\Packages\Quantstrat
http://r-forge.r-project.org/projects/returnanalytics/
http://blog.fosstrading.com/2014/03/intro-to-portfolioanalytics.html

# Steiner Alpha Misleading Performance Measure

# Why do we need a Risk Model
http://systematicinvestor.wordpress.com/2012/02/26/portfolio-optimization-why-do-we-need-a-risk-model/

# R Examples for the second edition
http://www.pfaffikus.de/springerex2.html



##############
### lecture topics

###
FRE7241_Lecture_1

Date and time objects
Time series objects: ts, zoo, xts
Environments in R
interactive plots: dygraphs, shiny
R markdown documents


###
FRE7241_Lecture_2

Modeling and Fitting Asset Returns
Standard Errors of Estimators Using Bootstrap Simulation
Performing rolling aggregations over time series

Performing rolling aggregations over time series using Rcpp

Time series modeling
Autocorrelation function
Time series regressions
Fitting calibrating ARIMA models
Forecasting ARIMA models
Augmented Dickey-Fuller ADF test
Simulating Ornstein-Uhlenbeck process using Rcpp


###
FRE7241_Lecture_3

GARCH models and volatility forecasting
Fitting calibrating Ornstein-Uhlenbeck process to data
Models of stock returns: Pareto distribution, stochastic volatility, Heston model, 



###
FRE7241_Lecture_4

GARCH models and volatility forecasting
Time series of asset prices
Time evolution of stock prices
Log-normal probability distribution
Simulating Random OHLC prices
Active Investment Strategies: EWMA strategies
package Rcpp
Linear Algebra
Regression


###
FRE7241_Lecture_5

Forecasting models for price returns, stock beta, and correlation, 
bias-variance tradeoff, 
Time series rolling regressions

Backtesting Active Investment Strategies

Plotting heatmaps
Out-of-sample strategy performance in two-period model
Model overfitting
Demonstrate that model with many parameters (EWMA, ARIMA) performs better in-sample, but worse out-of-sample
Demonstrate that one can always optimize parameters to fit random prices in-sample
Strategy backtesting (cross-validation)
Strategy optimization: data snooping
Parameter regularization (shrinkage)
Lasso and Elastic Net shrinkage
Optimization of the regularization (shrinkage) parameter using backtesting (cross-validation)

Package quantmod for quantitative financial modeling

cointegration 
pairs trading
Statistical Arbitrage
trading Ornstein-Uhlenbeck process

range OHLC estimators of volatility, skewness, kurtosis, and covariance, 
Fitting calibrating EWMA models

Package tseries for time series analysis
Downloading time series data
Logarithmic utility and risk-adjusted performance measures: Sharpe, Calmar, and Sortino ratios, 
Capital Asset Pricing Model (CAPM): the market portfolio, the Security Market Line, 
Beta-adjusted performance measures: Treynor ratio, Jensen's alpha, information coefficient, 
Factor models: Principal Component Analysis (PCA), cross-sectional regressions, Fama-French model, Barra model, 
Pricing anomalies: size, value, momentum, volatility, 


###
FRE7241_Lecture_6

Portfolio optimization: mean-variance efficient portfolios, efficient frontier, Capital Market Line, 
Correlation matrix estimation: Cholesky decomposition, Factor Augmented Regression, 
Simulating correlated time series using Cholesky matrx
Constrained portfolio optimization: coefficient shrinkage, 
Intertemporal portfolio choice and out-of-sample performance of optimized portfolios, 

Tail risk measures: value-at-risk, conditional value-at-risk, 

Loading data



###
FRE7241_Lecture_7

Static asset allocation strategies: cap-weighted and equal-weighted stock indices, all weather portfolios, 
Portfolio management strategies: risk parity, minimum correlation, minimum variance, maximum Sharpe, maximum CVaR, betting against beta, factor investing, smart beta asset allocation, 
Active portfolio management strategies: tactical asset allocation, portfolio rebalancing, Constant Proportion Portfolio Insurance (CPPI), sector rotation, 
Benchmarking portfolio management skill: performance attribution, random portfolios, random investment choices, 
Dynamic investment and consumption strategies: Merton model, 


##############
### order of topics

R packages

Date and Time Objects
Time Series Objects
Package tseries
Package quantmod

Performing Aggregations Over Time Series
in: investment_strategies.pdf
EWMA strategy heatmaps

simulating geometric Brownian Motion
simulating Ornstein-Uhlenbeck OU process
Regression

plotly
R Markdown documents
shiny apps

Optimization
Principal Component Analysis PCA

time series of investments: time series of returns, chart_Series plot
Cross-validation backtesting
Out-of-sample performance and strategy optimization
Model overfitting
Parameter regularization
Test for data snooping using random data
Optimize strategy that trades on random data to demonstrate that in-sample optimization is misleading
simulate ARIMA and trade it using shiny

parallel computing
parallel backtesting

high frequency data

Fit pairs data into Ornstein-Uhlenbeck OU process
Factor models
Risk-adjusted performance measures

Optimization techniques
Bolker Optimization Methods.pdf
Yollin Optimization.pdf
Boudt DEoptim Large Portfolio Optimization.pdf

In-sample strategy optimization

Bootstrap standard errors of strategy parameters
Strategy backtesting and optimization

Estimating rolling volatility, skewness, kurtosis

Portfolio optimization

downloading fundamental data
downloading data from WRDS

scrubbing high freq data


